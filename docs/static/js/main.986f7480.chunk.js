(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{357:function(e,t,o){},359:function(e,t,o){"use strict";o.r(t);var a=o(0),i=o.n(a),n=o(17),s=o.n(n),r=o(363),h=o(42),l=o.n(h),d=(o(77),o(79),o(14)),u=o(8),c=o(9),y=o(11),g=o(10),w=o(12),m=o(3),f=o(4),p=o(43),b=o.n(p);function k(){var e=Object(m.a)(["\n  flex: 5;\n  height: 80vh;\n"]);return k=function(){return e},e}var v={1:"XfoYk_Z5AkI",2:"ccMHJeQU4Qw",3:"MpZxV6DVsmM",4:"9YK6AnqpuEA",5:"CJKnDu2dxOE",6:"hkBa9pU-H48",7:"DGdRC4h78_o"},I=f.b.div(k()),x=i.a.forwardRef(function(e,t){var o=e.lesson;return i.a.createElement(I,null,i.a.createElement(b.a,{ref:t,url:"https://www.youtube.com/embed/".concat(v[o]),controls:!0,width:"100%",height:"90vh"}))}),j=o(18),z=o.n(j);function q(){var e=Object(m.a)(["\n  vertical-align: middle;\n  font-size: 1rem;\n"]);return q=function(){return e},e}function P(){var e=Object(m.a)(["\n  padding: 5% 0;\n  z-index: 20;\n  color: white;\n  cursor: pointer;\n  font-size: 2rem;\n  width: 30px;\n  position: absolute;\n  top: 1.7rem;\n  text-align: center;\n  right: ",";\n  left: ",";\n  background-color: var(--fastai-blue);\n"]);return P=function(){return e},e}var A=f.b.span(P(),function(e){return e.right||"inherit"},function(e){return e.left||"inherit"}),S=Object(f.b)(z.a)(q()),C=function(e){var t=e.onClick,o=e.condition,a=e.iconTrue,n=e.iconFalse,s=e.styles;return i.a.createElement(A,Object.assign({},s,{onClick:t,role:"button",tabIndex:"0"}),o?i.a.createElement(S,{className:a,name:a}):i.a.createElement(S,{className:n,name:n}))},N=o(361);function D(){var e=Object(m.a)(["\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n"]);return D=function(){return e},e}function G(){var e=Object(m.a)(["\n    padding: 0.9rem 0;\n    font-weight: 700;\n    border: solid 2px white;\n  "]);return G=function(){return e},e}function L(){var e=Object(m.a)(["\n  height: 3rem;\n  width: 80%;\n  text-align: center;\n  color: white;\n  cursor: pointer;\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  border: solid 1px white;\n  ","\n"]);return L=function(){return e},e}var R={1:"Lesson 1",2:"Lesson 2",3:"Lesson 3",4:"Lesson 4",5:"Lesson 5",6:"Lesson 6",7:"Lesson 7"},E=Object(f.b)(N.a)(L(),function(e){return e.selected&&Object(f.a)(G())}),T=f.b.div(D()),M=function(e){var t=e.selectedLesson;return i.a.createElement(T,null,Object.keys(R).map(function(e){var o=R[e];return i.a.createElement(U,{selectedLesson:t,lesson:o,num:e,key:o})}))},U=function(e){var t=e.num,o=e.lesson,a=e.selectedLesson;return i.a.createElement(E,{key:"lesson-".concat(t),role:"button",tabIndex:"0",selected:parseInt(t)===a,to:"?lesson=".concat(t)},o)},F=function(e){var t=e.lesson;return i.a.createElement(a.Fragment,null,i.a.createElement("header",null,i.a.createElement("h1",{style:{fontSize:"1.125rem",textAlign:"center",fontFamily:"Helvetica",color:"white"}},i.a.createElement(z.a,{className:"fa-home",name:"fa-home"}),i.a.createElement("a",{href:"/",target:"_blank",rel:"noopener noreferrer",style:{textDecoration:"none",marginLeft:"0.5rem"}},"course"))),i.a.createElement(M,{selectedLesson:t}))},X=o(65),O=o(46),B=o.n(O),Y=o(362),J=function(e){function t(){return Object(u.a)(this,t),Object(y.a)(this,Object(g.a)(t).apply(this,arguments))}return Object(w.a)(t,e),Object(c.a)(t,[{key:"render",value:function(){var e=this.props,t=e.language,o=e.value;return i.a.createElement(Y.a,{language:t},o)}}]),t}(i.a.PureComponent);J.defaultProps={language:null};var W=o(50),H=o.n(W),K=o(51),V=o.n(K),Z=o(52),Q=o.n(Z),_=o(53),$=o.n(_),ee=o(54),te=o.n(ee),oe=o(55),ae=o.n(oe),ie=o(56),ne=o.n(ie);function se(){var e=Object(m.a)(["\n  padding: 0 2%;\n  overflow-y: scroll;\n"]);return se=function(){return e},e}function re(){var e=Object(m.a)(["\n  height: 100vh;\n  display: flex;\n  flex-direction: column;\n  position: relative;\n  border-left: solid 1px var(--fastai-blue);\n  flex: ",";\n  max-width: 35vw;\n  background-color: white;\n"]);return re=function(){return e},e}var he={1:H.a,2:V.a,3:Q.a,4:$.a,5:te.a,6:ae.a,7:ne.a},le=f.b.section(re(),function(e){return e.open?"3":0}),de=Object(f.b)(B.a)(se()),ue={},ce=function(e){function t(){var e,o;Object(u.a)(this,t);for(var a=arguments.length,i=new Array(a),n=0;n<a;n++)i[n]=arguments[n];return(o=Object(y.a)(this,(e=Object(g.a)(t)).call.apply(e,[this].concat(i)))).state={notes:"",rendered:null},o}return Object(w.a)(t,e),Object(c.a)(t,[{key:"componentDidMount",value:function(){this.fetchLesson()}},{key:"componentDidUpdate",value:function(){this.props.lesson!==this.state.rendered&&this.fetchLesson()}},{key:"fetchLesson",value:function(){var e=this,t=ue[this.props.lesson];if(t)return this.setState({notes:t,rendered:this.props.lesson});fetch(he[this.props.lesson]).then(function(e){return e.text()}).then(function(t){return ue[e.props.lesson]=t}).then(function(t){return e.setState({notes:t,rendered:e.props.lesson})}).catch(console.error)}},{key:"render",value:function(){return i.a.createElement(de,{source:this.state.notes,renderers:{code:J}})}}]),t}(i.a.Component),ye=function(e){var t=e.lesson,o=e.showNotes,a=e.toggleNotes,n=Object(X.a)(e,["lesson","showNotes","toggleNotes"]);return i.a.createElement(le,Object.assign({open:o},n),i.a.createElement(C,{styles:{left:"-30px"},condition:o,onClick:a,iconTrue:"fa-chevron-right",iconFalse:"fa-chevron-left"}),o&&i.a.createElement(ce,{lesson:t}))};function ge(){var e=Object(m.a)(["\n  flex: 8;\n  margin-right: 2%;\n  input {\n    padding-left: 5px;\n    margin-left: 5px;\n    height: 1.5rem;\n    min-width: 11vw;\n  }\n"]);return ge=function(){return e},e}var we=f.b.div(ge()),me=function(e){var t=e.search,o=e.handleChange;return i.a.createElement(we,null,i.a.createElement("input",{value:t,onChange:o,placeholder:"Search transcript"}))};me.defaultProps={search:""};var fe=me;function pe(){var e=Object(m.a)(["\n  display: flex;\n  flex-direction: row;\n  overflow-x: scroll;\n  overflow-y: hidden;\n  width: 100%;\n"]);return pe=function(){return e},e}var be={1:o(57),2:o(58),3:o(59),4:null,5:o(60),6:o(61),7:null},ke=f.b.div(pe()),ve=function(e){function t(){var e,o;Object(u.a)(this,t);for(var a=arguments.length,i=new Array(a),n=0;n<a;n++)i[n]=arguments[n];return(o=Object(y.a)(this,(e=Object(g.a)(t)).call.apply(e,[this].concat(i)))).state={search:"",currentMoment:null},o.handleChange=function(e){var t=e.target.value;o.setState({search:t.toLowerCase()})},o}return Object(w.a)(t,e),Object(c.a)(t,[{key:"render",value:function(){var e=this.props.goToMoment,t=this.state.search;return this.currentTranscript?i.a.createElement("div",{className:"TranscriptBrowser"},i.a.createElement("div",{className:"top"},i.a.createElement(fe,{search:t,handleChange:this.handleChange,transcript:this.getTranscript}),i.a.createElement(ke,null,t&&this.searchResults.map(function(t){var o=function(){return e(t.moment)};return i.a.createElement("span",{key:t.moment,onClick:o,onKeyUp:o,role:"button",tabIndex:"0",className:"search-result"},t.sentence)})))):"Transcript coming soon..."}},{key:"currentTranscript",get:function(){var e=this.props.lesson;return be[e]}},{key:"searchResults",get:function(){var e=this.currentTranscript,t=this.state.search;return e?Object.keys(e).filter(function(o){return e[o].toLowerCase().includes(t)}).map(function(t){return{moment:t,sentence:e[t]}}).slice(0,12):[]}}]),t}(a.Component);ve.getDerivedStateFromProps=function(e,t){e.lesson;return Object(d.a)({},t)};var Ie=ve,xe=o(64),je=function(e){var t=e.split(":"),o=Object(xe.a)(t,2),a=o[0],i=o[1];return 60*Number(a)+Number(i)},ze=o(62),qe=o.n(ze);o(357);function Pe(){var e=Object(m.a)(["\n  height: 100vh;\n  width: 100vw;\n  display: flex;\n  flex-direction: row;\n  font-family: 'PT Sans', Helvetica, Arial, sans-serif;\n"]);return Pe=function(){return e},e}var Ae=f.b.div(Pe()),Se=function(e){function t(e){var o;return Object(u.a)(this,t),(o=Object(y.a)(this,Object(g.a)(t).call(this,e))).state={showLessons:!0,showNotes:!0,selectedLesson:1},o.goToMoment=function(e){var t=je(e);o.videoPlayer.current.seekTo(t),o.videoPlayer.current.getInternalPlayer().playVideo()},o.toggleLessons=function(){var e=o.state.showLessons;o.setState({showLessons:!e})},o.toggleNotes=function(){var e=o.state.showNotes;o.setState({showNotes:!e})},o.videoPlayer=i.a.createRef(),o}return Object(w.a)(t,e),Object(c.a)(t,[{key:"render",value:function(){var e=this.toggleLessons,t=this.toggleNotes,o=this.state,a=o.showLessons,n=o.showNotes,s=o.selectedLesson;return i.a.createElement(Ae,null,i.a.createElement("section",{className:"left ".concat(a?"":"closed")},i.a.createElement(C,{styles:{right:"-30px"},condition:a,onClick:e,iconTrue:"fa-chevron-left",iconFalse:"fa-chevron-right"}),a&&i.a.createElement(F,{lesson:s})),i.a.createElement("section",{className:"center"},i.a.createElement("div",{className:"row"},i.a.createElement(x,{lesson:s,ref:this.videoPlayer})),i.a.createElement(Ie,{lesson:s,goToMoment:this.goToMoment})),i.a.createElement(ye,{lesson:s,toggleNotes:t,showNotes:n}))}}],[{key:"getDerivedStateFromProps",value:function(e,t){var o=qe.a.parse(window.location.search);return Object(d.a)({},t,{selectedLesson:parseInt(o.lesson)||1})}}]),t}(a.Component),Ce=l()();s.a.render(i.a.createElement(r.a,{history:Ce},i.a.createElement(Se,null)),document.getElementById("root"))},50:function(e,t,o){e.exports=o.p+"static/media/notes.d4ae8cea.md"},51:function(e,t,o){e.exports=o.p+"static/media/notes.fcc83baf.md"},52:function(e,t,o){e.exports=o.p+"static/media/notes.b42449d6.md"},53:function(e,t,o){e.exports=o.p+"static/media/notes.b393f31c.md"},54:function(e,t,o){e.exports=o.p+"static/media/notes.4e6fd2da.md"},55:function(e,t,o){e.exports=o.p+"static/media/notes.7375363e.md"},56:function(e,t,o){e.exports=o.p+"static/media/notes.406f9c7a.md"},57:function(e){e.exports={"00:00":"okay so welcome practical deep learning","00:07":"for coders less than one it's kind of","00:10":"lesson two because there's a lesson zero","00:13":"in less than zero is is why do you need","00:15":"a GPU and how do you get it set up so if","00:17":"you haven't got the GPU running yet then","00:21":"go back and do that make sure that you","00:24":"can access a jupiter notebook and and","00:28":"then you're ready to start the real","00:30":"lesson one so if you're ready you will","00:33":"be able to see something like this and","00:37":"in particular hopefully you have gone to","00:40":"notebook tutorial it's at the top that's","00:42":"right with zero zero here as this grows","00:44":"you'll see more and more files but will","00:46":"keep a notebook tutorial at the top and","00:48":"you will have used your jupiter notebook","00:52":"to add one and one together getting the","00:55":"expected result bigger and hopefully","01:04":"you've learned these four keyboard","01:05":"shortcuts so the basic idea is that your","01:11":"jupiter notebook has pros in it it can","01:16":"have pictures you know it can have","01:20":"charts in it and most importantly it can","01:24":"have code in it okay so the code is in","01:29":"python how many people have used Python","01:32":"before so nearly all of you that's great","01:36":"um if you haven't used Python that's","01:39":"totally okay okay it's a pretty easy","01:42":"language to pick up but if you haven't","01:44":"used Python this will feel a little bit","01:47":"more intimidating because the code that","01:49":"you're seeing will be unfamiliar to you","01:51":"yes Rachel oh yeah no because I'm trying","02:00":"to keep them up separate yeah yeah okay","02:02":"we're not the way here so as I say there","02:06":"are things like this where people in the","02:09":"room in person","02:10":"and this is one of those bits just like","02:12":"this is really for the book audience not","02:14":"for you that's I think this will be the","02:17":"only time like this in the in the lesson","02:19":"where we've assumed you've got this set","02:21":"up thanks to a mother okay","02:25":"all right so yeah this is you're in the","02:28":"room or on foreign faster you're alive","02:30":"you can go back after this and make sure","02:32":"that you can get this running using the","02:34":"information in course III go faster do","02:40":"okay okay okay so a Jupiter notebook is","02:49":"a really interesting device for our data","02:55":"scientists because it kind of lets you","02:57":"run interactive experiments and it lets","03:01":"us give you not just a static piece of","03:05":"information but it let it lets ask you","03:07":"something that you can actually","03:10":"interactively experiment with so let me","03:15":"explain how we think works well to use","03:19":"these notebooks and to use this material","03:21":"and this is based on the kind of last","03:23":"three years of experience we've had with","03:24":"the students who have gone through this","03:26":"course first of all it works pretty well","03:31":"just to watch a lesson end to end okay","03:35":"don't try and follow along because it's","03:38":"not really designed to go to speed where","03:40":"you can follow along it's designed to be","03:41":"something where you just take in the","03:43":"information you get a general sense of","03:45":"all of the pieces how it all fits","03:46":"together right and then you can do it","03:49":"back and go through it more slowly","03:52":"pausing on in the video and trying","03:56":"things out making sure that you can do","03:58":"the things that I'm doing and that you","04:02":"can try and extend them to do it things","04:04":"in your own way okay so don't worry if","04:07":"things are zipping along faster then you","04:11":"can do them that's normal and also don't","04:13":"try and stop and understand everything","04:15":"the first time if you do understand","04:18":"everything the first time good for you","04:21":"but most people don't particularly as","04:23":"the lessons go on they get faster and","04:25":"they get more difficult okay so at this","04:31":"point we've got our notebooks going","04:33":"we're ready to start doing deep learning","04:35":"and so the main thing that hopefully","04:38":"you're going to agree at the end of this","04:39":"is that you can do deep learning","04:42":"regardless of who you are now I don't","04:45":"just mean do we mean do at a very high","04:47":"level","04:48":"I mean world-class practitioner level","04:50":"deep learning okay so your main place to","04:56":"be looking for things is course b3 to","04:58":"fast","04:59":"AI where you can find out how to get a","05:03":"GPU other information and you can also","05:07":"access our forums you can also access","05:12":"our forums and on our forums you'll find","05:14":"things like how do you build a deep","05:21":"learning box yourself and that's","05:22":"something that you can do after you","05:23":"don't later on once you've kind of got","05:25":"going Who am I so why should you listen","05:31":"to me well maybe you shouldn't but I'll","05:34":"try and justify why you should listen to","05:36":"me I've been doing stuff with machine","05:40":"learning for over 25 years I started out","05:43":"in management consulting where actually","05:45":"initially I was I think Mackenzie and","05:47":"company's first analytical specialist","05:49":"and went into a general consulting ran","05:52":"number of startups for a long time","05:53":"eventually became the president of","05:56":"cattle but actually the thing I'm","05:58":"probably most proud of in my life is","06:00":"that I got to be the number one ranked","06:02":"contestant in travel competitions","06:04":"globally so I think that's a good fact","06:10":"to call why can you actually train a","06:11":"predictive model that predicts things","06:12":"pretty important aspect of data science","06:16":"I didn't found a company called analytic","06:18":"which was the first kind of medical deep","06:21":"learning company nowadays I'm on the","06:25":"faculty at University of San Francisco","06:26":"and also co-founder with Rachel of fast","06:30":"AI so I","06:32":"used machine learning throughout that","06:36":"time and I guess I'm not really although","06:38":"I am at usf for the University","06:40":"I'm not really an academic type I'm much","06:42":"more interested in in using this tool to","06:45":"do useful things specifically through","06:49":"fast AI we are trying to help people use","06:52":"deep learning to do useful things","06:54":"through creating software to make deep","06:58":"learning easier to use at a very high","07:00":"level through education such as the","07:02":"thing you are watching now through","07:04":"research which is where we spend a very","07:06":"large amount of our time which is","07:07":"researching to figure out how can you","07:10":"make deep learning easier to use at a","07:12":"very high level which ends up in as","07:14":"you'll see in the software and the","07:15":"education and by helping to build a","07:17":"community which has made me through the","07:19":"forums so that practitioners can find","07:22":"each other and work together so that's","07:24":"what we're doing so this lesson","07:27":"practical deep learning for coders is","07:29":"kind of the starting point in this","07:30":"journey it contains seven lessons each","07:33":"one's about two hours long we're then","07:36":"expecting you to do about eight to ten","07:37":"hours of homework during the week so","07:40":"it'll end up being something around 70","07:42":"or 80 hours of work I will say there is","07:46":"a lot as to how much people put into","07:47":"this I know a lot of people who work","07:50":"full time on fast AI some folks whose do","07:54":"the two parts can spend a whole year","07:56":"doing it really intensively I know some","07:59":"folks watch the videos on double-speed","08:01":"and never do any homework and come at","08:03":"the end of it with you know a general","08:04":"sense of what's going on so there's lots","08:06":"of different ways you can do this but if","08:08":"you follow along with this kind of ten","08:10":"hours a week or so approach for the","08:12":"seven weeks by the end you will be able","08:15":"to build an image classification model","08:17":"on pictures that you choose that will","08:20":"work at a world class level you'll be","08:22":"able to classify text again using","08:26":"whatever datasets you're interested in","08:28":"you'll be able to make predictions of","08:30":"kind of commercial applications like","08:32":"sales you'll be able to build","08:34":"recommendation systems such as the one","08:37":"used by Netflix not Tory examples of any","08:40":"of these but actually things that can","08:42":"come top ten and capital competitions","08:45":"be everything that's in the academic","08:47":"community very very high-level versions","08:49":"of these things so that might surprise","08:51":"you that's slightly over the the","08:53":"prerequisite here is literally one year","08:57":"of coding and high school math but we","09:00":"have thousands of students now who have","09:02":"done this and shown it to be true you","09:06":"will probably hear a lot of naysayers","09:08":"less now than a couple of years ago than","09:11":"we started but a lot of naysayers","09:12":"telling you that you can't do it or that","09:15":"you shouldn't be doing it or the deep","09:17":"learnings got all these problems it's","09:19":"not perfect but these are all things","09:21":"that people claim about deep learning","09:24":"which are either pointless or untrue","09:27":"it's not a black box as you'll see it's","09:30":"really great for interpretive","09:32":"interpreting what's going on it does not","09:35":"need much data for most practical","09:37":"applications you certainly don't need a","09:39":"PhD rate from house one so it doesn't","09:42":"actually stop you from doing deep","09:43":"learning if you have a PhD I certainly","09:45":"don't I have a philosophy degree and","09:47":"nothing else it can be used very widely","09:50":"for lots of different applications not","09:52":"just for vision which is where it's most","09:54":"well-known you don't need lots of","09:57":"hardware you know that thirty-six cent","09:59":"and our server is more than enough to","10:01":"get world-class results for most","10:03":"problems it's true that maybe this is","10:07":"not going to help you to build a","10:08":"sentient brain but that's not our focus","10:11":"okay so for all the people who say deep","10:14":"learning is not interesting because it's","10:15":"not really AI not really a conversation","10:18":"that I'm interested in we're focused on","10:20":"solving interesting real-world problems","10:24":"what are you going to be able to do by","10:26":"the end of lesson one well this was an","10:28":"example from Nikhil who's actually in","10:29":"the audience now cuz he was in last","10:31":"year's course as well this is an example","10:35":"of something he did which is he","10:36":"downloaded 30 images of people playing","10:39":"cricket and people playing baseball and","10:41":"around the coach will see you today and","10:43":"build a nearly perfect classifier of","10:46":"riches which so this kind of its kind of","10:49":"stuff that you can build with some fun","10:51":"hobby examples like this or you can try","10:53":"stuff as we'll see in the workplace that","10:56":"could be of direct commercial value so","10:59":"we're going to get to by the end of","11:00":"lesson one we're going to start by","11:05":"looking at code which is very different","11:08":"to many of the academic courses so for","11:12":"those of you who haven't kind of an","11:13":"engineering or math or computer science","11:15":"background this is very different to the","11:16":"approach where you start with lots and","11:18":"lots of theory and then eventually you","11:21":"get to a postgraduate degree and you're","11:22":"finally at the point where you can build","11:23":"something useful we're gonna learn to","11:25":"build the useful thing today okay now","11:28":"that means that at the end of the day","11:29":"you want level of a theory okay there","11:32":"will be lots of aspects of what we do","11:34":"that you don't know why or how it works","11:36":"that's okay","11:38":"you will learn why and how it works over","11:41":"the next seven weeks but for now we've","11:45":"found that what works really well is to","11:47":"actually get your hands dirty","11:48":"coding not focusing on theory because","11:53":"there's still a lot of Addison ship in","11:56":"deep learning unfortunately it's still a","11:59":"situation where people who are good","12:01":"practitioners have a really good feel","12:04":"for how to work with code and how to","12:07":"work with the data and you can only get","12:08":"that through experience and so the best","12:11":"way to get that that that feel of how to","12:13":"get good models is to create lots of","12:16":"models through lots of coding and study","12:19":"them carefully and it's Jupiter notebook","12:21":"provides a really great way to study","12:23":"them so let's try that let's try getting","12:28":"that's so to get started you will open","12:30":"your Jupiter notebook and you'll click","12:35":"on lesson 1 lesson 1 yes and it will pop","12:39":"open looking something like this and so","12:41":"here it is so you can run a sail and a","12:47":"Jupiter notebook by clicking on it and","12:48":"pressing run but if you do so everybody","12:52":"will know that you're not a real deep","12:54":"learning practitioner because real deep","12:55":"learning practitioners know the keyboard","12:56":"shortcuts and the keyboard shortcut is","12:59":"shift enter given how often you have to","13:01":"run a cell don't be going all the way up","13:05":"here finding your clicking at just shift","13:07":"ok so type like type shift enter don't","13:09":"actually","13:10":"up and down to move around to pick","13:12":"something to run shift-enter to run okay","13:15":"so we're going to go through this","13:17":"quickly and then later on we're going to","13:20":"go back over it more carefully so here's","13:23":"the quick version to get a sense of","13:24":"what's going on","13:25":"so here we are in lesson 1 and these","13:29":"three lines is what we start every","13:31":"notebook with these things starting with","13:34":"percent are special directives to","13:36":"Jupiter notebook itself they're not","13:38":"Python code they're called magics which","13:41":"is kind of a cool name and these three","13:43":"directives the details aren't very","13:44":"important but basically it says hey if","13:46":"somebody changes the underlying library","13:48":"code while I'm running this place","13:50":"reloaded automatically if somebody asks","13:53":"to plot something then please plot it","13:55":"here in this Jupiter mo book so just put","13:57":"those three lines at the top of","13:59":"everything the next two lines load up","14:02":"the fast AI library","14:06":"what is the faster a library so it's a","14:08":"little bit confusing fast AI with no dot","14:10":"is the name of our software and then","14:13":"first dot AI with the dot is the name of","14:15":"our organization so if you go to dark","14:18":"start fast","14:19":"AI this is the fast a I might be okay","14:23":"well learn more about it in a moment but","14:25":"for now just realize everything we are","14:27":"going to do is going to be using","14:29":"basically either first AI or the thing","14:33":"that fast AI sits on top of which is","14:35":"platform height which is one of the most","14:39":"popular libraries for deep learning in","14:42":"the world it's a bit newer than","14:45":"tensorflow so in a lot of ways it's more","14:47":"modern than tensorflow it's extremely","14:54":"fast growing extremely popular and we","14:55":"use it because we used to use tensorflow","14:58":"a couple of years ago and we found we","15:00":"can just do a lot more a lot more","15:02":"quickly with paid watch and then we have","15:07":"this software that sits on top of plate","15:08":"watch unless you do far far far more","15:11":"things that are far more easily than can","15:13":"with plate or alone so it's a good","15:14":"combination we'll be talking about about","15:16":"it but for now just know that you can","15:19":"use past AI by doing two things","15:21":"importing","15:23":"star from past AI and then importing","15:25":"staff and fast AI dot something where","15:29":"something is the application you want","15:31":"concurrently fast AI supports for","15:33":"applications computer vision natural","15:35":"language text tabular data and","15:38":"collaborative filtering and we're and","15:41":"we're going to see lots of examples of","15:42":"all of those during the seven weeks so","15:43":"we're going to be doing some computer","15:44":"vision at this point if you are a Python","15:48":"software engineer you are probably","15:50":"feeling sick because you see me go","15:54":"import star which is something that","15:56":"you've all been told to never ever do","15:58":"okay and there's very good reasons to","16:00":"not use import star in standard","16:03":"production code with most libraries but","16:06":"you might have also seen for those of","16:08":"you that have used something like MATLAB","16:09":"it's kind of the opposite everything's","16:11":"there for you all the time you don't","16:13":"even have to import things a lot of the","16:14":"time it's kind of funny we've got these","16:17":"two extremes of like how to write code","16:19":"you've got a scientific programming","16:21":"community that has one way and then","16:24":"you've got the software engineering","16:25":"community that has the other both have","16:27":"really good reasons for doing things and","16:29":"with the faster a library we actually","16:31":"support both approaches you know you put","16:34":"a note block where you want to be able","16:36":"to quickly interactively try stuff out","16:38":"you don't want to be constantly going","16:39":"back up to the top and importing more","16:41":"stuff and trying to figure out where","16:42":"things are you want to be able to use","16:44":"lots of tab complete be you know very","16:46":"experimental so import start is great","16:49":"then when you're building stuff in","16:51":"production you can do the normal Pepe","16:54":"style you know proper software","16:57":"engineering practices so so don't worry","17:00":"when you see me doing stuff which at","17:03":"your workplace is found upon okay it's","17:05":"it's this is a different style of coding","17:08":"it's not that there are no rules in data","17:10":"science programming it's that the rules","17:12":"are different right when you're training","17:14":"models the most important thing is to be","17:16":"able to interactively experiment quickly","17:19":"and so you'll see we use a lot of very","17:22":"different processes styles and stuff to","17:26":"what you're used to but they're there","17:27":"for a reason and you'll learn about them","17:29":"over time you can choose to abuse a","17:31":"similar approach or not it's entirely up","17:33":"to you","17:34":"the other thing to mention","17:35":"is that the faster a library's it","17:39":"designed in a very interesting modular","17:41":"way and you'll find over time that when","17:43":"you do use import star there's far less","17:46":"clobbering of things and you might","17:47":"expect it's all explicitly designed to","17:49":"allow you to pull in things and use them","17:52":"quickly without having problems okay so","17:57":"we're going to look at some data and","17:59":"there's two main places that were","18:01":"pretending to get data from for the","18:03":"course one is from academic datasets","18:07":"academic datasets are really important","18:10":"they're really interesting they're","18:11":"things where academics spend a lot of","18:13":"time curating and gathering a data set","18:15":"so that they can show how well different","18:17":"kinds of approaches work with that data","18:19":"though the end here is they try to","18:20":"design data sets that are challenging in","18:23":"some way and require some kind of","18:25":"breakthrough to do them well so we're","18:28":"data set called the pet data set the","18:31":"other kind of data set we'll be using","18:33":"during the course is data sets from the","18:35":"categorical competitions platform both","18:37":"academic data sets and cadwal data sets","18:40":"are interesting for us particularly","18:42":"because they provide strong baselines","18:44":"that is to say you want to know if","18:47":"you're doing a good job so with capital","18:49":"data sets that have come from a","18:51":"competition you can actually submit your","18:53":"results to Carol and see how well would","18:55":"you have gone in that competition and if","18:57":"you can get in about the top 10% that","18:59":"I'd say you're doing pretty well for","19:03":"academic data sets academics write down","19:06":"in papers what the state of the art is","19:08":"so how well did they go with using","19:10":"models on that data set so this is this","19:12":"is what we're going to do we're going to","19:13":"try and create models that get right up","19:17":"towards the top of capital competitions","19:19":"preferably actually in the top ten what","19:21":"does the top 10% or that meet or exceed","19:25":"academic state-of-the-art published","19:27":"results so the when you use an academic","19:33":"data set it's important to cite it so","19:36":"you'll see here there's a link to the","19:37":"paper that it's from you definitely","19:39":"don't need to read that paper right now","19:40":"but if you're interested in learning","19:42":"more about it and why it was created and","19:44":"how it was created all the details there","19:48":"so in this case this is a pretty","19:50":"difficult challenge the PEC datasets","19:52":"going to ask us to distinguish between","19:54":"37 different categories of dog breed and","19:57":"cat breed so that's really hard in fact","20:01":"every course until this one we've used a","20:04":"different data set which is one where","20:06":"you just have to decide is something a","20:07":"dog or is it a cat so you've got a 50-50","20:11":"chance right away","20:12":"right and dogs and cats look really","20:13":"different there are lots of dog breeds","20:15":"and cat breeds look pretty much the same","20:17":"so why have we changed that dataset","20:19":"we've got to the point now where deep","20:22":"wedding is so fast and so easy that the","20:24":"dogs versus cats problem which a few","20:26":"years ago was considered extremely","20:28":"difficult 80% accuracy was","20:31":"state-of-the-art it's now too easy","20:33":"our models were basically getting","20:35":"everything right all the time without","20:38":"any tuning and so they want you know","20:40":"really a lot of opportunities for me to","20:42":"show you how to do more sophisticated","20:43":"stuff so we've picked a harder problem","20:45":"this year so this is the first class","20:48":"where we're going to be learning how to","20:49":"do this difficult problem and this kind","20:51":"of thing where you have to distinguish","20:53":"between similar categories it's called","20:56":"in the academic context is called","20:58":"fine-grained classification so we're","21:00":"classification task with figuring out","21:03":"particular kind of pet and so the first","21:06":"thing we have to do is download and","21:07":"extract the data that we want we're","21:11":"going to be using this function called","21:12":"ant our data which will download it","21:15":"automatically and we'll enter it","21:17":"automatically AWS has been kind enough","21:20":"to give us lots of space and bandwidth","21:23":"for these datasets so they are download","21:24":"super quickly for you and so the first","21:27":"question then would be how do I know","21:30":"what entire data does so you could just","21:34":"type help and you will find out what my","21:37":"talk did it come from because since we","21:39":"imported staff we don't necessarily know","21:41":"that what does it do and something you","21:44":"might not have seen before","21:45":"even if you're an experienced programmer","21:47":"is what exactly do you pass to it you're","21:51":"probably used to seeing the names URL","21:53":"file name destination but you might not","21:57":"be used to seeing these bits these bits","22:00":"are tight","22:01":"and if you've used a tight programming","22:03":"language you'll be used to seeing them","22:04":"but frankly programmers are less used to","22:06":"it but if you think about it you don't","22:09":"actually know how to use a function","22:11":"unless you know what type each thing is","22:14":"that you're providing it so we make sure","22:16":"that we give you that type information","22:18":"directly here in the help so in this","22:20":"case the URL is a string and the file","22:23":"is either Union means either over a path","22:27":"or a string and it defaults to nothing","22:31":"and the destination is either a path or","22:34":"a string of defaults to nothing so we'll","22:36":"learn more short me about how to get","22:38":"more documentation about the details of","22:40":"this but for now we can see we don't","22:42":"have to pass in a file name or a","22:44":"destination it'll figure that out for us","22:46":"from the URL so and for all the data","22:49":"sets we'll be using in the course we","22:51":"already have constants defined for all","22:53":"of them right so in this URLs module or","22:57":"class actually you can see that's where","23:00":"it's going to grab it from okay so it's","23:02":"going to download that to some","23:05":"convenient path and untie it for us and","23:07":"we'll then return the value of path okay","23:12":"and then in Jupiter map book it's kind","23:15":"of handy you can just write a variable","23:18":"on its own and semicolon is just it in","23:21":"the statement marker in Python so that's","23:23":"the same as doing this you can write it","23:25":"on phone and it fits it you can also say","23:27":"print write but again we're trying to do","23:29":"everything fast and interactively","23:31":"there's write it and here is the path","23:34":"where it's given us that data next time","23:38":"you run this since you've already","23:40":"downloaded it it won't download it again","23:42":"since you've already untied it it won't","23:44":"untie or it again so everything's kind","23:45":"of designed to be pretty automatic","23:47":"pretty easy there are some things in","23:52":"Python that are less convenient for","23:55":"interactive use and they should be for","23:56":"example when you do have a path object","23:58":"seeing what's in it actually is takes a","24:01":"lot more typing that I would like so","24:03":"sometimes we add functionality into","24:05":"existing Python stuff one of the things","24:07":"we do is we add an LS method to paths so","24:10":"if you go to path type LS here is what's","24:13":"inside","24:14":"this path so that's what we just","24:16":"downloaded so when you try this yourself","24:18":"you wait a couple of minutes for it to","24:20":"download unzip and then you can see","24:23":"what's in there if you're an experienced","24:27":"Python programmer you may not be","24:29":"familiar with this approach of using a","24:31":"splash like this now this is a really","24:33":"convenient function that's part of","24:35":"Python three its functionality from","24:37":"something called path Lib these are path","24:39":"objects path objects are much better to","24:41":"use then strings that lets you basically","24:43":"create sub paths like this it doesn't","24:46":"matter if you're on Windows Linux Mac","24:48":"it's always going to work exactly the","24:50":"same way so here's a path to the images","24:54":"in that data set alright so if you're","24:59":"starting with a brand new data set","25:01":"trying to do some deep learning on it","25:02":"what do you do well the first thing you","25:05":"would want to do is probably see what's","25:07":"in there so we've found that these are","25:09":"the directories that in there so what's","25:13":"in this images there's a lot of","25:16":"functions in fast i/o for you there's","25:18":"one called get image files that will","25:20":"just grab a array of all of the image","25:23":"files based on extension in a path and","25:26":"so here you can see we've got lots of","25:30":"different files okay so this is a pretty","25:33":"common way to for image computer vision","25:36":"datasets to get passed around as that is","25:38":"just one folder with a whole bunch of","25:39":"files in it so the interesting bit then","25:43":"is how do we get the labels so in","25:47":"machine learning the labels refer to the","25:50":"thing we're trying to predict and if we","25:52":"just eyeball this we could immediately","25:54":"see that the labels are actually part of","25:58":"the file name you see that right it's","26:00":"kind of like path slash label underscore","26:04":"number extension so we need to somehow","26:08":"get a list of these bits of each file","26:12":"name and that will give us our labels","26:13":"because that's all you need to build a","26:16":"deep learning model you need see","26:17":"pictures so files containing the images","26:19":"and you need some labels so in fast AI","26:23":"this is made really easy there's a","26:27":"object called image data Bunch and an","26:30":"image data bunch represents all of the","26:32":"data you need to build a model and","26:33":"there's basically some factory methods","26:36":"which try to make it really easy for you","26:39":"to create that data bunch we talked more","26:42":"about this role even a training set and","26:43":"the validation set with images and","26:45":"labels for you now in this case we can","26:49":"see we need to extract the labels from","26:52":"the names okay so we're going to use","26:54":"from name re so for those of you that","26:57":"use Python you know re is the module in","27:00":"Python that does regular expressions","27:01":"things that's really useful for","27:03":"extracting text I just went ahead and","27:06":"created the regular expression that","27:08":"would extract the label from this text","27:12":"okay so those of you who are not","27:16":"familiar with regular expressions super","27:18":"useful to be very useful to spend some","27:20":"time figuring out how and why that","27:23":"particular regular expression is going","27:25":"to extract the label from this text okay","27:29":"so with this factory method we can","27:31":"basically say okay I've got this path","27:32":"containing images this is a list of file","27:36":"names remember I got them back here this","27:38":"is the regular expression pattern that","27:40":"is going to be used to extract the label","27:43":"from the filename will talk about","27:46":"transforms later and then you obviously","27:49":"to say what size images do you want to","27:51":"work with so that might seem weird why","27:54":"do I need to say what size images I want","27:56":"to work with because the images have a","27:58":"size we can see what size the images are","28:01":"and I guess honestly this is a","28:03":"shortcoming of current deep learning","28:06":"technology which is that a GPU has to","28:10":"apply the exact same instruction through","28:13":"a whole bunch of things at the same time","28:14":"in order to be fast and so if the images","28:18":"are different shapes and sizes you can't","28:20":"do that right so we actually have to","28:23":"make all of the images the same shape","28:26":"and size in part one of the course we're","28:30":"always going to be making images square","28:33":"shapes in part two we'll learn how to","28:35":"use rectangles as well it turns out to","28:37":"be surprisingly nuanced but pretty much","28:40":"everybody in pretty much all computer","28:42":"vision modeling nearly all of it uses","28:44":"this approach of square and 224 by 224","28:49":"for reasons we learn about is an","28:51":"extremely common size that most models","28:54":"tend to use so if you just use size","28:56":"equals to 24 you're probably going to","28:58":"get pretty good results most of the time","29:00":"and this is kind of the little bits of","29:03":"artists in the ship that I want to teach","29:05":"you folks which is like what generally","29:08":"just works okay so if you just use size","29:10":"equal to 24 that'll generally just work","29:12":"for most things most of the time so this","29:17":"is kind of return a data bunch object","29:20":"and in fast AI everything you model with","29:22":"is going to be a data bunch object we're","29:24":"going to learn all about them and what's","29:25":"in them and how do we look at them and","29:27":"so forth they're basically a data bunch","29:28":"object contains two or three data sets","29:33":"it contains your training data we'll","29:36":"learn about this shortly it'll contain","29:37":"your validation data and optionally it","29:40":"contains your test data and for each of","29:42":"those it contains your your images and","29:46":"your labels or your texts and your","29:48":"labels or your tabular data and your","29:50":"labels or so forth and that all sits","29:52":"there in this one place something we'll","29:56":"learn more about a little bit is","29:58":"normalization but generally in all","30:00":"nearly all machine learning tasks you","30:03":"have to make all of your data about the","30:05":"same size they're specifically about the","30:07":"same mean and about the same standard","30:09":"deviation so there's a normalized","30:12":"function that we can use to normalize","30:14":"our data bunch in that way okay rich or","30:20":"come and ask the question thanks what is","30:26":"the function do an image size is not 224","30:30":"great so this is propaganda known about","30:33":"shortly basically this thing called","30:36":"transforms is is used to do a number of","30:38":"things and one of the things it does is","30:40":"to make something size 224","30:42":"let's take a look at a few pictures here","30:44":"are a few pictures of things from my","30:47":"digger from my data bunch so you can see","30:49":"data dot show batch can be used to show","30:52":"me the contents of","30:54":"some of the contents of my data bunch so","30:57":"this is going to be three by three and","30:59":"you can see roughly what's happened is","31:02":"that they all seem to have been kind of","31:04":"zoomed and cropped in a reasonably nice","31:06":"way so basically what it'll do is","31:08":"something called by default center","31:11":"cropping which means it'll kind of grab","31:13":"the middle bit and it also resize it so","31:17":"we'll talk more about the detail this","31:19":"because it turns out to actually be","31:20":"quite important but basically a","31:22":"combination of cropping and resizing is","31:25":"used something else we'll learn about is","31:28":"we also use this to do something called","31:30":"data augmentation so there's actually","31:31":"some randomization in how much and where","31:34":"it crops and stuff like that okay but","31:36":"that's the basic idea is some cropping","31:38":"and some resizing that often we also","31:41":"also do some some padding so there's","31:44":"also all kinds of different ways and it","31:46":"depends on data augmentation which we're","31:48":"going to learn about shortly and what","31:52":"does it mean to normalize the images so","31:56":"normalizing the images we're going to be","31:58":"learning more about later in the course","32:00":"but in short it means that the the pixel","32:03":"values we're going to be learning more","32:04":"about pixel values the pixel values","32:06":"start out from naught to 255 and some","32:09":"pixel values might tend to be really I","32:15":"should say some channels because there's","32:17":"red green and blue so some channels","32:19":"might tend to be really bright and some","32:22":"might tend to be really not bright at","32:23":"all and some might be area large and","32:25":"some might not very much at all it","32:27":"really helps train a deep learning model","32:29":"if each one of those red green and blue","32:31":"channels has a mean of 0 and a standard","32:34":"deviation of 1 ok we'll learn more about","32:36":"that if you haven't studied or don't","32:39":"remember means and standard deviations","32:40":"we'll get back to some of that later but","32:43":"that's the basic idea","32:44":"that's what normalization does if your","32:46":"data and again we'll learn much more","32:48":"about details but if your data is not","32:51":"normalized it can be quite difficult for","32:53":"your model to train well so if you do","32:56":"have trouble training a model one thing","32:57":"to check is that you've normalized it as","33:00":"GPU man will be in power up to doesn't","33:03":"size 256","33:05":"some more practical considering to be a","33:07":"little utilization so we're going to be","33:11":"getting into that shortly but the brief","33:13":"answer is that the models are designed","33:16":"so that the final layer is of size seven","33:19":"by seven so we actually want something","33:21":"where if you go seven times to a bunch","33:23":"of times then you end up with something","33:25":"that's a good size yeah all of these","33:28":"details we are going to we are going to","33:30":"get to but the key thing is I wanted to","33:32":"get you training a model as quickly as","33:33":"possible but you know one of the most","33:36":"important things to be a really good","33:38":"practitioner is to be able to look at","33:40":"your data okay so it's really important","33:42":"to remember to go do batch and take a","33:45":"look it's surprising how often when you","33:47":"actually look at the data set you've","33:48":"been given that you realize it's got","33:49":"weird black borders on earth or some of","33:52":"the things have text covering up some of","33:53":"it or some of its rotated in odd ways so","33:56":"make sure you take a look okay and then","34:01":"the other thing we want to do is not","34:02":"just look at the pictures but also look","34:04":"at the labels and so all of the possible","34:08":"label names accord your classes that's","34:12":"where the data bunch you can print out","34:13":"your data type classes and so here they","34:16":"are that's almost the possible labels","34:18":"that we found by using that regular","34:21":"expression on the file names and we","34:23":"learnt earlier on in that prose I wrote","34:25":"at the top that there are 37 possible","34:28":"categories and so just checking length","34:30":"data classes it is indeed 37 a data","34:34":"bunch will always have a property called","34:35":"C and that property called C the","34:39":"technical details will kind of get to it","34:41":"later but for now you can kind of think","34:43":"of it as being a number of classes for","34:46":"things like regression problems and","34:48":"multi-label classification and stuff","34:50":"that's not exactly accurate but it will","34:52":"do for them it's it's important to know","34:55":"that data dot C is a really important","34:59":"piece of information that is something","35:00":"like or at least for classification","35:02":"problems it is the number of classes","35:06":"okay believe it or not we're now ready","35:10":"to train a model and so a model is","35:14":"trained in fast AI using something","35:18":"called a learner and just like a data","35:21":"bunch is a general fast AI concept for","35:24":"your data and from there there are","35:27":"subclasses for particular applications","35:29":"like image data bunch Alanna is a","35:33":"general concept for things that can","35:35":"learn to fit the model and from that","35:38":"there are various subclasses to make","35:40":"things easier and a particular there's","35:41":"one called con flora which is something","35:43":"that will create a convolutional neural","35:45":"network for you and we'll be learning a","35:48":"lot about that over the next few lessons","35:51":"but for now just know that to create a","35:53":"learner for a convolutional neural","35:56":"network you just have to tell it two","35:58":"things the first is what's your data and","36:01":"not surprisingly it takes a data bunch","36:04":"and the second thing you need to tell it","36:06":"is what's your model or what's your","36:09":"architecture so as I learned there are","36:12":"lots of different ways of constructing a","36:14":"convolutional neural network but for now","36:17":"the most important thing for you to know","36:19":"is that there's a particular kind of","36:21":"model called a res net which works","36:24":"extremely well nearly all the time and","36:28":"so for a while at least you really only","36:31":"need to be doing choosing between two","36:33":"things which is what size ResNet do you","36:36":"want don't is basically how big is it","36:38":"and we'll learn them all about the","36:40":"details of what that means but there's","36:42":"that one quarter risen at 34 and there's","36:44":"one quarter of ResNet 50 and so when","36:46":"we're getting started with something up","36:47":"because small one because it'll train","36:49":"faster so that's kind of it that's as","36:53":"much as you need to know to be a pretty","36:55":"good practitioner about architectures","36:56":"for now which is that there's two","36:58":"architectures or two variants of one","37:01":"architecture that work pretty well","37:02":"present at 30 450 start with a smaller","37:05":"one and see if it's good enough so that","37:07":"is all the information we need to create","37:09":"a convolutional neural network learner","37:12":"there's one other thing I'm going to","37:14":"give it though which is a list of","37:16":"metrics metrics are literally just","37:18":"things that get printed out as it's","37:19":"training so I've saying I would like you","37:22":"to print out the error rate please now","37:25":"you can see the first time I ran this on","37:27":"a newly installed box it downloaded","37:31":"what's it downloading it's downloading","37:35":"the rest net 30 for pre-trained weights","37:39":"now what this means is that this","37:41":"particular model has actually already","37:44":"been trained for a particular task and","37:47":"that particular task is that it was","37:49":"trained on looking at about one and a","37:50":"half million pictures of all kinds of","37:53":"different things a thousand different","37:54":"categories of things using an image data","37:57":"set called image net and so we can","38:00":"download those pre trained weights so","38:02":"that we start start with a model that","38:04":"knows nothing about anything but we","38:06":"actually start with a model that knows","38:08":"how to recognize there are thousand","38:10":"categories of things in image net now I","38:13":"don't think I'm not sure but I don't","38:15":"think all of these 37 categories of pet","38:17":"or in image net but there was certainly","38:20":"some kinds of dog know certainly some","38:22":"kinds of cat so this pre trained model","38:25":"already knows quite a little bit about","38:28":"what pets look like and it certainly","38:30":"knows quite a lot about what animals","38:31":"look like and what photos look like so","38:34":"the idea is that we don't start with a","38:37":"model that knows nothing at all but we","38:39":"start by downloading a model that does","38:41":"something about recognizing images","38:44":"already so it downloads for us","38:46":"automatically the first time we use it a","38:48":"pre trained model and then from now on","38:50":"it won't need to download it again it'll","38:52":"just use the one we've got this is","38:54":"really important we're going to learn a","38:56":"lot about this it's kind of the focus of","38:58":"the whole course which is how to do this","39:01":"is called transfer learning how to take","39:03":"a moral that already knows how to do","39:05":"something pretty well and make it so","39:08":"that it can do your thing really well I","39:10":"take a pre trained model and then we fit","39:13":"it so that instead of predicting Li a","39:16":"thousand categories of imagenet with","39:17":"image net data it predicts the 37","39:20":"categories of pets using your pet data","39:22":"and it turns out that by doing this you","39:25":"can train models in 1/100 or less of the","39:30":"time of regular model training with","39:34":"1/100 or less of the data the regular","39:37":"model training in fact potentially many","39:39":"thousands of times less remember I","39:41":"showed you the slide of nickels lesson","39:43":"one","39:44":"from last year he used 30 images and","39:48":"there's not cricket and baseball images","39:50":"in imagenet but but it just turns out","39:52":"that image gets already so good at","39:54":"recognizing things in the world","39:56":"they're just 30 examples of people","39:57":"playing baseball and cricket was enough","40:00":"to build a nearly perfect classifier","40:02":"okay","40:03":"now you would naturally be potentially","40:09":"saying well wait a minute how do you","40:13":"know that it was going to actually that","40:15":"it can actually recognize pictures of","40:17":"people playing cricket versus baseball","40:19":"in general maybe it just learnt to","40:21":"recognize those 13 maybe it's just","40:24":"cheating right and that's called","40:26":"overfitting we'll be going talking a lot","40:27":"about that during this course right but","40:29":"what a fitting is where you don't learn","40:32":"to recognize pictures of say cricket","40:33":"versus baseball but just these","40:35":"particular cricketers and these","40:37":"particular photos and these particular","40:38":"baseball players in these particular","40:40":"photos we have to make sure that we","40:43":"don't move a fit and so the way we do","40:44":"that is using something called a","40:46":"validation set a validation set is a set","40:49":"of images that your model does not get","40:52":"to look at and so these metrics like in","40:56":"this case error rate get printed out","40:58":"automatically using the validation set","41:00":"and sort of images that our model never","41:02":"got to see when we created our data","41:05":"bunch it automatically created a","41:08":"validation set for us okay and we'll","41:11":"learn lots of ways of creating and using","41:13":"validation sets but because we're trying","41:16":"to bake in all of the best practices we","41:18":"actually make it nearly impossible for","41:21":"you not to use a validation set because","41:23":"if you're not using a validation set you","41:25":"don't know if you're overfitting okay so","41:27":"we always print out the metrics on a","41:28":"validation set we've always hold it out","41:30":"we always make sure that the model","41:32":"doesn't touch it that's all done for you","41:34":"okay and that's all built into this data","41:38":"bunch object so now that we have a","41:41":"corner we can fit it you can just use a","41:46":"method called fit but in practice you","41:49":"should nearly always use a method called","41:50":"fit one cycle we'll learn more about","41:53":"this during the course but in short one","41:56":"cycle learning is a paper","41:57":"that was released I'm trying to think","42:01":"few months ago listen a year ago yeah so","42:05":"a few months ago and it turned out to be","42:07":"dramatically better both more accurate","42:10":"and faster than any previous approach so","42:12":"again I don't want to teach you how to","42:14":"do 2017 deep learning right in 2018 the","42:19":"best way to fit models is to use","42:21":"something called one cycle well learn","42:23":"all about it but for now just know you","42:25":"should probably take my own fit one","42:27":"cycle okay if you forget how to type","42:31":"then you can start typing a few letters","42:33":"in hit tab okay and you'll get a list of","42:37":"potential options and then if you forget","42:41":"what to pass it you can press shift tab","42:43":"and it will show you exactly what to","42:46":"pass it so you don't actually have to","42:47":"type help and again this is kind of nice","42:49":"that we have all the types here because","42:51":"we can see cycle length that we'll learn","42:53":"more about what that is shortly is an","42:54":"integer and then next learning rate","42:56":"could either be the flow for reflection","42:58":"or whatever and so forth and you can see","43:00":"that the mentions will default to this","43:02":"couple and so forth okay so for now just","43:08":"know that this number four basically","43:11":"decides how many times do we go through","43:14":"the entire data set how many times do we","43:16":"show the data set to the model so that","43:19":"it can learn from it each time it sees a","43:20":"picture it's going to get a little bit","43:22":"but it's going to take time and it means","43:26":"it could over fit but sees the same","43:28":"picture too many times","43:29":"it'll just learn to recognize that","43:31":"picture not pets in general so we'll","43:35":"learn all about how to tune this number","43:39":"during the next couple of lessons but","43:42":"starting out with four is a pretty good","43:45":"start just to see how it goes and you","43:47":"can actually see after four epochs or","43:52":"four cycles we put an error rate of 6%","43:58":"so a natural question is how long that","44:01":"took that took a minute and 56 seconds","44:04":"yeah so we're paying you know 60 cents","44:08":"an hour now we just pay for two minutes","44:11":"I mean we actually pay for the whole","44:13":"time that it's on and running there's","44:15":"two minutes of compute time and we've","44:17":"got an error rate of 6% so 95% of the","44:21":"time we correctly picked the exact right","44:23":"one of those 94 dog and cat breeds which","44:28":"feels pretty good to me","44:29":"but to get a sense of how good it is","44:31":"maybe we should go back and look at the","44:33":"paper just remember I said the nice","44:36":"thing about using academic papers or","44:37":"capital data sets is we can compare our","44:41":"solution to whatever the best people in","44:44":"Cabell did or whatever the academics did","44:46":"so this particular data set of pet","44:49":"breeds is from 2012 and if I scroll","44:53":"through the paper you'll generally find","44:55":"in any academic paper there'll be a","44:56":"section called experiments about 2/3 of","44:59":"the way through and if you find the","45:00":"section on experiments then you can find","45:03":"the section on accuracy and they've got","45:06":"lots of different models and their","45:08":"models as you're read about in the paper","45:10":"it's really kind of pet specific they","45:13":"learn something about how pet heads look","45:15":"and how pet body is broken and techne","45:18":"which is in general look and they","45:19":"combine them all together and once they","45:21":"use all of this complex code and math","45:24":"they got an accuracy of 59% okay so in","45:29":"2012 this highly pet specific analysis","45:34":"got an accuracy of 59% these were the","45:37":"top researchers from Oxford University","45:39":"today in 2018 with basically if you go","45:45":"back and look at actually how much code","45:46":"we just wrote it's about three lines of","45:49":"code the other stuff is just printing","45:51":"out things to see what we're doing","45:52":"we got ninety four percent so six","45:56":"percent error so like that gives you a","45:58":"sense of you know how far we've come","46:01":"with deep learning and particularly with","46:03":"pay torch and fast AI how easy things","46:06":"are yeah so um before we take a break I","46:11":"just want to check to see if we've got","46:12":"any and just remember if you're in the","46:15":"audience and you see a question that you","46:18":"want asked please click them up heart","46:19":"next to it so that Rachel knows that you","46:22":"want to hear about it well","46:23":"if there is something with six likes and","46:26":"Rachel didn't notice it which is quite","46:28":"possible just just quote it in a reply","46:31":"and say hey Rachel this one's got six","46:34":"legs okay","46:36":"so what we're going to do is we're going","46:37":"to take a eight minute break so we'll","46:41":"come back at five past eight so where we","46:45":"got to was we just we just trained a","46:48":"model we don't exactly know what that","46:49":"involved or how it happened but we do","46:51":"know that we're three or four lines of","46:53":"code we've built something which smashed","46:57":"the accuracy of the state-of-the-art of","46:59":"2012 6% arrow certainly sounds like","47:02":"pretty impressive for something that can","47:04":"recognize different dog breeds and cat","47:06":"breeds but we don't really know why it","47:11":"works that we will that's okay all right","47:14":"and in terms of getting the most out of","47:18":"this course we very very regularly here","47:23":"after the course is finished the same","47:26":"basic feedback which this is literally","47:29":"copy and paste it for them forum I fell","47:31":"into the habit of watching the lectures","47:33":"too much and googling too much about","47:35":"concepts without running the code at","47:38":"first I thought I should just read it","47:39":"and then research the theory and we keep","47:43":"hearing people saying my number one","47:45":"regret is I just spent 70 hours doing","47:49":"that and at the very end I started","47:51":"running the code and oh it turned out I","47:53":"learned a lot more","47:54":"so please run the code really run the","47:58":"code I should have spent the majority of","48:01":"my time on the actual code and the","48:03":"notebooks running it seeing what goes in","48:05":"and seeing what comes out so your most","48:09":"important skills to practice our","48:11":"learning and we going to show you how to","48:13":"do this in a lot more detail but","48:15":"understanding what goes in and what goes","48:18":"out so we've already seen an example of","48:22":"looking at what goes in which is data","48:25":"dot show batch and that's going to show","48:27":"you examples of labels and images and so","48:32":"next we're going to be seeing how to","48:33":"look at what came out so that's the most","48:37":"important thing to study as I said the","48:41":"reason we've been able to do this so","48:42":"quickly is heavily because of the","48:44":"fostered a library now if I stay a","48:46":"library is pretty new but it's already","48:49":"getting an extraordinary amount of","48:50":"direction as you've seen all of the","48:52":"major cloud providers either support it","48:54":"or are about to support it","48:57":"a lot of researchers are starting to use","48:59":"it it's it's - remaking a lot of things","49:02":"a lot easier but it's also making new","49:06":"things possible and so really","49:09":"understanding the faster I software is","49:11":"something which is going to take you a","49:13":"long way and the best way to really","49:14":"understand the faster your software well","49:16":"is by using the fast AI documentation","49:19":"and we'll be learning more about the","49:21":"fast a documentation shortly so how does","49:26":"it compare I mean there's really only","49:28":"one major other piece of software like","49:30":"fast AI that is something that tries to","49:32":"make deep learning easy to use and","49:36":"that's chaos chaos is a really terrific","49:38":"piece of software we actually used it","49:40":"for the previous courses until we switch","49:42":"to first AI it runs on top of tensorflow","49:46":"it was kind of the gold standard for","49:48":"making deep learning easy to use before","49:50":"but life is much easier with bostero so","49:53":"if you look for example at the last","49:55":"year's course exercise which is getting","49:58":"dogs vs. cats fast AI lets you get more","50:04":"much more accurate less than half the","50:06":"error on a validation set of course","50:09":"training time is less than half the time","50:13":"lines of code is about a six of the","50:17":"lines of code and the lines of code are","50:20":"more important than you might realize","50:21":"because those 31 lines of Karis code","50:24":"involved you making a lot of decisions","50:27":"setting lots of parameters during list","50:29":"of configuration so that's all stuff","50:31":"where you have to know how to set those","50:34":"things to get kind of best practice","50:35":"results or else these five lines of code","50:38":"anytime we know what to do for you we do","50:41":"it for you anytime we can pick a good","50:42":"default we pick it for you okay so","50:45":"hopefully your","50:46":"is a really useful library not just for","50:50":"learning deep learning but for taking it","50:52":"a very long way how far can you take it","50:54":"well as you'll see all of the research","50:57":"that we do at past AI uses the library","51:00":"and an example of the research we did","51:03":"which was recently featured in Wired","51:04":"describes a new breakthrough in a","51:08":"natural language processing processing","51:10":"which people are calling the image net","51:12":"moment which is basically we broke a new","51:15":"state of the art resolved in text","51:17":"classification which open AI then built","51:20":"on top of our paper to do with more","51:23":"computing more data into different tasks","51:24":"to take it even further and like this is","51:28":"an example of something that we've done","51:29":"in the last six months in conjunction","51:32":"actually with my colleague Sebastian","51:33":"Reuter an example of something that's","51:37":"being built in the faccio library and","51:39":"you're going to learn how to use this","51:41":"brand-new model in three lessons time","51:44":"and you're actually going to get this","51:47":"exact result from this exact paper","51:49":"yourself another example one of our","51:53":"alums ml Hussain who you'll come across","51:57":"on the forum plenty because he's a great","51:59":"guy very active built a new system for","52:02":"natural language semantic code search","52:04":"you can find an on github where you can","52:07":"actually type in English sentences and","52:09":"find snippets of codes that do the thing","52:11":"you asked for and again it's being built","52:13":"with the FASTA a library using the","52:16":"techniques you'll be learning in the","52:17":"next seven weeks in production yeah well","52:20":"I think this stage is a part of their","52:22":"experiments platform so it's kind of","52:24":"pre-production I guess and so the best","52:28":"place to learn about these things and","52:31":"get involved from these things is on the","52:33":"forums where as well as categories for","52:36":"each part of the course and there's also","52:38":"a general category for deep learning","52:39":"where people talk about research papers","52:42":"applications so on and so forth so even","52:48":"though today we're kind of got to focus","52:50":"on a small number of lines of code to a","52:53":"particular thing which is image","52:55":"classification and we're not learning","52:57":"much math or theory or whatever over","53:00":"these seven weeks and then part two","53:02":"another seven weeks we're going to go","53:04":"deeper and deeper and deeper and so","53:05":"where can that take you I want to give","53:07":"you some examples that there is Sarah","53:10":"hooker she did our first course a couple","53:13":"of years ago her background was","53:16":"economics didn't have a background in","53:19":"coding math computer science I think she","53:21":"started learning to code two years","53:22":"before she took our costs she helped","53:26":"develop something at she started a","53:28":"nonprofit called Delta analytics they","53:33":"helped build this amazing system where","53:35":"they attached old mobile phones to trees","53:38":"in the Kenyan rain forests and used it","53:41":"to listen for chainsaw noises and then","53:44":"they used deep learning to figure out","53:45":"when there was a chainsaw being used and","53:47":"then they had a system set up to alert","53:49":"Rangers to go out and stop illegal","53:52":"deforestation in the rainforests so that","53:55":"was something that she was doing well","53:57":"she was in the course as part of her","53:59":"kind of class projects","54:01":"what's she doing now she is now a Google","54:04":"brain researcher which I guess is one of","54:08":"the top if not the top place to do deep","54:10":"learning","54:11":"she's just been publishing some papers","54:14":"now she is going to Africa to set up a","54:17":"Google brains first deep learning","54:19":"Research Center in Africa now I'll say","54:22":"like she worked her ass off you know she","54:25":"really really invested in this course","54:28":"not just doing all of the assignments","54:30":"but also going out and reading in","54:32":"Goodfellows book and doing lots of other","54:34":"things but it really shows where","54:37":"somebody who has no computer science or","54:40":"math background at all can be now one of","54:43":"the world's top deep learning","54:44":"researchers and doing very valuable work","54:49":"another example from our most recent","54:51":"course","54:52":"Christine Payne she is now at open AI","54:59":"and you can find her post and actually","55:02":"listen to her music samples of she","55:05":"actually built something","55:06":"to automatically create chamber music","55:10":"compositions you can play and you can","55:12":"listen to online and so again it's her","55:15":"background math and computer science","55:18":"actually that's her there","55:22":"classical pianist now I will say she is","55:25":"not your average classical pianist she's","55:27":"a festival pianist who also has a","55:29":"master's a medical researcher in","55:30":"Stanford and studied neuroscience and","55:33":"was a high-performance computing expert","55:34":"at Ian's shore and was valedictorian at","55:37":"Princeton anyway she you know very","55:39":"annoying person who did everything she","55:41":"does but you know I think it's really","55:44":"cool to see how I kind of a domain","55:46":"expert in this case the domain of","55:48":"playing piano can go through the","55:50":"fascinator course and come out the other","55:53":"I guess open AI would be you know of the","55:56":"three top research institutes bugle","55:58":"playing or open a would be two of them","56:00":"probably along with Diamond and","56:04":"interesting Lee actually one of our","56:05":"other students or alumni of the course","56:08":"recently interviewed her for a blog post","56:11":"series he's doing on top AI researchers","56:13":"and she said one of the most important","56:15":"pieces advice she got was from me and","56:18":"she said the piece of advice was kick","56:20":"one project do it really well make it","56:23":"fantastic okay so that was the piece of","56:27":"advice she found the most useful and","56:30":"we're going to be talking a lot about","56:31":"you doing projects and making them","56:33":"fantastic during this course having said","56:37":"that I don't really want you to go to AI","56:39":"or Google brain what I really want you","56:41":"to do is go back to your workplace or","56:44":"your passion project and apply these","56:47":"skills there right like let me give you","56:50":"an example","56:51":"MIT released a deep learning course and","56:55":"they highlighted in their announcement","56:57":"for this deep learning course this","56:58":"medical imaging example and one of our","57:03":"students Alex who is a radiologist said","57:08":"you guys just showed a model overfitting","57:12":"I can tell because I'm a radiologist","57:15":"and this is not what this would look","57:18":"like on a chest film","57:20":"this is what it should look like and","57:23":"this is a deep breading practitioner","57:25":"this is how I know that this is what","57:27":"happened in your model so alex is","57:29":"combining his knowledge of radiology and","57:31":"his knowledge of deep learning to assess","57:35":"mi t--'s model from just two images very","57:39":"accurately right and so this is actually","57:41":"what I want most of you to be doing is","57:43":"to take your domain expertise and","57:45":"combine it with the deep learning","57:47":"practical aspects that you'll learn in","57:49":"this course and bring them together like","57:51":"Alex is doing here and so a lot of","57:53":"radiologists have actually gone through","57:55":"this course now and have built journal","57:59":"clubs and American Council of radiology","58:01":"practice groups there's a data science","58:04":"Institute at the ACR now and so forth","58:06":"and Alex is one of the people who's","58:07":"providing kind of a lot of leadership in","58:09":"this area I would love you to do the","58:11":"same kind of thing that alex is doing","58:13":"which is to really bring deep learning","58:15":"related leadership into your industry","58:17":"and just your social impact project","58:19":"whatever it is that you're trying to do","58:22":"so another great example was this was","58:24":"Melissa fab bras who was a English","58:26":"literature PhD who studied like gendered","58:29":"language in English literature or","58:32":"something and actually wrench over the","58:36":"previous job taught her to code","58:37":"I think and then she came into the first","58:40":"day a course and she helped Kiva a micro","58:44":"lending a social impact organization to","58:46":"build a system that can recognize faces","58:49":"why is that necessary well we're going","58:51":"to be talking a lot about this but","58:53":"because most a I researchers are white","58:57":"men most computer vision software can","59:02":"only recognize white male faces","59:04":"effectively in fact I think of as IBM","59:07":"system is like ninety-nine point eight","59:09":"percent accurate on common white face","59:12":"men versus sixty percent accurate","59:17":"sixty-five percent accurate on dark","59:20":"faith dark-skinned women so it's like","59:23":"what is that like 30 or 40 times worse","59:26":"for black women versus white men and","59:29":"this is really important because for","59:31":"chemo black women","59:33":"you know perhaps the most common user","59:36":"base for their microlending platform so","59:39":"melissa after taking our course and","59:42":"again working in her ass off and being","59:44":"super intensive in her study and her","59:46":"won this $1,000,000 AI challenge for her","59:49":"work for Kiva Karthik did our course and","59:56":"realize that the thing he wanted to do","59:58":"wasn't at his company it was something","59:59":"else which is to help blind people to","60:01":"understand the world around them so he","60:02":"started a new startup you can find it","60:04":"now it's called envision you can","60:06":"download the app you can point your","60:08":"phone of things and it will tell you","60:10":"what it sees and I actually talked to a","60:12":"blind lady about these kinds of apps the","60:15":"other day and she confirmed to me this","60:16":"is a super useful thing for visually","60:19":"disabled users and it's not it's the","60:26":"level that you can get to with with the","60:30":"content that you're going to get over","60:31":"these seven weeks and with this software","60:33":"can get you right to the cutting edge in","60:37":"areas you might find surprising for","60:39":"example I helped a team of some of our","60:42":"students and some collaborators on","60:46":"actually breaking the world record for","60:49":"training remember I mentioned the","60:50":"imagenet data set lots of people want to","60:52":"train on the imagenet dataset we smashed","60:54":"the world record for how quickly you can","60:56":"train it we do standard AWS cloud","61:00":"infrastructure cost of $40 of compute to","61:03":"train this model using again faster","61:06":"library the techniques that we learn in","61:08":"this course so it can really take you a","61:10":"long way so don't be kind of put off by","61:13":"this what might seem pretty simple at","61:16":"first we're going to get deeper and","61:17":"deeper you can also use it for other","61:20":"kinds of passion project so Helene","61:22":"esaron actually you should definitely","61:24":"check out her Twitter account like ELISA","61:26":"this art is a basically a new style of","61:30":"art that she's developed which combines","61:33":"her painting and drawing with generative","61:37":"adversarial models to create these","61:39":"extraordinary results and so I think","61:42":"this is super cool she's not a","61:44":"professional artists she is a","61:46":"professional software developer","61:47":"but she just keeps on producing these","61:50":"beautiful results and when she started","61:53":"you know her art had not really been","61:58":"shown anywhere I discussed anywhere now","62:01":"there's recently been some quite","62:02":"high-profile articles describing how she","62:05":"is creating a new form of art again this","62:07":"is come out of the FASTA a course that","62:12":"she developed these skills or equally","62:14":"important bred counselor who figured out","62:16":"how to make a picture of Kanye out of","62:18":"pictures of Patrick Stewart's head also","62:21":"something you will learn to do if you","62:23":"wish to this particular style this","62:27":"particular type of what's called style","62:28":"transfer was a really interesting tweak","62:30":"it allowed him to do some things that","62:32":"hadn't quite been done before and this","62:35":"particular picture helped him to get a","62:36":"job as a deep learning specialist at AWS","62:39":"so another interesting example another","62:44":"alumni actually worked at Splunk as a","62:47":"software engineer and he'd signed an","62:52":"algorithm after like lesson three which","62:54":"basically turned out its plant to be","62:56":"fantastically good at identifying fraud","62:59":"and we'll talk more about it shortly if","63:02":"you've seen Silicon Valley the HBO","63:03":"series the the hot dog hot dog app","63:06":"that's actually a real app you can","63:07":"download and it was actually built by a","63:09":"team on Glade as a fast AI student","63:12":"project so there's a lot of cool stuff","63:15":"that you can do I'm like yes it wasn't","63:18":"very nominated so I think we only have","63:20":"one any nominated fast day alumni at","63:23":"this stage so please help change that","63:29":"alright the other thing you know is is","63:33":"is the forum threads can kind of turn","63:35":"into these really cool things so","63:37":"Francisco was actually here in the","63:38":"audience he's are really boring McKinsey","63:41":"consultant like me","63:42":"it's a Francisco and I both have this","63:44":"shameful past that we were McKinsey","63:46":"consultants but we left and we're okay","63:48":"and he started his threat saying like oh","63:52":"this stuff we've just been learning","63:53":"about building","63:55":"NLP in different languages let's try and","63:57":"do lots of different languages we","63:59":"started this thing with the language","64:00":"model zoom and add that there's now been","64:03":"an academic competition was one in","64:08":"Polish that led to an academic paper tie","64:11":"state-of-the-art German state of the art","64:14":"basically as students have been coming","64:16":"up with new study that results across","64:18":"lots of different languages and this all","64:19":"is entirely being done by students","64:23":"working together through the forum so","64:25":"please get on the forum but don't be","64:29":"intimidated because remember and one of","64:32":"the people everybody you see on the","64:34":"forum the vast majority posting post all","64:37":"the damn time right they've been doing","64:39":"this a lot and they do it a lot of the","64:41":"time and so at first it can feel","64:43":"intimidating because it can feel like","64:44":"you're the only new person there but","64:46":"you're not right all of you people in","64:49":"the audience everybody who's watching","64:50":"everybody who's listening you're all new","64:52":"people right and so when you just get","64:54":"out there and say like okay nor your","64:57":"people getting these state-of-the-art","64:58":"results in German language modeling if I","65:02":"can't start my server I try to click the","65:04":"notebook and I get an error what do I do","65:07":"people will help you okay just make sure","65:10":"you provide all the information this is","65:12":"the you know I'm using paper space this","65:14":"was the particular instance I try to use","65:16":"here's a screenshot of my error people","65:19":"will help you okay well if you've got","65:21":"something to add so if people were","65:23":"talking about crop yield analysis and","65:26":"you're a farmer and you think you know","65:28":"oh I've got something to add so please","65:31":"mention it even even if you're not sure","65:33":"it's exactly relevant it's fine you know","65:35":"just get involved and because remember","65:37":"everybody else in the forum's started","65:39":"out also intimidated right we all start","65:43":"out not knowing things and so just get","65:46":"out there and try it okay","65:50":"so let's get back and do some more","65:54":"coding yes Rachel do we have some","65:57":"questions about why you're using breast","66:02":"net is opposed to this session so the","66:07":"question is about this architecture","66:09":"so there are lots of architectures to","66:12":"choose from and it would be fair to say","66:15":"there isn't one best one but if you look","66:20":"at things like the Stanford dawn bench","66:25":"benchmark or imagenet classification","66:28":"you'll see in first place in second","66:31":"place in third place in fourth place is","66:33":"faster i Jeremy Hatton first a","66:35":"hydrometer plus the irony response from","66:37":"the Department of Defense innovation","66:39":"team Google RIS net ResNet ResNet ResNet","66:43":"listen it's good enough ok so it's fun","66:52":"there are other architect is the main","66:54":"reason you might want a different","66:55":"architecture is if you want to do inch","66:57":"computing so if you want to create a","66:58":"model that's gonna sit on somebody's","67:00":"mobile phone having said that even their","67:03":"most of the time I reckon the best way","67:05":"to get a model onto somebody's mobile","67:06":"phone is to run it on your server and","67:08":"then have your mobile phone app talk to","67:10":"it it really makes life a lot easier and","67:13":"you get a lot more flexibility but if","67:15":"you really do need to run something on a","67:16":"low powered device then there are some","67:18":"special architectures for them so the","67:22":"particular question was about inception","67:24":"that's a particular another architecture","67:27":"which tends to be pretty memory","67:29":"intensive and yeah resident I'm for","67:33":"inception tends to be pretty memory","67:34":"intensive but it's it's ok it's also","67:36":"like it's not terribly resilient one of","67:39":"the things we try to show you is like","67:41":"stuff which just tends to always work","67:43":"even if you don't quite ruin everything","67:46":"perfectly","67:47":"so Reznor tends to work pretty well","67:48":"across a wide range of different kind of","67:53":"details around choices that you might","67:54":"make so I think it's pretty good so","67:59":"we've got this trained model and so","68:00":"what's actually happened as we'll learn","68:02":"is it's basically creating a set of","68:05":"weights if you've ever done anything","68:06":"like a linear regression or logistic","68:08":"regression you'll be familiar with","68:10":"coefficients we basically found some","68:11":"coefficients and parameters that work","68:13":"pretty well and it took us a minute and","68:15":"56 seconds so if we want to start doing","68:18":"some more playing around and come back","68:19":"later we probably should save those","68:22":"we can save that minute and 56 seconds","68:24":"so you can just go and learn got save","68:25":"and give it a name it's going to put it","68:28":"in a model subdirectory in the same","68:31":"place the data came from so if you save","68:33":"different models or different data","68:35":"bunches from different data sets","68:37":"they'll all be kept separate so don't","68:39":"worry about it","68:42":"all right so we've talked about how the","68:44":"most important things that add on learn","68:45":"what goes into your model what comes out","68:47":"we've seen one way of seeing what goes","68:49":"in now let's see what comes out this is","68:52":"the other thing you need to get really","68:53":"good at so to see what comes out we","68:57":"could use this class for classification","68:59":"interpretation and we're going to use","69:02":"this factory method from learner so we","69:05":"pass in a loan object so remember a","69:07":"learn object from those two things","69:08":"what's your data and what is your model","69:12":"it's now I'm not just an architecture","69:14":"it's actually a trained model inside","69:16":"there and that's all the information we","69:17":"need to interpret that model so if this","69:20":"pass in the learner and we now have a","69:22":"classification interpretation object and","69:26":"so one of the things we can do it","69:28":"perhaps the most useful things to do is","69:30":"called plot top losses so we're going to","69:35":"be learning a lot about this idea of","69:36":"loss functions shortly but in short a","69:40":"loss function is something that tells","69:42":"you how good was your prediction and so","69:45":"specifically that means if you predicted","69:48":"one class of cat with great confidence","69:52":"you said I am very very sure that this","69:55":"is a BER man but actually you were wrong","70:01":"then then that's going to have a high","70:03":"loss because you were very confident","70:04":"about the wrong answer okay so that's","70:07":"what it basically means to have a high","70:09":"loss so by putting the top losses we are","70:11":"going to find out what were the things","70:13":"that we were the most wrong on are the","70:16":"most confident about what we got wrong","70:18":"so you can see here it prints out three","70:22":"things German Shorthaired before things","70:25":"beat all 7.0 for 0.92 well what do they","70:31":"mean perhaps we should look at the","70:35":"document","70:36":"so if you we've already seen help but","70:39":"and help just prints out a quick little","70:41":"summary but if you won't really see how","70:43":"to do something use doc and doc tells","70:47":"you the same information is help but it","70:49":"has this very important thing which is","70:51":"show in Doc's so when you click on","70:54":"showing dots it pops up the","70:58":"documentation for that method or class","71:01":"or function or whatever starts out by","71:04":"showing us the same information about","71:05":"what is what are the parameters it takes","71:07":"along with the doc string but then tells","71:11":"you more information so in this case I","71:13":"saw the thing that tells me the title of","71:15":"eight shows the prediction the actual","71:19":"the loss and the probability that was","71:24":"predicted so for example and you can see","71:26":"there's actually some code you can run","71:28":"so the documentation always has working","71:30":"code and so in this case it was trying","71:33":"things with handwritten digits and so","71:35":"the first one it was predicted to be a","71:37":"seven it was actually a three the loss","71:40":"is five point four four and the","71:43":"probability of the actual class was 0.07","71:47":"okay so I you know we did not have a","71:51":"high probability associated yet for","71:52":"class I can see why I thought this was a","71:54":"seven unless it was wrong so this is the","71:57":"documentation okay and so this is your","71:59":"friend when you're trying to figure out","72:01":"how to use these things the other thing","72:03":"I'll mention is if you're a somewhat","72:06":"experienced Python programmer you'll","72:08":"find the source code of faster I'm","72:09":"really easy to read we're trying to","72:11":"write everything in just a small number","72:14":"of you know much less than half a screen","72:16":"of code generally four or five lines of","72:18":"if you click source you can jump","72:20":"straight to the source code right so","72:23":"here is the plot top losses and this is","72:26":"also a great way to find out how to use","72:30":"the faster I'm I agree because every","72:32":"line of code here nearly every line of","72:33":"code is calling stuff in the faster you","72:35":"library okay so don't be afraid to look","72:39":"at the source code I've got another","72:43":"really cool trick about the","72:44":"documentation that you're going to see a","72:45":"little bit later","72:46":"okay so that's how we can look at these","72:51":"top losses and these suppress the most","72:53":"important image classification","72:55":"interpretation tools that we have","72:57":"because it lets us see what are we","73:00":"getting wrong and quite often like in","73:03":"this case if you're a dog and cat expert","73:06":"you'll realize that the things that's","73:08":"getting wrong breeds that are actually","73:10":"very difficult to tell apart and you'd","73:12":"be able to look at these and say oh I","73:14":"can see why they've got this one wrong","73:18":"so this is a really useful tool another","73:21":"useful tool kind of is to use something","73:23":"called a confusion matrix which","73:25":"basically shows you for every actual","73:28":"type of dog or cat how many times was it","73:32":"predicted to be that dog okay but","73:34":"unfortunately in this case because it's","73:35":"so accurate this diagonal basically says","73:38":"how it's pretty much right all the time","73:40":"and you can see this in slightly darker","73:42":"ones like a five here it's really hard","73:44":"to read exactly what their combination","73:46":"is so what I suggest you use is instead","73:48":"of if you've got lots of classes don't","73:50":"use a classification confusion matrix","73:52":"but this is my favorite named function","73:55":"in faster I are very proud of this you","73:57":"can call most confused and most confused","74:01":"will simply grab out of the confusion","74:03":"matrix the particular combinations have","74:06":"predicted and actual that got wrong the","74:08":"most often so this case the","74:11":"Staffordshire Bull Terrier was what it","74:13":"should have predicted and instead it","74:15":"predicted an American Pitbull Terrier","74:17":"and so forth it should have ridiculous I","74:19":"mean actually predicted Burma that","74:21":"happened four times this particular","74:22":"combination happens six times so this is","74:24":"again a very useful thing because you","74:26":"can look and you can say like with my","74:28":"domain expertise does it make sense that","74:31":"that would be something that was","74:32":"confused about so these are some of the","74:34":"kinds of tools you can use to look at","74:36":"the upload let's make our model better","74:39":"so how do we make the bottle better we","74:42":"can make it better using fine tuning so","74:46":"far we fitted for epochs and it ran","74:50":"pretty quickly and the reason it ran","74:52":"pretty quickly is that there was a","74:53":"little trick we used these deep learning","74:55":"models these convolutional networks they","74:57":"have","74:58":"lanes they learned a lot about exactly","75:00":"what layers are but but now just know it","75:01":"goes through a computer computational","75:03":"computation or computational computation","75:06":"what we did was we added a few extra","75:09":"layers to the end and we only trained","75:11":"votes we basically left most of the","75:13":"model exactly as it was so that's really","75:15":"fast and if we're trying to build a","75:18":"model at something that's similar to the","75:20":"original pre-trained model so in this","75:23":"case similar the imagenet data that","75:25":"works pretty well but what we really","75:27":"want to do is actually go back and train","75:30":"the whole model so this is why we pretty","75:33":"much always use this two-stage process","75:34":"so by default when we call fit or fit","75:40":"one cycle on a con Florida it'll just","75:43":"fine-tune these few extra layers add up","75:45":"to the end and it'll run very fast it'll","75:48":"basically never over fit but to really","75:50":"get it good you have to call an crits","75:53":"and unfreeze is the thing that says","75:55":"please train the whole model and then I","76:00":"can call fit one cycle again and of the","76:04":"error got much worse okay","76:09":"why in order to understand why we're","76:13":"actually going to have to learn more","76:14":"about exactly what's going on behind the","76:17":"scenes so let's start out by trying to","76:20":"get an intuitive understanding of what's","76:22":"going on behind the scenes and again","76:24":"we're going to do it by looking at","76:25":"pictures we're gonna start with this","76:29":"picture these pictures come from a","76:31":"fantastic paper by Nets Iowa who","76:33":"nowadays is CEO of clarify which is a","76:35":"very successful computer vision start","76:38":"and his supervisor is PhD Rob Fergus and","76:43":"they kind of paper showing how you can","76:44":"visualize the layers of a convolutional","76:47":"neural network so a convolutional neural","76:50":"network will learn mathematically about","76:51":"what the layers are shortly but the","76:53":"basic idea is that your red green and","76:55":"blue pixel values that are numbers from","76:57":"nought to 255 go into the simple","76:59":"computation the first layer and","77:02":"something comes out of that and then the","77:04":"result of that goes into a second layer","77:05":"back","77:06":"the third layer and so forth and there","77:11":"can be up to a thousand layers of a","77:14":"neural network president 34 has 34","77:17":"layers there's no 50s 50 layers but","77:21":"that's not that layer one there's this","77:23":"very simple computation it's a","77:25":"convolution if you know what they are","77:27":"we'll learn more about them shortly what","77:30":"comes out of this first layer well we","77:32":"can actually visualize these specific","77:34":"coefficients the specific parameters by","77:36":"drawing them as a picture there's","77:38":"actually a few dozen of of them in the","77:41":"first layer so we won't draw all of them","77:42":"and let's just look at mine at random so","77:45":"here are my examples of the actual","77:47":"coefficients from the first layer and so","77:50":"these operate on groups of pixels that","77:53":"are next to each other and so this first","77:55":"one basically finds groups of pixels","77:57":"that have a little horizontal diagonal","77:58":"line in this direction this one finds","78:00":"diagonal lines in the other direction","78:02":"despite ingredients that go from yellow","78:04":"to blue in this direction this one finds","78:07":"greated to go from pink to green in this","78:09":"and so forth that's a very very simple","78:12":"little filters let's layer one of a","78:17":"imagenet pre-trained convolutional","78:19":"neural net layer two takes the results","78:24":"of those filters and does a second layer","78:26":"of computation and it allows it to","78:28":"create so here at nine examples of kind","78:32":"of a way of visualizing this one of the","78:34":"second layer features and you can see","78:36":"it's basically learned to create","78:38":"something that looks for Connors top","78:42":"left corners and this one is learn to","78:44":"find things that find right-hand curves","78:46":"this one is learn to find things that","78:48":"find little circles right so you can see","78:51":"how Maya - like this is the easiest way","78:53":"to see it in layer one we have things","78:55":"that can find just one line and lay it -","78:57":"we can find things that have two lines","78:59":"turned up or one line repeated if you","79:02":"then look over here these nine show you","79:05":"nine examples of actual bits of actual","79:08":"photos that activated this filter a lot","79:10":"that's what other words this little bit","79:12":"of function math function here was good","79:16":"at finding these kind of window corners","79:18":"like that this little surly one was very","79:22":"good at finding bits of photos that had","79:23":"circles it okay so this is the kind of","79:26":"stuff you've got to get a really good","79:27":"intuitive understanding for slightly the","79:29":"start of my neural nets gonna find","79:31":"simple very simple gradients lines the","79:34":"second layer can find very simple shapes","79:36":"the third layer can find combinations of","79:38":"votes so now we can find repeating","79:42":"patterns of two-dimensional objects or","79:44":"we can find kind of things that joins","79:47":"that join together or we can find well","79:50":"what are these things well let's find","79:52":"out what is this let's go and have a","79:54":"look at some bits of picture that","79:55":"activated this one highly Oh mainly","79:59":"they're bits of text although sometimes","80:01":"windows so it's nice to be able to find","80:04":"kind of like four petered horizontal","80:06":"patterns and this one here since we have","80:08":"a find kind of edges of fluffy or","80:12":"flowery things this one here is kind of","80:14":"finding geometric patterns so layer","80:17":"three was able to take all the stuff in","80:19":"layer two and combine them together","80:21":"layer four can take all the stuff from","80:24":"layer three and combine them together by","80:26":"layer four we put something that can","80:28":"find dog faces and let's see what else","80:32":"we've got here yeah various kinds of oh","80:37":"here we have bird legs so you kind of","80:40":"get the idea so by layer five we've got","80:42":"something that can find the eyeballs of","80:44":"birds and wizards or faces of particular","80:48":"breeds of dogs and so forth so you can","80:50":"see how by the time you get to layer 34","80:54":"you can find specific dog breeds and cat","80:58":"breeds right this is kind of how it","80:59":"so when we first trained when we first","81:04":"fine-tune that pre-trained model we kept","81:07":"all of these layers that you've seen so","81:09":"far and we just trained a few more","81:11":"layers on top of all of those","81:13":"sophisticated features that are already","81:14":"being created okay and so now we're","81:17":"fine-tuning we're going back and saying","81:19":"let's change all of these rookies that","81:21":"we'll start with them where they are","81:23":"right but let's see if we can make them","81:25":"better now it seemed very unlikely that","81:29":"we can make these lay","81:31":"lively features better like is there I","81:33":"am likely that the kind of the","81:35":"definition of a diagonal line is going","81:36":"to be different when we look at dog and","81:38":"cat breeds versus the image net data","81:41":"that this is originally trained on so we","81:43":"don't really want to change layer one","81:45":"very much if at all or else the last","81:48":"layers you know this thing of like types","81:51":"of dog face seems very likely that we do","81:54":"want to change that right so you kind of","81:56":"want this intuition is understanding","81:58":"that the different layers of a neural","82:00":"network represents different levels of","82:03":"kind of semantic complexity so this is","82:07":"why our attempt to find through this","82:10":"model didn't work is because we actually","82:13":"by default it trains all the layers at","82:17":"the same speed right which is to say it","82:19":"will update those like things","82:21":"representing diagonal lines and","82:22":"gradients just as much as it tries to","82:24":"update the things that represent the","82:26":"exact specifics of what a my ball looks","82:28":"like so we have to change that okay and","82:30":"so um to change it we first of all need","82:34":"to go back to where we were before okay","82:36":"we did we just broke this model right","82:38":"just much worse than it started out so","82:40":"if we just go load this brings back the","82:43":"model that we saved earlier remember we","82:45":"saved it as stage one okay so let's go","82:52":"ahead and load that back up so that's","82:54":"now our models back to where it was","82:55":"before we killed it","82:57":"and let's run learning rate finder we're","83:01":"learning about what that is next week","83:03":"but for now just know this is the thing","83:05":"that figures out what is the fastest I","83:07":"can train this neural network at without","83:11":"making it zip off the rails and get","83:14":"blown apart okay so we can call it low","83:15":"ll find and then we can go and learn","83:18":"don't recorded up plot and that will","83:20":"plot the result of our LR finder and","83:23":"what this basically shows you is this","83:25":"this is T parameter that we're going to","83:27":"learn all about called the learning rate","83:28":"and the learning rate basically says how","83:31":"quickly am i updating the parameters in","83:33":"my model and you can see that what","83:36":"happens is as I in this this bottom one","83:39":"here shows me what happens as I increase","83:41":"the learning rate and this one here show","83:44":"what hapless and so you can see once the","83:48":"learning rate gets past ten to the","83:50":"negative four","83:51":"my last gets worse okay so it actually","83:56":"so happens in fact I can check this if I","83:58":"press shift tab here my learning rate","84:01":"defaults to 0.003 so my default loading","84:05":"rate is about here so you can see where","84:08":"I lost got worse right because we kind","84:09":"of fine-tune things now we can't use","84:12":"such a high learning rate so based on","84:15":"the learning rate finder I tried to pick","84:17":"something you know well before it","84:20":"started getting worse so I decided to","84:23":"pick one Enix's so I decided I got to","84:27":"train at that rate but there's no point","84:30":"trading all the layers of that rate","84:31":"because we know that the latent layers","84:33":"work just fine before when we were","84:36":"training much more quickly again it was","84:38":"the default which was to remind us 0.003","84:44":"so what we can actually do is we can","84:46":"pass a range of learning rates to learn","84:49":"theater and we do it like this you pass","84:52":"and use this keyword in fact in Python","84:54":"you may have come across fourth called","84:56":"slice and that can take a start value in","85:00":"a stock value and basically what this","85:02":"says is trained the very first players","85:04":"at a learning rate of 1e make 6 and the","85:09":"very last layers at a rate of 1 enoch 4","85:11":"and then kind of distribute all the","85:14":"other layers across that you know","85:16":"between those two values equally so","85:20":"we're going to see that in a lot more","85:21":"detail but basically for now this is","85:25":"kind of a good rule of thumb is to say","85:28":"when you after you unfreeze this is the","85:31":"thing that's going to train the whole","85:32":"thing past hey max learning rate","85:35":"parameter pass it a slice make the","85:39":"second part of that slice about 10 times","85:42":"smaller than your first stage so our","85:45":"first stage defaulted to about 1 in Dec","85:47":"3 so let's use about what I knew for and","85:48":"then this one should be a value from","85:52":"your learning rate finder which is well","85:54":"before things started getting worse and","85:56":"you can see things","85:57":"adding to get worse maybe about here so","86:01":"I picked something that's at least ten","86:02":"times smaller than that so if I do that","86:04":"then I get 0.05 788 so I don't quite","86:12":"remember what we got before now bit","86:14":"better all right so we've gone down from","86:16":"a six point one percent to a five point","86:18":"seven percent so that's about a 10","86:20":"percentage point relative improvement","86:22":"with another 58 seconds of training so I","86:26":"would perhaps save for most people most","86:30":"of the time these two stages are enough","86:32":"to get pretty much a world-class model","86:36":"you won't win a Carol competition","86:38":"particularly because now a lot faster I","86:41":"am on liar are competing on Carol and","86:42":"this is the first thing that they do but","86:45":"it'll in practice you'll get something","86:48":"that's you know about as good in","86:50":"practice as the vast majority of","86:52":"practitioners can do we can improve it","86:57":"by using more layers and we'll do this","86:59":"next week by basically doing a ResNet 50","87:01":"instead of ResNet 34 and you can try","87:05":"running this during the week if you want","87:07":"to you'll see it's exactly the same as","87:09":"before but I'm using resident 50 instead","87:11":"of resident 34 what you'll find is it's","87:15":"very likely if you try to do this you","87:17":"will get an error and the error will be","87:19":"your GPU is ran out of memory and the","87:22":"reason for that is that resident 50 is","87:23":"bigger than resident 34 and therefore it","87:27":"has more parameters and therefore it","87:28":"uses more of your graphics card memory","87:30":"just totally separate to your normal","87:32":"computer Ram this is GPU Ram if you're","87:36":"using the kind of default salamander AWS","87:41":"and so forth suggestion then you will be","87:44":"having a 16 gig of compute the pad I use","87:49":"most the time has 11 gig GPU memory the","87:53":"cheaper ones have 8 gig of GPU memory","87:55":"that's kind of the main range you tend","87:57":"to get if you also has less than 8 gig","87:59":"of GPU memory it's going to be","88:01":"frustrating for you anyway so you'll be","88:03":"somewhere around there and it's very","88:05":"likely that we're trying to run this","88:07":"you'll get","88:08":"out of memory error and that's because","88:10":"it's just trying to do too much too many","88:12":"parameter updates for the amount of RAM","88:14":"you have and that's easily fixed this","88:18":"image data bunch constructor has a","88:21":"parameter at the end batch size yes for","88:24":"batch size and this basically says how","88:26":"many images do you train at one time if","88:29":"you run out of memory just make it","88:31":"smaller okay","88:32":"so this worked for me on an 11 gig card","88:34":"it probably won't work for you if you've","88:36":"got an 8 gig card if you do just make","88:38":"that 32 it's fine to use a smaller batch","88:43":"size it just it might take a little bit","88:45":"longer that's all ok if you've got a big","88:48":"oak like a 16 gig you might be able to","88:50":"get away with 64 ok so that's just one","88:52":"number you'll need to try during the","88:53":"week and again we filled it for awhile","88:56":"and we get down 44.4%","89:01":"early so this is pretty extraordinary","89:04":"you know I was pretty surprised because","89:06":"I mean when we first did in the first","89:10":"course does cats versus dogs really kind","89:13":"of getting somewhere around a three","89:16":"percent error for something where you've","89:18":"got a fifty percent chance of being","89:19":"right and the two things work totally","89:20":"different so that we can get a four","89:23":"point four percent error of assad's for","89:24":"such a fine grain thing it's quite","89:27":"extraordinary in this case I unfroze it","89:31":"and fit it a little bit more than for","89:33":"4.4 to 4.3 five it's a tiny improvement","89:36":"basically risen at 50 is already a","89:38":"pretty good model it's interesting","89:43":"because again you can call the most","89:45":"confused here and you can see the kinds","89:48":"of things that it's getting wrong and I","89:51":"actually depending on when you run it","89:53":"you're going to get slightly different","89:55":"numbers but you'll get roughly the same","89:56":"kinds of things so quite often I find","89:59":"that rag doll and bir-men of things that","90:01":"it gets confused and I actually have","90:02":"never heard of either of those things","90:04":"so I actually looked them up on the","90:06":"internet and I found a page on the cat","90:12":"site called is this Superman or rag doll","90:15":"and there is a long spread of cats","90:19":"it's like arguing intentionally about","90:22":"which it is so I feel fine that my","90:25":"computer had problems I thoughtfully","90:30":"similar I think was this pitbull versus","90:31":"Staffordshire Bull Terrier","90:32":"apparently the main difference is like","90:34":"the particular Kennel Club guidelines as","90:37":"to how they are assessed but some people","90:40":"think that one of them might have a","90:41":"slightly read in those so this is the","90:43":"kind of stuff we're actually even if","90:45":"you're not a domain expert it helps you","90:48":"become one right because I now know more","90:51":"about which kinds of pet breeds are hard","90:53":"to identify than I used to so muddled","90:56":"interpretation works both ways so what I","90:59":"want you to do this week is to run this","91:04":"notebook you know make sure you can get","91:05":"through it but then what I really want","91:07":"you to do is to get your own image data","91:11":"set and actually um Francisco who I","91:14":"mentioned earlier he started the","91:16":"language to model thread and he's you","91:18":"know now helping to TA the costs he's","91:21":"actually putting together a dye it will","91:23":"show you how to download data from","91:25":"Google Images so you can create your own","91:28":"data set to play with but before I do I","91:31":"want to before I do I want to show you","91:37":"because how to create labels in lots of","91:40":"different ways because your data set","91:43":"wherever you get it from won't","91:44":"necessarily be that kind of regex based","91:47":"approach it could be in lots of","91:49":"different formats so it was telling you","91:51":"how to do this I'm going to use the","91:53":"feminist sample embolus is pictures of","91:56":"hand drawn numbers I'm just because I","91:58":"want to show you different ways of","92:01":"creating these data sets the the Emnes","92:09":"simple basically looks like this so I go","92:13":"path LS and you can see it's got a","92:18":"training set in the validation set","92:19":"already so basically the people that put","92:21":"together this data set have already","92:23":"decided what they want you to use as a","92:25":"validation set okay so if you go path","92:27":"slash train dot LS you'll see there's a","92:33":"Farva quadtree in a folder called seven","92:35":"now this is really really common way to","92:38":"just to give people labels it's","92:40":"basically to say Oh everything that's a","92:41":"three","92:42":"I'll put in a folder called three","92:43":"everything that's a seven I'll put in a","92:45":"folder called seven this is a muffin","92:47":"cordon imagenet style data set this is","92:50":"the self-image net is distributed so if","92:53":"you have something in this honor where","92:55":"the labels just whatever the folders","92:58":"called you can say from folder okay and","93:01":"that will create an image data bunch for","93:03":"you and as you can see 3/7 it's created","93:07":"the labels just by using the folder","93:09":"names","93:11":"another possibility and as you can see","93:13":"we can train there at 99.5% accuracy buh","93:16":"buh buh","93:17":"another possibility and for this M list","93:19":"sample I've got both it might come with","93:21":"a CSV file that would look something","93:24":"like this for each file name","93:26":"what's its label now in this case the","93:28":"labels are three or seven they're 0 or 1","93:31":"which is basically is it a 7 or not so","93:33":"that's another possibility so if this is","93:36":"how your labels are you can use from CSV","93:38":"and if it's called labels dot CSV you","93:41":"don't even have to pass in a file name","93:43":"if it's called anything else then you","93:45":"can call pass in the CSV labels bar","93:48":"there okay so that's how you can use a","93:49":"CSV okay there it is this is now is it a","93:53":"7 or not and not the possibility and","93:57":"then you can coordinated up classes to","93:59":"see what them another possibility is as","94:01":"we've seen this you've got paths that","94:03":"look like this and so in this case this","94:06":"is the same thing these are the folders","94:08":"that I could actually grab the the label","94:12":"by using a regular expression and so","94:14":"here's the original expression so we've","94:16":"already seen that approach and again you","94:18":"can see that our classes is founded so","94:21":"what if you it's something that's in the","94:24":"file name of a path but it's not just a","94:25":"regular expression it's more complex you","94:28":"can create an arbitrary function that","94:31":"extracts a label from the file name or","94:33":"path and in that case you would say from","94:35":"name and function another possibility is","94:42":"that even you need something even more","94:45":"flexible on there","94:46":"and so you're going to write some code","94:48":"to create an array of labels and so in","94:51":"that case you can just pass him from","94:53":"lists so here as I've created an array","94:55":"of labels through my labels is from","94:57":"lists okay and then I just pass in that","95:00":"break so you can see there's lots of","95:01":"different ways of creating labels so so","95:03":"during the week try this out now you","95:06":"might be wondering how would you know to","95:08":"do all these things like where am I","95:10":"going to find this kind of information","95:13":"right now would I","95:14":"how do you possibly know to do all this","95:16":"stuff so I'll show you something","95:18":"incredibly cool let's grab this function","95:21":"and do you remember to get documentation","95:24":"we type doc and here is the","95:30":"documentation for the function and I can","95:31":"click show in dots and it pops up the","95:36":"documentation so here's the thing every","95:40":"single line of code I just showed you","95:42":"I took it this morning and I copied and","95:45":"pasted it from the documentation so you","95:48":"can see here the exact code that I just","95:53":"used so the documentation for fast AI","95:55":"doesn't just tell you what to do but","95:59":"step to step how to do it and here is","96:02":"perhaps the coolest bit if you go too","96:05":"fast AI fast AI underscored drops and","96:13":"click on drop sauce it turns out that","96:18":"all of our documentation is actually","96:20":"just stupid about books so in this case","96:23":"I was looking at vision data so here is","96:29":"the vision data notebook you can","96:31":"download this repo you can get clone up","96:33":"and if you run it you can actually run","96:37":"every single line of the documentation","96:39":"yourself okay so so all of our Doc's is","96:45":"also code and so like this is the kind","96:47":"of the ultimate example to me of of","96:51":"experimenting right is that you can now","96:56":"experiment and","96:58":"you'll see in in github it doesn't quite","97:00":"render properly this github doesn't","97:02":"quite know how to render notebooks","97:03":"properly but if you get plowing this and","97:05":"open it up in Jupiter you can see it and","97:08":"so now anything that you read about the","97:10":"documentation nearly everything of the","97:12":"documentation has actual working","97:14":"examples in it with actual data sets","97:16":"that are already sitting in there in the","97:17":"repo for you and so you can actually try","97:20":"every single function in your browser","97:23":"try seeing what goes in and try seeing","97:25":"what comes out there's a question and","97:29":"can will the library use multi GPU and","97:32":"parallel by default the library will use","97:36":"multiple CPUs by default but just one","97:38":"GPU by default we've probably what","97:41":"you're looking at maka GPU into your pot","97:43":"true it's easy to do and you'll find it","97:45":"on the forum but most people won't be","97:48":"needing to use that now and the second","97:51":"question is whether the library can use","97:54":"3d data centers in IR yes it can and","98:01":"there is actually a forum thread about","98:02":"that already although that's not as","98:06":"developed as 2d yet but maybe by the","98:07":"time the MOOC is out it will be so","98:11":"before I wrap up I'll just show you an","98:13":"example of the kind of interesting stuff","98:15":"that you can do by doing this kind of","98:19":"exercise remember earlier I mentioned","98:21":"that one of our alums who works at","98:24":"Splunk which is a nasdaq listed big","98:27":"successful company created this new ad","98:30":"fraud software this is actually how he","98:33":"created it as part of a fast AI part one","98:37":"class project he talked the telemetry of","98:40":"the of users who had Splunk analytics","98:43":"installed and watched their mouse","98:45":"movements and included pictures of the","98:47":"mouse movements he converted speed into","98:50":"color and right and left clicks into","98:53":"splotches he then took the exact code","98:57":"that we saw with an earlier version of","98:59":"the software and trained a CNN in","99:01":"exactly the way we saw and use that at a","99:05":"train his fraud model so he basically","99:06":"took something which is not obviously a","99:09":"picture and he turned it into a picture","99:11":"I've got these fantastically good","99:13":"results for police overall analysis","99:16":"software so it they're pleased to think","99:19":"creatively so if you're wanting to study","99:21":"sounds a lot of people that study sounds","99:24":"do it by actually creating a spectrogram","99:26":"image and then sticking that into a","99:29":"confident so there's a lot of cool stuff","99:30":"you can do with this so during the week","99:32":"yeah get your jet your GPU going try and","99:35":"use your first notebook make sure that","99:37":"you can use Lesson one and work through","99:40":"it and then see if you can repeat the","99:42":"process on your own data set get on the","99:45":"forum and tell us any little success you","99:47":"had it's like oh I spent three days","99:49":"trying to get my GPU running and I","99:51":"finally did any constraints you hit you","99:56":"know try it for an hour or two but if","99:58":"you get stuck please ask and if you're","100:00":"able to successfully build a model with","100:02":"a new data set let us know and I will","100:05":"see you next week","100:07":"[Laughter]"}},58:function(e){e.exports={"00:00":"welcome to lesson two where we're going","00:04":"to be taking a deeper dive into computer","00:08":"vision applications and taking some of","00:11":"the amazing stuff that you've all been","00:12":"doing during the week and going even","00:14":"further so let's take a look before we","00:17":"do a reminder that we have these two","00:21":"really important topics on the forums","00:25":"they're pinned at the top of the forum","00:28":"category one is factory sources and","00:30":"official course updates this is where if","00:33":"there's something useful for you to know","00:35":"during the course we will post there","00:38":"nobody else can reply to that thread so","00:40":"if you set that thread to watching and","00:42":"notifications you're not going to be","00:43":"bugged by anybody else except stuff that","00:46":"we think you need to know for the course","00:47":"and it's got all the official","00:50":"information about how to get set up on","00:52":"each platform please note a lot of","00:54":"people post all kinds of other tidbits","00:57":"about how they've set up things on","01:00":"previous solutions or previous courses","01:02":"or other places I don't recommend you","01:04":"use those because these are the ones","01:06":"that we're testing everyday and that the","01:08":"folks involved in these platforms are","01:09":"testing every day and they definitely","01:11":"work okay so so I would strongly suggest","01:14":"you follow those tips and if you do have","01:18":"a question about using one of these","01:20":"platforms please use these discussions","01:22":"not some other topic that you create","01:25":"because this way people that are","01:27":"involved in these platforms will be able","01:28":"to see it and things won't get messy and","01:30":"then secondly for every lesson there","01:35":"will be an official updates thread for","01:39":"that lesson so lesson one official","01:40":"updates and the same thing only first AI","01:42":"people will be posting to that so you","01:47":"can you can watch it safely and we'll","01:48":"have all the things like the videos the","01:50":"notebooks and so forth and they're all","01:54":"wiki threads so you can help us to make","01:56":"them better as well so I mentioned the","01:59":"idea of watching a thread so this is a","02:01":"really good idea is that you can go to a","02:03":"thread like particularly those official","02:05":"update ones and click at the bottom","02:07":"watching ok and if you do that that's","02:09":"going to enable notifications or any","02:11":"updates to that thread","02:13":"secondly if you go in to click on your","02:14":"little user name in the top right","02:16":"preferences and turn this on that'll get","02:19":"gives you an email as well okay so any","02:22":"of you that have missed some of the","02:23":"updates so far go back and have a look","02:25":"through because we're really trained to","02:28":"make sure that we keep you updated with","02:30":"anything that we think's important one","02:33":"thing which can be more little","02:34":"overwhelming is even now after just one","02:36":"week the most popular thread has one","02:39":"point 1000 replies so that's that's an","02:42":"intimidating Li large number um I've","02:45":"actually read every single one of them","02:46":"and I know Rachel has and I know silver","02:49":"has and I think Francisco has but you","02:52":"shouldn't need to what you should do is","02:55":"click summarize this topic and it'll","02:58":"appear like this which is all of the","03:00":"most liked ones will appear and then","03:02":"they'll be view 31 hidden replies or","03:04":"whatever in between so that's how you","03:06":"navigate these giant topics that also","03:09":"why it's important you click the like","03:11":"button because that's the thing that's","03:12":"going to cause people to to see it in","03:15":"this recommended view so when you come","03:21":"back to work hopefully you've realized","03:23":"by now that on the official course","03:25":"website course - v3 - faster day I you","03:28":"will click returning to work you will","03:30":"click the name of the platform you're","03:31":"using and you will then follow the two","03:34":"steps the step one will be how to make","03:37":"sure that you've got the latest","03:38":"notebooks and step two will be how to","03:41":"make sure you've got the latest Python","03:43":"library software okay","03:44":"they all look pretty much like this but","03:46":"they're slightly different from platform","03:48":"to platform so please don't use some","03:51":"different set of commands you read","03:52":"somewhere else only use the commands","03:54":"that you read about here and that will","03:56":"make everything very smooth if things","03:59":"aren't working for you if you get some","04:01":"into some kind of Matthew situation","04:02":"which we all do and you don't just","04:06":"delete your instance and start again","04:08":"unless you've got mission-critical stuff","04:09":"there it's the easiest way just to get","04:11":"out of a sticky situation and you know","04:13":"if you follow the instructions here you","04:16":"really should find it works fine","04:20":"so this is what I really wanted to talk","04:22":"about most of all is what people have","04:24":"been doing this week if you've noticed","04:27":"and a lot of you have so there's have","04:29":"been a hundred and sixty-seven people","04:30":"sharing their work and this is really","04:33":"cool because it's pretty intimidating to","04:35":"put yourself out there and say like I'm","04:37":"new to all this but here's what I've","04:39":"done and so example four things I","04:41":"thought was really interesting was","04:42":"figuring out who's talking is it Ben","04:45":"Affleck or Joe Rogan I thought this is","04:50":"really interesting this is like actually","04:51":"very practical I wanted to clean up","04:53":"while whatsapp downloaded images to get","04:55":"rid of memes so I actually built a","04:57":"little neural network I mean how cool is","04:59":"that to say like oh yeah I've got","05:01":"something that cleans up my whatsapp","05:03":"it's a deep learning application I wrote","05:05":"last week why not like it's so easy now","05:07":"you can do stuff like this and then","05:12":"there's been some really interesting","05:15":"projects one was looking at the the","05:20":"sounds data that was used in this paper","05:23":"and in this paper they were trying to","05:25":"figure out what kind of sound things","05:28":"were and they got a as you would expect","05:30":"since they published a paper they got a","05:31":"state of the art of nearly 80% accuracy","05:34":"Ethan Sutan then tried using the lesson1","05:37":"techniques and got 80 point 5 percent","05:40":"accuracy so I think this is pretty","05:41":"awesome best as we know it's a new state","05:44":"of the art for for this problem","05:47":"maybe somebody since then has published","05:49":"something we haven't found it yet they","05:50":"take all of these of a slight grain of","05:51":"salt but I've mentioned them on Twitter","05:54":"and lots of people on Twitter follow me","05:55":"so if everybody knew that there was a","05:56":"much better approach I'm sure somebody","05:58":"would have said so","06:01":"this one is pretty cool Subash has a new","06:03":"state of the art accuracy for for devin","06:08":"gary text recognition i think he's got","06:11":"it even higher than this now and this is","06:13":"actually confirmed by the person on","06:15":"twitter who created the data set like we","06:17":"I don't think he had any idea he just","06:19":"posted her here's a nice thing I did and","06:20":"this guy on Twitter was like oh I made","06:22":"that data set congratulations you've got","06:24":"a new record so that was pretty cool I","06:27":"really liked this poster milena Harley","06:31":"she describes in","06:33":"quite a bit of detail about the issue of","06:36":"them miss fastest sizing cancers and the","06:40":"use of point mutations and why that's a","06:42":"challenging important problem and she's","06:45":"got some nice pictures expert describing","06:47":"like what she wants to do with this and","06:48":"like how she can go about turning this","06:51":"into pictures see this is the cool trick","06:53":"right it's the same with this this","06:55":"sounds one turning sounds into pictures","06:58":"and then using the lesson1 approach and","07:00":"here it's turning point mutations into","07:03":"pictures and then using the lesson1","07:05":"approach and what did she find it seems","07:10":"that she's got a new strategy out result","07:12":"by more than 30%","07:13":"feeding the previous best somebody on","07:16":"twitter who's a VP at a genomics","07:17":"analysis company looked at this as well","07:21":"and you know thought it looked to be a","07:25":"state of the art in this particular","07:26":"point mutation one as well","07:28":"so that's pretty exciting so you can see","07:31":"you know when we talked about last week","07:32":"this idea that this simple process is","07:36":"something which can take you a long way","07:38":"it really can I will mention that you","07:42":"know something like this one in","07:43":"particular is is using a lot of domain","07:45":"expertise like it's figuring out what","07:48":"picture to create I wouldn't know how to","07:51":"do that because I don't even really know","07:53":"what a point mutation is let alone how","07:55":"to create you know something that","07:56":"visually is meaningful that a CNN could","07:59":"recognize but the actual big learning","08:02":"side is is actually pretty","08:04":"straightforward another very cool result","08:09":"from Simon Ellison and Natalie down they","08:14":"created a cougar or not web application","08:18":"over the weekend and won the science sex","08:21":"Day award in San Francisco and so I","08:25":"think that's pretty pretty fantastic so","08:28":"lots of examples of people doing really","08:30":"interesting work hopefully this will be","08:33":"inspiring to you to think well this is","08:36":"this is cool that I can do this with","08:38":"it can also be intimidating to think","08:40":"like wow these people are doing amazing","08:42":"things but it's important to realize","08:45":"that as a thousands of people during","08:46":"this course","08:47":"you know I'm just picking out the kind","08:50":"of a few of the really amazing ones and","08:53":"in fact Simon is one of these very","08:55":"annoying people like Christine Payne who","08:57":"talked about last week who seems to be","08:58":"good at everything he does","08:59":"he created Django when it's the world's","09:01":"most popular web frameworks he founded a","09:03":"very successful startup and bla bla bla","09:04":"bla bla so you know one of these really","09:06":"annoying people who tends to keep being","09:09":"good at things now turns out he's good","09:10":"at deep learning as well so you know","09:12":"that's fine you know Simon can go and","09:14":"win a hackathon on his first week of","09:16":"playing with deep learning maybe it'll","09:18":"take you two weeks to win your first","09:20":"hackathon that's okay um and I think","09:23":"like it's important to mention this","09:24":"because there was this really inspiring","09:25":"blog post this week from James Dellinger","09:28":"who talked about how he created a bird","09:31":"using the techniques from lesson one but","09:34":"what I really found interesting was at","09:35":"the end he said he he nearly didn't","09:37":"start on deep learning at all because he","09:40":"went through the scikit-learn website","09:42":"which is one of the most important","09:43":"libraries of python and he saw this and","09:46":"he described in this blog post or how he","09:48":"was just like that's not something I can","09:50":"do it's not something I understand and","09:52":"then this kind of realization of like oh","09:53":"I can do useful things without reading","09:57":"the Greek so I thought that was a really","09:59":"cool message and I really want to","10:02":"highlight actually Daniel Armstrong on","10:04":"the forum I think really shows is a","10:08":"great role model here which was here","10:09":"saying I want to contribute to the","10:11":"library and I looked at the docs and I","10:14":"just started overwhelming and the next","10:16":"message one day later was I don't know","10:20":"what it is this is I didn't know how","10:21":"much goes to it it caught me off guard","10:23":"my brain shut down but I love the way it","10:28":"forces me to learn so much and then one","10:30":"day later I just submitted my first pull","10:32":"request so I think that's also right","10:35":"it's just kind of like it's okay to feel","10:38":"intimidated there's a lot right but just","10:40":"pick one piece and dig into it you don't","10:43":"try and try and push a piece of code or","10:45":"a documentation update or create a","10:48":"classifier or whatever","10:49":"so here's lots of cool classifiers","10:51":"people have built it's been really","10:53":"really inspiring Trinidad and Tobago","10:57":"Islander versus macerator classifier a","10:59":"zucchini this is cue","11:01":"humbert classifier this one was really","11:04":"nice this was taking the dog breeds dog","11:08":"and cat breeds a thing from last week","11:10":"and actually doing some exploratory work","11:12":"to see what the main features were and","11:14":"discovered that there they could have","11:16":"create a hairiness and classifier and so","11:20":"we're here we do have the most harried","11:22":"dogs and the most bold cats so there are","11:26":"you know interesting things you can do","11:27":"with interpretation somebody else in the","11:29":"forum took that and did the same thing","11:30":"for anime to find that they had","11:32":"accidentally discovered an anime","11:33":"haircolor classifier we can now detect","11:37":"the new versus the old panamanian buses","11:40":"correctly apparently these are the new","11:42":"ones I much prefer the old ones but","11:44":"maybe that's just me this was a really","11:48":"interesting Henri Pollachi discovered","11:49":"that he can recognize with 85% accuracy","11:52":"which of 110 City sorry which with 110","11:56":"countries a satellite image is of which","12:00":"you know is definitely got to be beyond","12:03":"human performance of just about anybody","12:05":"like I can't imagine anybody who can do","12:08":"that in practice so that was fascinating","12:12":"but ik+ classification with a hundred","12:16":"percent accuracy those rewarded this","12:20":"interesting one we actually went a","12:21":"little bit further using some techniques","12:22":"we'll be discussing in the next couple","12:24":"of courses to build something that can","12:26":"recognize complete or incomplete or","12:28":"foundation buildings and actually plot","12:30":"them on aerial satellite view","12:34":"so lots and lots of fascinating projects","12:38":"so don't worry it's only been one week","12:40":"it doesn't mean everybody has to have","12:42":"had a project out yet a lot of the folks","12:44":"who already have a project out have done","12:46":"a previous course so they've got a bit","12:48":"of a head start but we'll see today how","12:51":"you can definitely create your own","12:53":"classifier this week so from today after","12:58":"we dig a bit deeper into really how to","13:01":"make these computer vision classifiers","13:03":"and particular work well we're then","13:06":"going to look at the same thing for text","13:08":"we're then going to look at the same","13:11":"thing for tabular data so they're kind","13:12":"of like more like spreadsheets and","13:14":"databases","13:15":"then we're going to look at Labrador","13:16":"filtering so we're going to","13:19":"recommendation systems that's going to","13:21":"take us into a topic called embeddings","13:23":"which is basically a key underlying","13:26":"platform behind these applications that","13:30":"will take us back into more computer","13:32":"vision and then back into more NLP so","13:35":"the idea here is that it turns out that","13:37":"it's it's much better for learning if","13:39":"you kind of see things multiple times so","13:43":"rather than being like okay that's","13:44":"computer vision you won't see it again","13:45":"for the rest of the course","13:46":"we're actually going to come back to the","13:48":"two key applications NLP and computer","13:51":"vision a few weeks apart and that's","13:53":"going to force your brain to realize","13:54":"like oh I have to remember this it's not","13:56":"just something I can throw away so we","14:03":"are you know for people who have more of","14:08":"a hard sciences kind of background in","14:12":"particular a lot of folks find this hey","14:18":"here's some code type it in start","14:20":"running it approach rather than here's","14:22":"lots of theory approach confusing and","14:25":"surprising and odd at first and so for","14:28":"those of those of you I just wanted to","14:30":"remind you you know this basic tip which","14:32":"is keep going now you're not expected to","14:35":"remember everything yes you're not","14:37":"expected to understand everything yet","14:39":"you're not expected to know why","14:41":"everything works yet you just want to be","14:45":"in a situation where you can enter the","14:47":"code and you can run it and you can get","14:50":"something happening and then you can","14:51":"start to experiment and you kind of get","14:54":"a feel for what's going on and then push","14:57":"on right most of the people who have","15:00":"done the course and have gone on to be","15:01":"really successful watch the videos at","15:03":"least three times so they kind of go","15:04":"through the whole lot and then go","15:06":"through it slowly the second time then","15:08":"they go through it really slowly the","15:10":"third time and I consistently hear them","15:11":"say I get a lot more out of it each time","15:14":"I go through so don't pause at lesson","15:16":"one and stop until you can continue so","15:21":"um this approach is based on a lot of a","15:26":"research academic research into learning","15:28":"theory","15:29":"and one guy in particular david perkins","15:31":"from harvard has this really great","15:33":"analogy he's a researcher into learning","15:36":"theory he describes this approach of the","15:38":"whole game which is basically if you're","15:40":"teaching a kid to play soccer you don't","15:43":"you know first of all teach them about","15:45":"you know how the friction between a ball","15:47":"and grass works and then teach them how","15:49":"to so soccer ball with their bare hands","15:52":"and then teach them the mathematics of","15:55":"parabolas when you kick something in the","15:56":"air no is a here's a ball let's watch","16:00":"some people playing soccer okay now","16:01":"we'll play soccer and then you you know","16:03":"gradually over the following years learn","16:06":"more and more so that you can get better","16:07":"and better at it so this is kind of what","16:09":"we're trying to get you to do is to play","16:11":"soccer which in our case is to type code","16:14":"and look at the inputs and look at the","16:16":"outputs okay so let's dig into our first","16:25":"notebook which is called lesson to","16:27":"download and what we're going to do is","16:30":"we're going to see how to create your","16:34":"own classifier with your own images so","16:38":"it's going to be a lot like last week's","16:40":"tech detector but it'll detect whatever","16:43":"you like so to be like those some of","16:45":"those examples we just saw how would you","16:47":"create your own Panama bus detector from","16:51":"scratch so this is inspired the","16:56":"approaches inspired by Adrian Rose Brock","16:59":"who has a terrific website called pie","17:00":"image search and he has this nice","17:04":"explanation of how to create a data set","17:07":"using Google images so that was","17:09":"definitely an inspiration for some of","17:11":"the techniques we use here so thank you","17:12":"to Adrian and you should definitely","17:14":"check out his site it's a really it's","17:16":"full of lots of good resources so so","17:22":"here we are so we are going to try to","17:24":"create a teddy bear detector thanks","17:31":"we're going to try and make a teddy bear","17:33":"detector and we're going to try and","17:35":"separate teddy bears from black bears","17:38":"from grizzly bears now this is very","17:40":"important","17:42":"I have a three year old daughter and she","17:44":"needs to know what she's dealing with in","17:47":"our house you would be surprised at the","17:49":"number of monsters lions and other","17:52":"terrifying threats that are around","17:53":"particularly around Halloween and so we","17:55":"always need to be on the lookout to make","17:57":"sure that the thing we're about to","17:59":"cuddle is in fact a genuine teddy bear","18:02":"so let's deal with that with that","18:04":"situation as best as we can so our","18:07":"starting point is to find some pictures","18:09":"of teddy bears so we can learn what they","18:12":"look like so I got a images.google.com","18:15":"and I type in teddy bear and I just","18:22":"scroll through until I kind of find a","18:25":"goodly bunch of them and it's like okay","18:29":"that looks like funny of teddy bears to","18:31":"me so then I'll go back to here so you","18:36":"can see it says search and scroll go to","18:37":"Google Images and search and the next","18:40":"thing we need to do is to get a list of","18:42":"all of the URLs there and so to do that","18:44":"you back in your google images you hit","18:48":"ctrl shift J or command option J and you","18:51":"paste this into the window that appears","18:58":"so I've got Windows so I go ctrl shift J","19:04":"paste in that code so this is a","19:06":"JavaScript console for those of you you","19:08":"haven't done in JavaScript before I hit","19:10":"enter and it downloads my file for me so","19:14":"I would call this Teddy's dot txt and","19:18":"press save okay so I now have a file of","19:24":"Teddy's or URLs of Teddy's so then I","19:28":"would repeat that process for black","19:31":"bears and for brown bears since that's a","19:34":"classifier I would want to now put each","19:35":"one in a file with an appropriate name","19:37":"so that's step one so step two is we now","19:41":"need to download those URLs to our","19:45":"server just remember it when we're using","19:47":"Jupiter notebook it's not running on our","19:49":"computer it's running on sage maker or","19:52":"Kressel or G Google Play","19:55":"or whatever so to do that we have we","19:59":"start running some Jupiter cells so","20:01":"let's grab the first AI library and","20:03":"let's start with black bears I've","20:06":"already got my black bears URL so I","20:08":"click on this cell for black bears and","20:09":"I'll run it so here I've got three","20:12":"different cells with doing the same","20:15":"thing but different information this is","20:17":"this is one way I like to work with","20:18":"Jupiter notebook it's something that a","20:20":"lot of kind of people with a more strict","20:23":"scientific background are horrified by","20:25":"this is not reproducible research I","20:27":"actually click here and I run this cell","20:28":"to create a folder called black and a","20:31":"file called URLs black for my black","20:33":"bears I skip the next two cells and then","20:35":"I run this cell to create that folder","20:40":"okay and then I go down to the next","20:44":"section and I run the next cell which is","20:48":"download images for black bears right so","20:53":"that's just going to download my black","20:55":"bears to that folder and then I'll go","20:57":"back and I'll click on Teddy's and I run","21:00":"that cell and then scroll back down and","21:02":"I'll run this cell and so that way I'm","21:05":"just going backwards and forwards to","21:06":"download each of the classes that I want","21:08":"very manual but for me I'm very","21:12":"iterative and very experimental that","21:14":"works well for me if you're better at","21:16":"kind of planning ahead than I am you can","21:18":"you know write a proper loop or whatever","21:20":"and and do it that way so but when you","21:23":"see my notebooks and see things where","21:26":"there's kind of like configuration cells","21:28":"doing the same thing in different places","21:30":"this is a strong sign that I I didn't","21:33":"run this in order right I clicked one","21:35":"place went to another around that went","21:37":"back went back went back and for me I","21:39":"just I'm an experimentalist I really","21:42":"liked to to experiment in my book I","21:45":"treat it like a lab journal I try things","21:47":"out may see what happens and so this is","21:49":"how my notebooks end up looking it's a","21:52":"really controversial topic like for a","21:54":"lot of people they feel this is like","21:56":"wrong that you should only ever run","21:59":"things top to bottom everything you","22:00":"should do should be reproducible for me","22:02":"I don't think that's the best way of","22:04":"using human creativity I think human","22:07":"creativity is best in","22:09":"by trying things out seeing what happens","22:11":"and fiddling around so you can see how","22:13":"you go see what works for you so that","22:17":"will download the images to your server","22:20":"it's going to use multiple processes to","22:24":"do so and one problem there is if is if","22:27":"something goes wrong it's a bit hard to","22:29":"see what went wrong so you can see in","22:31":"the next section there's a commented out","22:32":"section that says max workers equals","22:35":"zero and that'll do it without spitting","22:37":"up a bunch of processes and will tell","22:39":"you the errors better so if if things","22:41":"aren't downloading try using the second","22:43":"version okay so it takes so I you know","22:47":"grabbed a small number of each and then","22:51":"the next thing that I found I needed to","22:52":"do was to remove the images that aren't","22:55":"actually images at all and this happens","22:57":"all the time there's always a few images","22:59":"in every batch that are corrupted for","23:03":"whatever reason you know Google Image","23:05":"tried to told us that this URL had an","23:07":"image but actually it doesn't anymore so","23:10":"I've got we've got this thing in the","23:11":"library called verify images which will","23:14":"check all of the images in a path and","23:16":"will tell you if there's a problem if","23:19":"you say delete equals true it will","23:21":"actually delete it for you okay so","23:23":"that's a really nice easy way to end up","23:25":"with a clean data set so at this point I","23:29":"now have a bears folder containing a","23:33":"grizzly folder and a Teddy's folder and","23:35":"the black folder in other words I have","23:38":"the basic structure we need to create an","23:40":"image data bunch to start doing some","23:42":"deep learning so let's go ahead and do","23:44":"that now very often when you get when","23:51":"you download a data set from like Kaggle","23:53":"or from some academic data set there","23:56":"will often be a folder called train and","23:59":"a folder called valid and a folder","24:01":"called test right containing the","24:03":"different data sets in this case we","24:06":"don't have a separate validation set","24:07":"because we just rid of grab these images","24:10":"from Google search right but you still","24:13":"need a validation set otherwise you","24:16":"don't know how well your model is going","24:18":"and we'll talk about more about this in","24:19":"a moment so whatever you create a data","24:22":"bunch","24:23":"if you don't have a separate training","24:25":"and validation set then you can just say","24:27":"okay well the training set is in the","24:29":"current folder because by default it","24:31":"looks in a folder called train and I","24:33":"want you to set aside 20 percent of the","24:36":"data please so this is going to create a","24:38":"validation set for you automatically and","24:40":"randomly you'll see that whenever I","24:43":"create a validation set randomly I","24:46":"always set my random seed to something","24:48":"fixed beforehand this means that every","24:51":"time I run this code I'll get the same","24:53":"validation set so in general I'm not a","24:59":"fan of making my machine learning","25:03":"experiments reproducible are you","25:05":"ensuring I get exactly the same result","25:07":"every time the randomness is to me","25:09":"really important a really important part","25:11":"of planning out is your solution stable","25:13":"you know these are going to work like","25:14":"each time you run it but what is","25:17":"important is that you always have the","25:18":"same validation set but otherwise when","25:21":"you're trying to decide has this hyper","25:24":"parameter change improved my model but","25:26":"you've got a different set of data","25:28":"you're testing it on then you don't know","25:30":"maybe that set of data it just happens","25:31":"to be a bit easier okay so that's why I","25:34":"always said the random seed here","25:37":"so we've now gone let's run that cell so","25:40":"we've now got a data bunch and so you","25:43":"can look inside at the data classes and","25:46":"you'll see these are the folders that we","25:48":"created so it knows that the classes or","25:51":"you know so by classes we main all the","25:52":"possible labels black bear grizzly bear","25:55":"or teddy bear we can run show batch and","25:58":"we can take a little look and it tells","26:02":"us straight away that some of these are","26:03":"going to be a little bit tricky so this","26:06":"is not a photo for instance some of them","26:11":"kind of crops funny some of them might","26:15":"be tricky like if you ended up with a","26:16":"black bear standing on top of a grizzly","26:18":"bear that might be tough anyway so you","26:21":"can kind of double check here data type","26:22":"classes there they are remember C is the","26:25":"attribute which the classifiers tells us","26:28":"how many possible labels that are we'll","26:30":"learn about some other more specific","26:31":"meanings at C later we can see how many","26:34":"things around now training set","26:37":"we can see how many things are in our","26:38":"validation set so we've got 473 trading","26:46":"set 141 validation set so at that point","26:50":"we can go ahead you'll see all these","26:51":"commands are identical to the pet","26:53":"classifier from last week we can create","26:56":"our CNN our convolutional neural network","26:59":"using that data I tend to default using","27:02":"a resin at 34 and let's print out the","27:05":"error rate each time and run fit one","27:08":"cycle four times and see how we go and","27:11":"we have a two percent error rate so","27:14":"that's pretty good I personally aren't","27:16":"for I mean some sometimes it's easy for","27:18":"me to recognize a black bear from a","27:19":"grizzly bear but sometimes it's a bit","27:21":"tricky this one seems to be doing pretty","27:23":"well okay so after I kind of make some","27:32":"progress with my model and things","27:33":"looking good I always like to save where","27:35":"I'm up to to save me the 54 seconds of","27:37":"going back and doing it again and as","27:39":"very usual we unfreeze the rest of our","27:42":"model we're going to be learning more","27:43":"about what that means during the course","27:45":"and then we run the learning rate finder","27:49":"and plot it tells you exactly what to","27:51":"type and we take a look now we're going","27:54":"to be learning about learning rates","27:56":"today actually but for now here's what","27:59":"you need to know on the learning rate","28:01":"finder what you're looking for is the","28:03":"strongest downward slope that's kind of","28:07":"sticking around for quite awhile right","28:10":"so this one here looks more like a bump","28:12":"but this looks like an actual downward","28:14":"slope to me so it's kind of like it's","28:16":"something you're going to have to","28:17":"practice with and get a feel for like","28:19":"what which fit works so like if you're","28:22":"not sure is it this bit or this bit try","28:25":"both learning rates and see which one","28:27":"works better","28:28":"okay but I'm I've been doing this for a","28:30":"while and I'm pretty sure this looks","28:32":"like where it's really learning properly","28:34":"so I would pick something okay here it's","28:37":"not so steep so I would probably pick","28:39":"something back here for my learning rate","28:43":"so you can see I picked three next five","28:47":"so you know somewhere around here that","28:50":"sounds pretty good so that's for my","28:52":"bottom learning rate so my top learning","28:54":"rate I normally pick you know one a neg","28:57":"four or three neg four it's kind of like","28:59":"I don't really think about it too much","29:00":"that's a rule of thumb it always works","29:02":"pretty well one of the things you'll","29:05":"realize is that most of these parameters","29:09":"don't actually matter that much in","29:11":"detail if you just copy the numbers that","29:14":"I use each time it'll the vast majority","29:17":"the time it'll just work fine and we'll","29:19":"see places where it doesn't today okay","29:22":"so we've got a one point four percent","29:24":"error rate after doing another couple of","29:26":"epochs so that's looking great so we've","29:28":"downloaded some images from Google Image","29:31":"Search and created a classifier we've","29:34":"got one point four percent error rate","29:35":"let's save it and then as per usual we","29:40":"can use the classification","29:41":"interpretation class to have a look at","29:44":"what's going on and in this case we made","29:46":"one mistake there was one black bear","29:49":"classified as grizzly bear so that's","29:54":"that's a really good step we come a long","29:57":"way but possibly you could do even","30:01":"better if your data set was less noisy","30:04":"like maybe Google Image Search didn't","30:08":"give you exactly the right images all","30:10":"the time so how do we fix that and so we","30:13":"want to we want to clean it up and so","30:15":"combining a human expert with a computer","30:19":"learner is a really good idea almost not","30:22":"no-nobody but very very few people","30:24":"publish on this very very few people","30:25":"teach this but to me it's like the most","30:29":"useful skill particularly for you you","30:31":"know most of the people watching this at","30:33":"domain experts not computer science","30:35":"experts and so this is where you can use","30:38":"your knowledge of you know point","30:41":"mutations in genomics or panamanian","30:43":"buses or whatever so let's see how that","30:46":"would work what I'm going to do is do","30:49":"you remember the plot top losses from","30:51":"last time where we saw the images which","30:52":"it was like either the most wrong about","30:55":"or the least confident about we're going","30:57":"to look at those","30:58":"and decide which of those are noisy like","31:02":"if you think about it it's very unlikely","31:05":"that if there is a mislabeled data that","31:09":"it's going to be predicted correctly and","31:11":"with high confidence but that that's","31:13":"really unlikely to happen so we're going","31:15":"to focus on the on the ones which the","31:18":"model is saying either it's not","31:20":"confident of or it was confident of that","31:23":"it was wrong about they are the things","31:25":"which might be mislabeled so a big","31:31":"shout-out to the San Francisco fast AI","31:34":"study group who created this new widget","31:37":"this week called the failed Aleta so","31:41":"that's Zach and Jason and Francisco","31:45":"built this thing where we basically can","31:47":"take the top losses from that","31:50":"interpretation object we just created","31:52":"right and then what we're going to do is","31:55":"we're going to say okay that returns top","31:57":"loss it there's not just plot top losses","31:59":"but there's also just top losses and top","32:01":"losses returns two things the losses of","32:04":"the things that were the worst and the","32:07":"indexes into the data set the things","32:10":"that were the worst and if you don't","32:11":"pass anything at all it's going to","32:13":"actually return the entire data set but","32:16":"sorted so the first things will be the","32:19":"highest losses as we learned during the","32:22":"course or will keep ginger in the course","32:24":"every data set in fast AI has an X and a","32:29":"Y and the X contains the things that are","32:31":"used to in this case get the images so","32:34":"this is the image file names and the Y's","32:36":"will be the labels so if we grab the","32:39":"indexes and pass them into the data set","32:41":"X this is going to give us the file","32:45":"names of the data set ordered by which","32:49":"ones had the highest loss so which ones","32:52":"it was either confident and wrong about","32:54":"or not confident about and so we can","32:58":"pass that to this new widget that","33:00":"they've created called the file 2-liter","33:02":"widget","33:07":"so just to clarify this top plus past","33:10":"contains all of the file names in our","33:14":"when I think it our data set and this","33:16":"particular one is in our validation data","33:18":"set so what this is going to do is it's","33:20":"going to clean up mislabeled images or","33:25":"images that shouldn't be there and we're","33:29":"going to remove them from a validation","33:30":"set so that our metrics will be more","33:32":"correct you then need to rerun these two","33:36":"steps replacing valid des with trained","33:38":"yes","33:39":"to clean up your training set to get the","33:41":"noise out of that as well so it's a good","33:44":"practice to do both","33:46":"we'll talk about test sets later as well","33:48":"if you also have a test set you would","33:50":"then repeat the same thing so we run","33:53":"failed a leader passing in that sort of","33:56":"list of paths and so what pops up is","33:59":"basically the same thing as plot top","34:02":"losses so in other words these are the","34:05":"ones which is either wrong about or at","34:08":"least confident about and so not","34:10":"surprisingly this one here does not","34:12":"appear to be a teddy bear or a black","34:16":"bear or a brown bear right so this","34:18":"shouldn't be in our data set so what I","34:20":"do is I work on the delete button okay","34:24":"and all the rest do look indeed like","34:26":"bears and then so I can click confirm","34:28":"and it'll bring up another five what's","34:32":"that is that's not a bear is it so","34:35":"anybody know what that is I'm going to","34:38":"say that's not a bear delete confirm oh","34:43":"not there well that's a teddy bear I'll","34:47":"leave that that's not really I'll get","34:49":"rid of that one","34:50":"confirm okay so what I tend to do when I","34:54":"do this is I'll keep going confirm until","34:57":"I get to a couple of screen for the","34:58":"things that all look okay and that","35:00":"suggests to me that I've kind of got","35:02":"past the worst bits of the data okay and","35:05":"that's it and so now you can go back","35:07":"once you do it for the training set as","35:09":"well and retrain your model so I'll just","35:13":"note here that what our San Francisco","35:16":"study group did here was that they","35:18":"actually built a little app","35:20":"inside Jupiter notebook which you might","35:23":"not have realized as possible but not","35:25":"only is it possible it's actually","35:28":"surprisingly straightforward and just","35:31":"like everything else you can hit double","35:32":"question mark to find out their secrets","35:35":"so here is the source code okay and","35:38":"really if you've done any GUI","35:41":"programming before it'll look incredibly","35:44":"normal you know there's there's","35:47":"basically callbacks for what happens","35:48":"when you click on a button where you","35:50":"just do standard Python things and to","35:53":"actually render it you just use widgets","35:56":"and you can lay it out using standard","35:58":"boxes and whatever so it's it this idea","36:03":"of creating applications inside","36:05":"notebooks is like it's really underused","36:08":"but it's super neat because it lets you","36:10":"create tools for your fellow","36:13":"practitioners to your fellow","36:14":"experimenters right and you could","36:17":"definitely envisage taking this a lot","36:20":"further in fact by the time you're","36:21":"watching this on the MOOC you will","36:23":"probably find that there's a whole lot","36:25":"more buttons here because we've already","36:26":"got a long list of to do that we're","36:28":"going to add to this particular thing so","36:33":"so that's it so I think like I'd love","36:38":"for you to have a think about now that","36:40":"you know it's possible to write","36:42":"applications in your notebook what are","36:44":"you going to write and if you google for","36:47":"I PI widgets you can learn about the","36:52":"little GUI framework to find out what","36:56":"kind of widgets you can creation what","36:58":"they look like and how they work and so","37:00":"forth and you'll find it's you know it's","37:02":"actually a pretty you know complete GUI","37:06":"programming environment you can play","37:09":"with and this will all work nicely with","37:11":"your models and so forth it's not a","37:14":"great way to productionize an","37:16":"application because it is sitting inside","37:18":"a notebook this is really for things","37:20":"which are going to help other","37:23":"practitioners other experimentalists and","37:26":"so forth for production izing things you","37:30":"need to actually build a production web","37:33":"app which","37:34":"look at next okay so after you have","37:39":"cleaned up your noisy images you can","37:43":"then retrain your model and hopefully","37:45":"you'll find it's a little bit more","37:46":"accurate one thing you might be","37:48":"interested to discover when you do this","37:50":"is it actually doesn't matter most of","37:53":"the time very much now I'm on the whole","37:55":"these models are pretty good at dealing","37:58":"with moderate amounts of noisy data the","38:03":"problem would occur is if your data was","38:06":"not randomly noisy but biased noisy so I","38:10":"guess the main thing I'm saying is if","38:11":"you go through this process of cleaning","38:13":"up your data and then rerun your model","38:15":"and point it's like point zero one","38:16":"percent better that's normal","38:19":"okay that's that's it's fine but it's","38:21":"still a good idea just to make sure that","38:22":"you don't have too much noise in your","38:25":"data in case it is biased so at this","38:27":"point we're ready to put our model in","38:30":"production and this is where I hear a","38:34":"lot of people ask me about you know","38:37":"which mega Google Facebook highly","38:42":"distributed serving system they should","38:45":"use and how do they use a thousand GPUs","38:48":"at the same time and whatever else for","38:51":"the bath bath vast majority of things","38:53":"that you all do you will want to","38:56":"actually run in production on a CPU not","38:59":"a GPU why is that because the GPU is","39:02":"good at doing lots of things at the same","39:04":"time but unless you have a very busy","39:06":"website it's pretty unlikely that you're","39:08":"going to have 64 images to classify at","39:11":"the same time to put into a batch into a","39:14":"GPU and if you did you've got to deal","39:16":"with all that queuing and running it all","39:18":"together all of your users have to wait","39:20":"until that batch has got filled up and","39:21":"run it's a whole lot of hassle right and","39:24":"then if you want to scale that there's","39:26":"another whole lot of hassle it's much","39:28":"easier if you just wrap one thing throw","39:32":"it at a CPU to get it done and it comes","39:34":"back again so yes it's going to take you","39:38":"know maybe 10 or 20 times longer right","39:41":"so maybe it'll take 0.2 seconds rather","39:44":"than 0.01 seconds that's about the kind","39:47":"about but it's so easy to scale all","39:50":"right you can chuck it on any standard","39:52":"serving infrastructure it's going to be","39:54":"cheap as hell","39:55":"you can horizontally scale it really","39:57":"easily okay so most people I know who","40:00":"are running apps that aren't kind of at","40:02":"Google scale based on deep learning are","40:04":"using CPUs and the term we use is","40:07":"inference right so when you're running","40:09":"when you're not training a model but","40:11":"you've got a trained model and you're","40:12":"getting to predict things we call that","40:14":"inference so that's why we see here you","40:16":"probably want to use CPU for inference","40:21":"so at inference time you've got your pre","40:24":"trained model you saved those weights","40:26":"and how are you going to use them to","40:29":"create something like Simon relations","40:31":"cougar detector well first thing you're","40:34":"going to need to know is what were the","40:35":"classes that you trained with right you","40:39":"need to not know not just what are they","40:41":"but what were the order okay so you will","40:44":"actually need to like serialize that or","40:47":"just type them in or in some way make","40:49":"sure you've got exactly the same classes","40:51":"that you trained with if you don't have","40:56":"a GPU on your server it will use the CPU","40:59":"automatically if you want to test if you","41:02":"have a GPU machine and you want to test","41:04":"using a CPU you can just uncomment this","41:06":"line and that tells first AI that you","41:09":"want to use CPU by passing it back to","41:13":"pay torch so here's an example we're not","41:16":"we don't have a cougar detector we have","41:18":"a teddy bear detector and my daughter","41:21":"Claire is about to decide whether to","41:23":"cuddle his friend okay so what she does","41:26":"is she takes daddy's deep learning model","41:29":"and she gets a picture of this and","41:31":"here's a picture that she's uploaded to","41:32":"the web app okay and here's a picture of","41:35":"the potentially cattle some object and","41:39":"so we're going to store that in a","41:40":"variable called image so open image is","41:42":"how you open an image in fast AI finally","41:44":"enough here is that list of classes that","41:48":"we saved earlier and so as per usual we","41:52":"created a data bunch but this time we're","41:55":"not going to create a data bunch from a","41:57":"folder full of images we're going to","42:00":"create a special kind of data bunch","42:01":"which is one that's going to grab one","42:03":"single image at a time so we're not","42:06":"actually passing at any data the only","42:09":"reason we pass it a path is so that it","42:11":"knows where to load our model from right","42:13":"that's just the path that's the folder","42:15":"that the model is going to be in but","42:18":"what we do need to do is that we need to","42:19":"pass it the same information that we","42:21":"trained with so the same transforms the","42:23":"same size the same normalization this is","42:26":"all stuff we'll learn more about but","42:28":"just make sure it's the same stuff that","42:29":"you use the port and so now you've got a","42:31":"data bunch that actually doesn't have","42:33":"any data in it at all it's just","42:35":"something that knows how to transform a","42:38":"new image in the same way that you","42:40":"trained with so that you can now do","42:41":"inference so you can now create a CNN","42:45":"with this kind of fake data bunch and","42:47":"again you would use exactly the same","42:49":"model that you trained with you can now","42:52":"load in those saved weights okay and so","42:55":"this is the stuff that you do once just","42:58":"once when your web app starting up okay","43:00":"and it takes you know 0.1 of a second to","43:02":"run this code and then you just go learn","43:05":"to predict image and it's lucky we did","43:09":"that because it is not a teddy bear this","43:12":"is actually a black bear so thankfully","43:14":"due to this excellent deep learning","43:18":"model my daughter will avoid having a","43:21":"very embarrassing black bear cut or","43:24":"incident so what does this look like in","43:28":"production well I took Simon Wilson's","43:31":"code and shamelessly stole it made it","43:35":"probably a little bit worse and but","43:38":"basically it's going to look something","43:39":"like this so Simon used a really cool","43:41":"web app toolkit called starlett if","43:44":"you've ever used flask","43:46":"this will look extremely similar but","43:47":"it's kind of a more modern approach by","43:51":"modern what I really mean is that you","43:53":"can use a weight it's basically means","43:57":"that you can wait for something that","43:59":"takes a while such as grabbing some data","44:03":"without using up a process so for things","44:06":"like I want to get a prediction or I","44:08":"want to load up some data or whatever","44:09":"it's really great to be able to use this","44:12":"modern Python 3 asynchronous stuff","44:15":"so starlet would come highly recommended","44:17":"for creating your web app and so yeah","44:21":"you just create a route as per usual in","44:24":"a web app and in that you say this is","44:28":"you say this is a think to ensure that","44:31":"it doesn't steal the process while it's","44:34":"waiting for things you open your image","44:36":"you call dot predict and you return that","44:40":"response and then you can use a you know","44:42":"whatever JavaScript client or whatever","44:45":"to to show it and that's it that's","44:48":"basically the the main contents of your","44:51":"web app so give it a go right you know","44:57":"this week even if you've never created a","45:00":"web application before there's a lot of","45:02":"you know nice little tutorials online","45:05":"and kind of start a code you know if in","45:08":"doubt why don't you try a solid there's","45:11":"a free hosting that you can use there's","45:15":"one called Python Python anywhere for","45:17":"example the one that Simon's used will","45:20":"go mentioned that on the forum it's","45:22":"something you can basically package it","45:23":"up as a docker thing and should it off","45:25":"and it'll serve it up for you so it","45:28":"doesn't even need to cost you any money","45:29":"and so all these classifiers that you're","45:32":"creating you can turn them into web","45:34":"applications so I'll be really","45:36":"interested to see what you're able to to","45:40":"make of that that will be really fun","45:43":"okay so let's take a break we'll come","45:47":"back at 7:35 see you then:","45:55":"okay so let's move on so I mentioned","46:07":"that most of the time the kind of rules","46:13":"of farm I've shown you will probably","46:15":"work and if you look at the share your","46:18":"work thread you'll find most of the time","46:20":"people are posting things saying I","46:22":"downloaded these images I tried this","46:24":"thing they worked much better than","46:27":"expected well that's cool","46:29":"and then like 1 out of 20 says like ah I","46:33":"had a problem so let's have a talk about","46:36":"what happens when you have a problem and","46:38":"this is where we're status start getting","46:39":"into a little bit of theory because in","46:42":"order to understand why we have these","46:43":"problems and how we fix them it really","46:45":"helps to know a little bit about what's","46:46":"going on so first of all let's look at","46:49":"examples of some problems the problems","46:52":"basically will be either your learning","46:55":"rate is too high or low or your number","46:58":"of epochs is too high or low so we're","47:01":"going to learn about what does mean and","47:02":"why they matter but first of all because","47:06":"we're experimentalists let's try them","47:08":"all right so let's grow with our teddy","47:10":"bear detector and let's make our","47:13":"learning rate really high the default","47:16":"learning rate is zero point zero zero","47:18":"three that works most of the time so","47:21":"what if we try a learning rate of 0.5","47:23":"that's huge","47:24":"what happens our validation Lofts gets","47:28":"pretty damn high remember this is","47:31":"normally something that's underneath one","47:33":"right so if you see your validation loss","47:36":"do that right before we even learn what","47:39":"validation loss is just know this if it","47:41":"does that your learning rates too high","47:43":"that's all you need to know okay make it","47:47":"lower doesn't matter how many epochs you","47:49":"do it's and if this happens there's no","47:52":"way to undo this you have to go back and","47:54":"create your neural net again and fit","47:57":"from scratch with a lower learning rate","47:59":"so that's learning rate to high learning","48:02":"rate to low what if we use a learning","48:06":"rate not of 0.003 but one a next five so","48:12":"0.00001 right so this is just I've just","48:17":"copied and pasted what happened when we","48:19":"trained before with a default error","48:20":"right now without default learning rate","48:22":"and within one epoch we were down to a","48:24":"two or three percent error rate with","48:27":"this really low learning rate our error","48:30":"rate does get better but very very","48:33":"slowly right and you can plot it if you","48:37":"go learn to learn dot recorder is an","48:40":"object which is going to keep track of","48:42":"happening where you train you can call","48:44":"plot losses to print to plot out the","48:46":"validation and training loss and you can","48:50":"just see them just like gradually going","48:52":"down so slow right so if you see that","48:55":"happening then you have a learning rate","48:58":"which is too small okay so bump it up by","49:01":"10 or bump it up by 100 and try again","49:05":"the other thing you'll see if your","49:07":"learning rate is too small is that your","49:10":"training loss will be higher than your","49:13":"validation loss you never want a model","49:18":"where your training loss is higher than","49:21":"your validation loss that always means","49:24":"you haven't fitted enough which means","49:27":"either your learning rate is too low or","49:30":"your number of epochs is too low so if","49:32":"you have a model like that train it some","49:35":"more or train it with a higher learning","49:38":"rate okay too few epochs so what if we","49:45":"train for just one epoch our error rate","49:49":"certainly better than random 5% but look","49:53":"at this the difference between training","49:55":"loss and validation loss a training loss","49:57":"is much higher than the validation loss","49:59":"so too few epochs and to lower learning","50:04":"rate look very similar right and so you","50:07":"can just try running more epochs and if","50:09":"it's taking forever you can try a higher","50:10":"learning rate where we try a higher","50:12":"learning rate and the loss goes off to","50:15":"100,000 million then put it back to","50:17":"where it was and try a few more epochs","50:19":"that's the balance right that's","50:21":"basically all you care about 99% of the","50:25":"time and this is only the one in 20","50:26":"times that the defaults don't work for","50:28":"you okay too many epochs we're going to","50:33":"be talking more about this create","50:34":"something called overfitting if you","50:37":"train for too long as we're going to","50:38":"learn about it will learn to recognize","50:40":"your particular teddy bears","50:43":"but not teddy bears in general here's","50:46":"the thing despite what you may have","50:48":"heard it's very hard to overfit with","50:50":"deep learning so we were trying today to","50:53":"show you an example of overfitting and I","50:55":"turned off","50:56":"and I turned off everything","51:00":"I turned and we're going to learn all","51:01":"about these terms soon I turned up all","51:03":"the data augmentation I turned off","51:07":"dropout I turned off weight decay I","51:09":"tried to make it over fit as much as I","51:10":"can I trained it on a small issue","51:13":"earning rate I trained it for a really","51:14":"long time and like maybe I started to","51:19":"get it to overfit maybe but so the only","51:25":"thing that tells you that your","51:27":"overfitting is that the error rate","51:29":"improves for a while","51:31":"and then starts getting worse again you","51:36":"will see a lot of people even people","51:39":"that claim to understand machine","51:41":"learning tell you that if you're","51:43":"training loss is lower than your","51:46":"validation loss then you are overfitting","51:48":"as you will learn today in more detail","51:51":"and during the rest of course that is","51:52":"absolutely not true","51:54":"any model is trained correctly will","51:57":"always have trained loss lower than","51:59":"validation loss that is not a sign of","52:01":"overfitting that is not a sign you've","52:02":"done something wrong that is a sign you","52:04":"have done something right okay the sign","52:08":"that you are overfitting is that your","52:10":"error start getting worse because that's","52:12":"what you care about right you want your","52:14":"model to have a low error so as long as","52:16":"your training and your model error is","52:19":"improving you are not overfitting how","52:22":"could you be okay so there's a basically","52:25":"the four possible there the main four","52:26":"things that can go wrong there are some","52:28":"other details that we will learn about","52:30":"during the rest of this course but","52:32":"honestly if you stopped listening now","52:34":"please don't that would be embarrassing","52:36":"and you just like okay I'm going to go","52:39":"and download images I'm going to create","52:42":"CNN's with resinate 34 or isn't it 50","52:44":"I'm going to make sure that my learning","52:46":"rate and number of epochs is okay and","52:47":"then I'm going to check them up in a in","52:49":"a starlet Web API most of the time","52:53":"you're done okay at least your computer","52:55":"vision hopefully you'll stick around","52:58":"because you want to learn about NLP and","53:01":"collaborative filtering and tabular data","53:03":"and segmentation and stuff like that as","53:06":"well","53:10":"let's now understand what's actually","53:14":"going on what does it mean loss mean","53:17":"water as an epoch man what is learning","53:20":"rate mean because for you to really","53:21":"understand these ideas you need to know","53:24":"what's going on and so we're going to go","53:26":"all the way to the other side rather","53:28":"than creating a state-of-the-art Krueger","53:32":"detector we're going to go back and","53:35":"create the simplest possible linear","53:37":"model okay so we're going to actually","53:41":"start seeing we're actually going to","53:47":"start seeing a little bit of math okay","53:50":"but don't be turned off it's okay right","53:53":"we're going to do a little bit of math","53:55":"but it's going to be totally fine","53:57":"even if maths not your thing because the","53:59":"first thing we're going to realize is","54:01":"that when we see a picture like this","54:03":"number eight it's actually just a bunch","54:06":"of numbers it's a matrix of numbers for","54:09":"this grayscale or one it's a matrix of","54:11":"numbers if it was a color image it would","54:14":"be have a third dimension so when you","54:18":"add an extra dimension we call it a","54:19":"tensor rather than a matrix it would be","54:21":"a 3d tensor of numbers red green and","54:25":"blue so when we created that teddy bear","54:31":"detector what we actually did was we","54:34":"created a mathematical function that","54:37":"took the numbers from the images of the","54:39":"teddy bears and the mathematical","54:41":"function converted those numbers into in","54:45":"our case three numbers a number for the","54:48":"probability that it's a teddy a","54:50":"probability that it's a grizzly and the","54:52":"probability is a black bear in this case","54:54":"there's some hypothetical function","54:56":"that's taking the pixels representing a","54:58":"handwritten digit and returning ten","55:01":"numbers the probability for each","55:04":"possible outcome the numbers from zero","55:07":"to nine and so what you'll often see in","55:12":"in our code and other deep learning code","55:15":"is that you're you'll find this a bunch","55:18":"of probabilities and then you'll find","55:20":"something called Max or Arg max","55:23":"attached to it a function called and so","55:26":"what that function is doing is it's","55:27":"saying find the highest number to the","55:30":"highest probability and tell me what the","55:33":"index is","55:34":"so NP dog Max or torch dog max of this","55:38":"array would return this number here okay","55:42":"we return index hey that makes sense in","55:45":"fact let's try it so we know that the","55:52":"function to predict something is called","55:55":"learn dot predict okay so we can check","56:03":"two question marks before or after it to","56:05":"get the source code and here it is right","56:09":"pred equals res result Arg max and then","56:15":"what is the class where you just pass","56:17":"that into the classes array so like you","56:19":"should find that the source code in the","56:21":"Farsi library can both kind of","56:25":"strengthen your understanding of the","56:27":"concepts and make sure that you know you","56:29":"know what's going on and and really help","56:31":"you here you've got a question come on","56:34":"over we have a definition of the error","56:40":"rate being discussed and how it is","56:42":"calculated I assume it's cross","56:44":"validation error sure so one way to","56:50":"answer the question of how is error rate","56:52":"calculated would be to type error rate","56:56":"question mark and look at the source","56:58":"code and it is one - accuracy fair","57:03":"enough and so then a question might be","57:05":"what is accuracy accuracy question mark","57:10":"it is AG max so we now know that means","57:14":"find out which particular thing it is","57:16":"and then look at how often that equals","57:19":"the target so in other words the actual","57:21":"value and take the mean so that's","57:24":"basically what it is and so then the","57:27":"question is okay well what does that","57:28":"being applied to and always in faster","57:32":"far say I metrics so these things that","57:35":"we pass in we call","57:37":"metrics are always going to be applied","57:39":"to the validation set okay","57:42":"so anytime you put a metric here it'll","57:45":"be applied to the validation set because","57:47":"that's your best practice right that's","57:48":"like that's what you always want to do","57:50":"is make sure that you're checking your","57:53":"performance on data that your model","57:56":"hasn't seen and we'll be learning more","57:58":"about the validation set","57:59":"shortly remember you can also type doc","58:05":"if the source code is not what you want","58:08":"which it will not be you actually want","58:10":"the documentation that will both give","58:13":"you a summary of the types in and out of","58:17":"the function and a link to the full","58:20":"documentation where you can find out all","58:23":"about how metrics work and what other","58:26":"metrics there are and so forth and","58:30":"generally speaking you'll also find","58:32":"links to more information where for","58:36":"example you will find complete runs","58:38":"through and sample code and so forth","58:40":"showing you how to use all these things","58:41":"so don't forget that the doc function is","58:45":"your friend okay","58:47":"and also in the documentation both in","58:50":"the doc function and in the","58:52":"documentation you'll see a source link","58:54":"this is like question mark question mark","58:56":"but what the source link does is it","59:00":"takes you into the exact line of code in","59:03":"github so you can see exactly how that's","59:05":"implemented and what else is around it","59:06":"so lots of good stuff there why were you","59:12":"using threes for your learning rates","59:14":"earlier with three back five and three","59:17":"next four we found that three a neg","59:25":"three is that just a really good default","59:27":"learning rate it works most of the time","59:30":"for your initial fine-tuning before you","59:34":"unfreeze and then I tend to kind of just","59:38":"multiply from there so I generally find","59:40":"then that the the next stage I will pick","59:43":"ten times lower than that so the second","59:46":"part of the slice and whatever the LR","59:48":"Finder found for the first part of this","59:51":"the second part of the slice doesn't","59:54":"come from the LR finder it's just a rule","59:55":"of thumb which is like ten times less","59:57":"than your your first part which defaults","60:00":"to three in x-ray and then the first","60:03":"part of the slice is what comes out of","60:05":"the LR finder and we'll be learning a","60:06":"lot more about these learning rate","60:08":"details both today and in the coming","60:11":"lessons but yeah for now","60:13":"all you need to remember is that in your","60:15":"you know your basic approach looked like","60:17":"this it was learned fit one cycle some","60:23":"number of epochs I often pick four and","60:26":"some learning rate which defaults to 3e","60:29":"next three I'll just type it up fully so","60:33":"you can see and then we do that for a","60:35":"bit and then we unfreeze it right and","60:39":"then we learn some more and so this is a","60:43":"bit where I just take whatever I did","60:45":"last time and divided by ten and then I","60:49":"also write like that and then I have to","60:53":"put one more number in here and that's","60:57":"the number that I get from the learning","60:58":"rate finder a bit where it's got the","61:00":"strongest slope so that's kind of the","61:02":"kind of don't have to think about it","61:05":"don't really have to know what's going","61:06":"on rule of thumb that works most of the","61:09":"time but let's now DV dig in and","61:13":"actually understand it more completely","61:17":"so we're going to create this","61:19":"mathematical function that takes the","61:21":"numbers that represent the pixels and","61:22":"spits out probabilities for each","61:24":"possible plus and by the way a lot of","61:28":"the stuff that we're using here we are","61:30":"dealing from other people who are","61:31":"awesome and so we are putting their","61:34":"details here so like please check out","61:36":"their work because they've got great","61:39":"work that we are highlighting in our","61:41":"course I really like this idea of this","61:44":"little animated gif of the numbers so","61:47":"thank you for adding Daiki for creating","61:49":"that and I guess that was probably on","61:52":"Quora by the looks of this medium I oh","61:55":"yes it was - that terrific medium post I","61:57":"remember I've had a whole series of","62:00":"medium posts","62:02":"so so let's look and see what how we","62:10":"create one of these functions and let's","62:15":"start with the simplest function I know","62:20":"y equals a X plus B okay that's a line","62:28":"right that's a line and the the gradient","62:37":"of the line is here and the intercept of","62:40":"the line is here okay so hopefully when","62:44":"we said that you need to know high","62:45":"school math to do this course these are","62:47":"the things we're assuming that you","62:48":"remember if we do kind of mention some","62:52":"math thing which I'm assuming you","62:53":"remember and you don't remember it don't","62:55":"freak out right happens to all of us","62:59":"Khan Academy is actually terrific it's","63:02":"not just for school kids go to Khan","63:04":"Academy find the concept you need a","63:06":"refresher on and he explains things","63:08":"really well so strongly recommend","63:11":"checking that out","63:14":"you know remember I'm just a philosophy","63:16":"student right so I all the time and","63:19":"trying to either remind myself about","63:20":"something or I never learnt something","63:22":"and so we have the whole Internet to","63:24":"teach us these things so I'm going to","63:27":"rewrite this slightly y equals a 1 X","63:34":"plus a 2 so let's just replace B with a","63:41":"2 just give it a different name ok so","63:43":"there's another way of saying the same","63:46":"thing and then another way of saying","63:48":"that would be if I could multiply a 2 by","63:52":"the number 1 ok this still is the same","63:55":"thing ok and so now at this point I'm","64:00":"actually going to say let's not put the","64:02":"number 1 there but let's put an X 1 here","64:06":"and an X 2 here and I'll say X 2 equals","64:12":"1","64:13":"ok so so far this is not","64:15":"you know this is pretty early high","64:16":"school math this is multiplying by 1","64:18":"which I think we can handle ok so these","64:21":"two are equivalent with a bit of","64:24":"renaming now in machine learning we","64:30":"don't just have one equation we've got","64:32":"lots right so if we've got some data","64:35":"that represents the temperature versus","64:45":"the number of ice creams sold then we","64:51":"kind of have lots of dots and so each","64:56":"one of those dots we might hypothesize","64:58":"you know is based on this this formula y","65:01":"equals a 1 X 1 plus a 2 X 2 all right","65:05":"and so basically there's lots of so this","65:08":"is our Y this is our X there's lots of","65:11":"values of Y so we can stick it or I here","65:13":"and there's lots of values of X so we","65:16":"can stick little X here okay so the way","65:19":"we kind of do that is a lot like numpy","65:21":"indexing right there rather than things","65:23":"in square brackets or PI to watch","65:24":"indexing rather than things in square","65:25":"brackets we kind of put them down here","65:31":"in our kind of in the subscript of our","65:35":"equation ok so this is now saying","65:37":"there's actually lots of these different","65:39":"Y eyes based on lots of different xi1","65:43":"and ex-situ ok but notice there's only","65:46":"this is still only one of each of these","65:47":"that's it so these these things here","65:50":"called the coefficients for the","65:54":"parameters so this is our linear","65:58":"equation and this is still we're going","66:01":"to say that every X I 2 is equal to 1 ok","66:07":"why did I do it that way because I want","66:11":"to do linear algebra why do I want to do","66:14":"in linear algebra well one reason is","66:16":"because Rachel teaches the world's best","66:18":"linear algebra course so if you're","66:21":"interested check out computational","66:22":"linear algebra for coders so it's a good","66:24":"opportunity for me to throw in a pitch","66:26":"for this","66:29":"course which we make no money but never","66:31":"mind","66:32":"but more to the point right now it's","66:35":"going to make life much easier right","66:37":"because I hate writing loops I hate","66:40":"writing code right I just I just want","66:42":"the computer to do everything for me at","66:45":"anytime you see like these little I","66:47":"subscripts that sounds like you're going","66:48":"to have to do loops and all kind of","66:49":"stuff but what you might remember from","66:52":"school is that when you've got like two","66:55":"things being multiplied together two","66:57":"things being multiplied together and","66:58":"then they get added up","66:59":"that's called a dot product and then if","67:06":"you do that for lots and lots of","67:08":"different numbers I then that's called a","67:11":"matrix product so in fact this whole","67:15":"thing can be written like this","67:16":"rather than lots of different way eyes","67:18":"we can see there's one vector called Y","67:21":"which is equal to one matrix called","67:27":"x times one vector called a now at this","67:34":"point I know a lot of you don't remember","67:37":"that so that's fine we have a picture to","67:41":"show you I don't know who created this","67:44":"somebody called Andres touts credit this","67:47":"fantastic thing called matrix","67:48":"multiplication XYZ and here we have a","67:52":"matrix by a vector and we're going to do","67:56":"a matrix vector product go that times","68:02":"that times that plus plus plus plus that","68:04":"times that times that Plus that Plus","68:06":"that times that times a plus plus plus","68:07":"plus finished","68:10":"that is what matrix vector","68:12":"multiplication does in other words it's","68:17":"just that except his version is much","68:19":"less messy okay so let's this is","68:26":"actually an excellent spot to have a","68:28":"little break and find out what questions","68:29":"we have coming through our students what","68:32":"are they asking ritual when generating","68:36":"new image data set how do you know how","68:38":"many images are enough what are ways to","68:41":"measure enough yeah that's a great","68:43":"question","68:44":"so I'm another possible problem you have","68:47":"is you don't have enough data how do you","68:49":"know if you don't have enough data","68:51":"because you found a good learning rate","68:53":"because if you make it higher then it","68:56":"goes off into massive losses if you make","68:58":"it lower it goes really slowly so you've","69:00":"got a good learning rate and then you","69:02":"train for such a long time that your","69:06":"arrow starts getting worse okay so you","69:08":"know that you're trained for long enough","69:09":"and you're still not happy with the","69:12":"accuracy it's not good enough for the","69:14":"you know teddy bear cuddling level of","69:18":"safety you want so if that happens","69:20":"there's a number of things you can do","69:22":"and we'll learn about some of them","69:25":"during roll and pretty much all of them","69:26":"during this course but one of the","69:28":"easiest ones is get more data now if you","69:31":"get more data then you can train for","69:33":"longer get a higher accuracy lower error","69:36":"rate without overfitting unfortunately","69:41":"there's no shortcut I wish there was I","69:43":"wish so somewhere to know ahead of time","69:44":"how much data you need but I will say","69:47":"this most of the time you need less data","69:49":"than you think so organizations very","69:51":"commonly spend too much time gathering","69:53":"data getting more data than it turned","69:55":"out they actually needed so get a small","69:57":"amount first and see how you go what do","70:00":"you do if you have unbalanced classes","70:02":"such as 200 Grizzlies and 50 teddies ah","70:07":"nothing try it","70:09":"works a lot of people ask this question","70:12":"about how do I deal with unbalanced data","70:13":"I've done lots of analysis with","70:17":"unbalanced data over the last couple of","70:18":"years and I just can't make it not work","70:20":"it always works so there's a there's","70:26":"actually a paper that said like if you","70:28":"want to get it slightly better then the","70:30":"best thing to do is to take that","70:31":"uncommon class and just make a few","70:34":"copies of it that's called over sampling","70:36":"but you're like I haven't found a","70:39":"situation in practice where I needed to","70:40":"do that I've found it always just works","70:42":"plain for me once you unfreeze and","70:49":"retrain with one cycle again if you're","70:51":"training loss is still lower than your","70:53":"validation loss likely underfitting","70:55":"do you retrain it unfrozen again which","70:58":"will technically be more than one cycle","71:00":"or do you redo everything with a longer","71:02":"epoch for the cycle hey you guys asked","71:06":"me that last week my answers still the","71:08":"same I don't know I just find if you do","71:12":"another cycle then it'll kind of maybe","71:15":"generalize a little bit better if you","71:17":"start again do twice as long it's kind","71:20":"of annoying depends how patient you are","71:22":"it won't make much difference you know","71:24":"for me personally I normally just train","71:26":"a few more cycles but yeah it doesn't","71:30":"make much difference most of the time so","71:38":"showing the code sample where you were","71:40":"creating a CNN with resin at 34 for the","71:44":"grizzly Teddy classifier it says this","71:48":"requires res not resident 34 which I","71:51":"find surprising I had assumed that the","71:53":"model created by dot save which is about","71:55":"85 megabytes on disk would be able to","71:58":"run without also needing a copy of resin","72:01":"at 34 yeah and I understand we're going","72:11":"to be learning all about this shortly","72:14":"[Music]","72:15":"you don't there's a copy of ResNet 34","72:20":"written at 34 is actually how what we","72:22":"call an architect","72:23":"we're going to be learning a lot about","72:24":"this it's a functional form just like","72:26":"this is a linear functional form it","72:29":"doesn't take up any room it doesn't","72:31":"contain anything it's just a function","72:32":"resident 34 is just a function it","72:35":"doesn't contain anything it doesn't","72:36":"store anything I think the confusion","72:38":"here is that we often use a pre trained","72:43":"neural net that's been learned on","72:45":"imagenet in this case we don't need to","72:49":"use a pre trained you're on it and","72:51":"actually to entirely avoid that even","72:58":"getting created you can actually pass","73:02":"pre-trained equals false and that'll","73:06":"ensure that nothing even gets loaded","73:07":"which will save you another 0.2 seconds","73:10":"I guess so yeah but we'll be learning a","73:13":"lot more about this so don't worry this","73:14":"is a bit unclear but the basic idea is","73:16":"this this thing here is is the basically","73:19":"equivalent of saying is it a line or is","73:22":"it a quadratic or is it a reciprocal","73:24":"this is if this is just a function this","73:27":"is the resonate 34 function it's a","73:28":"mathematical function it has no doesn't","73:31":"take any storage it doesn't have any","73:33":"numbers doesn't it be loaded as opposed","73:36":"to a pre-trained model and so that's why","73:42":"when we used when we did it at inference","73:44":"time the thing that took space is this","73:51":"bit which is where we load our","73:53":"parameters which is basically saying as","73:56":"we're ready to find out what are the","73:57":"values of a and B we have to store those","74:02":"numbers but for ResNet 34 you don't","74:05":"distort two numbers you store a few","74:08":"million or few tens of millions of","74:11":"numbers so why did we do all this well","74:17":"it's because I wanted to be able to","74:19":"write it out like this and then I think","74:22":"I think I would write it out like this","74:23":"is that we can now do that in pi torch","74:28":"with no loops single line of code and","74:32":"it's also going to run faster pi torch","74:35":"really doesn't like loop","74:37":"right it really wants you to send it a","74:39":"whole equation to do all at once which","74:41":"means you really want to try and specify","74:43":"things in these kind of linear algebra","74:45":"ways so let's go and take a look because","74:49":"what we're going to try and do then is","74:50":"we're going to try and take this we're","74:55":"going to call it an architecture like","74:56":"that this is like the tiniest world's","74:58":"tiniest neural network it's got two","75:00":"parameters you know a 1 and a 2 we're","75:03":"going to try and fit this architecture","75:04":"to some data so let's let's jump into a","75:07":"notebook and generate some dots right","75:11":"and see if we can get it to fit a line","75:15":"somehow and the somehow is going to be","75:18":"using something called s G D what is s","75:24":"GD well there's two types of SGD the","75:27":"first one is where I said in Lesson one","75:30":"hey you should all try building these","75:33":"models and try and come up with","75:34":"something cool and you guys all","75:35":"experimented and found really good stuff","75:37":"so that's where the s would be student","75:39":"that would be student gradient descent","75:41":"so that's version one of fgd version two","75:45":"of SGD which is what I'm going to talk","75:46":"about today is where we're going to have","75:48":"a computer try lots of things and try","75:50":"and come up with a really good function","75:51":"and that will be called stochastic","75:53":"gradient descent so the other one that","75:58":"you hear a lot in the on Twitter is","76:00":"stochastic grad student descent so","76:03":"that's the other one for you here so","76:08":"we're going to jump into lesson two SGD","76:12":"and so we're going to kind of go bottom","76:15":"up rather than top down we're going to","76:17":"create the simplest possible model we","76:21":"can which is going to be a linear model","76:23":"and the first thing that we need is we","76:25":"need some data and so we're going to","76:27":"generate some data the data we're going","76:30":"to generate looks like this so this","76:32":"might represent temperature and this","76:33":"rate represent number of ice creams we","76:35":"sell or something like that but we're","76:37":"just going to create some synthetic data","76:39":"that we know is following a line and so","76:41":"as we build this we're actually going to","76:43":"learn a little bit about PI torch as","76:46":"well so basically the way we're going to","76:49":"generate this data","76:51":"is by creating some coefficients a 1","76:55":"will be 3 and a 2 will be 2 and we're","77:00":"going to create some like which looks at","77:04":"before basically a column of numbers","77:07":"through axis and a whole bunch of ones","77:09":"and then we're going to do this X at a","77:12":"what is X at a X at a in Python means a","77:17":"matrix product between X and a it","77:22":"actually is even more general for that","77:23":"it can be a vector vector product a","77:25":"matrix vector product a vector matrix","77:27":"product or a matrix matrix product and","77:30":"then actually in pi torch specifically","77:32":"it can mean even more general things","77:34":"where we get into higher rank tensors","77:35":"which we will learn all about very soon","77:38":"right but this is basically the key","77:41":"seeing that's going to go on in all of","77:44":"our deep learning the vast majority of","77:46":"the time our computers are going to be","77:48":"basically doing this multiplying numbers","77:50":"together at adding them up which is the","77:52":"surprisingly useful thing to do","77:57":"ok so we basically are going to generate","78:01":"some data by by creating a line and then","78:04":"we're going to add some random numbers","78:05":"to it but let's go back and see how we","78:07":"created X 1/8 so I mentioned that you","78:11":"know we've basically got these two","78:12":"coefficients three and two and you'll","78:16":"see that we've wrapped it in this","78:17":"function called","78:18":"cancer you might have heard this word","78:21":"tensor before who's heard the word","78:22":"tensor before about two-thirds of you","78:25":"okay so it's one of these words that","78:28":"sounds scary and apparently if you're a","78:32":"physicist it actually is scary but in","78:35":"the world of deep learning is actually","78:36":"not scary at all tensor means array okay","78:41":"it means array so specifically it's an","78:43":"array of a regular shape right so it's","78:46":"not an array where Row one has two","78:47":"things and Row three has three things","78:49":"and row four has one thing what you call","78:51":"a jagged array that's not a tensor a","78:53":"tensor is any array which has a","78:56":"rectangular or cube or whatever you know","79:00":"as a shape where every element every row","79:03":"is the same length","79:04":"and then every column is the same length","79:06":"so four by three matrix would be a","79:08":"tensor a vector of length four would be","79:12":"a tensor a 3d array of length three by","79:16":"four by six would be a tensor","79:19":"that's all intensity is okay and so we","79:24":"have these all the time","79:25":"for example an image is a three","79:29":"dimensional tensor it's got number of","79:32":"rows by number of columns by number of","79:35":"channels normally red green blue so for","79:38":"example a kind of a vga texture would be","79:41":"640 by 480 by 3 or actually we do things","79:48":"backwards so when people talk about","79:49":"images they normally go width by height","79:52":"but when we talk mathematically we","79:54":"always go a number of rows by number of","79:55":"columns so it'd actually be 480 by 6 40","79:59":"by 3 that will catch you out we don't","80:03":"say dimensions so with tensors we use","80:06":"one of two words we had to say rank or","80:08":"or axes rank specifically means how many","80:12":"axes are there how many dimensions are","80:14":"there so an image is generally a rank 3","80:18":"tensor so what we've created here is a","80:23":"rank 1 tensor or also known as the","80:29":"vector right but like in math people","80:33":"come up with slightly different words or","80:35":"actually not they come up with very","80:37":"different words for slightly different","80:38":"concepts why is a one dimensional array","80:40":"a vector and a two dimensional arrays","80:43":"and matrix and then a three dimensional","80:45":"array does that even have a name not","80:48":"really doesn't have a name like it","80:50":"doesn't make any sense we also you know","80:53":"with computers we try to have some","80:54":"simple consistent naming conventions","80:56":"they're all called tensors rank 1 tensor","80:59":"rank two tensor rank 3 tensor you can","81:01":"certainly have a rank 4 tensor if you've","81:03":"got 64 images then that would be a rank","81:07":"4 tensor of 64 by 480 by 640 by 3 for","81:12":"example so tensors are very simple they","81:15":"just mean arrays and so","81:18":"in play torch you say tensor and you","81:20":"pass in some numbers and you get back in","81:23":"this case just a list I get back a","81:25":"vector okay so this then represents our","81:31":"coefficients the slope and the intercept","81:34":"of our line and so because remember","81:37":"we're not actually going to have a","81:39":"special case of ax plus B instead we're","81:43":"going to say there's always this second","81:45":"x value which is always 1 you can see it","81:48":"here always 1 which allows us just to do","81:51":"a simple matrix vector product ok so","81:55":"that's that's a and then we wanted to","81:58":"generate this X array of data which is","82:02":"going to have we're going to put random","82:04":"numbers in the first column and a whole","82:06":"bunch of ones in the second column so to","82:08":"do that we basically say 2 pi torch","82:11":"create a rank two tensor actually notice","82:19":"I said again we see the PI torch that we","82:24":"want to create a tensor of n by 2 so","82:30":"since we passed in a total of 2 things","82:32":"we get a rank two tensor the number of","82:35":"rows will be N and the number of columns","82:37":"will be 2 and in there every single","82:41":"thing in it will be a 1 that's what","82:43":"torch dot ones means and then this is","82:47":"really important you can index into that","82:51":"just like you can index into a list in","82:53":"Python but you can put a colon anywhere","82:57":"and a colon means every single value on","83:00":"that axis or every single value on that","83:03":"dimension so this here means every","83:06":"single row and then this here means","83:09":"column 0 so this is every row of column","83:13":"0 I want you to grab a uniform random","83:17":"number and here's another very important","83:21":"concept in PI torch anytime you've got a","83:24":"function that ends in an underscore it","83:26":"means don't return to me that uniform","83:29":"random number but replay","83:31":"whatever this is being called on with","83:34":"the result of this function so this","83:36":"takes column zero and replaces it with a","83:40":"uniform random number between minus 1","83:43":"and 1 so there's a lot to unpack there","83:47":"right but the good news is those two","83:50":"lines of code plus this one which we're","83:53":"coming to cover 95% of what you need to","83:57":"know about pay torch how to create an","84:00":"array how to change things in an array","84:02":"and how to do matrix operations on an","84:05":"array okay so that's a there's a lot to","84:07":"unpack but these these small number of","84:10":"concepts are incredibly powerful so I","84:13":"can now print out the first five rows","84:18":"okay so colon 5 is standard - slicing","84:25":"syntax to say the first five rows so","84:28":"here are the first five rows two columns","84:30":"looking like my random numbers and my","84:33":"ones so now I can do a matrix product of","84:37":"that X by my a add in some random","84:43":"numbers to add a bit of noise and then I","84:46":"can do a scatter plot and I'm not really","84:48":"interested in my scatter plot in this","84:49":"column of ones right there just there to","84:52":"make my linear function more convenient","84:55":"so I'm just going to flip plot my zero","84:59":"index column against my Y's and there it","85:03":"is PLT is what we universally use to","85:09":"refer to the plotting library matplotlib","85:13":"and that's what most people use for most","85:16":"of their plotting in Python in","85:19":"scientific python we use matplotlib it's","85:22":"certainly a library you'll want to get","85:24":"familiar with because being able to plot","85:26":"things is really important there are","85:29":"lots of other plotting packages lots of","85:33":"them the other packages are better at","85:35":"certain things than that plot lib but","85:38":"like matplotlib can do everything","85:41":"reasonably well sometimes it's a little","85:45":"could but you know I for me I do pretty","85:48":"much everything in that flight lib","85:50":"because there's really nothing it can't","85:52":"do even though some libraries can do","85:54":"other things a little bit better or a","85:56":"little bit prettier but it's really","85:59":"powerful so once you know matplotlib you","86:02":"can do everything so here I'm asking","86:04":"matplotlib to give me a scatterplot with","86:06":"my X's against my Y's and there it is","86:09":"okay so this is my my dummy data","86:13":"representing like you know of","86:15":"temperature and ice cream sales so now","86:18":"what we're going to do is we're going to","86:20":"pretend we were given this data and we","86:22":"don't know that the values of our","86:25":"coefficients are 3 & 2 so we're going to","86:28":"pretend that we never knew that we have","86:29":"to figure them out okay so how would we","86:32":"figure them out how would we draw a line","86:34":"to fit to this data and why would that","86:38":"even be interesting well we're going to","86:41":"look at more about why it's interesting","86:43":"in just a moment but the basic idea is","86:45":"this if we can find this is going to be","86:47":"kind of perhaps really surprising but if","86:51":"we can find a way to find those two","86:54":"parameters to fit that line to those how","86:57":"many points were there and was a hundred","87:01":"if we can find a way to fit that line to","87:04":"those 100 points we can also fit these","87:08":"arbitrary functions that convert from","87:11":"pixel values to probabilities","87:14":"it'll turn out that this techniques that","87:16":"we that we're going to learn to find","87:19":"these two numbers works equally well for","87:22":"the 50 million numbers in resident 34 so","87:27":"we're actually going to use an almost","87:28":"identical approach so that this and this","87:32":"is a bit that I found in previous","87:33":"classes people have the most trouble","87:36":"digesting like I often find even after","87:39":"week four or week type five people will","87:41":"come up to me and say I don't get it how","87:44":"do we actually train these models and","87:47":"I'll say it's it's SGD it's that it's","87:49":"that thing we throw in the notebook with","87:50":"the T numbers it's like yep it but we're","87:52":"fitting a neural network so I know and","87:56":"we can't print the 50 million numbers","87:58":"anymore","87:59":"but it is literally identically doing","88:01":"the same thing and the reason this is","88:03":"hard to digest is that the human brain","88:05":"has a lot of trouble conceptualizing of","88:08":"what an equation was fifteen milk 50","88:10":"million numbers looks like and can do so","88:13":"you're just kind of for now we'll have","88:15":"to take my word for it that can do","88:17":"things like recognize teddy deaths and","88:21":"all these functions turn out to be very","88:22":"powerful now we're going to learn a","88:23":"little bit more in just a moment about","88:24":"how to make them extra powerful but for","88:27":"now this thing we're going to learn to","88:30":"fit these two numbers is the same thing","88:32":"that we've just been using to fit 50","88:34":"million numbers okay so we want to find","88:38":"what pi torch calls parameters or in","88:42":"statistics you'll often hear called","88:43":"coefficients these values a 1 and a 2 we","88:47":"want to find these parameters such that","88:50":"the line that they create minimizes the","88:54":"error between that line and the points","89:00":"so in other words you know if we created","89:09":"you know if the if the a 1 and a 2 we","89:12":"came up with resulted in this line then","89:16":"we'd look and we'd see like how far away","89:18":"is that line from each point I would say","89:20":"oh that's quite a long way and so maybe","89:22":"there was some other a 1 or a 2 which","89:25":"resulted in this line and they would say","89:30":"like oh how far away is each of those","89:31":"points and then eventually we come up","89:34":"with blue we come up with this line and","89:43":"it's like Oh in this case each of those","89:45":"is actually very close all right so you","89:47":"can see how in each case we can say how","89:49":"far away is the line at each spot away","89:52":"from its point and then we can take the","89:54":"average of all those and that's called","89:57":"the loss and that is the value of our","90:00":"loss right so you need some mathematical","90:02":"function that can basically say how far","90:05":"away is this line from those points","90:10":"for this kind of problem which is called","90:12":"a regression problem a problem where","90:14":"your dependent variable is continuous so","90:21":"rather than being Grizzly's or Teddy's","90:23":"it's like some number between minus 1","90:27":"and 6 this is called a regression","90:28":"problem and for regression the most","90:30":"common loss function is called mean","90:32":"squared error which pretty much","90:34":"everybody calls MSE you may also see our","90:38":"MSE just root mean squared error and so","90:41":"the mean squared error is a loss it's","90:43":"the difference between some prediction","90:45":"that you've made okay","90:47":"which you know is like the value of the","90:49":"line and the actual number of ice cream","90:52":"sales and so in in the mathematics of","90:57":"this people normally refer to the actual","90:58":"they normally call it Y and the","91:01":"prediction they normally call it y hat","91:03":"as in they they write it like that and","91:10":"so what I try to do like when we're","91:14":"writing something like it you know means","91:16":"grid error equation","91:17":"there's no point writing ice cream here","91:20":"and temperature here because we wanted","91:21":"to apply it to anything so we tend to","91:23":"use these like mathematical placeholders","91:27":"so the value of mean squared error is","91:30":"simply the difference between those two","91:33":"squared all right and then we can take","91:36":"the mean because remember that is","91:39":"actually a vector or what we now call it","91:42":"a rank 1 tensor and that is actually a","91:45":"rank 1 tensor so it's the value of the","91:48":"number of ice cream sales at each place","91:50":"and so when we subtract 1 vector from","91:54":"another vector we're going to be","91:56":"learning a lot more about this but it","91:57":"does something called element wise","91:58":"arithmetic in other words it subtracts","92:00":"each each one from each other and so we","92:04":"end up with a vector of differences and","92:05":"then if we take the square of that it","92:08":"squares everything in that vector and so","92:10":"then we can take the mean of that to","92:12":"find the average square of the","92:15":"differences between the actuals and the","92:17":"predictors so","92:20":"if you're more comfortable with","92:23":"mathematical notation what we just wrote","92:26":"there was the some of which we rounded","92:30":"we do it y hat minus y squared over n","92:41":"right so that equation is the same as","92:45":"that equation so one of the things I'll","92:49":"note here is I don't think this is you","92:54":"know more complicated or unwieldy than","92:59":"this right but the benefit of this is","93:02":"you can experiment with it like once you","93:05":"have to find it","93:06":"you can use it you can send things into","93:09":"it and get stuff out of it and see how","93:10":"it works alright so for me most of the","93:13":"time I prefer to explain things with","93:16":"code rather than with math right because","93:19":"I can actually they're the same now","93:21":"they're doing in this case at least in","93:23":"all the cases we'll look at they exactly","93:26":"the same they're just different","93:27":"notations for the same thing but one of","93:30":"the notations is executable it's","93:32":"something that you can experiment with","93:34":"and one of them is abstract so that's","93:37":"why I'm generally going to show code so","93:40":"the good news is if you're a coder with","93:44":"not much of a math background actually","93:47":"you do have a math background because","93:48":"code is math right if you've got more of","93:52":"a math background and less of a code","93:53":"background then actually a lot of the","93:56":"stuff that you learned from math is","93:57":"going to translate very directly into","93:59":"code and now you can start to experiment","94:01":"really with your math okay so this is","94:04":"some lost function this is something","94:05":"that tells us how good our line is so","94:08":"now we have to kind of come up with what","94:12":"is the line that fits through here","94:14":"remember we don't know we're going to","94:16":"pretend we don't know so what you","94:18":"actually have to do is you have to guess","94:20":"you actually have to come up with a","94:22":"guess what are the values of a 1 and a 2","94:24":"so let's say we guess that a 1 and a 2","94:27":"are both 1 so this is our tensor a is 1","94:32":"comma 1","94:34":"so here is how we create that tenser and","94:38":"I wanted to write it this way because","94:40":"you'll see this all the time like","94:42":"written out it should be 1.0 olives so","94:45":"it's also it was telling of minus 1","94:47":"minus 1 written out fully it would be","94:51":"minus 1.0 1.0 like that's that's written","94:55":"out fully we can't write it without the","94:57":"point because that's now an INT not a","95:02":"floating point so that's going to spit","95:04":"the dummy if you try to do calculations","95:06":"with that neural Nets","95:07":"ok I'm lazy I'm far too lazy to type dot","95:13":"0 every time Playford knows perfectly","95:15":"well that if you added dot next to any","95:17":"of these numbers then the whole thing is","95:20":"now floats right so that's that's why","95:22":"you'll often see it written this way","95:24":"particularly by lazy people let me okay","95:27":"so a is a chancer you can see it's","95:33":"floating-point you see like even pi","95:34":"torch is lazy they just put a dot they","95:36":"don't bother with a zero right but if","95:38":"you want to actually see exactly what it","95:40":"is you can write dot type and you can","95:46":"see it's a float tensor okay and so now","95:52":"we can calculate our predictions with","95:54":"this like random guess X at a matrix","95:58":"product of X and a and we can now","96:01":"calculate the mean squared error of our","96:03":"predictions and their actuals and that's","96:06":"our loss okay so for this regression our","96:09":"loss is 0.9 and so we can now plot a","96:15":"scatter plot of X against Y and we can","96:18":"plot the scatter plot of X against Y hat","96:20":"our predictions and there they are","96:23":"okay so this is the 1 1 comma minus 1","96:27":"line so it minus 1 comma 1 line and","96:30":"here's actuals so that's not great - not","96:33":"surprising it's just a guess so FGD or","96:38":"gradient descent more generally and","96:40":"anybody who's done in d engineering or","96:43":"probably computer science at school will","96:45":"have done plenty of this like Newton's","96:47":"all the stuff that you did University if","96:50":"you didn't don't worry we're going to","96:51":"learn it now it's basically about taking","96:54":"this guess and trying to make it a","96:56":"little bit better so how do we make it a","96:59":"little bit better well there's only two","97:02":"numbers right and the two numbers are","97:05":"and the two numbers are the intercept of","97:09":"that orange line and the gradient of","97:11":"that orange line so what we're going to","97:13":"do with gradient descent is we're going","97:15":"to simply say what if we change those","97:18":"two numbers a little bit what if we made","97:20":"the intercept a little bit higher or a","97:23":"little bit lower what if we made the","97:28":"gradient a little bit more positive or a","97:33":"little bit more negative so there's like","97:36":"four possibility and then we can just","97:38":"calculate the loss for each of those","97:41":"four possibilities and see what see what","97:43":"work did lifting it up or down make it","97:46":"better there tilting it more positive or","97:48":"more negative make it better and then","97:50":"all we do is we say okay well whichever","97:52":"one of those made it better that's what","97:55":"we're going to do and that's it right","97:58":"but here's the cool thing","97:59":"for those of you that remember calculus","98:01":"you don't actually have to move it up","98:04":"and down and round about you can","98:07":"actually calculate the derivative the","98:09":"derivative is the thing that tells you","98:11":"we're moving it up or down make it","98:13":"better or would rotating it this way or","98:15":"that way make it better","98:17":"okay so the good news is if you didn't","98:19":"do calculus or you don't remember","98:20":"calculus I just told you everything you","98:23":"need to know about it right which is","98:26":"that it tells you how changing one thing","98:29":"changes the function right that's what","98:32":"that's what the derivative is kind of","98:35":"not quite strictly speaking right close","98:37":"enough also called the gradient okay so","98:39":"the gradient or the derivative tells you","98:41":"how changing a one up or down would","98:45":"change our MSE now changing a true up or","98:48":"down will change your MSE and this does","98:51":"it more quickly does it more quickly","98:52":"than actually moving it up and down okay","98:55":"so um","98:59":"in school unfortunately they forced us","99:02":"to sit there and calculate these","99:04":"derivatives by hand we have computers","99:07":"computers can do that for us we are not","99:10":"going to calculate them by hand instead","99:13":"we're going to call dot bread on our","99:19":"computer that will calculate the","99:20":"gradient for us so here's what we're","99:23":"going to do we're going to create a loop","99:26":"we're going to loop through 100 times","99:28":"and we're going to call a function","99:30":"called update that function is going to","99:33":"calculate Y hat our prediction it is","99:38":"going to calculate loss now means grad","99:41":"error from time to time it will print","99:44":"that out so we can see how we're going","99:47":"it will then calculate the gradient and","99:50":"in pi torch calculating the gradient is","99:52":"done by using a method called backward","99:55":"so you'll see something really","99:57":"interesting which is mean squared error","99:59":"was just a simple standard mathematical","100:04":"function pi torch for us keeps track of","100:09":"how it was calculated and lets us","100:12":"calculate the derivatives so if you do a","100:14":"mathematical operation on a tensor in pi","100:17":"torch you can call backward to calculate","100:20":"the derivative what happens to that","100:22":"derivative that gets stuck inside an","100:25":"attribute called dot Brad so I'm going","100:29":"to take my coefficients a and I am going","100:32":"to subtract from them my gradient and","100:36":"there's an underscore here why because","100:40":"that's going to do it in place so it's","100:42":"going to actually update those","100:44":"coefficients a to subtract the gradients","100:49":"from them right so why do we subtract","100:52":"well because the gradient tells us if I","100:54":"move the whole thing downwards the loss","100:59":"goes up if I move the whole thing","101:00":"upwards the loss goes down so I want to","101:03":"like do the opposite of the thing that","101:05":"makes it go up right so because our last","101:07":"we want to loss to be small so that's","101:10":"why we have to subtract","101:12":"and then there's something here called","101:14":"LR LR is our learning rate and so","101:22":"literally all it is is the thing that we","101:24":"multiply by the gradient why is there","101:29":"any LR at all let me show you why let's","101:36":"take a really simple example a quadratic","101:45":"okay and let's see your algorithms job","101:49":"was to find where that quadratic was at","101:51":"its lowest point and so well how could","101:54":"it do this well just like what we're","101:55":"doing now the starting point would just","101:57":"be to pick some x value at random and","102:01":"then pop up here to find out what the","102:04":"value of y is okay that's the starting","102:07":"point and so then it can calculate the","102:10":"gradient and the gradient is simply the","102:12":"slope but it tells you moving in which","102:16":"direction is going to make you go down","102:17":"and so the gradient tells you you have","102:20":"to go this way so if the gradient was","102:25":"really big you might jump this way a","102:29":"very long way so you might jump all the","102:32":"way over to here maybe even here right","102:40":"and so if you jumped over to there then","102:46":"that's actually not going to be very","102:47":"helpful because then you see well where","102:50":"does that take us to Oh it's now worse","102:53":"right we jumped too far so we want don't","102:59":"want to jump too far so maybe we should","103:01":"just jump a little bit maybe to here and","103:06":"the good news is that is actually a","103:09":"little bit closer and so then we'll just","103:11":"do another little jump see what the","103:13":"gradient is into another liberal jump","103:14":"that takes us to here and another little","103:16":"jump that takes us to here here yeah","103:20":"right so in other words we find our","103:23":"gradient to tell us kind of what","103:25":"direction to go and like","103:26":"we have to go a long way or not too far","103:28":"but then we multiply it by some number","103:31":"less than one so we don't jump too far","103:34":"and so hopefully at this point this","103:37":"might be reminding you of something","103:38":"which is what happened when our learning","103:45":"rate was too high so do you see why that","103:49":"happened now our learning rate was too","103:51":"high","103:52":"meant that we jumped all the way past","103:56":"the right answer further than we started","103:59":"and it got worse and worse and worse so","104:04":"that's what a learning rate to high does","104:10":"on the other hand if our learning rate","104:13":"is too low then you just take tiny","104:17":"little steps and so eventually you're","104:20":"going to get there but you're doing lots","104:22":"and lots of calculations along the way","104:23":"so you really want to find something","104:26":"where it's kind of either like this or","104:30":"maybe it's kind of a little bit","104:31":"backwards and forwards maybe it's kind","104:32":"of like this something like that you","104:36":"know you want something that kind of","104:37":"gets in there quickly but not so quickly","104:40":"it jumps out and diverges not so slowly","104:44":"that it takes lots of steps so that's","104:46":"why we need a good learning rate and so","104:50":"that's all it does so if you look inside","104:52":"the source code of any deep learning","104:55":"library you will find this you will find","104:58":"something that says coefficients dot","105:00":"subtract learning rate times gradient","105:03":"and we'll learn about some minor up not","105:06":"minor what about so easy bad important","105:09":"optimizations we can do to make this go","105:11":"faster but that's basically it there's a","105:16":"couple of other little minor issues that","105:18":"we don't need to talk about now one","105:19":"involving zeroing out the gradients and","105:21":"other involving making sure that you","105:23":"turn gradient calculation off when you","105:25":"do the SGD update if you're interested","105:29":"we can discuss them on the forum or you","105:32":"can do our introduction to machine","105:35":"learning course which covers the other","105:38":"mechanics of this in more detail","105:41":"but this is the basic idea so if we run","105:44":"update 100 times printing out the loss","105:47":"from time to time you can see it starts","105:49":"at 8.9 it goes down down down down down","105:53":"down down and so we can then print out","105:55":"scatter plots and there it is that's it","105:59":"but leave it or not that's gradient","106:02":"descent so we just need to start with a","106:05":"function that's a bit more complex than","106:08":"X at a but as long as we have a function","106:13":"that can represent things like is this a","106:15":"teddy bear we now have a way to fit it","106:18":"okay and so let's now take a look at","106:22":"this as a picture as an animation and","106:24":"this is one of the nice things that you","106:26":"can do with this is one of the nice","106:33":"things that you can do with matplotlib","106:35":"is you can take Eddie plot and turn it","106:38":"into an animation mat and so you can now","106:40":"actually see it updating each step so","106:42":"let's see what we did here we simply","106:45":"said as before create a scatter plot but","106:50":"then rather than having a loop we used","106:53":"matplotlib func animation so call 100","106:57":"times this function and this function","107:01":"just called that update that we created","107:03":"earlier and then updated the Y data in","107:07":"our line and so did that 100 times","107:10":"waiting 20 milliseconds after each one","107:12":"and there it is right so you might think","107:15":"that like visualizing your algorithms","107:19":"with animations is some amazing and","107:22":"complex thing to do but actually now you","107:24":"know it's 1 2 3 4 5 6 7 8 9 10 11 lines","107:28":"of code okay so I think that is pretty","107:33":"damn cool","107:35":"so that is SGD visualized and so we","107:39":"can't visualize as conveniently what","107:42":"updating 50 million parameters in a","107:44":"resonant 34 looks like but basically","107:46":"doing the same thing okay and so","107:49":"studying these simple versions is","107:50":"actually a great way to get an intuition","107:52":"so you should try running this No","107:54":"book with a really big learning rate","107:56":"with a really small learning rate and","107:58":"see what this animation looks like that","108:01":"and try get a feel for it maybe you can","108:03":"even try a 3d plot I haven't tried that","108:05":"yet but I'm sure it would work fine - so","108:09":"the only difference between stochastic","108:12":"gradient descent and this is something","108:14":"called mini-batches","108:15":"you'll see what we did here was we","108:17":"calculated the value of the loss on the","108:20":"whole data set on every iteration but if","108:23":"your data set is one and a half million","108:25":"images in image net that's going to be","108:27":"really slow right just to do a single","108:29":"update of your parameters you've got to","108:31":"calculate the loss on one and a half","108:33":"million images you wouldn't want to do","108:36":"that so what we do is we grab 64 images","108:40":"or so at a time at random and we","108:44":"calculate the loss on those 64 images","108:46":"and we update our weights and then we","108:49":"have another 64 random images we update","108:51":"the weights so in other words the loop","108:54":"basically looks exactly the same but at","108:57":"this point here so it'd basically be Y","109:00":"square bracket and some random indexes","109:04":"here you know and some random indexes","109:08":"here and we'd basically do the same","109:10":"thing and well actually so it would be","109:16":"there right so some random indexes on","109:19":"our X and some random indexes on our way","109:21":"to do a mini batch at a time and that","109:23":"would be the basic difference and so","109:25":"once you add those you know grab a","109:29":"random few points each time those random","109:32":"few points accord your mini batch and","109:34":"that approach is called SGD for","109:36":"stochastic gradient descent okay so","109:40":"there's quite a bit of vocab we've just","109:44":"covered right so let's just remind","109:47":"ourselves the learning rate is a thing","109:51":"that we multiply our gradient by to","109:53":"decide how much to update the weights by","109:55":"an epoch is one complete run through all","110:01":"of our data points all of our images so","110:05":"for the non stochastic gradient descent","110:08":"we just did every single loop we did the","110:11":"entire data set but if you've got a data","110:13":"set with a thousand images and your mini","110:17":"batch size is 100 then it would take you","110:19":"ten iterations to see every image once","110:22":"so that would be one epoch the epochs","110:26":"are important because if you do lots of","110:28":"epochs then you're looking at your","110:30":"images lots of times and so every time","110:33":"you see an image there's a bigger chance","110:36":"of overfitting so we generally don't","110:38":"want to do too many epochs a mini batch","110:41":"is just a random bunch of points that","110:44":"you use to update your weights SGD is","110:48":"just gradient descent using mini-batches","110:53":"architecture and model kind of mean the","110:56":"same thing in this case our architecture","110:59":"is y equals XA and the architecture is","111:06":"the mathematical function that you're","111:08":"fitting the parameters to and we're","111:10":"going to learn later today or next week","111:14":"what the mathematical function of things","111:17":"like ResNet 34 actually is but it's","111:20":"basically pretty much what you've just","111:22":"seen it's a bunch of matrix products","111:26":"parameters also known as coefficients","111:29":"also known as weights the set the","111:32":"numbers that you're updating and then","111:35":"loss function is the thing that's","111:37":"telling you how far away or how close","111:39":"you are to the correct answer any","111:41":"questions all right so these model these","111:48":"predictors these teddybear classifiers","111:50":"are functions that take pixel values and","111:52":"return probabilities they start with","111:55":"some functional form like y equals XA","112:00":"and they fit the parameters a using SGD","112:05":"to try and do the best to calculate your","112:09":"predictions so far we've learned how to","112:11":"do regression which is a single number","112:15":"next week we'll learn how to do the same","112:18":"thing for classification where we have","112:20":"multiple numbers","112:21":"the same in the process we had to do","112:29":"some math we had to do some linear","112:31":"algebra and we had to do some calculus","112:33":"and a lot of people get a bit scared at","112:37":"that point and tell us I am NOT a math","112:40":"person if that is you that's totally","112:44":"okay but you're wrong you are a math","112:47":"person in fact it turns out that when in","112:50":"the actual academic research around this","112:53":"there are not math people and non math","112:55":"people it turns out to be entirely a","112:58":"result of culture and expectations so","113:02":"you should check out Rachel's talk","113:05":"there's no such thing as not a math","113:08":"person where she will introduce you to","113:11":"some of that academic research and so if","113:13":"you think of yourself as not a math","113:14":"person you should watch this so that you","113:17":"learn that you're wrong that your","113:19":"thoughts are actually there because","113:21":"somebody has told you you're not a math","113:23":"person but there's actually no academic","113:27":"research to suggest that there is such a","113:29":"thing in fact there are some cultures","113:31":"like Romania and China where the not a","113:35":"math person concept never even appeared","113:38":"there that it's almost unheard of in","113:41":"some cultures for somebody to say I'm","113:43":"not a math person because they're just","113:45":"never entered that cultural identity so","113:50":"don't freak out if words like derivative","113:53":"and gradient and matrix product are","113:56":"things that you're kind of scared of","113:58":"it's something you can learn it's","114:00":"something you'll be okay with okay","114:04":"so the last thing that we're going to","114:06":"close with today","114:10":"oh I just got a message from Simon","114:13":"Willison ah","114:17":"Simon's telling me he's actually not","114:19":"that special","114:20":"lots of people won medals so","114:24":"that's the worst part about Simon is not","114:27":"only is he really smart he's also really","114:29":"modest which I think it's just awful","114:31":"I mean if you're going to be that smart","114:35":"at least be a horrible human being and","114:36":"you know make it okay okay so the last","114:43":"thing I want to close with is the idea","114:45":"of and we're going to look at this more","114:47":"next week underfitting over and over","114:49":"fitting we just fit a line to our data","114:56":"but imagine that our data wasn't","114:57":"actually line shaped right and so if we","115:01":"try to fit something which was like","115:03":"constant plus constant times X ie align","115:06":"to it that it's never going to fit very","115:08":"well right no matter how much we change","115:11":"these two coefficients it's never going","115:14":"to get really close on the other hand we","115:17":"could fit some much bigger equation so","115:20":"in this case it's a higher degree","115:21":"polynomial with lots of lots of Wiggly","115:23":"bits like so right but if we did that","115:26":"it's very unlikely we go and look at","115:29":"some other place to find out the","115:31":"temperature that it is and how much ice","115:32":"cream they're selling and that will get","115:34":"a good result because like the Wiggles","115:36":"are far too Wiggly so this is called","115:39":"overfitting we're looking for some","115:42":"mathematical function that fits just","115:44":"right to stay with a teddy bear","115:46":"analogies so you might think if you have","115:52":"a statistics background the way to make","115:54":"things fit just right is to have exactly","115:57":"the right number of parameters it's to","115:59":"use a mathematical function that doesn't","116:01":"have too many parameters in it","116:03":"it turns out that actually completely","116:05":"not the right way to think about it","116:07":"there are other ways to make sure that","116:09":"we don't over fit and in general this is","116:12":"called regularization regularization or","116:15":"all the techniques to make sure that","116:17":"when we train our model that it's going","116:20":"to work not not only well on the data","116:23":"its seen but on the data it hasn't seen","116:26":"yet so the most important thing to know","116:30":"when you've trained a model is actually","116:33":"how well does it work","116:34":"on data that it hasn't been trained with","116:37":"and so as we're going to learn a lot","116:39":"about next week that's why we have this","116:42":"thing called a validation set so what","116:44":"happens with the validation set is that","116:48":"we do our mini batch F GED training loop","116:52":"with one set of data with one set of","116:55":"teddy bears Grizzlies black bears and","116:57":"then when we're done we check the lost","117:00":"function and the accuracy to see how","117:03":"good is it on a bunch of images which","117:05":"were not included in the training and so","117:08":"if we do that then if we have something","117:10":"which is too Wiggly it'll tell us oh","117:13":"your loss function in your air is really","117:15":"bad because on the Bears that it hasn't","117:17":"been trained with the wiggly bits are in","117:19":"the wrong spot where if it was under","117:21":"fitting it would also tell us that your","117:24":"validation sets really bad so like even","117:29":"for people that don't go through this","117:32":"course and don't learn about the details","117:34":"of deep learning like if you've got","117:37":"managers or colleagues or whatever at","117:39":"work who are kind of wanting to like","117:41":"moan about AI the only thing that you","117:43":"really need to be teaching them is about","117:45":"the idea of a validation set because","117:47":"that's the thing they can then use to","117:48":"figure out you know if somebody's","117:51":"telling them snake oil or not you know","117:53":"they're like hold back some data and","117:54":"then they get told like oh here's a","117:56":"model that we're going to roll out and","117:58":"then you say okay fine I'm just going to","118:00":"check it on this held out data to see","118:02":"whether it generalizes there's a lot of","118:04":"details to get right when you design","118:07":"your validation set we will talk about","118:10":"them briefly next week but a more full","118:14":"version would be in Rachel's piece on","118:17":"the first day I blog called how and why","118:19":"to create a good validation set and this","118:22":"is also one of the things we go into in","118:24":"a lot of detail in the intro to machine","118:26":"learning course so we're going to try","118:28":"and give you enough to get by for this","118:31":"course but it is certainly something","118:32":"that's worth deeper study as well any","118:35":"questions or comments before we wrap up","118:38":"okay good all right well thanks","118:41":"everybody I hope you have a great time","118:42":"building your web applications see you","118:44":"next week"}},59:function(e){e.exports={"00:00":"welcome back to lesson three so we're","00:05":"going to start with a quick correction","00:06":"which is to let you know that when we","00:09":"referred to this chart is coming from","00:11":"last week we were correct it did come","00:13":"from Chora but actually we realized","00:15":"originally it came from Andrew earns","00:17":"excellent machine learning course on","00:19":"Coursera so apologies for the incorrect","00:21":"citation but in exchange let's talk","00:24":"about Andrew owns excellent machine","00:25":"learning course on Coursera it's it's","00:28":"really great as you can see people gave","00:31":"it four point nine out of five stars in","00:34":"some ways it's a little dated but a lot","00:36":"of the content really is as as","00:40":"appropriate as ever and taught in a more","00:42":"bottom-up style so it can be quite nice","00:45":"to combine andrew's bottom-up style and","00:47":"our top-down style and meet somewhere in","00:49":"the middle also if you're interested in","00:51":"more machine learning foundations you","00:54":"should check out our machine learning","00:55":"course as well if you go to course too","00:57":"fast at AI and click on the machine","00:59":"learning button that will take you to","01:00":"our course which is about twice as long","01:03":"as this deep learning course and kind of","01:06":"takes you much more gradually through","01:07":"some of the foundational stuff around","01:09":"validation sets and model interpretation","01:12":"and our PI torch tensors work and and","01:15":"stuff like that so I think all these","01:18":"courses together if you want to really","01:20":"dig deeply into the material do all of","01:23":"them I know a lot of people who have and","01:25":"end up saying oh I got more out of each","01:27":"one by doing the whole lot or you can","01:29":"skip back within four words see which","01:30":"one works for you so we started talking","01:37":"about deploying your web app last week","01:41":"one thing that's going to make life a","01:43":"lot easier for you is that on the course","01:45":"v3 website there's a production section","01:49":"where right now we have one platform but","01:53":"more will be added by the time this","01:54":"video comes out showing you how to","01:56":"deploy your web app really really easily","01:59":"and when I say easily for example here's","02:03":"the how to deploy on site guide created","02:06":"by San Francisco study group member neph","02:09":"John as you can see it it's just a page","02:11":"there's almost nothing to do","02:13":"and it's free it's not going to serve","02:17":"10,000 simultaneous requests but it'll","02:22":"certainly get you started and I found it","02:24":"works really well it's fast and so","02:27":"deployment you know deploying a model","02:29":"doesn't have to be slow more complicated","02:31":"anymore","02:32":"and the nice thing is you can kind of","02:34":"use this for an MVP and if you do find","02:36":"just started to get a thousand","02:37":"simultaneous requests then you know that","02:40":"things are working out and you can start","02:41":"to you know upgrade your instance types","02:43":"or you know add to a more traditional","02:45":"you know big engineering approach so if","02:49":"you actually use this starter kit it","02:53":"will actually create my teddy bear","02:55":"finder for you and this is an example of","02:58":"my teddy bear fighter so the idea is","02:59":"it's like it's as simple as possible","03:01":"this template so you can fill in your","03:05":"own style sheets your own custom logic","03:07":"and so forth this is kind of designed to","03:09":"be a minimal thing so you can see","03:11":"exactly what's going on the back end is","03:13":"a simple kind of rest style you know","03:17":"interface it sends back JSON and the","03:20":"front end is a super simple little","03:22":"JavaScript thing so yeah it should be a","03:27":"good way to get a sense of how to build","03:29":"a web app which talks to a PI torch","03:33":"model so examples of web apps people","03:38":"have built during the week","03:41":"Edward Ross built the what car is that","03:44":"Apple more specifically the what","03:46":"Australian car is that is that I thought","03:49":"it was kind of interesting that Edward","03:50":"said on the forum that the building of","03:52":"the app was actually a great experience","03:55":"in terms of understanding how dumb how","03:57":"the model works himself better and like","04:04":"it's it's a it's interesting that he's","04:06":"describing like trying it out on his","04:08":"phone lot of people think like oh if I","04:10":"want something on my phone I have to","04:11":"create some kind of mobile tensorflow","04:13":"onn X whatever tricky mobile app you","04:17":"really don't you can run it all in the","04:19":"cloud and make it just a web app or use","04:21":"some kind of simple little GUI front-end","04:25":"that talks to a","04:26":"back end it's not that often that you'll","04:29":"need to actually run stuff on the phone","04:31":"so this is a good example of that","04:35":"see Werner has created a guitar","04:38":"classifier you can decide whether your","04:42":"food is healthy or not apparently this","04:44":"one is healthy that can't be right I","04:46":"would have thought of hamburger is more","04:47":"what we're looking for but there you go","04:51":"apparently Trinidad and Tobago is the","04:53":"home of the hummingbird so if you're","04:55":"visiting you can find out what kind of","04:56":"hummingbirds you're looking at you can","04:59":"decide whether or not to eat a mushroom","05:01":"if you happen to be one of the cousins","05:04":"of Charlie Harrington you can now figure","05:07":"out who is who I believe this was","05:08":"actually designed for his fiancee even","05:11":"will tell you about the interests of","05:13":"this particular cousin so you know","05:15":"fairly niche application but you know","05:17":"apparently there are 36 people who will","05:20":"appreciate this at least I have no","05:24":"cousins that's a lot of cousins this is","05:27":"an example of a a nap which actually","05:30":"takes a video feed and turns it into an","05:32":"emotion classifier that's pretty cool I","05:39":"like it","05:42":"team 26 good job here's a similar one","05:49":"for American Sign Language and so like","05:54":"it's it's not a big step from taking a","05:57":"single image model to taking a video","06:01":"model you can just grab the occasional","06:02":"frame put it through your model and and","06:05":"update the update the UI as the kind of","06:10":"model results come in so it's really","06:12":"cool that you can do this kind of stuff","06:14":"either in plant or in browser nowadays","06:21":"Henri plushie is built your city from","06:26":"space which he describes as creepy how","06:31":"accurate it is so here's why I live","06:34":"which it figured out was in the United","06:35":"States it's interesting he describes","06:37":"here how he actually had to be very","06:40":"the validation set he built make sure","06:43":"that the satellite tails were not","06:45":"overlapping or close to each other and","06:47":"doing so he realized he had to download","06:48":"more data but once he did he got this","06:51":"amazingly effective model that can look","06:54":"at satellite imagery and figure out what","06:55":"country it's from I thought this one was","06:58":"pretty interesting which was doing","07:01":"univariate time series analysis by","07:03":"converting it into a picture using","07:07":"something I've never heard of a gradient","07:09":"angular field but he says he's getting","07:12":"closer to say that the results for","07:14":"univariate time series modeling into a","07:17":"picture and so I like this is I like","07:19":"this idea of turning stuff that's not a","07:21":"picture into a picture so something","07:26":"really interesting about this project","07:27":"which was looking at a motion","07:30":"classification from faces was that he","07:33":"was specifically asking the question how","07:35":"well does it go without changing","07:36":"anything just using the default settings","07:38":"which i think is a really interesting","07:39":"experiment because we were all told it's","07:42":"really hard to train models and it takes","07:44":"a lot of you know specific knowledge and","07:47":"actually we're finding that that's often","07:48":"not the case and he looked at this","07:51":"facial expression recognition dataset","07:54":"there was a 20-17 paper that he compared","07:56":"his results to and he got equal more","08:00":"slightly better results than the state","08:02":"of the art paper on face recognition","08:04":"recognition without doing any customer","08:07":"eye perimeter training at all so that","08:09":"was really cool and then Elena Harley","08:12":"who I featured one of her works last","08:16":"week has done another really cool work","08:18":"in the genomic space which is looking at","08:25":"variant analysis looking at false","08:28":"positives in these kinds of pictures and","08:33":"she found she was able to decrease the","08:35":"number of false positives coming out of","08:37":"the kind of industry standard software","08:39":"she was using by 500% by using a deep","08:44":"learning workflow I think this is a nice","08:47":"example of something where if you are","08:48":"going through you know spending hours","08:51":"every day looking at","08:53":"in this case looking at you know it's","08:55":"kind of get rid of the false positives","08:56":"maybe you can make that a lot faster by","08:59":"using deep learning to do a lot of the","09:00":"work for you and again this is an","09:03":"example of a computer vision based","09:05":"approach on something which originally","09:07":"wasn't actually images so that was yeah","09:11":"that's a really cool application so","09:15":"really nice to see what people have been","09:17":"building in terms of both web apps and","09:20":"just classifiers what we're going to do","09:22":"today is look at a whole lot more","09:24":"different types of model that you can","09:26":"build and we're going to kind of zip","09:28":"through them pretty quickly and then","09:29":"we're going to go back and say like oh","09:31":"how did all these things work what's the","09:33":"common denominator but all of these","09:35":"things you can create web apps from","09:38":"these as well but you'll have to think","09:41":"about how to slightly change that","09:43":"template to make it work with these","09:45":"different applications I think that'll","09:47":"be a really good exercise in making sure","09:49":"you understand the material so the first","09:52":"one we're going to look at is a data set","09:54":"of satellite images and satellite","09:57":"imaging is a really fertile area for","10:03":"deep learning it's certainly a lot of","10:05":"people already using deep learning and","10:07":"satellite imaging but only scratching","10:09":"the surface and the data set that we're","10:11":"going to look at looks like this it has","10:15":"satellite tiles and for each one as you","10:19":"can see there's a number of different","10:21":"labels for each tile one of the labels","10:25":"or way always represents the weather","10:27":"that's shown so in this case cloudy or","10:29":"partly cloudy and then all of the other","10:33":"labels tell you any interesting features","10:36":"that are seen there so primary means","10:38":"primary rainforest agriculture means","10:41":"there's some farming road road and so","10:44":"forth so as I'm sure you can tell this","10:47":"is a little different to all the","10:49":"classifiers we've seen so far because","10:51":"there's not just one label is","10:53":"potentially multiple labels so","10:55":"multi-label classification can be done","10:57":"in a very similar way but the first","11:00":"thing we're going to need to do is to","11:01":"download the data now this data comes","11:04":"from cattle cargo is","11:06":"known for being a competitions website","11:08":"and its really great to download data","11:10":"from Kegel when you're learning because","11:13":"you can see how would I have gone in","11:14":"that competition and it's a good way to","11:16":"see whether you kind of know what you're","11:18":"doing I tend to think the goal is to try","11:21":"and get in the top 10% and in my","11:23":"experience all the people in the top 10%","11:25":"of a competition really know what","11:28":"they're doing","11:29":"so if you can get in the top 10% then","11:31":"and that's a really good sign","11:34":"pretty much every Kegel data set is not","11:36":"available for download outside of cattle","11:38":"at least the competition data sets so","11:41":"you have to download it through cattle","11:42":"and the good news is that cowbell","11:44":"provides a python-based download at all","11:47":"which you can use so we've got a quick","11:50":"description here of how to download","11:52":"stuff from cattle so to install stuff to","11:57":"download stuff from cattle you first","11:59":"have to install the the cattle download","12:02":"tool so just pip install cattle and so","12:04":"you can see what we tend to do when","12:06":"there's one-off things to do is we show","12:08":"you the commented out version in the","12:10":"notebook and you can just remove the","12:11":"comment so here's a cool tip for you if","12:13":"you select a few lines and then hit","12:16":"control slash it uncomment them all and","12:19":"then when you're done select them again","12:21":"control slash again and recommence the","12:23":"ball okay so if you run this line it'll","12:27":"install cattle for you depending on your","12:30":"platform you may need sudo you may need","12:34":"slash something else slash pip you may","12:38":"need source activate so have a look on","12:40":"the setup instructions actually the","12:43":"returning to work instructions on the","12:45":"course website to see like when we do","12:48":"condor install you have to do the same","12:51":"basic steps for your pip install so once","12:56":"you've got that module installed you can","13:00":"then go ahead and download the data and","13:02":"basically it's as simple as saying calc","13:05":"or competitions download the competition","13:08":"name and then the files that you want","13:12":"the only other steps before you do that","13:13":"is that you have to authenticate","13:16":"yourself and you'll see there's a little","13:18":"bit of information here on","13:20":"exactly how you can go about downloading","13:21":"from Kegel the the file containing your","13:25":"your API authentication information so I","13:28":"won't bother going through it here but","13:30":"is follow these deaths sometimes stuff","13:34":"on Kegel is not just zipped or tired but","13:38":"it's compressed with a program called","13:40":"7-zip which will have a 7z extension if","13:45":"that's the case you'll need to either","13:47":"app to install P 7-zip or here's","13:51":"something really nice some kind person","13:53":"has actually created a condor","13:54":"installation of 7-zip that works on","13:56":"every platform so you can always just","13:58":"run this condor install doesn't even","14:00":"require a sudo or anything like that and","14:03":"this is actually a good example of where","14:04":"condor is super handy is that you can","14:06":"actually install binaries and libraries","14:08":"and and stuff like that and it's nicely","14:10":"cross-platform so that's a good if you","14:13":"don't have 7-zip installed that's a good","14:15":"way to get get it and so this is how you","14:19":"unzip a 7-zip file in this case it's","14:23":"tired and 7-zip so you can do this all","14:26":"in one step","14:29":"so 7z a is the name of the 7-zip archive","14:32":"a program that you would run okay so","14:34":"that's all basic stuff which if you're","14:37":"not so familiar with the command line","14:39":"and stuff it might take you a little bit","14:40":"of experimenting to get it working feel","14:42":"free to ask on the forum make sure you","14:44":"yes","14:45":"search the forum first to get started","14:49":"okay so once you've got the data","14:51":"downloaded and unzipped you can take a","14:55":"look at it so in this case so in this","15:00":"case because we have multiple labels for","15:04":"each tile we we clearly can't have a","15:08":"different folder for each image telling","15:11":"us what the label is we need some","15:12":"different way to label it and so the way","15:15":"the Cavill did it was they provided a","15:17":"CSV file that had each file name along","15:21":"with a list of all of the labels in","15:25":"order to just take a look at that CSV","15:27":"file we can read it using the pandas","15:29":"library if you haven't used pandas","15:32":"before it's kind of","15:33":"the standard way of dealing with tabular","15:36":"data in in Python pretty much always","15:41":"appears on the PD namespace in this case","15:43":"really well not really doing anything","15:44":"with it other than just showing you the","15:47":"contents of this file so we can read it","15:49":"we can take a look at the first few","15:50":"lines and there it is so we want to turn","15:54":"this into something we can use for","15:58":"modeling so the kind of object that we","16:02":"use for modeling is an object of the","16:04":"data bunch plus so we have to somehow","16:07":"create a data bunch out of this once we","16:10":"have a data bunch we'll be able to go","16:12":"show batch to take a look at it and then","16:15":"we'll be able to go create CNN with it","16:17":"and then we will be the start training","16:18":"okay so really the the trickiest step","16:23":"previously in deep learning has often","16:25":"been getting your data into a form that","16:27":"you can get it into a model so far we've","16:32":"been showing you how to do that using","16:33":"various um factory methods so methods","16:36":"where you basically say I want to create","16:38":"this kind of data from this kind of","16:40":"sauce with these kinds of options the","16:42":"problem is I've been that works fine","16:44":"sometimes when we showed you a few ways","16:46":"of doing it over the last couple of","16:47":"weeks but sometimes you want more","16:52":"flexibility because there's so many","16:53":"choices that you have to make about","16:56":"where do where do the files live and","16:58":"what's the structure they're in and how","16:59":"do the labels appear and how do you spit","17:01":"out the validation set and how do you","17:03":"transform it and so forth so we've got","17:06":"this unique API that I'm really proud of","17:09":"called the data block API and the data","17:12":"block API makes each one of those","17:14":"decisions a separate decision that you","17:16":"make there's separate methods and with","17:18":"their own parameters for every choice","17:20":"that you make around how do I create you","17:22":"know set up my data so for example to","17:27":"grab the planet data we would say we've","17:29":"got a list of image files that are in a","17:32":"folder and they're labeled based on a","17:34":"CSV with this name they have this","17:37":"separator remember I showed you back","17:39":"here that there's a space between them","17:41":"so by passing in separator it's going to","17:43":"create multiple labels the images are in","17:45":"this folder they have","17:46":"Suffolk's we're going to randomly split","17:49":"out a validation set with 20% of the","17:51":"data we're going to create data sets","17:53":"from that which were then going to","17:55":"transform with these transformations and","17:58":"then we're going to create a data bunch","17:59":"out of that which will then normalize","18:01":"using these statistics so there's all","18:04":"these different steps so to give you a","18:07":"sense of what that looks like the first","18:11":"thing I'm going to do is kind of go back","18:13":"and explain what are all of the PI torch","18:16":"and fast they are kind of classes that","18:18":"you need to know about that are going to","18:20":"appear in this process because you're","18:23":"good you're going to see them all the","18:24":"time in the first day I Docs and the PI","18:26":"torch does so the first one you need to","18:31":"know about is a class called a data set","18:33":"and the data set class is part of PI","18:37":"torch and this is the source code for","18:40":"the data set class as you can see it","18:43":"actually does nothing at all so the data","18:52":"set class in PI torch defines two things","18:56":"get item and when in python these","18:59":"special things that are underscore","19:01":"underscore something underscore","19:03":"underscore - Easter's call them dunder","19:06":"some things this would be done to get","19:07":"item dunder lin and they're basically","19:10":"special magical methods that do some","19:14":"special behavior and this particular","19:16":"method you can look them up in the","19:17":"python docs this particular method means","19:20":"that your object if you had an object","19:22":"called o can be indexed with square","19:25":"brackets something like that right so","19:28":"that would call get item with three as","19:31":"the index and then this one called len","19:33":"means that you can go Len o","19:37":"and it will call that method and you can","19:40":"see in this case they're both not","19:42":"implemented so that is to say although","19:44":"pi torch says you tell them to tell","19:49":"piped watch about your data you have to","19:50":"create a data set it doesn't really do","19:52":"anything to help you create the data set","19:55":"it just defines what the data set needs","19:57":"to do so in other words your data this","20:00":"pure data is something where you can see","20:02":"what is the third item of data in my","20:05":"data set so that's what getitem does and","20:08":"how big is my data set that's what the","20:10":"length does so first AI has lots of data","20:16":"set subclasses that do that for all","20:18":"different kinds of stuff and so so far","20:21":"you've been seeing image classification","20:24":"data sets and so their data sets where","20:26":"getitem will return an image and a","20:30":"single label of what is that image so","20:34":"that's what a data set is now a data set","20:38":"is not enough to train a model the first","20:41":"thing we know we know we have to do if","20:42":"you think back to the gradient descent","20:45":"tutorial last week is we have to have a","20:48":"few images or a few items at a time so","20:52":"that our GPU can work in parallel","20:54":"remember we do this this thing called a","20:56":"mini batch so mini batches a few items","20:58":"that we present to the model at a time","21:00":"that it can train from in parallel so to","21:03":"create a mini batch we use another PI","21:07":"torch another pipe torch plus quite a","21:11":"data loader and so a data loader takes a","21:15":"data set in its constructor so it's now","21:19":"saying oh this is something I can get","21:21":"the third item and the fifth item in the","21:22":"ninth item and it's going to grab items","21:25":"at random and create a batch of whatever","21:29":"size you asked for and passed and pop it","21:32":"on the GPU and send it off to your model","21:35":"for you right so a data loader is","21:36":"something that grabs individual items","21:39":"combines them into a mini batch pops","21:41":"them on the GPU for modeling so that's","21:44":"quite a data loader and that comes from","21:46":"a data set so you can see already","21:49":"there's kind of choices you have to make","21:51":"you know what kind of data set am i","21:52":"creating what is the data for it where","21:54":"it's going to come from and then when I","21:55":"create my data load or what batch size","21:57":"do I want to use right it still isn't","22:00":"enough to train a model not really","22:02":"because we've got no way to validate the","22:05":"model if all we have is a training set","22:07":"then we have no way to know how we're","22:09":"doing because we need a separate set of","22:11":"held out data a validation set","22:14":"see how we're getting along so for that","22:16":"we use a fast a a class called a data","22:20":"bunch and a data bunch is something","22:22":"which as it says here binds together a","22:24":"training data loader and a valid data","22:27":"loader and when you look at the fast AI","22:31":"Docs when you see these kind of mono","22:34":"spaced font things they're always","22:36":"referring to some symbol you can look up","22:38":"elsewhere so in this case you can see","22:39":"train DL is here and there's their point","22:43":"knowing what an act that there's an","22:45":"argument with a certain name with unless","22:47":"you know what that argument is so you","22:50":"should always look after the colon to","22:52":"find out that is a data loader ok so","22:54":"when you create a data Bunch","22:56":"you're basically giving it a training","22:57":"set data loader and a validation set","23:00":"data loader and that's now an object","23:03":"that you can send off to a learner and","23:05":"start that loading so they're the basic","23:10":"pieces so coming back to here this stuff","23:20":"plus this line is all the stuff which","23:23":"create is creating the data set so it's","23:25":"saying read of the images come from","23:27":"because the data set the indexer returns","23:29":"two things it returns the the image and","23:32":"the labels assuming it's an image data","23:34":"set so what are the images come from","23:35":"where do the labels come from and then","23:38":"I'm going to create two separate data","23:40":"sets the training and the validation","23:41":"this is the thing that actually turns","23:43":"them into piped watch data sets this is","23:45":"the thing that transforms them okay and","23:49":"then this is actually going to create","23:50":"the the data loader and the data bunch","23:54":"in one in one go so let's look at some","23:57":"examples of this data block API because","24:00":"once you understand the data block API","24:02":"you'll never be lost for how to convert","24:05":"your data set into something you can","24:07":"start modeling with so here's some","24:11":"examples of using the data block API so","24:13":"for example if you're looking at m mist","24:15":"which remember is the pictures and","24:18":"classes of handwritten numerals you can","24:25":"do something like this","24:27":"this what kind of data set is this going","24:29":"to be it's going to be an it's going to","24:31":"come from a list of image files which","24:34":"are in some folder and they're labeled","24:38":"according to the folder name that","24:41":"they're in and then we're going to split","24:44":"it into trained and validation according","24:47":"to the folder that they're in trainer","24:49":"validation you can optionally add a test","24:52":"set we're going to be talking more about","24:54":"test sets later in the course ok we'll","24:58":"convert those into PI torch data sets","25:00":"now that that's all set up","25:01":"well then transform them using this set","25:06":"of transforms and we're going to","25:09":"transform into something of this size","25:11":"and then we're going to convert them","25:13":"into a data bunch so each of those","25:14":"stages inside these parentheses of","25:16":"various parameters you can pass to","25:20":"customize how that all works right but","25:22":"in the case of something like this M","25:23":"nest data set all the defaults pretty","25:26":"much work so this is all fine","25:29":"so here it is so you can check let's","25:31":"grab something so data dot trained es is","25:34":"the data set not the data load of the","25:36":"data set so I can actually index into it","25:39":"with a particular number so here is the","25:40":"zero indexed item in the training data","25:44":"set it's got an image and a label or you","25:47":"can show batch to see an example of the","25:49":"pictures of it and we could then start","25:51":"training here are the classes that are","25:54":"in that data set and this a little cut","25:56":"down sample of M nest has threes and","25:58":"sevens here's an example using planet","26:04":"this is actually again a sub little","26:06":"subset of planet we use for you know","26:09":"make it easy to try things out so in","26:11":"this case again it's an image file list","26:13":"again we grabbing it from a folder this","26:16":"time we're labeling it based on a CSV","26:17":"file we randomly splitting it by default","26:20":"it's 20%","26:21":"creating data sets transforming it using","26:24":"these transforms we're going to use a","26:28":"smaller size and then create a data","26:30":"bunch there it is and so don't a bunch","26:35":"just know how to draw themselves amongst","26:37":"other things so here's some more","26:39":"examples we're going to be seeing some","26:40":"seeing later today what if we look at","26:43":"this data set called cam vid can vid","26:46":"looks like this","26:48":"it contains pictures and every pixel in","26:51":"the picture is color coded right so in","26:54":"this case we have a list of files in a","26:57":"folder and we're going to label them in","27:00":"this case using a function and so this","27:03":"function is basically the thing we're","27:05":"going to see it later which tells it","27:07":"whereabouts of the color coding for each","27:09":"pixel it's in a different place randomly","27:13":"split it in some way create some","27:15":"datasets in some way we can tell it for","27:19":"a particular list of classes you know","27:21":"how do we know what pixel it'll value 1","27:24":"versus pixel value 2 is and that was","27:26":"something that we can basically read in","27:27":"like so again some transforms create a","27:33":"data bunch you can optionally pass in","27:35":"things like what batch size do you want","27:37":"and again it knows how to draw itself","27:39":"and you can start learning with that or","27:41":"one more example what if we wanted to","27:45":"create something like this it has like","27:46":"bars and chair and remote control and","27:50":"book this is called an object detection","27:52":"data set so again we've got a little","27:54":"minimal cocoa data set cocoa is kind of","27:57":"the most famous academic data set for","27:59":"object detection we can create it using","28:02":"the same process grab a list of files","28:04":"from a folder label them according to","28:07":"this little function randomly split them","28:10":"create an object detection data set","28:12":"create a data bunch in this case as","28:15":"you'll learn when we get to object","28:16":"detection you have to use generally","28:17":"small or batch sizes or your read out of","28:19":"memory and as you'll also learn you have","28:22":"to use something called a collation","28:23":"function and once that's all done we can","28:26":"again show it and here's our object","28:28":"detection data set so you get the idea","28:30":"right so here's a really convenient","28:32":"notebook where will you find this ah","28:35":"this notebook is the documentation","28:38":"remember how I told you that all of the","28:40":"documentation comes from notebooks","28:41":"you'll find them in your faster yo repo","28:44":"in Docs underscore sauce so this which","28:48":"you can play with an experiment with","28:50":"inputs and outputs and try all the","28:51":"different parameters you will find","28:54":"datablock api examples of use if you go","28:56":"to the documentation here it is the data","28:58":"plot API examples of use right so","29:01":"remember everything that you want to use","29:03":"in fast AI you can look it up in the","29:05":"documentation so let's search data block","29:13":"API go straight there and away you go","29:22":"and so once you find some documentation","29:24":"that you actually want to try playing","29:26":"with yourself just look up the name data","29:28":"block and then you can open up a","29:30":"notebook with the same name in the first","29:33":"day I repo and play with it yourself","29:35":"okay so that's a quick overview of this","29:40":"really nice data block API and there's","29:42":"lots of documentation for all of the","29:44":"different ways you can label label","29:46":"inputs and split data and create data","29:49":"sets and so forth and so that's what","29:54":"we're using for planet","29:55":"okay so we're using that API you'll see","29:57":"like in the documentation these these","30:02":"two steps we had all joined up together","30:05":"we can certainly do that here too but","30:07":"you'll learn in a moment why it is that","30:10":"we're actually splitting these up into","30:12":"two separate steps which is also fine as","30:14":"well so a few interesting points about","30:17":"this transforms so transforms by default","30:25":"remember you can hit shift tab to get","30:28":"all the information right transforms by","30:30":"default will flip randomly each image","30:35":"right but they'll actually randomly only","30:38":"flip them horizontally which makes sense","30:41":"right if you're trying to tell if","30:42":"something is a cat or a dog doesn't","30:44":"matter whether it's pointing left or","30:45":"right but it wouldn't expect it to be","30:47":"upside down on the other hand satellite","30:49":"imagery whether something's cloudy or","30:51":"hazy or whether there's a road there or","30:53":"not it could absolutely be flipped","30:55":"upside down there's no such thing as a","30:56":"right way up from space so flip vert","30:59":"which defaults to false we're going to","31:02":"flip over to TRO to say like what","31:04":"randomly you should actually do that and","31:06":"it doesn't just flip it vertically it","31:07":"actually tries also it","31:08":"possible 90-degree rotation so there are","31:11":"eight possible kind of symmetries that","31:13":"it tries out so there's various other","31:17":"things here I've found that these","31:20":"particular settings work pretty well for","31:22":"planet one that's interesting is warp","31:27":"perspective warping is something which","31:29":"very few libraries provide and those","31:31":"that do provide it it tends to be really","31:32":"slow","31:33":"I think fast AI is the first work first","31:35":"one to provide really fast perspective","31:37":"warping and basically the reason this is","31:39":"interesting is if I kind of look at you","31:41":"from below versus look at you from above","31:44":"they're kind of your shape changes right","31:48":"and so when you're taking a photo of a","31:51":"you know sometimes you'll be higher","31:53":"sometimes you'll be lower then that kind","31:56":"of change of shape is certainly","31:58":"something that you would want to include","31:59":"as you're creating your training batches","32:03":"you want to modify it a little bit each","32:05":"time not true for satellite images a","32:09":"satellite always points straight down at","32:12":"the planet so if you added perspective","32:15":"warping you would be making changes that","32:17":"aren't going to be there in real life so","32:19":"I turn that off so this is all something","32:22":"called data augmentation we'll be","32:23":"talking a lot more about it","32:25":"later in the course but you can start to","32:28":"get a feel for the kinds of things that","32:29":"you can do to to augment your data and","32:33":"in general maybe the most important one","32:35":"is if you're looking at astronomical","32:37":"data or kind of pathology you know","32:40":"Digital slide data or satellite data you","32:43":"know data where there isn't really an up","32:45":"or down turning on flip verticals true","32:48":"is generally going to make your models","32:50":"generalize better okay so here's the","32:55":"steps necessary to create our data bunch","32:58":"and so now to create a satellite imagery","33:03":"[Music]","33:04":"classifier multi-label classifier that's","33:07":"going to figure out for each satellite","33:09":"tile what's the weather and what else","33:11":"what can I see in it there's basically","33:13":"nothing else to learn everything else","33:15":"that you've already learnt is going to","33:17":"be exactly nearly the same here it is","33:21":"learn equals create see and","33:22":"in data architecture right and in this","33:27":"case when I first built built this","33:30":"notebook I used resin at 34 as per usual","33:33":"and I found this was a case I tried","33:35":"resin at 50 as I always like to do I","33:36":"found resin at 50 helped a little bit","33:38":"and I had some time to run it so in this","33:40":"case I was using resin at 15 there's one","33:44":"more change I make which is metrics now","33:49":"to remind you a metric has got nothing","33:51":"to do with how the model trains changing","33:55":"your metrics will not change your","33:57":"resulting model at all the only thing","34:00":"that we use metrics for is we print them","34:02":"out during training so here it's","34:04":"printing out accuracy and it's printing","34:06":"out this other metric called F better so","34:08":"if you're trying to figure out how to do","34:11":"a better job with your model changing","34:13":"the metrics will never be something that","34:15":"you need to do they're there just to","34:17":"show you how you're going so that's the","34:21":"first thing to know you can have one","34:23":"metric or no metrics or a list of","34:25":"multiple metrics to be printed out as","34:28":"your models training in this case I want","34:31":"to know two things the first thing I","34:33":"want to know is the accuracy and the","34:36":"second thing I want to know is how would","34:38":"I go on cattle and cattle","34:40":"told me that I'm gonna be judged on a","34:43":"particular metric called the F score so","34:46":"I'm not gonna bother telling you about","34:48":"the F score it's not really interesting","34:49":"enough to be worth spending your time on","34:51":"you can look it up but it's it's","34:53":"basically this when you have a","34:55":"classifier you're going to have some","34:57":"false positives you're going to have","34:59":"some false negatives how do you weigh up","35:01":"those two things to kind of create a","35:03":"single number there's lots of different","35:05":"ways of doing that and something called","35:07":"the F score has is basically a nice way","35:11":"of combining that into a single number","35:13":"and there are various kinds of F scores","35:16":"F 1 F 2 and so forth and Kaggle said in","35:20":"the competition rules we're going to use","35:22":"a metric called","35:23":"F 2 so we have a metric called F beta","35:31":"which in other words it's f with 1 or 2","35:34":"or whatever depending on the value","35:36":"better and we can have a look at its","35:38":"signature and you can see that it's got","35:43":"a threshold in the beta okay so the","35:45":"beater is 2 by default and cackled said","35:48":"that we're going to use f2 so I don't","35:51":"have to change that but there's one","35:53":"other thing that I need to set which is","35:56":"a threshold what does that mean well","36:00":"here's the thing","36:01":"do you remember we had a little look the","36:04":"other day at the source code for the","36:06":"accuracy metric so he put two question","36:09":"marks you get the source code and we","36:11":"found that it used this thing called AG","36:13":"mix and the reason for that if you","36:17":"remember was we we kind of had this you","36:21":"know input image that came in and it","36:24":"went through our model and at the end it","36:28":"came out with a table of ten numbers","36:32":"right this is like if we're doing M&S;","36:34":"digit recognition and the ten numbers","36:35":"were like the probability of each of the","36:40":"possible digits and so then we had to","36:42":"look through all of those and find out","36:45":"which one was the biggest and so that","36:48":"the function in num PI or PI torch or","36:51":"just math notation that finds the","36:53":"biggest in returns its index is called","36:55":"Arg max all right so to get the accuracy","37:01":"for our pet detector we use this","37:03":"accuracy function the called Arg max to","37:06":"find out behind the scenes which Plus ID","37:10":"pet was the one that we're looking at","37:12":"and then it compared that to the actual","37:17":"and then took the average and that was","37:21":"the that was the accuracy we can't do","37:24":"that for satellite recognition in this","37:27":"case because there isn't one label we're","37:30":"looking for","37:31":"there's lots so instead what we do is we","37:35":"look at so in this case","37:44":"so I don't know if you remember but a","37:47":"data bunch has a special attribute","37:48":"called C and C is going to be basically","37:51":"how many outputs do we want our model to","37:54":"create and so for any kind of classifier","37:56":"we want one probability for each","37:59":"possible class so in other words dated C","38:02":"for classifiers is always going to be","38:04":"equal to the length of data type classes","38:08":"right so data dot classes there they all","38:12":"are there's the 17 possibilities right","38:14":"so there they're the we're going to have","38:15":"one probability for each of those but","38:18":"then we're not just going to pick out","38:19":"one of those 17 we're going to pick out","38:22":"any of those 17 and so what we do is we","38:25":"compare each probability to some","38:27":"threshold and then we say anything","38:29":"that's higher than that threshold we're","38:31":"going to assume that the models saying","38:33":"it does have that feature and so we can","38:36":"pick that threshold I found that for","38:41":"this particular data set a threshold of","38:43":"0.2 seems to generally work pretty well","38:46":"this is the kind of thing you can easily","38:47":"just experiment to find a good threshold","38:49":"so I decided I want to print out the","38:52":"accuracy at a threshold of 0.2 so the","38:57":"normal accuracy function doesn't work","38:59":"that way it doesn't Arg max we have to","39:01":"use a different accuracy function called","39:03":"accuracy underscore Thresh and that's","39:05":"the one that's going to compare every","39:07":"probability to a threshold and return","39:09":"all the things higher than that","39:10":"threshold and compare accuracy that way","39:12":"and so one of the things we had passed","39:14":"in is Thresh now of course our metric is","39:20":"going to be calling our function for us","39:22":"so we don't get to tell it every time","39:24":"every time it calls back what threshold","39:27":"do we want so we really want to create a","39:29":"special version of this function that","39:32":"always uses an accuracy of a threshold","39:35":"of point two so one way to do that would","39:37":"be could go define something called","39:39":"accuracy o2 that takes some input and","39:43":"some target and returns accuracy","39:48":"threshold with that input and that","39:51":"target and a threshold of 0.2","39:56":"do it that way okay but it's so common","40:00":"that you want to kind of say create a","40:02":"new function that's just like that other","40:05":"function that we're always going to call","40:07":"it with a particular parameter that","40:08":"computer science has a term for that","40:10":"it's called a partial that's what a","40:12":"partial function application and so","40:13":"Python three has something called","40:16":"partial that takes some function and","40:19":"some lists of keywords and values and","40:23":"creates a new function that is exactly","40:26":"the same as this function that is always","40:28":"going to call it with that keyword","40:30":"argument so yeah this is exactly the","40:33":"same thing as a thing I just typed in a","40:35":"co2 is now a new function that calls","40:38":"accuracy Thresh with a threshold 0.2 and","40:40":"so this is a really common thing to do","40:43":"particularly with the FASTA a library","40:45":"because there's lots of places where you","40:47":"have to pass in functions and you very","40:50":"often want to pass in a slightly","40:51":"customized version of a function so that","40:53":"here's how you do it so here I've got an","40:55":"accuracy threshold point - I've got a F","40:59":"beta threshold point - I can pass them","41:02":"both in his metrics and I can then go","41:05":"ahead and do all the normal stuff LR","41:07":"find recorded up plot find the thing","41:11":"with the steepest slope so I don't know","41:14":"somewhere around money Nick - so we'll","41:17":"make that our learning rate and then fit","41:19":"for awhile with five comma slice LR and","41:22":"see how we go okay and so we've got an","41:25":"accuracy of about 96% and an F beta of","41:29":"about 0.9 to 6 and so you could then go","41:33":"and have a look at Planet leaderboard","41:38":"private leaderboard okay and so the top","41:42":"fiftieth is about 0.93 so we kind of say","41:46":"like oh we're on the right track okay","41:48":"with some something we're doing we're","41:50":"doing fine so as you can see like once","41:52":"you get to a point that the data is","41:54":"there it's very little extra - most of","41:59":"the time so when your model makes an","42:04":"incorrect prediction in a deployed app","42:06":"is there a good way to record that air","42:08":"and use that learning","42:09":"improve the model in a more targeted way","42:11":"oh yeah","42:14":"that's a great question so the first bit","42:16":"is there a way to record that couse","42:18":"there is you record it that's up to you","42:20":"right so maybe some of you can try it","42:21":"this week have you you need to have your","42:25":"user tell you you were wrong this","42:28":"Australian car you said it was a holder","42:30":"and actually it's a falcon so first of","42:33":"all you'll need to collect that feedback","42:34":"and the only way to do that is to ask","42:36":"the user to tell you when it's wrong so","42:39":"you an app need to record in some log","42:40":"somewhere something saying you know this","42:42":"was the file I've stored it here","42:45":"this was the prediction I made this was","42:47":"the extra life of you know this is the","42:49":"actual that they told me and then at the","42:52":"end of the day or at the end of the week","42:54":"you could set up a little job to run","42:55":"something or you can manually run","42:58":"something and what are you going to do","43:00":"you're going to do some fine-tuning","43:02":"what does fine-tuning look like good","43:04":"segue Rachel it looks like this","43:06":"alright so let's pretend here's your","43:09":"safe model right and so then we unfreeze","43:13":"right and then we fit a little bit more","43:17":"right now in this case I'm fitting with","43:19":"my original data set but you could","43:21":"create a new data bunch with just the","43:25":"misclassified instances and go ahead and","43:28":"fit right and the misclassified ones are","43:32":"likely to be particularly interesting so","43:34":"you might want to fit at a slightly","43:35":"higher learning rate you know to make","43:37":"them kind of really mean more or you","43:39":"might want to run them through a few","43:40":"more epochs but it's exactly the same","43:42":"thing right you just call fit with your","43:46":"misclassified examples and passing in","43:48":"the correct classification and that","43:50":"should really help your model quite a","43:53":"lot there there are various other tweaks","43:55":"you can do to this but that's the basic","43:58":"idea next question could someone talk a","44:02":"bit more about the data block ideology","44:04":"I'm not not quite sure how the blocks","44:06":"are meant to be used do they have to be","44:08":"in a certain order is there any other","44:10":"library that uses this type of","44:11":"programming that I could look at yes","44:17":"they do have to be in a certain order","44:23":"they do have to be in a certain order","44:25":"and it's basically the order that you","44:26":"see in the example of use right it's","44:28":"it's what kind of data do you have where","44:35":"does it come from how do you label it","44:37":"how do you split it what kind of data","44:40":"sets do you want optionally how do I","44:42":"transform it and then how do I create a","44:44":"data bunch from it so they're the steps","44:49":"I mean we invented this API I don't know","44:56":"if other people have independently","44:57":"invented it the basic idea of kind of a","45:00":"a pipeline of things that dot into each","45:04":"other is is pretty common in a number of","45:09":"places not so much in Python but you see","45:13":"it more in JavaScript although this kind","45:15":"of approach of like each stage produces","45:19":"something slightly different you don't","45:21":"you tend to see it more in like ETL","45:24":"software like extraction extraction","45:25":"transformation and loading software","45:27":"where there's kind of particular stages","45:29":"in a pipeline so yeah I mean it's been","45:31":"inspired by a bunch of things but yeah","45:34":"oh all you need to know is to kind of","45:36":"use this example to guide you and then","45:41":"look up the documentation to see you","45:44":"know which particular kind of thing you","45:45":"want and in this case the image file","45:49":"list you're actually not going to find","45:51":"the documentation of image file list in","45:53":"data blocks documentation because this","45:55":"is specific to the vision application so","45:58":"to then go and actually find out how to","46:00":"do something for your particular","46:01":"application you would then go you know","46:04":"to look at text and vision and so forth","46:06":"and that's where you can find out what","46:08":"are the data block API pieces available","46:10":"for that application and of course you","46:13":"can then look at the source code if","46:14":"you've got some totally new application","46:16":"you could create your own part of any of","46:20":"these stages like pretty much all of","46:22":"these functions are you know","46:25":"very few lines of code maybe we could","46:29":"look an example of one","46:33":"image list from folder so let's just put","46:37":"that somewhere temporary and then we're","46:40":"gonna go t dot label from CSD and you","46:47":"can look at the documentation to see","46:48":"exactly what that does and that's gonna","46:50":"call label from date of data frame so I","46:54":"mean this is already like useful like if","46:56":"you you know wanted to create a data","46:58":"frame a panda's data frame from","46:59":"something other than the CSV you now","47:01":"know that you could actually just call","47:03":"label from data frame you can look up to","47:05":"find what that does and as you can see","47:07":"like most fast AI functions are no more","47:11":"than you know a few lines of code","47:13":"they're normally pretty pretty","47:15":"straightforward to see what are all the","47:16":"pieces there and how can you use them","47:21":"it's probably one of these things that","47:23":"as you play around with it you'll get a","47:25":"good sense of how it all gets put","47:28":"together but if during the week there","47:29":"are particular things where you're","47:30":"thinking I don't understand how to do","47:32":"this please let us know and we'll try to","47:34":"help you sure what resources do you","47:40":"recommend for getting started with video","47:42":"for example being able to pull frames","47:44":"and submit them to your model","47:50":"I guess it's I mean the answer is it","47:56":"depends if you're using if you're using","48:00":"the web which I guess probably most of","48:02":"you will be then there's there's web api","48:05":"s-- that basically do that for you so","48:08":"you can grab the frames with with the","48:10":"web api and then they're just images","48:13":"which you can pass along if you're doing","48:16":"it client-side i guess most people tend","48:18":"to use OpenCV for that but maybe people","48:22":"during the week could who are doing","48:25":"these video apps can tell us what if","48:26":"what have you used and found useful and","48:28":"we can start to prepare something in the","48:30":"lesson wiki with a list of video","48:32":"resources since it sounds like some","48:33":"people are interested okay so just like","48:41":"usual we unfreeze our model and then we","48:44":"fit some more and we get","48:46":"down to nine to nine ish so one thing to","48:53":"notice here is that wet before we","48:57":"unfreeze your temp to get this shape","48:59":"pretty much all the time if you do your","49:01":"learning rate find it before you","49:02":"unfreeze it's pretty easy you know find","49:04":"the steepest slope not the bottom right","49:07":"remember we're trying to find the bit","49:08":"where we can like slide down it quickly","49:10":"so if you start at the bottom it's just","49:12":"going to send you straight off to the","49:13":"end here so somewhere around here and","49:16":"then we can call it again after you","49:21":"unfreeze","49:22":"i George only get a very different shape","49:24":"right and this is a little bit harder to","49:27":"say what to look for because it tends to","49:29":"be this kind of shape where you get a","49:31":"little bit of upward and then a kind of","49:32":"very gradual downward and then up here","49:34":"so you know I tend to kind of look for","49:37":"just before it shoots up and go back","49:40":"about 10x bad is a kind of a rule of","49:43":"thumb so one a neg five right and that","49:46":"is what I do for the first half of my","49:48":"slice and then for the second half of my","49:51":"slice I normally do whatever learning","49:54":"rate are used for the the frozen part so","49:58":"L R which was 0.01 kind of divided by 5","50:03":"or divided by 10 somewhere around that","50:06":"so that's kind of my role of thumb right","50:08":"look for the bit kind of at the bottom","50:10":"find about 10x smaller that's the number","50:13":"that I put here and then Li over 5 or Li","50:16":"over 10 is kind of what I put there","50:18":"seems to work most of the time we'll be","50:22":"talking more about exactly what's going","50:23":"on here is called discriminative","50:25":"learning rates as the course continues","50:29":"so how am I going to get this better","50:31":"than 9 to 9 because you know there are","50:37":"how many people in this competition","50:39":"about a thousand teams right so we want","50:43":"to get into the top 10% so the top five","50:49":"percent would be 0.93 one ish the top","50:52":"10% is going to be about nine to nine","50:55":"ish so we're not","51:00":"and so um here's a trick right I don't","51:04":"know if you remember but I when I","51:06":"created my data set I put size equals","51:10":"128 and actually the images that Carol","51:14":"gave us are 256 so I used the size of","51:17":"128 partially because I wanted to","51:19":"experiment quickly it's it's much","51:22":"quicker and easier to use small images","51:24":"to experiment but there's a second","51:26":"reason I now have a model that's pretty","51:30":"good at recognizing the contents of 128","51:34":"by 128 satellite images so what am I","51:38":"going to do if I now want to create a","51:39":"model that's pretty good at 256 by 256","51:42":"satellite images well why don't I use","51:45":"transfer learning why don't I start with","51:47":"the model that's good at 128 by 128","51:49":"images and fine-tune that so don't start","51:53":"again right and that's actually going to","51:55":"be really interesting because if I'm","51:59":"trained quite a lot if I'm on the verge","52:01":"of overfitting which I don't want to do","52:03":"right then I'm basically creating a","52:07":"whole new dataset effectively one where","52:09":"my images are twice the size on each","52:12":"axis right so four times bigger so it's","52:14":"really a totally different data set as","52:16":"far as my convolutional neural networks","52:17":"concerned so I kind of got to lose all","52:21":"that overfitting I get to start again so","52:23":"let's create a new learner right well","52:27":"let's let's keep our same liner but use","52:30":"a new data bunch where the data bunch is","52:32":"256 by 256 so that's why I actually","52:36":"stopped here right before I created my","52:39":"data sets because I'm going to now take","52:41":"this this data source and I'm going to","52:45":"create a new data bunch with 256 instead","52:49":"so let's have a look at how we do that","52:51":"so here it is take that source right","52:56":"take that source transform it with the","52:59":"same transforms as before but this time","53:01":"use size 256 now that should be better","53:05":"anyway because this is going to be you","53:07":"know higher resolution images but also","53:09":"I'm going to start with I haven't got","53:11":"rid of my learner it's the same","53:12":"I had before so I'm going to start with","53:14":"this kind of pre trade model and so I'm","53:17":"going to replace the data inside by","53:20":"learner with this new data bunch and","53:22":"then I will freeze again so that means","53:25":"I'm going back to just training the last","53:27":"few layers and I will do a new LR find","53:32":"and because I actually now have a pretty","53:36":"good model like it's pretty good for 128","53:38":"by 128 so it's probably going to be like","53:40":"at least okay for 256 by 256 I don't get","53:44":"that same sharp shape that I did before","53:46":"but I can certainly see where it's way","53:48":"too high right so I'm gonna pick","53:52":"something well before where it's way too","53:54":"high again maybe 10x smaller so here I'm","53:57":"gonna go 1e neg 2 over 2 that's you know","54:00":"seems well before it shoots up and so","54:03":"let's fit a little bit more okay so we","54:07":"frozen again so we're just training the","54:08":"last few layers and fit a little bit","54:10":"more and as you can see I very quickly","54:13":"remember kind of mine to weight was","54:15":"where we got to before after quite a few","54:17":"epochs we're straight up there and","54:18":"suddenly we've passed point 9 3 all","54:22":"right so we're now already kind of into","54:26":"the top 10% so we've hit our first goal","54:30":"right we're doing we're at the very","54:32":"least pretty competent at the problem of","54:35":"understeer cognizing satellite imagery","54:36":"but of course now we can do the same","54:39":"thing before we can unfreeze and train a","54:42":"little more ok again using the same kind","54:45":"of approach I described before lr over 5","54:47":"here and even smaller one here trained a","54:50":"little bit more 0.9 3 1 4 so that's","54:58":"actually pretty good point 9 3 1 well","55:05":"somewhere around top 20 ish so you can","55:11":"see actually when my friend Brendan and","55:13":"I entered this competition we came 22nd","55:15":"with 0.9 31 5 and we spent this was a","55:18":"year or two ago months trying to get","55:21":"here so using kind of pretty much you","55:25":"know defaults with","55:26":"tweaks and one trick which is the","55:28":"resizing tweak you can kind of get right","55:33":"up into the top of the leaderboard of","55:34":"this very challenging competition now I","55:36":"should say we we don't really know where","55:41":"we'd be we'd actually have to check it","55:42":"on the test set that Cable gave us and","55:44":"actually submit to the competition but","55:46":"you can do you can do a late submission","55:47":"and so later on in the course we'll","55:51":"learn how to do that but we certainly","55:53":"know we're we're doing well you know","55:56":"we're doing we're doing very well so","55:58":"that's great news and so you can see","56:03":"also as I kind of go along I tend to","56:05":"save things I just you can name your","56:07":"models but ever you like but I just want","56:09":"to basically know you know is it kind of","56:10":"before or after the unfreeze so I kind","56:13":"of had stage one or two what size were","56:15":"though training on what architecture was","56:17":"a training on so that we could have","56:19":"always go back and experiment pretty","56:22":"easily so that's that's planet","56:26":"multi-label classification","56:30":"let's look another example so another","56:34":"the other example next we're gonna look","56:36":"at is this data set called km vid and","56:39":"it's going to be doing something called","56:41":"segmentation we're going to start with a","56:43":"picture like this and we're going to try","56:45":"and create a color-coded picture like","56:47":"this where all of the bicycle pixels are","56:50":"the same color all of the road line","56:53":"pixels are the same color all of the","56:55":"tree pixels of the same color all of the","56:57":"building pixels are same color the sky","56:59":"the same color and so forth okay now","57:01":"we're not actually going to make them","57:03":"colors we're actually going to do it","57:05":"where each of those pixels has a unique","57:09":"number so in this case the top of left","57:11":"is building so I guess building this","57:13":"number for the top right is tree so tree","57:16":"is 26 and so forth all right so in other","57:20":"words this single top left pixel we're","57:26":"basically committing this we're going to","57:27":"do a classification problem just like","57:29":"the pet's classification for the very","57:31":"top left pixel we're going to say what","57:33":"is that top left pixel is it bicycle","57:37":"Road lines sidewalk","57:40":"what is the very top left pixel and then","57:42":"what is the next pixel along what is the","57:45":"next pixel long so we're going to do a","57:46":"little classification problem for every","57:49":"single pixel in every single image so","57:54":"that's called segmentation all right in","57:59":"order to build a segmentation model you","58:02":"actually need to download or create a","58:06":"dataset where someone has actually","58:10":"labeled every pixel so as you can","58:13":"imagine that's a lot of work okay so","58:16":"this is so that's going to be a lot of","58:18":"work you're probably not going to create","58:20":"your own segmentation datasets but","58:23":"you're probably going to download or","58:24":"find them from somewhere else this is","58:25":"very common in medicine life sciences","58:29":"you know if you're looking through","58:31":"slides at nuclei it's very likely you","58:35":"already have a whole bunch of segmented","58:37":"cells and segmented nuclei in radiology","58:41":"you probably already have lots of","58:43":"examples of segmented lesions and so","58:45":"forth so there's a lot of you know kind","58:50":"of different domain areas where there","58:53":"are domain-specific tools for creating","58:55":"these segmented images as you could","58:58":"guess from this example it's also very","59:00":"common in kind of self-driving cars and","59:03":"stuff like that where you need to see","59:05":"you know what what objects are around","59:07":"and where are they so in this case","59:10":"there's a nice data set called cambered","59:14":"which we can download and they have","59:17":"already got a whole bunch of images and","59:20":"segment masks prepared for us which is","59:24":"pretty cool and remember pretty much all","59:29":"of the data sets that we have provided","59:31":"kind of inbuilt URLs for you can see","59:36":"their details at coarse top faster day I","59:39":"slash data sets and nearly all of them","59:43":"are academic data sets where some very","59:46":"kind people have gone to all of this","59:48":"trouble for us","59:49":"so that we can use this data set and","59:51":"made it available for us to","59:53":"so if you do use it one of these","59:56":"datasets for any kind of project it","59:58":"would be very very nice if you were to","60:00":"go and find the citation and say you","60:03":"know thanks to these people for this","60:05":"data set okay because they've they've","60:08":"provided it and all they're asking in","60:10":"return is is for us to give them that","60:12":"credit okay so here is the canva data","60:14":"set here is the citation and on our data","60:17":"sets page that will link to the academic","60:19":"paper where it came from","60:21":"okay Rachel now is a good time for a","60:23":"question is there a way to use learn","60:30":"Dodd LR find and have it return a","60:33":"suggested number directly rather than","60:35":"having to plot it as a graph and then","60:37":"pick a learning rate by visually","60:38":"inspecting that graph there are a few","60:41":"other questions I think around more","60:42":"guidance on reading the learning rate","60:44":"finder graph yeah I mean it's a great","60:48":"question yeah I mean the short answer is","60:49":"no and the reason the answer is no is","60:53":"because this is still a bit more","60:56":"artisinal than I would like you know as","60:58":"you can kind of see I've been kind of","60:59":"saying how I read this learning rate","61:01":"graph depends a bit on what stage I'm at","61:03":"and kind of what the shape of it is I","61:08":"guess like the when you're just training","61:12":"the head","61:13":"so before you unfreeze it pretty much","61:15":"always looks like this and you can","61:18":"certainly create something that kind of","61:19":"creates a slightly you know creates a","61:21":"smooth version of this finds the","61:23":"sharpest negative slope and picked that","61:26":"you would probably be fine nearly all","61:29":"the time but then for you know these","61:32":"kinds of ones you know it requires a","61:36":"certain amount of experimentation but","61:39":"the good news is you can experiment","61:40":"right you can like you can try obviously","61:43":"if the lines going up you don't monitor","61:46":"almost certainly at the very bottom","61:48":"point you don't want it right because","61:51":"you needed to be going downwards but if","61:53":"you kind of start with somewhere around","61:54":"10x smaller than that and then also you","61:57":"could try another 10x more than that try","61:59":"a few numbers and find out which ones","62:01":"which ones worked best and within a","62:04":"small number of weeks","62:06":"you will find that you're picking the","62:09":"best learning rate most of the time all","62:12":"right so I don't know it's kind of so at","62:14":"this stage it still requires a bit of","62:16":"playing around to get a sense of the","62:18":"different kinds of shapes that you see","62:19":"and how to respond to them maybe by the","62:22":"time this video comes out someone will","62:24":"have a pretty reliable auto learning","62:27":"rate finder we're not there yet it's","62:30":"probably not a massively difficult job","62:34":"to do be an interesting project collect","62:37":"a whole bunch of different data sets","62:39":"maybe grab all the data sets from our","62:41":"data sets page try and come up with some","62:44":"simple heuristic compare it to all the","62:48":"different lessons I've shown but it'd be","62:50":"a really fun project to do but at the","62:53":"moment we we don't have that I'm sure","62:59":"it's possible that we haven't got there","63:04":"okay so how do we do image segmentation","63:10":"same way we do everything else and so","63:14":"basically we're going to start with some","63:15":"path we've just got some information in","63:18":"it of some sort so I always start by you","63:20":"know untiring my data do an LS see what","63:24":"I was given in this case there's a live","63:26":"photo record labels and the photo record","63:28":"images so I'll create paths for each of","63:31":"those we'll take a look inside each of","63:34":"those and you know at this point like","63:37":"you can see there's some kind of coded","63:40":"file names for the images and some kind","63:42":"of coded file names for the segment","63:45":"masks and then you kind of have to","63:47":"figure out how to map from one to the","63:48":"other you know normally these kind of","63:51":"data sets will come with a readme you","63:52":"can look at or you can look at their","63:53":"website often it's kind of obvious in","63:56":"this case I can see like these ones","63:59":"always have this kind of particular","64:00":"format these ones always have exactly","64:03":"the same format with an underscore PE so","64:05":"I kind of but I did this honestly I just","64:07":"guessed I thought oh it's probably the","64:09":"same thing underscore P and so I created","64:12":"a little function that basically took","64:16":"the file name and added the underscore P","64:18":"and put it in the different place","64:20":"and I tried opening it and it I noticed","64:22":"it worked so you know so I've created","64:24":"this little function that converts from","64:27":"the image file names to the equivalent","64:30":"label file names I opened up that to","64:33":"make sure it works normally we use open","64:37":"image to open the file and then you can","64:40":"go touch show to take a look at it but","64:44":"this as we described this is not a usual","64:46":"image file that contains integers so you","64:51":"have to use open masks rather than open","64:54":"image because we want to return integers","64:56":"not floats and fast AI knows how to deal","65:00":"with masks so if you go mask show it","65:03":"will automatically color code it for you","65:05":"in some appropriate way that's why we","65:07":"said open masks so you know we can kind","65:09":"of have a look inside look at the data","65:11":"see what the size is","65:12":"so there's 720 by 960 we can take a look","65:16":"at the data inside and so forth the","65:22":"other thing you might have noticed is","65:23":"that they gave us a file called codes","65:25":"text and a file called valid text so","65:28":"codes dot txt we can load it up and have","65:31":"a look inside and not surprisingly it's","65:33":"got a list telling us that for example","65:35":"number four is zero one two three four","65:39":"it's building top left is building there","65:42":"you go okay so just like we had you know","65:44":"Grizzlies black bears and Teddy's here","65:46":"we've got the coding for what each one","65:49":"of these pixels means so we need to","65:54":"create a databank so to create a data","65:56":"bunch we can go through the data block","65:59":"API and say okay we've got a list of","66:01":"image files that are in a folder we need","66:04":"to create labels which we can use with","66:06":"that get Y file name function we just","66:09":"created we then need to split into","66:11":"training and validation in this case I","66:14":"don't do it randomly why not","66:16":"because actually the pictures they've","66:18":"given us frames from videos so if I did","66:21":"them randomly I would be having like two","66:23":"frames next to each other one in the","66:25":"validation set one in the training set","66:27":"that would be far too easy that's","66:28":"treating right so the people that","66:31":"created this data set actually gave us","66:33":"a data set saying here is the list of","66:35":"file names that are meant to be in your","66:37":"validation set and their non contiguous","66:39":"parts of the video so here's how you can","66:44":"let your validation and training using a","66:47":"file name fail so from that I can create","66:51":"my data sets and so I actually have a","66:54":"list of plus names so like often with","66:59":"stuff like the planet data set or the","67:00":"pets data set we actually have a string","67:03":"saying you know this is a this is a pug","67:05":"or this is a ragdoll or this is a bur","67:08":"man or this is cloudy or whatever in","67:11":"this case you don't have every single","67:13":"pixel labeled with an entire string that","67:15":"would be incredibly inefficient they're","67:17":"each labeled with just a number and then","67:19":"there's a separate file telling you what","67:21":"those numbers mean so here's where we","67:23":"get to tell it and the data block API","67:26":"this is the list of what the numbers","67:28":"mean okay so these are the kind of","67:29":"parameters that the data block API gives","67:31":"you here's our transformations and so","67:36":"here's an interesting point remember I","67:38":"told you that for example sometimes we","67:40":"randomly flip an image right what if we","67:43":"randomly flip the independent variable","67:48":"image but we don't also randomly flip","67:51":"this one there now not matching anymore","67:53":"right so we need to tell fast AI that I","67:58":"want to transform the Y so what so X is","68:01":"our independent variable Y is that a","68:03":"pendant I want to transform the Y as","68:04":"well so whatever you do to the X they","68:07":"also want you to do to the way so","68:08":"there's all these little parameters that","68:10":"we can play with and I can create a data","68:13":"bunch I'm using a smaller batch size","68:15":"because as you can imagine because I'm","68:17":"creating a classifier for every pixel","68:19":"that's going to take a lot more GPU","68:21":"that's why I found a batch size of eight","68:23":"is all I could handle and then normalize","68:26":"in the usual way and this is quite nice","68:29":"fast AI because it knows that you've","68:33":"given it a segmentation problem when you","68:35":"call show batch it actually combines the","68:38":"two pieces for you and it will color","68:39":"code the photo isn't that nice right so","68:42":"you can see here the green on the trees","68:45":"and the red on the line","68:47":"and this kind of color on the walls and","68:50":"so forth alright so you can see here","68:52":"here are the pedestrians this is the","68:55":"pedestrians backpack so this is what the","68:57":"ground truth data looks like so once","69:00":"we've got that we can go ahead and","69:08":"create a learner I'll show you some more","69:10":"details in a moment","69:12":"call allow find find the sharpest bit","69:15":"which looks about one a neg to call fit","69:18":"passing in slice ela and see the","69:21":"accuracy and save the model and unfreeze","69:25":"and train a little bit more so that's","69:30":"the basic idea","69:31":"okay and so we're going to have a break","69:33":"and when we come back I'm going to show","69:35":"you some little tweaks that we can do","69:38":"and I'm also going to explain this","69:41":"custom metric that we've created and","69:43":"then we'll be able to go on and look at","69:45":"some other cool things so let's all come","69:47":"back at eight o'clock six minutes okay","69:55":"welcome back everybody and we're going","69:57":"to start off with a question we got","69:58":"during the break could you use","70:04":"unsupervised learning here pixel","70:06":"classification with the bike example to","70:08":"avoid needing a human to label a heap of","70:11":"images well not exactly","70:15":"unsupervised learning but you can","70:17":"certainly get a sense of where things","70:19":"are without needing these kind of labels","70:23":"and time permitting well we'll try and","70:27":"see some examples of how to do that it's","70:30":"you're certainly not going to get as","70:32":"such a quality in such a specific","70:35":"example as what you see here though if","70:38":"you want to get this level of","70:39":"segmentation mask you need a pretty good","70:43":"segmentation mask ground truth to work","70:45":"with","70:51":"and is there a reason we shouldn't","70:53":"deliberately make a lot of smaller data","70:55":"set up sets to step up from in tuning","70:58":"let's say 64 by 64 128 by 128 256 by 256","71:03":"and so on yes you should totally do that","71:08":"it works great try it I found this idea","71:14":"is something that I first came up with","71:18":"in the course a couple of years ago and","71:21":"I kind of thought it seemed obvious and","71:24":"just presented it as a good idea and","71:26":"then I later discovered that nobody had","71:27":"really published this before and then we","71:29":"started experimenting with it and it was","71:32":"basically the main tricks that we use to","71:34":"to to win the imagenet competition the","71:37":"dawn Banshee imagenet training","71:38":"competition and we're like wow people","71:41":"this wasn't only not not only was this","71:45":"not standard nobody had heard of it","71:46":"before there's been now a few papers","71:50":"that use this trick for various specific","71:52":"purposes but it's still largely unknown","71:54":"and it means that you can train much","71:57":"faster it generalizes better there's","72:00":"still a lot of unknowns about exactly","72:02":"like how how small and how big and how","72:06":"much at each level and so forth but I","72:12":"guess in as much as it has a name now it","72:14":"probably does and I guess we call it","72:15":"progressive resizing I found that going","72:18":"much under 64 by 64 tends not to help","72:22":"very much but yeah it's it's a it's a","72:28":"great technique and I definitely try a","72:29":"few a few different sizes what does","72:36":"accuracy mean for pix pixel wise","72:38":"segmentation is it correctly classified","72:41":"pixels divided by the total number of","72:43":"pixels yep that's it so if you mentioned","72:47":"each pixel was a separate you know","72:50":"object you're classifying it's exactly","72:53":"the same accuracy and so you actually","72:56":"can just pass the inaccuracy as","73:02":"geometric","73:03":"but in this case we actually don't we've","73:06":"created a new metric called accuracy cam","73:10":"vid and the reason for that is that when","73:13":"they labeled the images sometimes they","73:17":"labeled a pixel as void I'm not quite","73:20":"sure why maybe it's some that they","73:23":"didn't know or somebody felt it they'd","73:25":"made a mistake or whatever but some of","73:27":"the pixels avoid and in the canvas paper","73:30":"they say when you're reporting accuracy","73:33":"you should remove the void pixels so","73:38":"we've created a accuracy camford so all","73:41":"metrics take the actual output of the","73:46":"neural net that's the input to the actor","73:48":"this is what they called the inputs is","73:49":"the input to the metric and the target","73:51":"ie the labels we're trying to predict so","73:54":"we then basically create a mask so we","73:57":"look for the places where the target is","73:59":"not equal to Boyd and then we just take","74:04":"the input do the Arg max as per usual","74:09":"just the standard accuracy Arg max but","74:11":"then we just grab those that are not","74:13":"equal to the void code and we do the","74:15":"same for the target and we take the mean","74:17":"okay so it's it's just a standard","74:20":"accuracy it's almost exactly the same as","74:22":"the accuracy source code we saw before","74:24":"with the addition of this mask so this","74:28":"quite often happens that the particular","74:32":"kaggle competition metric you're using","74:36":"or the particular way your organization","74:38":"you know scores things or whatever","74:40":"there's often like little tweaks you","74:42":"have to do and this is how easy it is","74:45":"right and so as you'll see to do this","74:48":"stuff the main thing you need to know","74:50":"pretty well is how to do basic","74:54":"mathematical operations in pi torch so","74:57":"that's just something you kind of need","74:59":"to practice I've noticed that most of","75:05":"the examples and most of my models","75:06":"result in a training loss greater than","75:08":"the validation loss what are the best","75:10":"ways to correct that I should add that","75:13":"this still happens after trying many","75:14":"variations on number of","75:16":"and learning rate okay good question so","75:21":"remember from last week if you're","75:22":"training loss is higher than your","75:24":"validation loss than you're underfitting","75:26":"okay it definitely means that your","75:28":"underfitting you want your training loss","75:31":"to be lower than your validation loss if","75:35":"your underfitting","75:37":"you can train for longer you can train a","75:42":"train the last bit at a lower learning","75:44":"rate but if you're still under fitting","75:49":"then you're going to have to decrease","75:51":"regularization and we haven't talked","75:53":"about that yet so in the second half of","75:57":"this part of the course we're going to","75:59":"be talking quite a lot about","76:00":"regularization and specifically how to","76:04":"avoid overfitting or underfitting by","76:07":"using regularization if you want to skip","76:09":"ahead we're going to be learning about","76:11":"weight decay dropout and data","76:14":"augmentation will be the key things that","76:16":"are we talking about okay for","76:25":"segmentation we don't just create a","76:29":"convolutional neural network we can but","76:34":"actually a architecture called unit","76:37":"turns out to be better and actually the","76:41":"let's find it","76:49":"okay so this is what a unit looks like","76:52":"and this is from the University website","76:56":"where they talk about the unit and so","76:59":"we'll be learning about this both in","77:00":"this part of the course and in part two","77:02":"if you do it but basically this bit down","77:07":"on the left hand side is what a normal","77:09":"convolutional neural network looks like","77:11":"it's something which starts with a","77:13":"bigger big image and gradually makes it","77:14":"smaller and smaller and smaller and","77:16":"smaller until eventually you just have","77:17":"one prediction what a unit does is it","77:20":"then takes that and makes it bigger and","77:22":"bigger and bigger again and then it","77:24":"takes every stage of the downward path","77:27":"and kind of copies it across and it","77:29":"creates this new shape","77:30":"it's was originally actually created or","77:34":"published as a biomechanical image","77:37":"segmentation method but it turns out to","77:40":"be useful for far more than just","77:41":"biomedical image segmentation so it was","77:43":"presented at Mick I which is the main","77:47":"medical imaging conference and as of","77:50":"just yesterday it actually just became","77:52":"the most cited paper of all time from","77:56":"that conference so it's been incredibly","77:58":"useful over 3,000 citations you don't","78:01":"really need to know any details at this","78:03":"stage all you need to know is if you","78:05":"want to create a segmentation model you","78:10":"want to be saying learn add or create","78:11":"unit rather than create CNN but you pass","78:16":"at the normal stuff their data bunch and","78:19":"architecture and some metrics ok so","78:24":"having done that everything else works","78:26":"the same you can do the yelow finder","78:28":"find the slope train it for a while","78:32":"what's the accuracy go up save it from","78:35":"time to time","78:36":"unfreeze probably want to go about 10","78:40":"lists we're still going up so probably","78:43":"10 less than that so one enoch 5 comma","78:46":"lr over 5 train a bit more and there we","78:51":"go right now here's something","78:55":"interesting you can learn dot recorder","78:58":"is where we keep track of what's going","79:00":"on during training and it's got a number","79:02":"nice methods one of which is plot losses","79:04":"and this plots your training loss and","79:07":"your validation loss and you'll see","79:11":"quite often they actually go up a bit","79:14":"before they go down why is that that's","79:18":"because you can also plot your learning","79:21":"rate over time and you'll see that the","79:24":"old learning rate goes up and then it","79:27":"goes down why is that because we said","79:31":"fit one cycle and that's what fit one","79:33":"cycle does it actually makes the","79:35":"learning rate start low go up and then","79:38":"go down again why is that a good idea","79:41":"well to find out why that's a good idea","79:44":"let's first of all look at a really cool","79:48":"project done by Jose Fernandez Patil","79:53":"during the week he took our gradient","79:55":"descent demo notebook and actually","80:00":"plotted the weights over time not just","80:05":"the ground truth and model over time and","80:08":"he did it for a few different learning","80:10":"rates and so remember we had two weights","80:13":"we were doing basically y equals ax plus","80:15":"B or in his nomenclature here y equals W","80:20":"naught X plus W 1 and so we can actually","80:23":"look and see over time what happens to","80:27":"those weights and we know this is the","80:28":"correct answer","80:29":"Yeah right so what a learning rate of","80:32":"point one they're kind of like slides on","80:34":"in here and you can see that it takes a","80:36":"little bit of time to get to the right","80:38":"point and you can see the loss improving","80:42":"at a higher learning rate of 0.7 you can","80:45":"see that the ground truth the model","80:48":"jumps to the ground truth really quickly","80:50":"and you can see that the weights jump","80:53":"straight to the right place really","80:54":"quickly and what if we have a learning","80:58":"rate that's really too high you can see","81:00":"it takes a very very very long time to","81:03":"get to the right point or if it's really","81:05":"too high it diverges okay so you can see","81:10":"here why getting the right learning rate","81:12":"is important when you get the right","81:14":"learning rate it","81:15":"zooms into the best but very quickly now","81:20":"as you get closer to the final spot","81:27":"something interesting happens which is","81:30":"that you really want your learning rate","81:33":"to decrease right because you're kind of","81:35":"you're getting close to the right spot","81:37":"right and what actually happens so what","81:45":"actually happens is I can only draw 2d","81:49":"sorry you don't generally actually have","81:52":"some kind of loss function surface that","81:55":"looks like that and remember there's","81:57":"lots of dimensions but it actually tends","81:59":"to kind of look like bumpy like that","82:02":"right and so you kind of want a learning","82:07":"rate that's like high enough to jump","82:10":"over the bumps right but then once you","82:13":"get close to the middle you know once","82:15":"you get close to the the best answer you","82:18":"don't want to be just jumping backwards","82:19":"and forwards between bumps so you really","82:21":"want your learning rate to go down so","82:23":"that as you get closer you take smaller","82:26":"and smaller steps so that's why it is","82:30":"that we want our learning rate to go","82:32":"down at the end now this idea of","82:37":"decreasing the learning rate during","82:38":"training has been around forever and","82:41":"it's just called learning rate annealing","82:44":"but the idea of gradually increasing it","82:46":"at the start is much more recent and it","82:49":"mainly comes from a guy called Leslie","82:51":"Smith if you're in San Francisco next","82:53":"week actually you can come and join me","82:55":"and Leslie Smith we're having a meet-up","82:57":"where we'll be talking about this stuff","82:59":"so come along to that what Leslie","83:03":"discovered is that if you gradually","83:07":"increase your learning rate what tends","83:10":"to happen is that actually actually what","83:17":"tends to happen is that loss function","83:19":"surfaces tend to kind of look something","83:21":"like this bumpy bumpy bumpy bumpy bumpy","83:24":"bumpy bumpy bumpy bumpy bumpy something","83:27":"like this right they have flat areas","83:29":"and bumpy areas and if you end up in the","83:33":"bottom of a bumpy area that that","83:36":"solution will tend not to generalize","83:37":"very well because you've found a","83:39":"solution that's it's good in that one","83:41":"place but it's not very good","83:43":"in other places where else if you found","83:46":"one in the flat area it probably will","83:48":"generalize well because it's not only","83:50":"good in that one spot but it's good to","83:52":"kind of around it as well if you have a","83:55":"really small learning rate it'll tend to","83:57":"kind of plug down and stick in these","84:03":"places right but if you gradually","84:06":"increase the learning rate then it'll","84:08":"kind of like jump down and then as the","84:11":"learning rate goes up it's going to","84:12":"start kind of going up again like this","84:15":"right and then the learning rate now","84:18":"going to be up here it's going to be","84:19":"bumping backwards and forwards and","84:20":"eventually the learning rate starts to","84:22":"come down again and so it'll tend to","84:26":"find its way to these flat areas so it","84:29":"turns out that gradually increasing the","84:32":"learning rate is a really good way of","84:33":"helping the model to explore the whole","84:37":"function surface and try and find areas","84:40":"where both the loss is is low and also","84:44":"it's it's not bumpy because if it was","84:47":"bumpy it would get kicked out again and","84:49":"so this allows us to train at really","84:52":"high learning rates so it tends to mean","84:54":"that we solve our problem much more","84:55":"quickly and we tend to end up with much","84:58":"more generalizable solutions so if you","85:01":"call plot losses and find that it's just","85:04":"getting a little bit worse and then it","85:07":"gets a lot better you've found a really","85:09":"good maximum learning rate so when you","85:11":"actually call fit one cycle you're not","85:15":"actually passing in a learning rate","85:16":"you're actually passing in a maximum","85:19":"learning rate and if it's kind of always","85:23":"going down particularly after you","85:25":"unfreeze that suggests you could","85:28":"probably bump your your learning rates","85:29":"up a little bit because you really want","85:31":"to see this kind of shape it's going to","85:34":"train faster and generalize better just","85:37":"just a little bit right and return to","85:39":"particularly see it in the validation","85:41":"set the orange is the validation set","85:43":"right and again the difference between","85:45":"kind of knowing this theory and being","85:48":"able to do it is looking at lots of","85:51":"these pictures right so like after you","85:53":"train stuff type learn dot recorder dot","85:56":"and hit tab and see what's in there but","86:01":"and particularly the things that start","86:02":"with plot and start getting a sense of","86:04":"like what are these pictures looking","86:06":"like when you're getting good results","86:07":"and then try making the learning rate","86:09":"much higher try making it much lower","86:11":"more epochs lessee paths and get a sense","86:14":"for that it's not like so in this case","86:21":"we use the size and our transforms of","86:28":"the original image size over to these","86:31":"two slashes in Python means integer","86:33":"divide okay because obviously we can't","86:35":"have half pixel amounts in ell sizes so","86:39":"integer divide divided by two and we use","86:41":"the batch size of eight now I found that","86:43":"fits on my GPU it might not fit on yours","86:46":"if it doesn't you can just decrease the","86:48":"batch size down to four and this isn't","86:52":"really solving the problem because the","86:53":"problem is to segment all of the pixels","86:56":"not half of the pixels so I'm going to","86:58":"use the same trick that I did last time","87:01":"which is I'm now going to put the size","87:03":"up to the full size of the source images","87:06":"which means I now have to have my batch","87:09":"size otherwise I ran out of GPU memory","87:11":"and I'm then going to set my learner I","87:17":"can either say loan dot data equals my","87:19":"new data well I actually found us had a","87:21":"lot of trouble with kind of GPU memory","87:23":"so I generally restarted my kernel came","87:25":"back here created a new learner and","87:27":"loaded up the weights that I saved last","87:30":"time but the key thing here being that","87:33":"this learner now has the same weights","87:35":"that I had here but the data is now the","87:38":"full image size so I can now do an LR","87:42":"find again find an area where it's kind","87:45":"of you know well before it goes up so","87:47":"we're going to use one a Nick three and","87:49":"fit some more and then unfreeze and fit","87:54":"some more","87:56":"and you could go to loan dot show","87:59":"results to see how your predictions","88:01":"compare to the ground truth and you're","88:04":"gonna see they really look pretty good","88:07":"not bad huh","88:09":"so how good is pretty good an accuracy","88:14":"of point of ninety two point one five","88:18":"the best paper I know of for","88:21":"segmentation was a paper called the","88:24":"hundred layers tiramisu which developed","88:27":"a convolutional dense net came out about","88:31":"two years ago so after I trained this","88:33":"today I went back and looked at the","88:35":"paper to find their state-of-the-art","88:39":"accuracy here it is and I looked it up","88:47":"and their best was ninety one point five","88:52":"and we got ninety two point one so I got","88:57":"to say where this happened today I was","88:59":"like wow III don't know if better","89:02":"results have come out since this paper","89:04":"but I remember when this paper came out","89:06":"and it was a really big deal I was like","89:08":"wow this this is an exceptionally good","89:11":"segmentation result like when you","89:12":"compare it to the previous bests that","89:14":"they compared it to it was a big step up","89:16":"and so like in last year's course we","89:20":"spent a lot of time in the course","89:22":"re-implementing the hundred layers","89:23":"tiramisu and now with our totally","89:27":"default fast AI + and easily beating","89:33":"this and I also remember this I had to","89:35":"train for hours and hours and hours","89:37":"where else today's I trained in minutes","89:41":"so we've this is a super strong","89:45":"architecture for segmentation so yeah","89:49":"I'm not going to promise that this is","89:51":"the definite state of the art today","89:52":"because I haven't done a complete","89:54":"literature search to see what's happened","89:56":"in the last two years but it's certainly","89:58":"beating the world's best approach the","90:02":"last time I looked into this which was","90:05":"in last year's course basically and so","90:08":"these are kind of just all the little","90:10":"tricks I guess we've picked up along the","90:12":"way","90:13":"in terms of like how to train things","90:15":"well things like using the pre train","90:17":"model and things like you know using the","90:19":"one cycle convergence and all these","90:21":"little tricks they work extraordinarily","90:25":"well and it's really nice to be able to","90:28":"like show something in class where we","90:29":"can say you know I we actually haven't","90:32":"published the paper on the the exact","90:34":"details of how this variation of the","90:37":"unit works there's a few little tweaks","90:38":"we do but if you come back for part two","90:41":"we'll be going into all of the details","90:43":"about how we make this work so well but","90:47":"for you or you have to know at this","90:49":"stage is that you can say learner doctor","90:51":"yet unit and you should get great","90:53":"results also there's another trick you","91:01":"can use if you're running out of memory","91:06":"a lot which is you can actually do","91:09":"something called mixed precision","91:12":"training and mixed precision training","91:15":"means that instead of using for those of","91:17":"you that have done a little bit of","91:18":"computer science instead of using single","91:20":"precision floating point numbers you can","91:23":"do all the calculations in your model","91:25":"with half precision floating point","91:27":"numbers so 16 bits instead of 32 bits","91:30":"tradition I mean the very idea of this","91:33":"has only been around really for the last","91:36":"couple of years in terms of like","91:38":"hardware that actually does this","91:39":"reasonably quickly and then faster a","91:43":"library I think is the first and","91:45":"probably still the only that makes it","91:47":"actually easy to use this if you add","91:49":"through FP 16 on the end of any learner","91:52":"call you're actually going to get a","91:54":"model that trains in 16-bit precision","91:59":"because it's so new you'll need to have","92:03":"kind of the most recent CUDA drivers and","92:06":"all that stuff for this even to work","92:07":"when I tried it this morning on some of","92:10":"the platforms it just killed the colonel","92:12":"so you need to make sure you've got the","92:14":"most recent drivers but if you've got a","92:18":"really recent GPU like a 20 atti","92:21":"not only will it work","92:23":"but it'll work about twice as fast as","92:27":"otherwise now the reason I'm mentioning","92:28":"it is that it's going to use less GPU","92:32":"Ram so even if you don't have like a 28","92:35":"ETA you might find or you'll probably","92:38":"find that things that didn't fit into","92:40":"your GPU without this then do fit in","92:44":"with this now I actually have never seen","92:48":"people use 16 the mixed precision","92:51":"floating point for segmentation before","92:53":"just for a bit of a laugh I tried it and","92:57":"actually discovered that I got even","93:00":"better resolved so I only found this","93:05":"this morning so I don't have anything","93:06":"more to add here rather than quite often","93:09":"when you make things a little bit less","93:11":"precise in deep learning it generalizes","93:13":"a little bit better and I you know I've","93:16":"never seen a 92.5 accuracy on camford","93:21":"before so yeah this not only will this","93:24":"be faster you'll be able to use bigger","93:25":"batch sizes but you might even find like","93:28":"I did that you get an even better result","93:31":"so that's a cool little trick now you","93:34":"just need to make sure that every time","93:35":"you create a learner you're at this 2fp","93:37":"16 if your kernel dies it probably means","93:39":"you have slightly out of date CUDA","93:42":"drivers or maybe even an old to old","93:46":"graphics card I'm not sure exactly which","93:49":"cards support FP 16 okay so one more","93:58":"before we kind of rewind sorry two more","94:03":"the first one I'm going to show you is","94:05":"an interesting data set called the be.we","94:08":"hippos data set and gabrielle finale was","94:13":"kind enough to give us permission to use","94:15":"this in the class his team created this","94:19":"this cool data set here's what the data","94:21":"set looks like it's pictures it's","94:24":"actually got a few things in it we're","94:25":"just going to do a simplified version","94:26":"and one of the things they do is they","94:28":"have a dot saying this is the center of","94:32":"the face and so we're going to try and","94:35":"create a model that can find this","94:37":"ever faced so um for this data set","94:43":"there's a few data set specific things","94:46":"we have to do which I don't really even","94:48":"understand but I just know from the","94:50":"readme that you have to they use some","94:52":"kind of depth sensing camera I think","94:54":"they actually use to connect you know","94:56":"Xbox Kinect there's some kind of","94:58":"calibration numbers that they provide in","94:59":"a little file which I had to read in and","95:01":"then they provided a little function","95:03":"that you have to use to take their","95:06":"coordinates to change it from this this","95:09":"depth sensor calibration thing to end up","95:12":"with actual coordinates so when you when","95:15":"you open this and you see these at all","95:16":"conversion routines that's just you know","95:20":"I'm just doing what they told us to do","95:22":"basically it's about nothing","95:23":"particularly to do with deep learning to","95:25":"end up with this dot the interesting bit","95:28":"really is where we create something","95:32":"which is not an image or an image","95:34":"segment put an image points and we'll","95:38":"mainly learn about this later in the","95:40":"course but basically image points use","95:45":"this idea of kind of their coordinates","95:48":"right they're not pixel values they're","95:51":"XY coordinates there's just two numbers","95:53":"as you can see let me see","96:07":"so here's an example for a particular","96:10":"image file name this particular image","96:12":"file and here it is the coordinates of","96:16":"the centre of the face are at 263 , 428","96:20":"and here it is so there's just two","96:24":"numbers which represent whereabouts on","96:26":"this picture as the centre of the face","96:27":"so if we're going to create a model that","96:30":"can find the center of a face we need a","96:32":"neural network that spits out two","96:34":"numbers but note this is not a","96:38":"classification model these are not two","96:40":"numbers that you look up in a list to","96:42":"find out that they're Road or building","96:43":"or ragdoll cat or whatever their actual","96:47":"locations so so far everything we've","96:53":"done has been a classification model","96:54":"something that's created labels or","96:56":"classes this for the first time is what","96:59":"we call a regression model a lot of","97:01":"people think regression means linear","97:03":"regression it doesn't regression just","97:05":"means any kind of model where your","97:07":"output is some continuous number or set","97:10":"of numbers so this is we need to create","97:12":"an image regression model something that","97:15":"can predict these two numbers so how do","97:19":"you do that same way as always right so","97:23":"we can actually just say I've got a list","97:26":"of image files it's in a folder and I","97:29":"want to label them using this function","97:32":"that we wrote that basically does the","97:34":"stuff that the readme says to grab the","97:36":"coordinates out of their text files so","97:39":"that's going to give me the two numbers","97:40":"for everyone and then I'm going to split","97:43":"it according to some function and so in","97:45":"this case that the files they gave us","97:50":"again they're from videos and so I","97:52":"picked just one folder to be my","97:55":"validation set in other words a","97:57":"different person so again I was trying","97:59":"to think about like how do I validate","98:01":"this fairly so I said well the the fair","98:03":"validation would be to make sure that it","98:05":"works well on a person that it's never","98:07":"seen before","98:08":"so my validation set is all going to be","98:10":"a particular person create a data set","98:13":"and so this data set I just tell it what","98:15":"kind of data set is it well they're","98:17":"going to be a set of point","98:18":"two points means you know specific","98:20":"coordinates do some transforms again I","98:24":"have to say transform y equals true","98:26":"because that red dot needs to move if I","98:28":"flip or rotate or warp okay pick some","98:32":"size I just picked a size that's going","98:34":"to work pretty quickly create a data","98:35":"bunch normalize it and again show batch","98:38":"there it is okay I noticed that there","98:41":"are red dots don't always seem to be","98:43":"quite in the middle of the face I don't","98:44":"know exactly what they're kind of","98:47":"internal algorithm for putting dots on","98:50":"they kind of sometimes looks like it's","98:52":"meant to be the nose but sometimes it's","98:53":"not quite the nose anyway you get the","98:56":"reps it's somewhere around the center of","98:57":"the face or the nose so how do we create","99:00":"a model we create a CNN but we're going","99:07":"to be learning a lot about loss","99:09":"functions in the next few lessons but","99:12":"generally that basically the loss","99:14":"function is that that that number that","99:16":"says how good is the model and so for","99:19":"classification we use this loss function","99:22":"called cross-entropy loss which says","99:24":"basically remember this from earlier","99:27":"lessons did you predict the correct","99:30":"class and were you confident of that","99:32":"prediction now we can't use that for","99:35":"regression so instead we use something","99:37":"called mean squared error and if you","99:40":"remember from last lesson we actually","99:43":"implemented being squared error from","99:44":"scratch it's just the difference between","99:45":"the two squared and added up together","99:49":"okay so we need to tell it this is not","99:52":"classification so we use mean squared","99:53":"error shown all these so this is not","100:04":"classification so we have to use mean","100:06":"squared error and then once we've","100:08":"created the learner we've taught it what","100:09":"loss function to use we can go ahead and","100:11":"do Ella find we can then fit and you can","100:15":"see here within a minute and a half","100:18":"our mean squared error is 0.0004 now the","100:23":"nice thing is about like mean squared","100:24":"error that's very easy to interpret","100:26":"right so we're trying to predict","100:28":"something which is somewhere around","100:31":"a few hundred and we're getting a","100:34":"squared error on average of 0.0004 so we","100:38":"can feel pretty confident that this is a","100:39":"really good model and then we can look","100:41":"at the results by learner results and we","100:43":"can see predictions ground truth it's","100:47":"doing nearly perfect job okay so that's","100:52":"how you can do image regression models","100:56":"so anytime you've got something you're","100:57":"trying to predict which is some","100:59":"continuous value you use an approach","101:01":"that's something like this so last","101:08":"example before we look at some kind of","101:09":"more foundational theory stuff NLP and","101:13":"next week we're going to be looking at a","101:15":"lot more NLP but let's now do the same","101:19":"thing but rather than creating a","101:21":"classification of pictures let's try and","101:24":"classify documents and so we're going to","101:29":"go through this in a lot more detail","101:30":"next week but let's do the quick version","101:32":"rather than importing from faster I","101:35":"Division are now import for the first","101:37":"time from faster I dot text that's where","101:39":"you'll find all the application specific","101:41":"stuff for analyzing text documents and","101:44":"in this case we're going to use a data","101:45":"set called IMDB and IMDB has lots of","101:50":"movie reviews they're generally about a","101:54":"couple of thousand words and each movie","101:57":"review has been classified as either","102:00":"negative or positive so it's just in a","102:04":"CSV file so we can use pandas to read it","102:06":"we can take a little look we can take a","102:08":"look at a review and basically as per","102:13":"usual we can either use factory methods","102:17":"or the data block API to create a","102:20":"databank so here's the quick way to","102:22":"create a data bunch from a CSV of texts","102:25":"data bunch from CSV and that's that and","102:32":"yeah at this point I could create a","102:35":"learner and start training it but we're","102:38":"going to show you a little bit more","102:39":"detail which remain going to look at","102:41":"next week the steps that actually happen","102:43":"when you create these data buns","102:45":"there's a few steps the first is it does","102:48":"something called tokenization or does it","102:51":"takes those words and it converts them","102:54":"into a standard form of tokens where","102:57":"there's basically each token represents","103:00":"a word but it does things like see here","103:02":"see how didn't has been turned here into","103:05":"two separate words and you see how","103:07":"everything's been lowercased see how","103:10":"your has been turned into two separate","103:12":"words so tokenization is trying to make","103:15":"sure that each each token each each","103:19":"thing that we've got with spaces around","103:21":"it here represents a single you know","103:24":"linguistic concept okay","103:28":"also it finds words that are really rare","103:32":"like really rare names and stuff like","103:35":"that and replaces them with a special","103:37":"token called unknown so anything's","103:40":"starting with XX in fast AI is some","103:42":"special token so this is tokenization so","103:46":"we end up with something where we've got","103:48":"a list of tokenized words you'll also","103:51":"see that things like punctuation end up","103:53":"with spaces around them to make sure","103:55":"that they're separate tokens the next","103:59":"thing we do is we take a complete unique","104:03":"list of all of the possible tokens","104:05":"that's called the vocab and that gets","104:07":"created for us and so here's the first","104:10":"ten items of the vocab so here is every","104:13":"possible token the first ten of them","104:15":"that appear in our all of the movie","104:17":"reviews and we then replace every movie","104:21":"review with a list of numbers and the","104:24":"list of numbers simply says what","104:27":"numbered thing in the vocab is in this","104:30":"place so here 6 is 0 1 2 3 4 5 6 so this","104:35":"is the word ah and this is 3 0 1 2 3","104:39":"this was a comma and so forth right so","104:42":"through","104:43":"organization and numerical ization this","104:46":"is the standard way in NLP of turning a","104:48":"document into a list of numbers we can","104:53":"do that with the data block API right so","104:56":"this time it's not image files list","104:59":"it's text spit data from a CSB convert","105:04":"them to datasets tokenize the numerical","105:08":"eyes them create a data bunch and at","105:12":"that point we can start to create a","105:17":"model as we learn about next week when","105:22":"we do NLP classification we actually","105:24":"create two models the first model is","105:27":"something called a language model which","105:31":"as you can see we train in a kind of a","105:34":"usual way we say we want to create a","105:36":"language model learner we train it we","105:40":"can save it and we unfreeze we train","105:42":"some more and then after we've created a","105:44":"language model we fine-tune it to create","105:47":"the classifier so here's the thing where","105:49":"we create the data bunch of the","105:50":"classifier we created learner train it","105:58":"and we end up with some accuracy so","106:02":"that's the really quick version we're","106:04":"going to go through it in more detail","106:05":"next week but you can see the basic idea","106:07":"of training and NLP classifier is very","106:11":"very very similar to creating every","106:13":"other model we've seen so far and this","106:17":"accuracy so the current state of the art","106:19":"for IMDB classification is actually the","106:24":"algorithm that we built and published","106:26":"with colleague called as named Sebastian","106:29":"Reuter and this basically what I just","106:32":"showed you is pretty much the state of","106:34":"the art algorithm with some minor tweaks","106:35":"you can get this up to about 95% I'm if","106:39":"you try really hard so this is very","106:40":"close to the state of the art accuracy","106:42":"that we developed the question okay","106:48":"that's a great time for question for a","106:54":"dataset very different than imagenet","106:55":"like the satellite images or genomic","106:57":"images shown in lesson two we should use","107:00":"our own stats Jeremy once said if you're","107:03":"using a pre trained model you need to","107:04":"use the same stats it was trained with","107:06":"why is that isn't it that normalized","107:09":"data with its own stats will have","107:11":"roughly the same distribution","107:12":"like imagenet the only thing I can think","107:15":"of which may differ is skewness is it","107:18":"the possibility of skewness or something","107:19":"else the reason of your statement and","107:22":"does that mean you don't recommend using","107:23":"pre train models with very different","107:25":"data sets like the one point mutation","107:28":"that you mentioned in lesson two nope","107:34":"as you can see I've used pre trade","107:36":"models for all of those things","107:38":"every time I've used an image Nate train","107:39":"pre train model and every time I've used","107:41":"image net stats why is that because that","107:45":"model was trained with those stats so","107:48":"for example imagine you're trying to","107:51":"classify different types of green frogs","107:55":"so if you were to use your own per","107:58":"channel means from your data set you","108:00":"would end up converting them to a mean","108:02":"of zero a standard deviation of one for","108:05":"each of your red green and blue channels","108:07":"which means they don't look like green","108:09":"frogs anymore they now look like grey","108:11":"frogs right that imagenet expects frogs","108:14":"to be green okay so you need to","108:17":"normalize with the same stats that the","108:19":"imagenet training people normalized with","108:21":"otherwise the unique characteristics of","108:24":"your data set won't appear anymore","108:25":"you've actually normalized them out in","108:27":"terms of the per channel statistics so","108:29":"you should always use the same stats","108:31":"that the model was trained with okay so","108:40":"in every case what we're doing here is","108:44":"we're using gradient descent with mini","108:48":"batches so stochastic gradient descent","108:50":"to fit some parameters of a model and","108:53":"those parameters are parameters to","108:56":"basically make fixed multiplications and","108:59":"the second half of this part we're","109:01":"actually going to learn about a little","109:02":"tweak called convolutions but it's a","109:04":"basically a type of matrix","109:06":"multiplication","109:07":"the thing is though no amount of matrix","109:11":"multiplications is possibly going to","109:13":"create something that can read IMDB","109:18":"movie reviews and decide if it's","109:19":"positive or negative or look at","109:21":"satellite imagery and decide whether","109:23":"it's got a road in it that's far more","109:26":"and linear classifier can do now we know","109:28":"these are deep neural networks and deep","109:31":"neural networks period contain lots of","109:33":"these matrix multiplications but every","109:35":"matrix multiplication is just a linear","109:39":"model and a lot a linear function on top","109:42":"of a linear function is just another","109:45":"linear function if you remember back to","109:48":"your you know high school math you might","109:51":"remember that if you you know have a y","109:54":"equals ax plus B and then you stick","109:56":"another you know C y plus D on top of","110:01":"that it's still just another slope and","110:04":"another intercept so no amount of","110:06":"stacking matrix multiplications is going","110:09":"to help in the slightest so what are","110:13":"these models actually what are we","110:14":"actually doing and here's the","110:18":"interesting thing","110:19":"all we're actually doing is we literally","110:24":"do have a matrix multiplication or a","110:26":"slight variation like a convolution that","110:28":"we'll learn about and but after each one","110:30":"we do something called a non linearity","110:34":"or an activation function an activation","110:38":"function is something that takes the","110:39":"result of that matrix multiplication and","110:42":"sticks it through some function and","110:46":"these are some of the functions that we","110:50":"use in the old days the most common","110:55":"function that we used to use was","110:58":"basically this shape these shapes are","111:02":"called sigmoid and they have you know","111:09":"particular mathematical definitions","111:12":"nowadays we almost never use those for","111:16":"these between H matrix multiply nowadays","111:21":"we nearly always use this one it's","111:25":"called a rectified linear unit it's very","111:28":"important when you're doing deep","111:29":"learning to use big long words that","111:31":"sound impressive otherwise normal people","111:33":"might think they can do it too but just","111:37":"between you and me a rectified linear","111:39":"is to find using the following function","111:46":"that's it","111:48":"okay so and if you want to be really","111:51":"exclusive of course you then shorten the","111:54":"long version and you call it a RAL you","111:56":"to show that you're really in the","111:57":"exclusive in the exclusive team so this","112:00":"is a value activation right so here's","112:04":"the crazy thing if you take your red","112:07":"green blue pixel inputs and you chuck","112:10":"them through a matrix modification and","112:11":"then you replace the negatives with zero","112:15":"and you put it through another matrix","112:17":"modification place the negatives at zero","112:19":"and you keep doing that again and again","112:21":"and again you have a deep learning","112:23":"neural network that's it right so how","112:28":"the hell does that work so extremely","112:32":"cool guy called Michael Nielsen showed","112:34":"how this works he has a very nice","112:38":"website affecting more than a website","112:40":"it's a book neural networks and deep","112:43":"learning calm and he has these beautiful","112:45":"little JavaScript things where you can","112:48":"get to play around because this was back","112:50":"in the old days this was back when we","112:52":"used to use sigmoids right and what he","112:54":"shows is that if you have enough little","112:58":"these shows these little matrix","113:00":"multiplications if you have enough","113:01":"little matrix multiplications followed","113:03":"by sigmoids and there's exactly the same","113:05":"thing works for a matrix multiplication","113:07":"followed by a value you can actually","113:09":"create arbitrary shapes right and so","113:15":"this this this idea that these","113:17":"combinations of of linear functions and","113:22":"nonlinearities can create arbitrary","113:25":"shapes actually has a name and this name","113:27":"is the universal approximation theorem","113:30":"and what it says is that if you have","113:33":"stacks of linear functions and","113:36":"nonlinearities the thing you end up with","113:38":"can approximate any function arbitrarily","113:43":"closely so you just need to make sure","113:46":"that you have a big enough matrix to","113:48":"multiply by or enough of them so if you","113:52":"have","113:53":"you know now this this this dysfunction","113:56":"which is just a sequence of matrix","113:58":"multiplies and nonlinearities where the","114:00":"nonlinearities can be you know basically","114:02":"any of these things we normally use this","114:04":"one if that can approximate anything","114:07":"then all you need is some way to find","114:09":"the particular values of the of the","114:12":"weight matrices in your matrix model","114:14":"players that solve the problem you want","114:15":"to solve and we already know how to find","114:18":"the values of parameters we can use","114:20":"gradient descent and so that's actually","114:23":"it right and this is the bit I find the","114:28":"hardest thing normally to explain to","114:30":"students is that we're actually done","114:33":"male people often come up to me after","114:35":"this lesson and they say what's the rest","114:39":"please explain to me the rest of deep","114:41":"learning but like no there's no rest","114:43":"like we have a function where we take","114:46":"our input pixels or whatever we multiply","114:48":"them by some weight matrix we replace","114:50":"the negatives with zeros we multiply it","114:52":"by another weight matrix replace the","114:53":"negative zeros we do that a few times we","114:56":"see how close it is to our target and","114:58":"then we use gradient descent to update","115:01":"our weight matrices using the","115:02":"derivatives and we do that a few times","115:05":"and eventually we end up with something","115:07":"that can classify movie reviews or can","115:11":"recognize pictures of reptile cats that","115:15":"that's actually it okay so it's it's the","115:18":"reason it's hard to understand","115:22":"intuitively is because we're talking","115:26":"about weight matrices that have you know","115:28":"once you read them all up something like","115:30":"a hundred million parameters they're","115:33":"very big weight matrices all right so","115:35":"your intuition about what multiplying","115:39":"something by a linear model and","115:41":"replacing the negative zeros a bunch of","115:43":"times can do your intuition doesn't hold","115:46":"right you just have to accept","115:49":"empirically the truth is doing that","115:52":"works really well so in part two of the","115:56":"course we're actually going to build","115:58":"these from scratch right but I mean just","116:02":"to skip ahead you know basically we'll","116:05":"find that you know it's going to be","116:07":"kind of five lines of code right it's","116:09":"going to be a little for loop that goes","116:10":"you know T equals you know X at weight","116:16":"matrix one t2 equals max of T comma zero","116:23":"stick that in a for loop that goes","116:25":"through which weight matrix and at the","116:27":"end calculate my loss function and of","116:31":"course we're not going to calculate the","116:32":"gradients ourselves because pi torch","116:34":"does that for us and that's about it so","116:42":"okay Kristin there's a question about","116:46":"tokenization I'm curious about how","116:48":"tokenizing words works when they depend","116:50":"on each other such as San Francisco yeah","116:56":"okay okay tokenization how do you","117:05":"tokenize something like san francisco","117:09":"san francisco contains two tokens San","117:13":"Francisco that's it that's how you","117:16":"tokenize San Francisco the Christian may","117:18":"be coming from people who have done like","117:22":"traditional NLP often need to kind of","117:26":"use these things called engrams and","117:28":"engrams are kind of this idea of like a","117:30":"lot of NLP in the old days was all built","117:34":"on top of linear models where you","117:36":"basically counted how many times","117:38":"particular strings of text appeared like","117:41":"the phrase San Francisco that would be a","117:44":"bigram","117:45":"for an Engram with an N of 2 the cool","117:49":"thing is that we're deep learning we","117:50":"don't have to worry about that like like","117:52":"with many things a lot of the complex","117:55":"feature engineering disappears when you","117:56":"do deep learning so with deep learning","117:58":"each token is literally just a word or","118:03":"in the case that the word really","118:05":"consists of two words like you're you","118:07":"split it into two words and then what","118:10":"we're going to do is we're going to then","118:13":"let the deep learning model figure out","118:16":"how best to combine words together","118:20":"now when we see like let the beep","118:21":"learning model figure it out of course","118:22":"all we really mean is find the weight","118:26":"matrices using gradient descent that","118:28":"gives the right answer like there's not","118:30":"really much more to it than that again","118:34":"there's some minor tweaks right in the","118:36":"second half of the course we're going to","118:37":"be learning about the particular tweak","118:39":"for image models which is using a","118:41":"convolution there'll be a CNN for","118:44":"language there's a particular tweak we","118:46":"do called using recurrent models or an","118:49":"RNN but they're very minor tweaks on on","118:53":"what we've just described so basically","118:54":"it turns out with an R and n that it it","118:58":"can learn that sound plus Francisco has","119:03":"a different meaning when those two","119:05":"things are together some satellite","119:10":"images have four channels how can we","119:12":"deal with data that has four channels or","119:14":"two channels when using pre-trained","119:16":"bottles yeah that's a good question I","119:22":"think that's something that we're going","119:23":"to try and incorporate into fast AI so","119:28":"hopefully by the time you watch this","119:29":"video they'll be easier ways to do this","119:31":"but the basic idea is a pre trained","119:36":"imagenet model expects a red green and","119:39":"blue pixels so if you've only got two","119:44":"channels there's a few things you can do","119:46":"but basically you'll want to create a","119:49":"third Channel and so you can create the","119:52":"third channel as either being all zeros","119:54":"or it could be the average of the other","119:57":"two channels and so you can just use you","120:01":"know normal hi torch arithmetic to","120:05":"create that third channel you could","120:06":"either do that ahead of time in a little","120:09":"loop and save your three Channel","120:11":"versions or you could create a custom","120:13":"data set class that does that on demand","120:18":"for a full channel you probably don't","120:23":"want to get rid of the fourth channel so","120:25":"instead what you'd have to do is to","120:26":"actually modify the model itself so to","120:30":"know how to do that we'll only know how","120:32":"to do","120:33":"in a couple more lessons time but","120:35":"basically the idea is that the initial","120:37":"weight matrix weight matrix is really","120:41":"the wrong term they're not waiting","120:42":"matrices their weight tensors so they","120:45":"can have more than just two dimensions","120:47":"so that weight that initial weight","120:49":"matrix in the neural net it's going to","120:52":"have it's actually a tensor and one of","120:54":"its axes is going to have three whatever","120:58":"three slices so you would just have to","121:02":"change that to add an extra slice which","121:05":"I would generally just initialize to","121:07":"zero or to some random numbers so that's","121:11":"the short version but really to answer","121:13":"this to understand exactly what I meant","121:15":"by that we're going to need a couple","121:16":"more lessons to get there okay","121:20":"so wrapping up what if we looked at","121:24":"today basically we started out by saying","121:34":"hey it's really easy now to create web","121:39":"apps we've got starter kits for you that","121:43":"show you how to create web apps and","121:45":"people have created some really cool web","121:47":"apps using what we've learned so far","121:48":"which is single label classification but","121:54":"the cool thing is the exact same steps","121:57":"we use to do single label classification","122:00":"you can also do to do multi-label","122:04":"classification such as in the planet or","122:12":"you could use to do segmentation or you","122:19":"could use to do or you could use to do","122:26":"any kind of image regression or this is","122:30":"probably a bit earlier if you try this","122:31":"yet you could do for an LP","122:33":"classification and a lot more so and in","122:37":"each case all we're actually doing is","122:42":"we're doing gradient descent on not just","122:45":"two","122:46":"parameters but on maybe 100 million","122:49":"parameters but still just plain gradient","122:51":"descent along with a non-linearity which","122:58":"is normally this one which it turns out","123:01":"the universal approximation theorem","123:03":"tells us lets us arbitrarily accurately","123:06":"approximate any given function including","123:09":"functions such as converting a spoken--","123:13":"waveform into the thing the person was","123:15":"saying while converting a sentence in","123:17":"Japanese to a sentence in English while","123:20":"converting a picture of a dog into the","123:22":"word dog these are all mathematical","123:25":"functions that we can learn using this","123:27":"approach so this week see if you can","123:33":"come up with an interesting idea of a","123:35":"problem that you would like to solve","123:37":"which is either multi-label","123:39":"classification or image regression or","123:43":"image segmentation something like that","123:46":"and see if you can try to solve that","123:51":"problem you will probably find the","123:53":"hardest part of solving that problem is","123:56":"coming up creating the data Bunch and so","123:58":"then you'll need to dig into the data","124:00":"block API to try to figure out how to","124:02":"create the data Bunch from the data you","124:04":"have and with some practice you will","124:09":"start to get pretty good at that it's","124:10":"not a huge API there's a small number of","124:12":"pieces it's also very easy to add your","124:15":"own but for now you know ask on the","124:18":"forum if you try something and you get","124:21":"stuck ok great so um next week we're","124:27":"going to come back and we're going to","124:29":"look at some more NLP we're going to","124:31":"learn some more about some details about","124:35":"how we actually train with SGD quickly","124:37":"we're going to learn about things like","124:38":"Adam and rmsprop and so forth and","124:42":"hopefully we're also going to show off","124:44":"lots of really cool web apps and models","124:47":"that you've all built during the week so","124:49":"I'll see you then Thanks"}},60:function(e){e.exports={"00:00":"um welcome everybody to lesson 5 and so","00:05":"we have officially peaked and everything","00:09":"is down here from here as of halfway","00:13":"through the last lesson we started with","00:18":"computer vision because it's the most","00:23":"mature kind of out-of-the-box ready to","00:26":"use deep learning application it's","00:30":"something which if you're not using deep","00:32":"learning you won't be getting good","00:34":"results so the difference you know","00:35":"hopefully between not during lesson one","00:38":"versus doing less than one you've gained","00:40":"a new capability you didn't have before","00:42":"and you kind of get to see a lot of the","00:47":"kind of tradecraft of training and","00:51":"effective neural net and so then we","00:53":"moved into NLP because text is kind of","00:58":"another one which you really kind of","01:00":"can't do really well without deep","01:02":"learning generally speaking and it's","01:06":"just got to the point where it's pretty","01:08":"you know works pretty well now in fact","01:10":"the New York Times just featured an","01:12":"article about the latest advances in","01:14":"deep learning for text yesterday and","01:17":"talked quite a lot about the work that","01:19":"we've done in that area along with open","01:22":"AI and Google and Allen Institute of","01:26":"artificial intelligence and then we've","01:32":"kind of finished our application journey","01:35":"with tabula and collaborative filtering","01:39":"partly because tabular and collaborative","01:42":"filtering of things that you can still","01:44":"do pretty well without deep learning so","01:47":"it's not such a big step it's not a kind","01:49":"of whole new thing that you could do","01:50":"that you couldn't used to do and also","01:52":"because the you know we're going to try","01:58":"to get to a point where we understand","01:59":"pretty much every line of code and the","02:01":"implementations of these things and the","02:03":"implementations of those things it's","02:05":"much less intricate than","02:08":"vision and NLP so as we come down this","02:12":"other side of the journey which is like","02:14":"all the stuff we've just done how does","02:16":"it actually work by by starting where we","02:19":"just ended which is starting with","02:21":"collaborative filtering and then tabular","02:23":"we're going to be able to see what all","02:25":"those lines of code do by the end of","02:28":"today's lesson that's our goal so","02:33":"particularly this lesson you should not","02:35":"expect to come away knowing how to solve","02:39":"you know how to do applications you","02:41":"couldn't do before but instead you","02:43":"should have a better understanding of","02:44":"how we've actually been solving the","02:46":"applications we've seen so far","02:48":"particularly we're going to understand a","02:51":"lot more about regularization which is","02:53":"how we go about managing over versus","02:56":"under fitting and so hopefully you can","02:58":"use some of the tools from this lesson","02:59":"to go back to your previous projects and","03:02":"get a little bit more performance or","03:05":"handle models where previously maybe you","03:07":"felt like your data was not enough or","03:10":"maybe your underfitting","03:11":"and so forth and it's also going to lay","03:14":"the groundwork for understanding","03:15":"convolutional neural networks and","03:17":"recurrent neural networks that will do","03:19":"deep dives into in the next two lessons","03:21":"and as we do that we're also going to","03:23":"look at some new applications some new","03:25":"vision and NLP applications let's start","03:34":"where we left off last week do you","03:41":"remember this picture so this picture we","03:47":"were looking at kind of waters a deep","03:51":"neural net look like and we had various","03:57":"layers and the first thing we pointed","04:01":"out is that there are only and exactly","04:05":"two types of layer there are layers that","04:09":"contain parameters and there are layers","04:12":"that contain activations parameters the","04:17":"things that your model","04:20":"learns they're the things that you use","04:22":"gradient descent to go parameters -","04:28":"equals learning rate times parameters","04:31":"grad okay that's our basic that's what","04:35":"we do okay and those parameters are used","04:40":"by multiplying them by input activations","04:44":"doing a matrix product so the yellow","04:48":"things are our weight matrices your","04:52":"weight tensors more generally but that's","04:55":"plus enough so we take some input","04:57":"activations or some layer activations","04:59":"and we multiply it by weight matrix to","05:03":"get a bunch of activations so","05:05":"activations numbers that these are","05:09":"numbers that are calculated okay so I","05:12":"find in our study group I keep getting","05:14":"questions about where does that number","05:15":"come from and I always answer it in the","05:18":"same way you tell me is it a parameter","05:19":"or is it an activation because it's one","05:22":"of those two things okay that's where","05:24":"numbers come from","05:25":"I guess inputs a kind of a special","05:27":"activation so they're not calculated","05:30":"they're just there so maybe that's a","05:33":"special case so maybe it's an input or a","05:35":"parameter or an activation activations","05:40":"don't only come out of matrix","05:41":"multiplications","05:42":"they also come out of activation","05:44":"functions and the most important thing","05:46":"to remember about an activation function","05:47":"is that it's an element-wise function so","05:51":"it's a function that is applied to each","05:52":"element of the input that evasions in","05:55":"turn and creates one activation for each","05:58":"input element so if it starts with a","06:00":"twenty long vector it creates a twenty","06:03":"long vector by looking at each one of","06:05":"those in turn doing one thing to it and","06:08":"spitting out the answer okay so an","06:09":"element-wise function value is the main","06:13":"one we've looked at and honestly it","06:16":"doesn't too much matter which you pick","06:18":"so we don't spend much time talking","06:20":"about activation functions because if","06:21":"you just use RAL you you'll get a pretty","06:23":"good answer pretty much all the time and","06:27":"so then we learnt that this combination","06:29":"of matrix multiplications followed by","06:32":"values","06:33":"stack together has this amazing","06:35":"mathematical property called the","06:37":"universal approximation theorem which is","06:39":"if you have big enough weight matrices","06:41":"and enough of them it can solve any","06:45":"arbitrarily complex mathematical","06:47":"function to any arbitrarily high level","06:51":"of accuracy assuming that you can train","06:55":"the parameters both in terms of time and","06:58":"data availability and so forth okay so","07:03":"that's the bit which I find particularly","07:07":"more advanced computer scientists get","07:10":"really confused about is they're always","07:12":"asking like where's the next bit what's","07:15":"the trick how does it work but that's it","07:18":"you know you just do those things and","07:20":"you pass back the gradients and you","07:24":"update the weights with the learning","07:25":"rate and that's it so that piece where","07:29":"we take the loss function between the","07:34":"actual targets and the output of the","07:39":"final layer for the final activations we","07:42":"calculate the gradients with respect to","07:44":"all of these yellow things and then we","07:46":"update those yellow things by learning","07:48":"rate by subtracting learning rate times","07:50":"the gradient that process of calculating","07:53":"those gradients and then subtracting","07:54":"like that is called back propagation","07:57":"okay so when you hear the term well","08:01":"that's this very small fun so when you","08:05":"see when you hear the term back","08:09":"propagation it's one of these terms that","08:14":"neural networking folks love to use it","08:16":"sounds very impressive okay that you can","08:19":"replace it with your head with weights","08:23":"minus equals weight start grad times","08:26":"learning rate or parameters I should say","08:28":"rather than weights a bit more general","08:30":"okay","08:31":"so that's what we covered last week and","08:35":"then I mentioned last week that we're","08:37":"going to cover a couple more things I'm","08:41":"going to come back to these ones cross","08:42":"entropy and softmax later today let's","08:45":"talk about fine-tuning","08:47":"now so what happens when we take a res","08:50":"net 34 and we do transfer learning","08:54":"what's actually going on so the first","08:56":"thing to notice is there is net 34 that","08:59":"that we grabbed from image net has a","09:03":"very specific weight matrix at the end","09:05":"it's a weight matrix that has 1000","09:08":"columns why is that because image net","09:11":"the problem they asked you to solve in","09:13":"the image net competition is please","09:15":"figure out which one of these 1000 image","09:18":"categories this picture is so that's why","09:21":"they need a thousand things here because","09:23":"an image net this target vector is","09:26":"length a thousand it's a you've got to","09:29":"pick the probability that it's which one","09:32":"of those thousand things so there's a","09:37":"couple of reasons this weight matrix is","09:39":"no good to you when you're doing","09:40":"transfer learning the first is that you","09:43":"probably don't have a thousand","09:44":"categories you know I was trying to do","09:45":"teddy bears black bears or brown bears","09:47":"so I don't want a thousand categories so","09:50":"the second is even if I did have it","09:51":"exactly a thousand categories they're","09:52":"not the same thousand categories that","09:54":"are in image net so basically this whole","09:57":"weight matrix is a waste of time for me","10:00":"so what do we do we throw it away so","10:04":"when you go create CNN in first AI it","10:06":"deletes that and what does it do instead","10:09":"instead it puts in two new weight","10:13":"matrices in there for you with a rel you","10:20":"in between and so there are some","10:26":"defaults as to what size this first one","10:30":"is but the second one the size there is","10:34":"as big as you need it to be so in your","10:37":"data bunch which you passed your learner","10:40":"from that we know how many activations","10:43":"you need if you're doing classification","10:45":"it's wherever many classes you have if","10:48":"you're doing regression it so if in many","10:50":"numbers you're trying to predict in the","10:52":"regression problem and so remember that","10:53":"in your if your data bunch is called","10:55":"data that'll be called data dot C so","10:58":"we'll add for you","10:59":"the","11:00":"weight matrix of size dado C by however","11:03":"much was in the previous layer okay so","11:10":"now we need to train those because","11:11":"initially these weight matrices are full","11:14":"of random numbers okay because new","11:17":"weight matrices are always full of","11:19":"random numbers if they're new and these","11:21":"ones and you we're just we've grabbed","11:23":"them and thrown them in there so we need","11:25":"to train them but the other layers are","11:30":"not new the other layers are good at","11:32":"something right and what are they good","11:35":"at well let's remember that xyler and","11:39":"furgus paper here are examples of some","11:43":"visualization of some filters some some","11:47":"weight matrices in the first layer and","11:49":"some examples of some things that they","11:50":"found right so the first layer had one","11:54":"part of the weight matrix was good at","11:56":"finding diagonal edges in this direction","11:58":"and then in layer two one of the filters","12:01":"was good at finding corners in the top","12:04":"left and then in layer three one of the","12:08":"filters was good at finding repeating","12:10":"patterns another one was good at finding","12:13":"round orange things another one was good","12:16":"at finding kind of like fairy your","12:18":"floral textures so as we go up they're","12:22":"becoming more sophisticated but also","12:26":"more specific right so like layer four I","12:30":"think was finding like eyeballs for","12:32":"instance now if you're wanting to","12:34":"transfer and learn to something for","12:38":"histopathology slides there's probably","12:41":"going to be no eyeballs in that right so","12:43":"the later layers are no good for you but","12:46":"they'll certainly be some repeating","12:47":"patterns and they'll certainly be some","12:49":"diagonal edges right so the earlier you","12:51":"grow in the model the more likely it is","12:54":"that you want those weights to stay as","12:56":"they are well to start with we","13:02":"definitely need to train these new","13:03":"weights because they're random so let's","13:05":"not bother training any of the other","13:06":"weights at all to start with so what we","13:09":"do is we basically say let's freeze","13:17":"let's freeze all of those other layers","13:19":"so what does that mean all that means is","13:22":"that we're asking first di and PI torch","13:25":"that when we train you know however many","13:29":"epochs we do when we call fit don't back","13:32":"propagate the weights but don't prep a","13:36":"back propagate the gradients back into","13:38":"those layers in other words when you go","13:40":"parameters equals parameters - learning","13:44":"rate times gradient only do it for the","13:47":"new layers don't bother doing it for the","13:49":"that's what freezing means okay just","13:51":"means don't update those parameters so","13:54":"it'll be a little bit faster as well","13:59":"because there's a few less calculations","14:00":"to do it'll take up a little bit less","14:03":"memory because there's a few less","14:04":"gradients that we have to store but most","14:07":"importantly it's not going to change","14:10":"weights that are already better than","14:13":"nothing they're better than random at","14:15":"the very least so that's what happens","14:17":"when you call freeze it doesn't freeze","14:18":"the whole thing it freezes everything","14:20":"except the randomly generated atom added","14:22":"layers that we put on for you so then","14:25":"what happens next okay after a while we","14:28":"say okay this is looking pretty good we","14:31":"probably should train the rest of the","14:32":"network now so we unfreeze okay and so","14:39":"now we're gonna chain the whole thing","14:42":"but we still have a pretty good sense","14:44":"that these new layers we added to the","14:46":"end probably need more training and","14:49":"these ones right at the start that might","14:52":"just be like diagonal edges probably","14:54":"don't need much training at all so we","14:57":"split our our model into a few sections","15:04":"right and we say let's give different","15:09":"parts of the model different learning","15:11":"rates so this part of the model we might","15:16":"give a learning rate of 1e neg 5 and","15:21":"this part of the model we might give a","15:23":"learning rate of 1","15:27":"a neg 3c and so what's gonna happen now","15:31":"is that we can keep training the entire","15:33":"network but because the learning rate","15:36":"for the early layers is smaller it's","15:39":"going to move them around less because","15:41":"we think they're already pretty good and","15:43":"also like if it's already pretty good","15:45":"too the optimal value if you used a","15:47":"higher learning rate it could kick it","15:48":"out right it could actually make it","15:50":"worse which we really don't want to","15:51":"happen okay so this this process is","15:55":"called using discriminative learning","15:57":"rates you won't find much online about","16:01":"it because I think we were kind of the","16:04":"first to use it for this purpose or at","16:06":"least talked about it extensively maybe","16:08":"other probably other people used it","16:09":"without writing it down so most of the","16:12":"stuff you'll find about this will be","16:13":"fast AI students but it's it's starting","16:17":"to get more well-known slowly now but","16:21":"it's a really really important concept","16:22":"for transfer learning without using this","16:24":"you just can't get nearly as good","16:26":"results so how do we do discriminative","16:28":"learning rates in fast AI when you when","16:37":"you anywhere you can put a learning rate","16:38":"in fast AI such as with the fit function","16:42":"the first thing you put in is the number","16:44":"of epochs and then the second thing you","16:46":"put in is learning rate saying if you","16:48":"use fit one cycle the learning rate you","16:51":"can put a number of things that you can","16:52":"put a single number like one a neg three","16:55":"you can write a slice so you can write","16:59":"slice for example one a neg three with a","17:02":"single number or you can write slice","17:06":"with two numbers","17:14":"which of those men in the first case","17:18":"just using a single number means every","17:21":"layer gets the same learning rate so","17:24":"you're not using discriminative learning","17:25":"rates if you pass a single number to","17:31":"slice it means the final layers get a","17:34":"learning rate of whatever you wrote down","17:37":"of whatever you wrote down one e neck 3","17:41":"and then all the other layers get the","17:44":"same learning rate which is that divided","17:46":"by 3 okay so all of the other layers","17:50":"will be one a neg 3/3 the last layers","17:53":"will be one in x3 in the last case the","17:57":"final layers the these randomly hadn't","17:59":"added layers will still be again 1 enoch","18:01":"3 the first layers will get 1 in egg 5","18:06":"and the other layers will get learning","18:10":"rates that are equally spread between","18:12":"those two so ink it multiplicatively","18:17":"equal right so if there were three","18:20":"layers there would be one in egg five","18:22":"one in egg for one in egg three so equal","18:25":"multiples each time one slight tweak to","18:31":"make things a little bit simpler to","18:32":"manage we don't actually give a","18:35":"different learning rate to every layer","18:37":"we give a different learning rate to","18:39":"every layer group which is just we","18:41":"decided to put the groups together for","18:44":"you and so specifically what we do is","18:47":"the randomly added extra layers we call","18:50":"those one layer group this is by default","18:52":"you can modify it and then all the rest","18:54":"we split in half into two layer groups","18:58":"so by default at least with a CNN you'll","19:00":"get three layer groups and so if you say","19:02":"slice one enoch in egg three you","19:05":"will get one in egg five learning rate","19:07":"for the first layer group one in egg","19:09":"four for the second one day neck three","19:10":"for the third so now if you go back and","19:13":"look at the way that we're training","19:14":"hopefully you'll see that this makes a","19:16":"lot of sense this divided by three thing","19:19":"there's a little weird and we won't talk","19:23":"about why that is until part two of the","19:26":"course it says","19:27":"specific quirk around batch","19:30":"normalization so we can discuss that in","19:33":"the advanced topic if anybody's","19:34":"interested all right","19:37":"so that is that is fine tuning so","19:43":"hopefully that makes that a little bit","19:45":"less mysterious so we were looking at","19:54":"collaborative filtering last week and in","19:59":"the collaborative filtering example we","20:02":"called fit one cycle and we passed in","20:04":"just a single number and that makes","20:06":"sense because in collaborative filtering","20:08":"we only have one layer there's a few","20:14":"different pieces in it but there isn't","20:15":"you know a matrix multiply followed by","20:20":"an activation function followed by","20:22":"another matrix multiply I'm going to","20:25":"introduce a another piece of jargon here","20:29":"they're not always exactly matrix","20:32":"multiplications there's something very","20:34":"similar there they're linear functions","20:37":"that we add together but the more","20:39":"general term for these for these things","20:41":"that are written more general than","20:42":"matrix multiplications is our fine","20:44":"functions okay so if you hear me say the","20:47":"word a fine function you can replace it","20:50":"in your head with matrix multiplication","20:54":"but as we'll see when we do convolutions","20:56":"convolutions our matrix multiplications","20:59":"where some of the weights are tied and","21:01":"so it would be slightly more accurate to","21:04":"call them f-fine functions and I'd like","21:06":"to introduce a little bit more drug in","21:07":"each lesson so that when you you know","21:10":"read books or papers or watch other","21:12":"courses or read documentation there will","21:15":"be more of the words you're recognized","21:17":"okay so when you see a fine function it","21:20":"just means a linear function right and","21:23":"it means something very very close to","21:26":"matrix multiplication now matrix","21:28":"multiplication is the most common kind","21:30":"of fi-in function at least in deep","21:32":"learning so specifically for","21:38":"collaborative filtering","21:41":"the model we were using was this one it","21:46":"was where we had a bunch of numbers here","21:49":"and a bunch of numbers here and we took","21:54":"the dot product of them and given that","21:58":"one here is a row and when there's a","21:59":"column we can actually that's the same","22:01":"as a matrix product so M mult in Excel","22:03":"multiplies matrices so here's the matrix","22:06":"product of those two and so I started","22:10":"this training last week by using solver","22:13":"in Excel and we never actually went back","22:15":"to see how it went so let's go and have","22:18":"a look now so the average sum of squared","22:23":"error got down to 0.39 so we're trying","22:26":"to predict something on a scale of 0.5","22:29":"to 5 so on average we're being wrong by","22:32":"about 0.4 that's pretty good and you can","22:34":"kind of see it's pretty good if you look","22:38":"at like 3 5 1 is what it meant to be","22:41":"three point two five five point one or","22:43":"0.98 that's pretty close right so you","22:47":"get the general idea and then I started","22:51":"to talk about this idea of embedding","22:53":"matrices and so in order to understand","22:56":"that let's put this worksheet aside now","23:01":"look at another worksheet so here's","23:04":"another worksheet and what I've done","23:07":"here is I have copied over those two","23:10":"weight matrices from the previous","23:12":"worksheet right here's the one for users","23:17":"and here's the one for movies and the","23:18":"movies one I've transposed it so it's","23:21":"now got exactly the same dimensions as","23:23":"the users one okay so the here are two","23:27":"weight matrices initially they were","23:30":"random we can train them with gradient","23:33":"descent in the original data the user","23:36":"IDs and movie IDs were numbers like","23:39":"these okay to make life more convenient","23:44":"I've converted them to numbers from 1 to","23:48":"15 okay so in these columns I've got for","23:52":"every rating","23:53":"I've got user ID","23:54":"movie ID rating using these mapped","23:57":"numbers so that they're contiguous","23:59":"starting at one okay now I'm going to","24:01":"replace user ID number one with this","24:07":"vector the vector contains a 1 followed","24:11":"by 14 zeros and then user number 2 I'm","24:16":"going to replace with a vector of 0 and","24:19":"then 1 and then 13 zeros and so forth so","24:22":"movie ID 14 or these are movie ID 14","24:25":"I've also replaced with another vector","24:29":"which is 13 zeros and then a 1 and then","24:32":"a 0 okay so these are called one-hot","24:36":"encodings by the way so this is not part","24:42":"of a neural net this is just like some","24:44":"input pre-processing room literally","24:46":"making this my new input so this is my","24:50":"new inputs for the mo movies this is my","24:52":"new inputs for my users ok so these are","24:56":"the inputs to a neural net so what I'm","24:59":"going to do now is I'm going to take","25:00":"this input matrix and I'm going to do a","25:05":"matrix multiplied by this weight matrix","25:11":"and that'll work","25:12":"because this has 15 rows and this has 15","25:18":"columns so I can multiply those two","25:20":"matrices together because they match and","25:22":"you can do matrix multiplication in","25:24":"Excel using the air mult function just","25:28":"be careful if you're using Excel because","25:31":"this is a function that returns multiple","25:33":"numbers you can't just hit enter when","25:36":"you finish with it you have to hit","25:37":"control shift enter control shift enter","25:39":"means this is a array function is","25:41":"something that returns multiple values","25:42":"so here is the matrix product of this","25:47":"input matrix of per of of inputs and","25:54":"this make this parameter matrix or","25:58":"weight matrix so that's just a normal","26:02":"neural network layer okay it's just","26:06":"a regular matrix model play and so we","26:09":"can do the same thing for movies and so","26:11":"here's the matrix model play for movies","26:15":"well here's the thing this input is we","26:22":"claim is this kind of one hot encoded","26:24":"version of user ID number one and these","26:27":"activations are the activations for user","26:32":"ID number one why is that because if you","26:34":"think about it","26:35":"the matrix multiplication between a one","26:37":"hot encoded vector and some matrix is","26:41":"actually going to find the nth row of","26:45":"that matrix when the one is in position","26:48":"in does that make sense so what we've","26:51":"done here is we've actually got a matrix","26:57":"multiply that is creating this these","26:59":"output activations right but it's doing","27:01":"it in a very interesting way which is","27:03":"it's effectively finding a particular","27:05":"row when the input matrix so having done","27:07":"that we can then multiply those two sets","27:12":"together just a dot product and we can","27:17":"then find the loss squared and then we","27:22":"can find the average loss and lo and","27:25":"behold that number 0.39 is the same as","27:33":"this number because they're doing the","27:35":"same thing so this one was kind of","27:41":"finding this particular users embedding","27:48":"vector this one is just doing a matrix","27:52":"multiply and therefore we know they are","27:55":"mathematically identical so let's lay","27:58":"that out again so here's our final","28:00":"version this is the same weight matrices","28:04":"again exactly the same I've copied them","28:06":"over and here's those user IDs and movie","28:10":"IDs again right but this time I've laid","28:13":"them out just in a normal kind of","28:16":"tabular form just like you would expect","28:18":"to see","28:19":"the input to your model and this time I","28:22":"have got exactly the same set of","28:24":"activations here that I had here but in","28:32":"this case I've calculated these","28:34":"activations using excels offset function","28:37":"which is an array look up right it says","28:40":"find the first row of this so this is","28:45":"doing it as an array lookup so this","28:48":"version is identical to this version but","28:52":"obviously it's much less memory","28:54":"intensive and much faster because I","28:56":"don't actually create the one hot","28:58":"encoded matrix and I don't actually do a","29:00":"matrix multiply because that matrix","29:02":"multiply is nearly all multiplying by","29:04":"zero which is a total waste of time so","29:07":"in other words multiplying by a one","29:10":"handed matrix is identical to doing an","29:13":"array lookup therefore we should always","29:17":"do the array lookup version and","29:20":"therefore we have a specific way of","29:23":"doing we have a specific way of saying I","29:25":"want to do a matrix multiplication by a","29:27":"one hot encoded matrix without ever","29:30":"actually creating it I'm just instead","29:32":"going to pass in a bunch of intz and","29:34":"pretend they're one not encoded and that","29:37":"is called","29:38":"and embedding right so you might have","29:42":"heard this word embedding all over the","29:44":"places if there's some magic advanced","29:47":"mathy thing but embedding means look","29:52":"something up in an array okay but it's","29:57":"interesting to know that looking","29:59":"something up in an array is","30:00":"mathematically identical to doing a","30:03":"matrix product by a one hot encoded","30:05":"matrix and therefore an embedding fits","30:10":"very nicely in our standard model of our","30:12":"neural networks work so now suddenly","30:15":"it's as if we have another whole kind of","30:17":"layer it's a kind of layer where we get","30:20":"to look things up in an array but we","30:22":"actually didn't do anything special","30:24":"right we just added this computational","30:26":"shortcut this thing called an embedding","30:28":"which is simply a fast memory efficient","30:31":"way of multiplying by","30:32":"hot encoded matrix okay so this is","30:37":"really important because when you hear","30:39":"people say embedding you need to replace","30:42":"it in your head with an array lookup","30:46":"which we know is mathematically","30:48":"identical to matrix multiplied by a one","30:51":"hot encoder matrix here's the thing","30:55":"though it has kind of interesting","30:57":"semantics right because when you do","31:00":"multiply something by a one hot encoded","31:02":"matrix you get this nice feature where","31:05":"the rows of your weight matrix the","31:10":"values only appear for row number one","31:13":"for example where you get user ID number","31:16":"one in your inputs right so in other","31:20":"words you kind of end up with this","31:22":"weight matrix where certain rows of","31:25":"weights correspond to certain values of","31:29":"your input and that's pretty interesting","31:32":"it's particularly interesting here","31:35":"because going back to a kind of most","31:37":"convenient way to look at this because","31:41":"the only way that we can calculate an","31:43":"output activation is by doing a dot","31:46":"product of these two input vectors that","31:49":"means that they kind of have to","31:53":"correspond with each other right like","31:56":"there has to be some way of saying if","32:00":"this number for a user is high and this","32:04":"number for a movie is high then the user","32:06":"will like the movie so the only way that","32:09":"can possibly make sense is if these","32:12":"numbers represent features of personal","32:15":"taste and corresponding features of","32:18":"movies for example the movie has John","32:22":"Travolta in it and user ID likes John","32:29":"Travolta then you'll like this movie","32:33":"okay so like we're not actually deciding","32:37":"the Rhodes mean anything we're not doing","32:39":"anything to make the Rhodes mean","32:40":"anything but the only way that this","32:42":"gradient descent could possibly come up","32:44":"with a good answer is if it figures","32:46":"out what the aspects of movie taste are","32:50":"and the corresponding features of movies","32:53":"are so those underlying kind of features","32:57":"that appear that are called latent","32:59":"factors or latent features they're these","33:03":"hidden things that were there all along","33:04":"and once we train this neural net they","33:07":"suddenly appear now here's the problem","33:11":"no one's going to like Battlefield Earth","33:13":"right it's not a good movie even though","33:16":"it has John Travolta in it so how are we","33:19":"going to deal with that right because","33:21":"there's this feature called","33:22":"I like John Travolta movies and this","33:24":"feature called this movie has John","33:26":"Travolta and so this is now like you're","33:29":"gonna like the movie but we need to save","33:31":"some way to say unless it's Battlefield","33:33":"Earth or you're a Scientologist either","33:35":"one right so how do we do that we need","33:38":"to add in bias right so here is the same","33:44":"thing again same weight matrix sorry not","33:48":"the same weight because he's the same","33:51":"construct right same shape of everything","33:55":"but this time you've got an extra row so","33:59":"now this is not just the matrix product","34:03":"of that and that but I'm also adding on","34:07":"this number and this number which means","34:12":"now each movie can have an overall this","34:16":"is a great movie versus this isn't a","34:17":"great movie and every user can have an","34:20":"overall this user rates movies highly or","34:23":"this user doesn't rate movies highly so","34:26":"that's called the bias so this is","34:28":"hopefully going to look very familiar","34:30":"right this is the same usual linear","34:33":"model concept or linear layer concept","34:35":"from a neural net that you have a matrix","34:37":"product and a bias and remember from","34:39":"lesson to lesson 2's genie SGD notebook","34:42":"you never actually need a bias you could","34:46":"always just add a column of ones to your","34:48":"input data and then that gives you bias","34:50":"for free but that's pretty inefficient","34:53":"right so in practice all neural networks","34:56":"library explicitly have a concept","34:58":"of bias we don't actually add the column","35:01":"of ones so what does that do well just","35:05":"before I came in today I ran tools","35:07":"solver or notes data solver on this as","35:11":"well and we can check the RMS see and so","35:15":"the root mean squared here is 0.32","35:17":"versus the version without bias whereas","35:22":"0.39 okay so you can see that this","35:27":"slightly better model gives us a better","35:30":"result and it's better because it's it's","35:32":"it's giving both more flexibility right","35:35":"and it's also just makes sense","35:37":"semantically that you need to be able to","35:39":"say it's not the weather I'd like the","35:42":"movie is not just about the combination","35:44":"of what actors it has and whether it's","35:46":"dialogue-driven and how much action is","35:48":"in it but just is it a good movie","35:49":"okay or am i somebody who rates movies","35:53":"highly okay so there's all the pieces of","36:00":"this collaborative filtering model how","36:04":"are we going sancisco any questions we","36:07":"have three questions okay okay so a","36:12":"first question then is when we load a","36:16":"pre trained model can we explore the","36:20":"activation grids to see what they might","36:22":"be good at recognizing yes you can and","36:25":"we will learn how to should be in the","36:28":"next lesson can we have an explanation","36:33":"of what the first argument in fit one","36:36":"cycle actually represents is it","36:38":"equivalent to an epoch yes","36:40":"the first argument to fit one cycle or","36:42":"fit is number of epochs it's in other","36:48":"words an epoch is looking at every input","36:52":"once so if you do ten epochs you're","36:57":"looking at every every input ten times","37:00":"and so there's a chance you might start","37:02":"overfitting if you've got lots of lots","37:04":"of parameters and a high learning rate","37:05":"if you only do one epoch it's impossible","37:10":"to have a fit","37:11":"and so that's why it's kind of useful to","37:13":"remember how many epochs you're doing","37:18":"can we have an exponent that one what is","37:22":"an affine function an affine function is","37:26":"a linear function I don't know if we","37:30":"need much more detail than that","37:32":"if you're multiplying things together","37:34":"and adding them up it's an air fine","37:37":"function I'm not going to bother with","37:41":"exact mathematical definition partly cuz","37:44":"I'm a terrible mathematician and partly","37:45":"because it doesn't matter but if you","37:47":"just remember that you're multiplying","37:48":"things together and then adding them up","37:50":"that's the most important thing it's","37:52":"linear okay and therefore if you put an","37:55":"F fine function on top of an F fine","37:56":"function that's just another F fine","37:58":"function you haven't won anything at all","38:00":"that's a total waste of time right so","38:03":"you need to sandwich it with any kind of","38:07":"non-linearity pretty much works right","38:09":"including replacing the negatives with","38:10":"zeros which we call value okay so if you","38:13":"draw Fi and really F I'm really f I'm","38:15":"really you you have a deep neural","38:17":"network okay so so let's go back to the","38:26":"collaborative filtering notebook and","38:29":"this time we're going to grab the whole","38:31":"movie lens 100k dataset there's also a","38:35":"20 million dataset","38:37":"by the way so really a great project","38:42":"available made by this group called","38:44":"group lens they actually update the","38:46":"movie lens data sets on a regular basis","38:49":"but they helpfully provide the original","38:51":"one and we're going to use the original","38:53":"one because that means that we can","38:54":"compare two baselines because everybody","38:58":"basically they say hey if you're going","38:59":"to compare the baselines make sure you","39:01":"all use the same data set here's the one","39:03":"you should use unfortunately it means","39:05":"that we're going to be restricted to","39:06":"movies that are before 1998 so maybe you","39:10":"won't have seen them all but that's the","39:13":"price we pay you can replace this with","39:15":"ml latest when you download it and use","39:18":"it if you want to play around with","39:20":"movies that are up to date okay","39:24":"the original movie lens data set the","39:28":"more recent ones are in a CSV file it's","39:30":"super convenient to use the original one","39:32":"is a slightly messy first of all they","39:35":"don't use commas for two limiters they","39:37":"use tabs so in pandas you can just say","39:39":"what's the delimiter and you loaded in","39:41":"the second is they don't add a header","39:43":"row so that you know what color room is","39:45":"what so you have to tell pandas there's","39:46":"no header row and then since there's no","39:48":"header row you have to tell pandas what","39:51":"are the names of four columns rather","39:53":"than that that's what we need okay so we","39:57":"can then have a look at head which","39:59":"remembers the first few rows and there","40:00":"is our user ratings user movie rating","40:04":"and let's make it more fun let's see","40:07":"what the movies actually are I'll just","40:10":"point something out here which is","40:14":"there's this thing called encoding","40:15":"equals I'm going to get rid of it and I","40:19":"get this error Unicode I just want to","40:21":"point this out because you'll all see","40:23":"this at some point in your lives codec","40:26":"can't decode blah blah blah what this","40:28":"means is that this is not a Unicode file","40:31":"this will be quite common when you're","40:33":"using datasets are a little bit older","40:36":"back before you know us folks in the","40:39":"West really realized that there are","40:41":"people that use languages other than","40:42":"well English people we English languages","40:44":"other than English nowadays you know","40:48":"we're much better at handling different","40:50":"languages we use this standard called","40:53":"Unicode for it and Python very helpfully","40:57":"uses Unicode by default but so if you","40:59":"try to load an old file it's not Unicode","41:01":"you actually believe it or not have to","41:03":"guess how it was coded but since like","41:07":"it's really likely that it was created","41:10":"by you know some Western European or","41:14":"American person they almost certainly","41:17":"used Latin one so if you just papi an","41:20":"encoding equals Latin one if you use","41:23":"file open in Python or pandas open or","41:26":"whatever that will generally get around","41:30":"your problem again they didn't have the","41:35":"names so we had to list of the names are","41:37":"this is kind of interesting they had a","41:39":"separate column for every one of however","41:41":"many genres they had 19 genres and","41:44":"you'll see it this looks one hot encoded","41:46":"but it's actually not it's actually n","41:48":"hot encoded in other words a movie can","41:51":"be in multiple genres we're not going to","41:52":"look at Jean Roos today but it's just","41:54":"interesting to point out that this is a","41:56":"way that sometimes people will represent","41:58":"something like genre and the more recent","42:01":"version they actually listed the genres","42:03":"directly which is much more convenient","42:05":"ok so I find life is so we got a hundred","42:10":"thousand ratings I find life is easier","42:12":"when you're modeling when you actually","42:13":"denormalize the data so I actually want","42:16":"the movie title directly in my ratings","42:18":"so pandas has a merge function to let us","42:21":"do that so here's the ratings table with","42:23":"actual titles so as per usual we can","42:27":"create a data bunch for our application","42:29":"so a collab data bunch for the collab","42:31":"application from what from a data frame","42:34":"there's our data frame set aside some","42:38":"validation data really we should use the","42:42":"validation sets and cross validation","42:43":"approach that they used if you're going","42:45":"to properly compare with a benchmark so","42:46":"take these comparisons with a grain of","42:48":"salt","42:49":"by default car lab data bunch assumes","42:52":"that your first column is you user","42:57":"second column of item the third column","42:59":"is rating but now we're actually going","43:01":"to use the title column as item so we","43:04":"have to tell it what the item column","43:07":"name is and then all of our data bunches","43:10":"support show batch so you can just check","43:12":"what's in there and there it is okay so","43:18":"I'm going to try and get as good a","43:21":"result as I can so I'm gonna try and use","43:24":"whatever tricks I can come up with to","43:26":"get a good answer now one of the tricks","43:28":"is to use the Y range and remember the","43:32":"the Y range was the thing that made the","43:35":"final activation function a sigmoid and","43:40":"specifically last week we said let's","43:43":"have a sigmoid that goes from naught to","43:45":"5 and that way it's going to ensure that","43:48":"it kind of is going to help the neural","43:49":"network predict things that are in the","43:51":"range actually didn't do that in my","43:56":"Excel version and so you can see I've","43:58":"actually got some negatives Maddon","44:00":"there's also some things bigger than","44:01":"five so if you want to beat me in Excel","44:04":"you could you could add the sigmoid to","44:08":"excel and train this and you'll get a","44:10":"slightly better answer now the problem","44:15":"is that a sigmoid actually asymptotes at","44:18":"say whatever the maximum is we said five","44:21":"which means you can never actually","44:23":"predict five but plenty of movies have a","44:25":"rating of five so that's a problem so","44:28":"actually it's slightly better to make","44:30":"your way range go from a little bit less","44:32":"than the minimum to a little bit more","44:33":"than the maximum and the minimum of this","44:35":"data is 0.5 and the maximum is 5 so this","44:39":"range is just a little bit further so","44:42":"that's a that's one little trick to get","44:44":"a little bit more accuracy the other","44:49":"trick I used is to add something called","44:51":"weight decay and we're going to look at","44:53":"that next ok after this section we got","44:56":"to learn about weight okay so then how","44:59":"many how many factors do you want or","45:04":"what are factors the number of factors","45:07":"is the width of the embedding matrix so","45:10":"why don't we say embedding sighs maybe","45:13":"we should but in the world of","45:16":"collaborative filtering they don't use","45:18":"that word they use the word factors","45:20":"because of this idea of latent factors","45:22":"and because the standard way of doing","45:24":"collaborative filtering has been with","45:27":"something called matrix factorization","45:28":"and in fact what we just saw happens to","45:33":"actually be a way of doing matrix","45:35":"factorization so we've we've actually","45:37":"accidentally learned how to do matrix","45:39":"factorization today so so this is a term","45:42":"that's kind of specific to this domain","45:44":"okay but you can just remember it as the","45:47":"width of the embedding matrix and so why","45:50":"40 well this is one of these","45:51":"architectural decisions you have to play","45:54":"around with and see what works so I","45:55":"tried 10 20 40 and 80 and I found 42 in","45:59":"to work pretty well and it rained really","46:02":"quickly so like you can check it in a","46:04":"little for loop","46:05":"to try a few things and see what looks","46:06":"best and then for learning rates so","46:10":"here's the learning rate finder as usual","46:14":"so five Enoch three seemed to work","46:17":"pretty well remember this is just a rule","46:18":"of thumb right five e neg three is a bit","46:21":"lower than both Silver's rule in my rule","46:23":"so Silver's role is find the bottom and","46:26":"go back by ten","46:27":"so his rule would be more like two e neg","46:30":"- I reckon my rule is kind of find about","46:33":"the steepest section which is about here","46:35":"which again like often it agrees with","46:37":"your man so that would be about - Enoch","46:39":"- I tried that but I always like to try","46:42":"like 10 X less than 10x more just to","46:45":"check and actually I found a bit less","46:46":"was helpful so the answer to the","46:50":"question like should I do blah is always","46:53":"try blah and see now that's how you","46:56":"actually become a good practitioner so","47:01":"that gave me point eight one three right","47:03":"and as usual you can save the result to","47:05":"save you another 33 seconds from having","47:07":"to do it again later and so there's a","47:11":"library called Lib wreck and they","47:14":"published some benchmarks for movie lens","47:19":"100k and there's a root mean squared","47:21":"error section and about point nine one","47:24":"is about as good as they seem to have","47:25":"been able to get point nine one is the","47:28":"root mean square error we use the mean","47:30":"square error not the root so we have to","47:32":"go to point nine one squared which is","47:34":"0.8 three and what we're getting point","47:37":"eight one so that's cool with this very","47:39":"simple model we're doing a little bit","47:43":"better quite a lot better actually","47:47":"although as I said take it with a grain","47:49":"of salt because we're not doing the same","47:51":"spits and the same cross validation that","47:54":"so we're at least highly competitive","47:55":"with their approaches okay so we're","48:01":"going to look at the Python code that","48:03":"does this in a moment we're going to","48:06":"look at the Python code that does this","48:07":"in a moment but for now just take my","48:10":"word for it that we're going to say","48:11":"something that's just doing this","48:17":"right looking things up in an array and","48:19":"then model plugging them together adding","48:22":"them up and doing the mean square error","48:24":"loss function so given that and given","48:28":"that we noticed that the only way that","48:30":"that can do anything interesting is by","48:32":"trying to kind of find these latent","48:37":"factors it makes sense to look and see","48:40":"right particularly since as well as","48:43":"finding latent factors we also now have","48:46":"a specific bias number for every user","48:49":"and every movie right now you could just","48:52":"say what's the average rating to each","48:56":"movie but there's a few issues with that","48:59":"in particular this is something you see","49:01":"a lot with like anime people who like","49:04":"anime just love anime right and so","49:07":"they're watching lots of anime and then","49:09":"they just rate all the enemy highly and","49:11":"so very often on kind of charts of","49:14":"movies you'll see a lot of anime at the","49:16":"top particularly if it's like you know a","49:19":"hundred long series of anime you'll find","49:22":"you know every single item of that","49:25":"series in the top thousand movie lists","49:27":"or something so how do we deal with that","49:30":"well the nice thing is that instead if","49:33":"we look at the movie bias right the","49:36":"movie bias says kind of once we've","49:40":"included the user bias right which for","49:42":"an anime lover might be a very high","49:45":"number because they're just reading a","49:46":"lot of movies highly now once we account","49:48":"for the specifics of this kind of movie","49:50":"which again might be people love anime","49:53":"right what's left over is something","49:56":"specific to that movie itself so it's","49:58":"kind of interesting to look at movie","50:01":"bias numbers as a way of saying what are","50:04":"the best movies or what people what do","50:06":"people really like as movies even if","50:09":"those people don't rate movies very","50:11":"highly or even if there does that movie","50:14":"doesn't have the kind of features that","50:15":"people tend to have rate rate highly so","50:17":"it's kind of nice","50:19":"it's funny to say this and I'm by a by","50:22":"using the bias we get an unbiased kind","50:24":"of movie score so how do we do that well","50:31":"to make it interesting because","50:32":"particularly because this data set only","50:34":"start only goes to 1998 let's only look","50:39":"at movies that are plenty of people","50:41":"watch right so we'll use pandas to grab","50:45":"our reading movie table grip it by title","50:48":"and then count the number of ratings and","50:52":"not measuring how high their rating just","50:54":"how many ratings do they have okay and","50:56":"so the top thousand is that is them","51:02":"other movies that have been rated the","51:04":"most and so there hopefully movies that","51:06":"we might have seen okay that's the only","51:08":"reason I'm doing this and so I've called","51:09":"this top movies by which I mean not not","51:12":"good movies just movies were likely to","51:15":"have seen so not surprisingly Star Wars","51:17":"is the one that at that point most the","51:21":"most people were had put a rating to","51:27":"Independence Day there you go so we can","51:32":"then take our loner that we trained and","51:36":"asked it for the bias of the items","51:42":"listed here okay so is item equals true","51:46":"you would pass true to say I want the","51:48":"items or false to say I want the users","51:51":"and so this is kind of like a pretty","51:53":"common piece of nomenclature for","51:56":"collaborative filtering these IDs tend","52:01":"to be called users these IDs tend to be","52:05":"called items even if your problem has","52:08":"got nothing to do with users and items","52:10":"at all you know you just use these names","52:13":"for convenience okay so they're just","52:16":"they're just words","52:17":"so in our case we want the items this is","52:20":"the list of items we want we want the","52:22":"bias so this is specific to klepto","52:24":"filtering and so that's going to give us","52:26":"back a thousand numbers back because we","52:29":"asked for this has a thousand movies in","52:31":"it so we can now take and just for","52:36":"comparison let's also group the titles","52:39":"by the mean rating so then we can zip","52:42":"through so going through together","52:45":"each of the movies along with the bias","52:47":"and grab their rating and the bias and","52:51":"the movie and then we can sort them all","52:56":"by the zero index thing which is the","53:02":"bias so here are the lowest numbers so I","53:08":"can say you know","53:11":"Mortal Kombat annihilation not a great","53:14":"movie lawnmower man - not a great movie","53:16":"I haven't seen children of the corn but","53:18":"we did have a long discussion at SF","53:20":"study group today and people who have","53:21":"seen it agree not a great movie and you","53:25":"can kind of see like some of them","53:27":"actually have pretty decent ratings even","53:32":"as though like relative to right so this","53:35":"one's actually got a much higher rating","53:36":"than the next one right but you know","53:40":"that's kind of saying well the kind of","53:42":"actors that were in this in the kind of","53:44":"movie that this was and the kind of","53:45":"people who do like it and watch it you","53:48":"would expect it to be higher and then","53:51":"here's the sort by reverse okay","53:54":"Schindler's List Titanic Shawshank","53:56":"Redemption seems reasonable and again","53:58":"you can kind of look for ones where like","54:01":"the rating you know isn't that high but","54:04":"it's still very high here so that's kind","54:07":"of like you know at least in 1998 people","54:09":"weren't that into Leonardo DiCaprio or","54:12":"you know people aren't that into","54:14":"dialogue-driven movies or people aren't","54:17":"that into romances or whatever but still","54:19":"people liked it more than you would have","54:20":"expected so it's interesting to kind of","54:23":"like interpret our models in this way we","54:27":"can go a bit further and grab not just","54:29":"the biases but the weights so that is","54:35":"these things and again we're going to","54:40":"grab the weights for the items for our","54:42":"top movies and that is a thousand by","54:45":"forty because we asked for forty factors","54:47":"so rather than having a width of five we","54:50":"have a width of 40 often","54:57":"really there's there isn't really","55:00":"conceptually forty latent factors","55:02":"involved in taste and so trying to look","55:05":"at the forty can be you know not that","55:09":"intuitive so what we want to do is we","55:11":"want to squish those forty down to just","55:14":"three and there's something that we're","55:17":"not going to look into called PCA stands","55:19":"for principal components analysis so","55:21":"this is a movie W is a torch tensor and","55:25":"fast AI adds the PCA method to torch","55:30":"tensors and what PCA does principal","55:32":"components analysis is it's a simple","55:35":"linear transformation that takes an","55:37":"input matrix and tries to find a smaller","55:40":"number of columns that kind of cover a","55:45":"lot of the space of that original matrix","55:47":"if that sounds interesting which it","55:49":"totally is you should check out our","55:52":"course computational linear algebra","55:54":"which Rachele teachers where we will","55:58":"show you how to calculate PCA from","56:02":"scratch and why you'd want to do it and","56:03":"lots of stuff like that it's absolutely","56:07":"not a prerequisite for anything in this","56:09":"course but it's definitely worth knowing","56:12":"that taking layers of neural nets and","56:16":"chucking them through PCA is very often","56:18":"a good idea because very often you have","56:20":"like way more activations than you want","56:22":"in a layer and there's all kinds of","56:24":"reasons you would might want to play","56:25":"with it for example Francisco who's","56:29":"sitting next to me today is has been","56:32":"working on something to do image","56:38":"similarity right and very weak","56:39":"similarity a nice way to do that is to","56:41":"compare activations from a model but","56:43":"often those activations will be huge and","56:45":"therefore your thing could be really","56:46":"slow and unwieldy so people often for","56:49":"something like image similarity will","56:51":"chuck it through a PCA first and that's","56:55":"kind of cool","56:56":"in our case we're just going to do it so","56:58":"that we take our 40 components down to","57:00":"three components so hopefully they'll be","57:02":"easier for us to interpret so we can","57:06":"grab each of those three factors will","57:08":"call them factor naught one and two","57:10":"and let's grab that movie components and","57:14":"then sort and now the thing is we have","57:19":"no idea what this is going to mean but","57:21":"we're pretty sure it's going to be some","57:22":"aspect of taste and movie feature so if","57:28":"we print it out the top and the bottom","57:30":"we can see that the highest ranked","57:34":"things on this feature you would kind of","57:37":"describe them as you know connoisseur","57:41":"movies I guess you know like Chinatown","57:44":"you know really classic Jack Nicholson","57:47":"movie","57:48":"everybody knows Casablanca and even like","57:50":"wrong trousers is like this kind of","57:52":"classic claymation movie","57:55":"and so forth right so yeah this this is","57:58":"definitely measuring like things that","58:00":"are very high on the kind of connoisseur","58:02":"level where else maybe home alone 3 not","58:06":"such a favorite with Connor says perhaps","58:08":"it's just not to say that there aren't","58:10":"people who don't like it right but","58:12":"probably not the same kind of people","58:14":"that would appreciate secrets and lies","58:17":"ok so you can kind of see this idea that","58:19":"this has found some feature of movies","58:22":"and a corresponding feature of the kind","58:24":"of things people like so let's look at","58:26":"so here's factor number one so this","58:31":"seems to have found like okay these are","58:33":"just big hits that you could watch with","58:36":"the family you know these are definitely","58:41":"not that you know Trainspotting very","58:43":"gritty kind of you know thing so again","58:47":"it's kind of found this interesting","58:49":"feature of taste and we could even like","58:53":"draw them on a graph right I've just","58:56":"cuddled them randomly to make them","58:57":"easier to see and you can kind of see","58:59":"like and this is just the top 50 most","59:03":"popular movies by rating by how many","59:07":"times they've been rated and so kind of","59:09":"on this one factor you've got the head","59:10":"of the terminators really high up here","59:12":"and the kind of English Patient and","59:14":"students list at the other end and then","59:16":"kind of is your godfather and Auntie","59:18":"Python over here and Independence Day","59:21":"and lie a liar over there so you get the","59:23":"so that's kind","59:24":"it would be interesting to see if you","59:26":"can come up with some stuff at work or","59:30":"other kind of datasets where you could","59:31":"try to pull out some some features and","59:34":"play with them so how does that work","59:44":"any questions what okay the question is","59:50":"why am I sometimes getting negative loss","59:54":"when training you shouldn't be so you're","60:03":"doing something wrong so ask on show us","60:07":"your your penny particularly since","60:09":"people are uploading this I guess other","60:10":"people seen it too so to put it on the","60:12":"forum I mean they sit there doing","60:16":"negative love likelihood yeah so we're","60:19":"going to be learning about cross or","60:20":"entropy and negative log likelihood","60:21":"after the break","60:22":"today they are lost functions that have","60:27":"very specific expectations about what","60:29":"your input looks like and if your input","60:30":"doesn't look like that then they're","60:32":"going to give very weird answers so","60:35":"probably you press the wrong buttons so","60:38":"don't do that okay okay","60:44":"so we said collab learner and so here is","60:55":"the collab learner function the collab","61:02":"learner function as per usual takes a","61:08":"data bunch and normally learners also","61:12":"take something where you ask for","61:14":"particular architectural details in this","61:17":"case there's only one thing which does","61:18":"that which is basically do you want to","61:19":"use a multi-layer neural net or do you","61:21":"want to use a classic collaborative","61:22":"filtering and we're only going to look","61:24":"at the classic collaborative filtering","61:25":"today or maybe your briefly look at the","61:28":"other one too let's see and so what","61:32":"actually happens here well basically","61:33":"we're going to create we create a","61:37":"an embedding dot bias model and then we","61:40":"pass back a learner which has our data","61:42":"and that model so obviously all the","61:44":"interesting stuff is happening here and","61:45":"embedding drop bias so let's take a look","61:48":"at that","61:49":"I clearly press the wrong button","61:51":"embedding dot bias there we go okay so","61:58":"here's our embedding dot bias model it","62:04":"is a NN module so in in pi torch to","62:10":"remind you all PI torch layers and","62:14":"models are NN modules they are things","62:17":"that once you create them look exactly","62:20":"like a function you call them with","62:22":"parentheses and you pass them arguments","62:25":"but they're not functions they don't","62:28":"even have normally in Python to make","62:31":"something look like a function you have","62:33":"to give it a method called dunder call","62:35":"remember that means underscore","62:37":"underscore call underscore underscore","62:38":"which doesn't exist here and the reason","62:40":"is that pi torch actually expects you to","62:44":"have something called forward and that's","62:47":"what pi torch will call for you","62:48":"when you call it like a function so when","62:51":"this model is being trained to get the","62:55":"predictions it's actually going to call","62:57":"forward for us so this is where we do","63:02":"the calculations right to calculate our","63:07":"predictions so this is where you can see","63:10":"we grab our why is this users rather","63:14":"than user that's because everything's","63:16":"done a mini-batch at a time right so it","63:18":"is kind of when I read the forward in in","63:23":"a PI torch module I tend to ignore in my","63:28":"head the fact that there's a mini batch","63:29":"and I pretend there's just one because","63:32":"PI torch automatically handles all of","63:35":"the stuff about doing it to everything","63:37":"in the mini batch for you right so let's","63:40":"pretend there's just one user right so","63:42":"grab that user and what is this self dot","63:45":"u underscore weight self dot u","63:47":"underscore weight is","63:50":"bedding we create an embedding for each","63:53":"of users by factors items by factors","63:58":"users by one items by one well that","64:02":"makes sense right so what users by one","64:05":"is yeah that's the users bias right and","64:12":"then users by Factor is here so users by","64:21":"factors is the first couple so that's","64:23":"going to go in you underscore weight and","64:25":"users comma one is the third so that's","64:28":"going to go in you underscore bias so","64:30":"remember when PI torch creates our NN","64:34":"module","64:35":"it calls dunder init and so this is","64:38":"where we have to create our weight","64:40":"matrices right and we don't normally","64:43":"create the actual weight matrix tensors","64:45":"we normally use PI torches convenience","64:48":"functions to do that for us","64:49":"and we're going to see some of that","64:50":"after the break so for now just","64:54":"recognize that this function is going to","64:56":"create an embedding matrix for us it's","65:00":"going to be a PI torch and n dot module","65:03":"as well so therefore to actually pass","65:07":"stuff into that embedding matrix and get","65:10":"activations out you treat it as if it","65:14":"was a function okay stick it in","65:16":"parentheses so if you want to look in","65:17":"the PI that pipe torch source code and","65:20":"find n n dot embedding you will find","65:23":"there's something called dot forward in","65:24":"there which will do this array lookup","65:26":"for us so here's where we grab the users","65:33":"here's where we grab the items and so","65:37":"we've now got the embeddings for each","65:39":"right and so at this point we're kind of","65:44":"like here and we found that and that so","65:50":"we multiply them together and sum them","65:53":"up and then we add on the user bias and","65:57":"the item bias and then if we've got a","66:00":"wide range then we do our sigmoid","66:03":"trick and so the nice thing is you know","66:08":"and you now understand the entirety of","66:11":"this model and this is not just any","66:13":"model this is a model that we just found","66:15":"is at the very least highly competitive","66:19":"with and perhaps slightly better than","66:22":"some published table of pretty good","66:25":"numbers from a software group that does","66:29":"nothing about this so you're doing well","66:31":"right this is nice","66:35":"so that's probably a good place to have","66:40":"a break and so after the break we're","66:43":"going to come back and we're going to","66:44":"talk about the one piece of this puzzle","66:47":"we haven't learnt yet which is what the","66:49":"hell is this - okay so let's come back","66:53":"at 750 okay","67:03":"so this idea of interpreting embeddings","67:06":"is really interesting and as we'll see","67:09":"later in this lesson the the things that","67:12":"we create for categorical variables more","67:15":"generally in tabular data sets are also","67:17":"embedding matrices and again that's just","67:20":"a normal matrix multiplied by a one hot","67:22":"encoded input where we skip the","67:26":"computational computational and memory","67:28":"burden of it by doing it in a more","67:30":"efficient way and it happens to end up","67:33":"with these interesting semantics kind of","67:35":"accidentally and there was this really","67:38":"interesting paper by these folks who","67:41":"came second in a capital competition for","67:46":"something called AI Rossman will","67:49":"probably look in more detail at the","67:50":"rustman competition in part two I think","67:53":"we're gonna run out of time in part one","67:55":"but it's basically there's pretty","67:57":"standard tabular stuff the main","68:00":"interesting stuffs in the pre-processing","68:03":"and it was interesting because Eve they","68:05":"came second despite the fact that the","68:08":"person who came first and pretty much","68:09":"everybody else was the top of the","68:10":"leaderboard did a massive amount of","68:12":"highly specific feature engineering","68:15":"where else these folks did","68:17":"we're less feature engineering than","68:18":"anybody else but instead they used a","68:20":"neural net and this was at a time in","68:22":"2016 when just no one did that no one","68:26":"was doing neural nets for tabular data","68:27":"so they have you know the kind of stuff","68:30":"that we've been talking about kind of a","68:34":"rose there or at least was kind of","68:37":"popularized there and when I say","68:38":"popularized I mean only popularized a","68:40":"tiny bit it's still most people unaware","68:42":"of this idea but it's pretty cool","68:45":"because in their paper they showed that","68:46":"the main average percentage error for","68:49":"various techniques K nearest neighbors","68:50":"random forests and gradient boosted","68:53":"trees","68:55":"well first you know neural Nets just","68:56":"works work worked a lot better but then","68:58":"with entity embeddings which is what","69:00":"they call this just using entity","69:03":"matrices in capital data you can","69:06":"actually they actually added the entity","69:08":"embeddings to all of these different","69:09":"tasks after training them and they all","69:12":"got way better right so neural nets with","69:15":"entity embeddings are still the best but","69:17":"a random forest with empty embeddings","69:18":"was not at all far behind and you know","69:22":"that's often kind of that's kind of nice","69:23":"right because you could train these","69:25":"entity matrices for products or stores","69:29":"or genome motifs or whatever and then","69:33":"use them in lots of different models","69:35":"possibly you know using faster things","69:37":"like random forests about getting a lot","69:41":"of the benefits that was something","69:43":"interesting they took a two-dimensional","69:47":"projection of their of their embedding","69:51":"matrix for state for example German","69:54":"state because this was a German","69:56":"supermarket chain I think using the same","69:59":"kind of approach we did I don't remember","70:00":"if they use PCA or something else","70:02":"slightly different and then here's the","70:05":"interesting thing I've circled here you","70:09":"know a few things in this embedding","70:11":"space and I've circled it with the same","70:13":"color over here and here I've circled","70:16":"some same color over here and it's like","70:19":"oh my god the embedding projection has","70:25":"actually discovered geography","70:27":"like but they didn't do that right but","70:30":"it's it's it's found things that are","70:32":"near by each other in grocery purchasing","70:36":"patterns because this was about","70:38":"predicting how many sales there will be","70:40":"you know it's it there is some","70:43":"Geographic element of that in fact here","70:48":"is a graph of the distance between two","70:50":"embedding vectors so you can just take","70:53":"an embedding vector and say what's the","70:55":"sum of squared you know compared to some","70:58":"other embedding vector that's the","70:59":"Euclidean distance what's the distance","71:01":"in embedding space and then plotted","71:03":"against the distance in real life","71:05":"between shops and you get this very","71:07":"strong positive correlation here is an","71:11":"embedding space for the days of the week","71:12":"and as you can see there's a very clear","71:16":"path through them here's the embedding","71:18":"space for the month of the year and","71:20":"again there's a very clear path through","71:21":"them so like embeddings are amazing and","71:26":"I don't feel like anybody's even close","71:29":"to exploring the kind of interpretation","71:35":"that you could get right so if you've","71:38":"got genome motifs or plant species or","71:45":"products that your shop sells or","71:47":"whatever like it would be really","71:48":"interesting to train a few models and","71:52":"try and kind of fine tune some","71:53":"embeddings and then like start looking","71:57":"at them in these ways in terms of","71:58":"similarity to other ones and clustering","72:00":"them and projecting them into 2d spaces","72:03":"and whatever I think is really","72:05":"interesting now so we're trying to make","72:10":"sure we understood what every line of","72:12":"code did in this some pretty good collab","72:15":"liner model we built and so the one","72:17":"piece missing is this WD piece and WD","72:21":"start stands for weight decay so what is","72:23":"weight decay weight decay is a type of","72:27":"regularization what is regularization","72:30":"well let's start by going back to this","72:32":"nice little chart that Andrew owned did","72:34":"in his terrific machine learning course","72:36":"where he plot you know plotted some data","72:39":"and then","72:40":"showed a few different lines through it","72:42":"this one here because Andrews at","72:46":"Stanford he has to use Greek letters","72:48":"okay","72:49":"so we couldn't say this is a plus BX but","72:51":"you know if you want to go there theta","72:53":"naught plus theta 1 X here's a line","72:57":"right it's a line even if it's a Greek","72:59":"letters is still alone so here's a","73:03":"second-degree polynomial a plus BX plus","73:07":"CX squared bit of curve right and here's","73:10":"a high degree polynomial which is curvy","73:15":"as anything so models with more","73:20":"parameters tend to look more like this","73:23":"and so in traditional statistics we say","73:27":"hey let's use less parameters because we","73:31":"don't want it to look like this because","73:32":"if it looks like this then the","73:34":"predictions over here and over here","73:36":"they're going to be you're wrong right","73:39":"it's not going to generalize well we're","73:42":"overfitting","73:43":"so we avoid overfitting by using less","73:45":"parameters and so if any of you are","73:48":"unlucky enough to have been brainwashed","73:51":"by a background in statistics or","73:54":"psychology or econometrics or any of","73:56":"these kinds of courses you'll have you","73:58":"know you're gonna have to unlearn the","74:00":"idea that you need less parameters","74:02":"because what you instead need to realize","74:04":"this is you will fit this lie that you","74:07":"need less parameters because it's a","74:09":"convenient fiction for the real truth","74:12":"which is you don't want your function to","74:15":"be too complex and having less","74:17":"parameters is one way of making it less","74:20":"complex but what if you had a thousand","74:24":"parameters and 999 of those parameters","74:27":"were 1 a neg 9 well what if there was 0","74:32":"if there's 0 they're not they're not","74:33":"really there or if they want a neg 9","74:35":"they're hardly there right so like why","74:38":"can't I have lots of parameters if like","74:40":"lots of them are really small man the","74:43":"answer is you can okay you know so this","74:47":"this thing of like counting the number","74:49":"of parameters is how we limit complexity","74:51":"is actually","74:54":"extremely limiting it's a fiction that","74:57":"really has a lot of problems right and","75:00":"so if in your head","75:01":"complexity is scored by how many","75:03":"parameters you have you're doing it all","75:05":"wrong right score it properly right so","75:09":"why do we care why would I want to use","75:12":"more parameters because more parameters","75:15":"means more nonlinearities more","75:19":"interactions more curvy bits right and","75:23":"real life is full of curvy bits but real","75:27":"life does not look like this but we","75:32":"don't want them to be more curvy than","75:34":"necessary or more interacting than","75:37":"necessary so therefore let's use lots of","75:40":"parameters and then penalize complexity","75:45":"okay so one way to penalize complexity","75:49":"is as I kind of suggested before is","75:52":"let's sum up the value of your","75:55":"parameters now that doesn't quite work","75:57":"because some parameters are positive and","75:59":"some are negative right so what if we","76:02":"sum up the square of the parameters all","76:06":"right and that's actually a really good","76:09":"idea okay let's actually create a model","76:12":"and in the loss function we're going to","76:15":"add the sum of the square of the","76:18":"parameters now here's a problem with","76:21":"that though maybe that number is way too","76:23":"big and it's so big that the best loss","76:28":"is to set all of the parameters to zero","76:32":"now that would be no good","76:34":"right so actually we want to make sure","76:37":"that doesn't happen so therefore let's","76:40":"not just add the sum of the squares of","76:42":"the parameters to the model but let's","76:44":"multiply that by some number that we","76:47":"choose and that number that we choose in","76:50":"first AI is called WD okay so that's","76:58":"we're gonna take our loss function and","77:02":"we're going to add to it the sum of the","77:03":"squares of parameters multiplied by some","77:07":"number WD what should that number be","77:13":"well generally it should be zero point","77:17":"one people with fancy machine learning","77:24":"PhDs are extremely skeptical and","77:27":"dismissive of any claims that a learning","77:30":"rate can be 3 in X 3 most of the time or","77:33":"a weight decay can be point 1 what's the","77:35":"time but here's the thing we've done a","77:37":"lot of experiments on a lot of data sets","77:40":"and we've had a lot of trouble finding","77:41":"anywhere a weight decay of 0.1 isn't","77:44":"great however we don't make that the","77:49":"default we actually make the default","77:51":"0.01 why because in those rare occasions","77:57":"where you have too much weight decay no","78:00":"matter how much you train it just never","78:04":"quite fits well enough where else if you","78:07":"have too little weight decay you can","78:10":"still train well you're just at to","78:12":"overfit so you just have to stop a","78:13":"little bit early so we've been a little","78:16":"bit conservative with our defaults but","78:18":"my suggestion to you is this now that","78:20":"you know that every learner has a wd","78:24":"argument and I should mention you won't","78:27":"always see it in this list right because","78:30":"there's this concept of kW args in","78:33":"Python which is basically parameters","78:36":"that are going to get passed up the","78:37":"chain to the next thing that we call now","78:39":"so basically all of the learners will","78:42":"call eventually this constructor and","78:48":"this constructor has a WD right so this","78:52":"is just one of those things that you can","78:53":"either look in the docs or you now know","78:56":"it anytime you're constructing a learner","78:59":"from pretty much any kind of function in","79:01":"fast AI you can pass WD okay and so","79:05":"passing 0.1 instead of the default point","79:08":"0 1 will often help ok so give it a go","79:15":"so what's really going on here it would","79:21":"be helpful I think to go back to lesson","79:27":"two SGD because everything we're doing","79:30":"the rest of today really is based on","79:33":"this right and this is where we created","79:35":"some data and then we try and then we","79:39":"add at a loss function MSE and then we","79:42":"created a function called update which","79:45":"calculated our predictions","79:47":"that's our weight make matrix multiply","79:50":"now this is just a one layer so there's","79:52":"no value we calculated our loss using","79:55":"that mean squared error we calculated","79:57":"the gradients using loss type backward","79:59":"we then subtracted in place the learning","80:04":"rate times the gradients and that is","80:06":"gradient descent so if you haven't","80:08":"reviewed lesson two SGD please do","80:13":"because this is where we're this is our","80:15":"starting point so if you don't get this","80:17":"then none of this is going to make sense","80:19":"if you watching the video maybe pause","80:21":"now go back re-watch this part of listen","80:23":"to make sure you get it remember a dot","80:28":"sub underscore is basically the same as","80:31":"a minus equals because a dotsub is","80:36":"subtract and everything in pi torch if","80:39":"you add an underscore to it means do it","80:41":"in place so this is updating our a","80:44":"parameters which started out as minus","80:48":"0.1 one we just barbeque pick those","80:50":"numbers and it gradually makes them","80:52":"better all right so let's write that","80:55":"down","80:58":"so we are trying to calculate the","81:05":"parameters I'm going to call them","81:07":"weights because this is just more common","81:15":"in kind of epoch tea or time tea and","81:18":"they're going to be equal to whatever","81:21":"the weights were in the previous epoch","81:25":"- our learning rate multiplied by it's","81:31":"the derivative of our loss function with","81:36":"respect to our weights at time t minus 1","81:42":"okay so that's that's what this is doing","81:49":"okay and we don't have to calculate the","81:51":"derivative because it's boring and","81:53":"because it computers do it for us fast","81:57":"and then they store it here for us so","82:01":"we're good to go okay so make sure","82:06":"you're exceptionally comfortable with","82:09":"either that equation or that line of","82:14":"code because they are the same thing","82:19":"where do we go from here all right so","82:25":"what's that what's our loss our loss is","82:31":"some function of our independent","82:37":"variable variables X and now weights","82:44":"right and in our case we're using mean","82:50":"squared error for example and it's","82:53":"between our predictions and our actuals","82:57":"right so where does X and W come in","83:01":"well our predictions come from running","83:04":"some model we'll call it m on those","83:09":"predictions and that model contains some","83:11":"weights all right so that's that's what","83:14":"our loss function might be and this","83:16":"might be you all kinds of other loss","83:17":"functions will see some more today and","83:20":"so that's what ends up creating","83:27":"grab over here so we're going to do","83:33":"something else we're going to add weight","83:37":"decay some number which in our case is","83:40":"0.1 x times the sum of weights squared","83:58":"okay so let's do that and let's make it","84:05":"interesting by not using synthetic data","84:09":"but let's do some real data and we're","84:12":"going to use em NIST the hand-drawn","84:14":"digits right but we're going to do this","84:17":"as a standard fully connected net not as","84:21":"a convolutional net because we haven't","84:22":"learnt the details of how to really","84:24":"create one of those from scratch so in","84:27":"this case is actually deep learning net","84:29":"provides amnesty as a python pickle file","84:34":"in other words it's a file that pickle","84:35":"that Python can just open up and it'll","84:38":"give you numpy arrays straight away and","84:40":"they're flat and umpire rays we don't","84:42":"have to do anything to them so go grab","84:44":"that and it's a gzip file so you can","84:49":"actually just gzip don't open it","84:50":"directly and then you can pick all","84:54":"download it directly and again encoding","84:57":"equals latin-1 because yeah you know and","85:01":"then we can just put that static that'll","85:03":"give us the training the validation and","85:05":"the test set I don't care about the test","85:07":"set so generally in Python if there's","85:09":"like something you don't care about you","85:11":"tend to use this special variable called","85:13":"underscore there's no reason you have to","85:15":"it's just kind of people know you mean I","85:17":"don't care about this right so there's","85:19":"our trading trading X&Y; and a valid X&Y;","85:23":"now this actually comes in as a as you","85:26":"can see if I print the shape 50,000 rows","85:29":"by 784 columns but those 784 columns are","85:32":"actually 28 by 28 pixel pictures so if I","85:36":"reshape one of them into a 28 by 28","85:38":"pixel picture and plot it","85:41":"right then you can see it's the number","85:42":"five okay so that's our data we've seen","85:45":"em nest before in its kind of pre","85:48":"reshaped version here it is in its","85:49":"flattened version so I'm going to be","85:51":"using it in its flattened version okay","85:54":"and currently they are numpy arrays I","85:58":"need them to be tensors so I can just","86:01":"map Torche tensor across all of them and","86:04":"so now they're tensors okay I may as","86:10":"well create a variable with the number","86:12":"of things I have which we normally call","86:13":"n and remember we normally have a thing","86:15":"called you know we don't use seed I mean","86:17":"the number of activations we need we","86:20":"actually say this is not going to be","86:21":"activation sorry this is going to be","86:22":"number of columns that's not a great","86:24":"name for it sorry okay so there we are","86:28":"and then the the why not surprisingly","86:32":"the minimum value is zero and the","86:34":"maximum value is nine because that's the","86:36":"actual number we're gonna predict great","86:38":"so in lesson two SGD we like we created","86:42":"a data where we actually added a column","86:44":"of ones on so that we didn't have to","86:47":"worry about bias we're not going to do","86:49":"that we're going to have plate watch to","86:51":"do that kind of implicitly for us we had","86:53":"to write our own MSC function we're not","86:55":"going to do that we had to write our own","86:57":"little matrix model location thing we're","87:00":"not going to do that we're gonna have","87:01":"plate or do all this stuff for us now","87:03":"and what's more and really important","87:06":"we're going to do mini batches right","87:09":"because this is a big enough data set we","87:10":"probably don't want to do it all at once","87:13":"so if you want to do mini batches so we","87:17":"could we're not going to use too much","87:18":"faster i stuff here apply torch has","87:22":"something called intense a data set that","87:24":"basically grabs a any kind of tensor","87:30":"sorry two tensors and creates a data set","87:33":"remember a data set is something where","87:35":"if you index into it you get back an x","87:38":"value and a y value just one of them","87:40":"okay so it kind of looks like it looks a","87:44":"lot like a list of XY tuples once you","87:49":"have a data set then you can use a","87:51":"little bit of convenience by calling","87:54":"data by","87:55":"create and what's that going to do is","87:57":"it's going to create data loaders for","87:59":"you a data loader is something which you","88:03":"don't say I want the first thing or the","88:05":"fifth thing you just say I want the next","88:07":"thing and it will give you a batch a","88:10":"mini batch of whatever size you asked","88:12":"for and specifically it'll give you the","88:14":"X and the y of a mini batch so if I just","88:17":"grab the next of the iterator this is","88:20":"just standard Python if you haven't used","88:22":"it a radius in Python before here's my","88:25":"training data loader that data bunch","88:27":"courier creates for you and you can","88:31":"check that as you would expect the X is","88:34":"64 by 784 because there's 784 pixels","88:37":"flattened out 64 in a mini batch and the","88:40":"Y is just 64 numbers there are things","88:43":"we're trying to predict so and you know","88:47":"if you look at the source code for data","88:48":"batch job create you'll see there's not","88:50":"much there but so feel free to do so we","88:53":"just make sure that like your training","88:54":"set gets shuffled randomly shuffled for","88:57":"you we make sure that the data is put on","89:00":"the GPU for you just a couple of little","89:03":"convenience things like that but don't","89:06":"let it be magic","89:07":"if it feels magic check out the source","89:09":"code to make sure you see what's going","89:10":"on okay","89:11":"so rather than do this y hat equals x at","89:15":"a thing we're going to create an NN","89:18":"module all right if you want to create","89:20":"an end up module that does something","89:22":"different to what's already out there","89:24":"you have to subclass it right so sub","89:27":"classing is very very very normal in","89:30":"plaid torch so if you're not comfortable","89:32":"with sub classing stuff in python go","89:36":"read a couple of tutorials to make sure","89:38":"you our main thing is you have to","89:39":"override the constructor dunder init and","89:42":"make sure that you call the super","89:45":"classes constructor because n n dot","89:47":"modules super classes constructor is","89:49":"going to like set it all up to be a","89:51":"proper n n dot module for you so if you","89:55":"try to using if you're trying to create","89:56":"your own PI torch subclass and things","89:58":"don't work it's almost certainly because","90:00":"you forgot this line of code alright so","90:05":"the only thing we want to add is we want","90:07":"to create","90:08":"and an attribute in our class which","90:11":"contains a linear layer and n n dot","90:14":"linear module what is an N n dot linear","90:16":"module it's something which does that","90:21":"but actually it doesn't only do that it","90:23":"actually is X at a plus B so in other","90:26":"words we don't have to add the column of","90:27":"ones okay that's all it does okay so if","90:31":"you want to play around why don't you","90:34":"try and create your own and end on","90:37":"linear class you could create something","90:39":"called my linear and it'll take you you","90:43":"know depending on your piped watch","90:45":"background an hour or two and then","90:48":"you'll feel like okay this is we don't","90:50":"want any of this to be magic and you","90:52":"know all of the things necessary to","90:53":"create this know so you know these are","90:56":"the kind of things that you should be","90:57":"doing for your assignments this week is","90:59":"not so much new applications but try to","91:02":"start writing more of these things from","91:04":"scratch and get them to work learn how","91:06":"to debug them check what's going in and","91:08":"out and so forth okay but we could just","91:11":"use n n dot linear and that's this going","91:12":"to do so it's going to have a def","91:14":"forward inner there goes a at X plus B","91:18":"right and so then in our forward how do","91:22":"we calculate the result of this well","91:24":"remember every NN dot module looks like","91:27":"a function so we pass our X mini-batch","91:30":"so I don't use xB to mean a batch of X","91:33":"to self dot Lin and that's going to give","91:36":"us back the result of the ax plus B on","91:40":"this mini batch so this is a logistic","91:44":"regression model a logistic regression","91:46":"model is also known as a neural net with","91:48":"no hidden layers so it's a one layer","91:51":"neural net no nonlinearities because","91:55":"we're doing stuff ourself a little bit","91:57":"we have to put the weight matrices the","92:00":"parameters onto the GPU manually so just","92:04":"type CUDA to do that so here's our model","92:07":"and as you can see the end module","92:10":"machinery has automatically given us a","92:13":"representation of it it's automatically","92:15":"stored the dot Lin thing and it's","92:17":"telling us what's inside it so there's a","92:19":"lot of little conveniences that PI torch","92:20":"does for us","92:21":"so if you look at now at model n you can","92:24":"see not surprisingly here it is perhaps","92:27":"the most interesting thing to point out","92:29":"is that our model automatically gets a","92:35":"bunch of methods and properties and","92:38":"perhaps the most interesting one is the","92:40":"one called parameters which contains all","92:43":"of the yellow squares from our picture","92:46":"but it contains our parameters it","92:49":"contains our weight matrices and biased","92:52":"matrices in as much as they're different","92:54":"so if we have a look at P dot shape for","92:57":"P and modeled up parameters there's","92:59":"something of ten by two 784 and there's","93:03":"something of ten so what are they well","93:05":"ten by 784 okay so that's the thing","93:08":"that's going to take in 784 dimensional","93:11":"input and spit out a 10 dimensional","93:12":"output because that's handy because our","93:14":"input is 784 dimensional and we need","93:17":"something that's going to give us a","93:18":"probability of ten numbers after that","93:21":"happens we've got ten activations which","93:23":"we then want to add the bias to so there","93:26":"we go here's a vector of length 10 so","93:29":"you can see why this this model we've","93:33":"created has exactly the stuff that we","93:35":"need to do our ax plus B so let's grab a","93:41":"learning rate we're going to come back","93:43":"to this loss function in a moment but we","93:44":"can't use em as well hmm we can't really","93:48":"use MSE for this right because we're not","93:50":"trying to see how close are you did you","93:52":"predict three and actually it was four","93:54":"gosh you were really close it's like no","93:56":"three is just as far away from four as","93:58":"zero is away from four when you're","94:01":"trying to predict what number did","94:02":"somebody draw so we're not going to use","94:04":"MSE we're going to use cross-entropy","94:06":"loss which we'll look at in a moment and","94:08":"here's our update function I copied it","94:11":"from less than two SGD but now we're","94:15":"calling our model rather than going a at","94:17":"X we're calling our model as if it was a","94:19":"function to get Y hat and we're calling","94:23":"our loss func rather than calling MSE to","94:26":"get our loss and then this is all the","94:28":"same as before except rather than going","94:32":"through each parameter and going","94:34":"parameter","94:35":"sub underscore learning rate times","94:37":"gradient we loop through the parameters","94:39":"okay because very nicely for us pipe","94:45":"torch will automatically create this","94:46":"list of the parameters of anything that","94:48":"we created in our dunder init and look","94:51":"I've added something else I've got this","94:54":"thing called w2 I go through HP and","94:57":"model drop parameters and I add two","94:59":"double to w2 the sum of squares so w-2","95:05":"now contains my summer squared sweets","95:06":"and then I multiply it by some number","95:10":"which I set to one a neg five so now I","95:14":"just implemented weight decay okay so","95:17":"when people talk about weight decay it's","95:20":"not an amazing magic complex thing","95:22":"containing thousands of lines of CUDA","95:25":"C++ code it's those two lines of Python","95:31":"that's weight okay this is not a","95:33":"simplified version that's just enough","95:35":"for now this is weight okay that's it","95:37":"okay and so here's the thing there's a","95:42":"really interesting kind of drool way of","95:45":"thinking about weight decay one is that","95:48":"we're adding the sum of squares weights","95:50":"and that seems like a very sound thing","95:53":"to do and it is and well let's go ahead","95:56":"and run this","96:02":"so here I've just got a list","96:03":"comprehension that's going through my","96:06":"data loader so the data loader gives you","96:09":"back one mini batch and it's for the","96:11":"whole thing giving you XY each time I'm","96:14":"gonna call update for each each one","96:17":"returns loss now PI torch tensors since","96:24":"I did it all on the GPU that's sitting","96:25":"in the GPU and it's like got all these","96:27":"stuff attached to it to calculate","96:28":"gradients it's going to use up a lot of","96:31":"memory so if you if you called dot item","96:33":"on a scalar tensor it turns it into an","96:36":"actual normal Python number so this is","96:39":"just means I'm returning back normal","96:41":"Python numbers and then I can plot them","96:44":"and yeah there you go my loss function","96:47":"is going down","96:48":"and you know it's really nice to try","96:51":"this stuff to see it behaves as you","96:52":"expect like we thought this is what","96:54":"would happen as we get closer and closer","96:56":"to the answer it bounces around more and","96:59":"more right because we're kind of close","97:01":"to where we should be","97:02":"it's kind of fitting flat probably","97:03":"flatter and weight space so we kind of","97:05":"jumping further and so you can see why","97:07":"we would probably want to be reducing","97:09":"our learning rate as we go learning rate","97:11":"annealing okay now here's the thing that","97:17":"is only interesting for training a","97:22":"neural net because it appears here","97:29":"because we take the gradient of it","97:33":"that's the thing that actually updates","97:35":"the weights right so they actually the","97:37":"only thing interesting about WD times","97:41":"sum of W squared is its gradient so we","97:45":"don't do a lot of math here but I think","97:47":"we can handle that the gradient of this","97:51":"whole thing if you remember back to your","97:53":"high school math is equal to the","97:56":"gradient of H part taken separately and","97:59":"then add them together so let's just","98:02":"take the gradient of that right because","98:04":"we already know the gradient of this is","98:05":"just whatever we had before right so","98:07":"what's the gradient of W D times the sum","98:09":"of W squared right let's remove the","98:13":"psalm and pretend there's just one","98:14":"parameter it doesn't change the","98:16":"generality of it so the gradient of W D","98:20":"times W squared so what's the gradient","98:24":"of that with respect to W it's just two","98:30":"WD times W ok and so remember this is","98:37":"our constant which now case was like","98:39":"well in that little loop it was 1 e neg","98:42":"5","98:45":"and that's our weights and like we could","98:48":"replace WD with like 2wd without loss of","98:52":"generality so let's throw away the two","98:54":"so in other words all weight decay does","98:58":"is it subtracts some constant times the","99:02":"weights every time we do a batch so","99:07":"that's why it's called weight decay okay","99:10":"when it's in this form where we add the","99:14":"square to the loss function that's","99:18":"called l2 regularization when it's in","99:24":"this form where we subtract WD times","99:28":"weights from the gradients","99:30":"that's called weight decay and they are","99:38":"kind of mathematically identical for","99:40":"everything we've seen so far in fact","99:41":"they are mathematically identical and","99:44":"we'll see in a moment a place where","99:45":"they're not where are things get","99:46":"interesting ok so this is just a really","99:50":"important tool you now have in your","99:52":"toolbox you can make giant neural","99:55":"networks right and still avoid","99:58":"overfitting by adding more weight decay","100:01":"okay or you could use really small data","100:04":"sets with moderately large sized models","100:08":"and avoid overfitting with weight decay","100:10":"it's not magic right like you might","100:14":"still find you don't have enough data in","100:15":"which case like you get to the point","100:17":"where you're not overfitting by adding","100:18":"lots of weight decay and it's just not","100:20":"training very well that can happen all","100:22":"right but at least this is something","100:24":"that Union can now play around with just","100:30":"to kind of go on here now that we've got","100:34":"this update function we could replace","100:36":"this M missed logistic with amnesty row","100:40":"Network and build a neural network from","100:41":"scratch right now we just need two","100:44":"linear layers right in the first one we","100:47":"could use a weight matrix of size 50 and","100:49":"so we didn't need to make sure that the","100:50":"second linear layer has an input of size","100:52":"50 so it matches the final layer has to","100:56":"have an output of size 10","100:57":"that's the number of classes we're","100:58":"predicting and so now our forward just","101:00":"goes to a linear layer calculate value","101:04":"to a second linear layer and now we've","101:07":"actually created a neural net from","101:09":"scratch I mean we didn't write it in","101:11":"linear but you can write it yourself or","101:13":"you could like do the matrices directly","101:16":"you know how to so again you know if we","101:20":"go model dot CUDA and then we can","101:23":"calculate losses for the exact same","101:24":"update function there it goes right so","101:28":"this is why this kind of idea of neural","101:30":"nets is so easy right once you have","101:32":"something that can do gradient descent","101:34":"right then you can try different models","101:38":"and then you can start to add more Pytor","101:42":"stuff so like rather than add doing all","101:43":"this stuff yourself why not just go opt","101:49":"equals opt e m dot something so there's","101:53":"something we've done so far is SGD and","101:56":"so now you're saying 2pi torch i want","102:00":"you to take these parameters and","102:02":"optimize them using SGD and so this now","102:06":"rather than saying for P in parameters P","102:10":"minus equals L R times P dot grad you","102:14":"just say up dot step it's the same thing","102:16":"okay it's just less code right but and","102:20":"it does the same thing but the reason","102:22":"it's kind of particularly interesting is","102:23":"that now you can replace SGD with atom","102:28":"for example and you can even add things","102:32":"like weight decay right because like","102:37":"there's more stuff it's kind of in these","102:40":"things for you right so that's why we","102:43":"tend to use you know optiom glass so","102:46":"behind the scenes this is actually what","102:48":"we do in first ago so if I go up to m","102:55":"dot sgt okay so this","103:01":"right and so that's that's just that","103:03":"picture but if we change to a different","103:05":"optimizer so look what happened it","103:14":"diverged and we've seen a great picture","103:17":"of that from one of our students who","103:19":"showed what divergence looks like this","103:21":"is what it looks like when you try to","103:22":"train something so let's use we're using","103:25":"a different optimizer so we need a","103:26":"different learning rate and you can't","103:29":"just continue training because by the","103:31":"time it's diverged the the the weights","103:33":"are like really really big and really","103:35":"really small they're not going to come","103:36":"back so start again okay there's a","103:41":"better learning rate but look at this","103:43":"we're down underneath point five by","103:45":"about epoch 200 where else before and","103:48":"I've even sure we ever got to quite that","103:51":"level so what's going on what's what's","103:54":"Adam let me show you and we're gonna do","104:01":"gradient descent in Excel because why","104:04":"wouldn't you okay so here is some","104:09":"randomly generated data okay some X's","104:12":"and some whites well they're actually","104:13":"they're randomly generated XS and the","104:14":"Y's are all calculated by doing ax plus","104:19":"B where a is 2 and B is 30 okay so this","104:23":"is some data that we got to try and","104:24":"match and here is SGD and so we got to","104:31":"do it with SGD now in our lesson to SGD","104:34":"notebook we did the whole data set at","104:37":"once as a batch in the notebook we just","104:41":"looked at we did mini batches in this","104:43":"spreadsheet we're going to do online","104:45":"gradient descent which means every","104:47":"single row of data is a batch there's","104:49":"kind of a batch size of one okay so as","104:52":"per usual we're going to start by","104:53":"picking an intercept and slope kind of","104:56":"arbitrarily so I'm just going to pick","104:57":"them at 1 doesn't really matter","105:01":"so here I've copied over the data this","105:03":"is my X&Y; and so my intercept and slope","105:06":"as I said is 1 all right I'm just","105:08":"literally referring back to this cell","105:09":"here so my prediction for this","105:13":"particular intercept them","105:14":"would be 14 times one plus one which is","105:17":"15 and so there's my error means that","105:21":"there's my summer Squared's but not even","105:23":"a sum at this point it's the squared","105:24":"error okay so now I need to calculate","105:29":"the gradient so that I can update","105:31":"there's two ways you can calculate the","105:33":"gradient one is analytically and so I","105:37":"you know you can just look them up on","105:39":"Wolfram Alpha or whatever so there's the","105:40":"gradients if you write it out by hand or","105:44":"look it up or you can do something","105:46":"called finite differencing because","105:47":"remember gradients just how far you move","105:51":"in act sorry how far you how far the the","105:53":"outcome moves divided by how far your","105:56":"change was for really small changes so","106:00":"let's just make a really small change so","106:06":"here we've taken our intercept and added","106:10":"point O 1 to it right and then","106:13":"calculated our our loss and you can see","106:17":"that our loss went down a little bit","106:21":"right and we added 0.01 here so our","106:24":"derivative is that difference divided by","106:27":"that point I 1 okay now that's called","106:29":"finite differencing and you can always","106:31":"do derivatives of find out different","106:32":"seeing it's slow we don't do it in","106:35":"practice but it's nice for just checking","106:36":"stuff out so we can do the same thing","106:38":"for our a term at 0.012 that take the","106:42":"difference and divide by 0.01 or as I","106:45":"say we can calculate it directly using","106:47":"the actual derivative analytical and you","106:49":"can see that you know that and that as","106:52":"you'd expect it's very similar and that","106:54":"and that not very similar so gradient","106:58":"descent then just says let's take our","107:01":"current value of that weight and","107:03":"subtract the learning rate times the","107:06":"derivative there it is okay and so now","107:10":"we can copy that intercept and that","107:16":"slope to the next row and do it again","107:19":"and do it lots of times and at the end","107:23":"we've done one epoch so at the end of","107:26":"that epoch","107:27":"we could say oh great so this is our","107:31":"slope so let's copy that over to where","107:35":"it says slope and this is our intercept","107:42":"so I'll copy it to where it says","107:43":"intercept and now it's done another","107:47":"epoch okay so that's kind of boring I'm","107:51":"copying and pasting so I created a very","107:55":"sophisticated macro which copies and","107:59":"pastes for you and so I just recorded it","108:03":"basically and so and then I created a","108:06":"very sophisticated for loop that goes","108:07":"through and does it five times and I","108:10":"attach that to the Run button so if I","108:12":"press run it'll go ahead and do it five","108:14":"times and just keep track of the era","108:17":"each time okay so that is SGD and as you","108:22":"can see it is just infuriatingly slow","108:27":"like particularly the intercept is meant","108:30":"sorry yeah it's meant to be 30 and we're","108:34":"still only up to one point five seven","108:36":"and like just it's just going so slowly","108:40":"so let's beat it up so the first thing","108:42":"we can do to speed it up is to use them","108:44":"in court momentum right so here's the","108:46":"exact same spreadsheet is the last","108:50":"worksheet I've removed the finite","108:52":"difference seeing version of the","108:53":"derivatives because they're not that","108:55":"useful does the analytical ones here and","108:58":"here's the thing where I take the the","109:02":"derivative and I'm going to update by","109:08":"the derivative but what I do it's kind","109:11":"of more interesting to look at this one","109:12":"is I take the derivative and I multiply","109:15":"it by 0.1 now what I do is I look at the","109:20":"previous update and I multiply that by","109:23":"0.9 and I add the two together so in","109:27":"other words the update that I do is not","109:31":"just based on the derivative but 1/10 of","109:35":"it is the derivative and 90% of it is","109:38":"just the same direction I went last","109:41":"and this is called momentum right what","109:45":"it means is remember how we kind of","109:51":"thought about what might happen","109:54":"if you're trying to find the minimum of","109:57":"this and you were here and your learning","109:59":"rate was too small right and you just","110:02":"keep doing the same steps or if you keep","110:05":"doing the same steps then if you also","110:07":"add in the step you talked last time and","110:13":"your steps are going to get bigger and","110:14":"bigger aren't they okay until eventually","110:18":"they go too far but now of course your","110:23":"gradients point in the other direction","110:24":"to whether your momentum is pointing so","110:26":"you might just take a little step over","110:28":"here and then you'll start going small","110:30":"steps bigger steps bigger steps small","110:32":"steps bigger stairs like that right so","110:35":"that's kind of what momentum does or if","110:37":"you're if you're kind of going too far","110:47":"like this which is also slow all right","110:52":"then the average of your last few steps","110:55":"is actually somewhere kind of between","111:00":"the two isn't it all right so this is a","111:04":"really common idea right it's like when","111:07":"you have something that says kind of my","111:11":"what is in this case it's like my step","111:15":"my step at time T equals some number","111:21":"people often use alpha because like I","111:24":"say they've got to love these Greek","111:25":"letters some number times the actual","111:31":"thing I want to do right so it might in","111:34":"this case it's like the gradient right","111:36":"plus one minus alpha times whatever you","111:42":"had last time st minus one this thing","111:50":"here","111:52":"is called an exponentially weighted","111:54":"moving average and the reason why is","111:56":"that if you think about it these 1 minus","111:59":"alphas are going to mount a play so s T","112:02":"minus 2 is in here with a kind of a 1","112:06":"minus alpha squared and s T minus 3 is","112:08":"in there with a net 1 minus alpha cubed","112:10":"so in other words this ends up being the","112:15":"actual thing I want plus a weighted","112:18":"average of the last few time periods","112:20":"where the most recent ones are","112:23":"exponentially higher weighted ok and","112:26":"this is going to keep popping up again","112:28":"and again all right so that's what","112:30":"momentum is it says I want to go based","112:32":"on the current gradient plus the","112:36":"exponentially weighted moving average of","112:38":"my last few steps so that's useful","112:42":"that's called SGD with momentum and we","112:46":"can do it by changing this here to","112:49":"saying SGD momentum and momentum 0.9 is","112:54":"really common it's couple add a lot it's","112:56":"like it's so common it's always pointing","112:57":"in just about four basic stuff so that's","113:02":"how you do rest you deal with momentum","113:03":"and and again it's not I didn't show you","113:06":"some simplified version I showed you the","113:09":"version that is that is SGD ok that's","113:12":"that's you again you can write your own","113:13":"try it out that would be a great","113:15":"assignment would be to take lesson to","113:18":"SGD and add momentum to it or even the","113:22":"new notebook we've got feminists get rid","113:25":"of the OP team dot and write your own","113:27":"update function with with momentum then","113:31":"there's a cool thing called rmsprop one","113:32":"of the really cool things about rmsprop","113:34":"is that Geoffrey Hinton created it","113:38":"famous neural net guy everybody uses it","113:42":"it's like really popular it's really","113:44":"common the correct citation for rmsprop","113:48":"is the Coursera online free MOOC that","113:52":"that's where he first mentioned rmsprop","113:56":"so I love this thing that like you know","113:59":"call new things appear in MOOCs that not","114:01":"a paper so rmsprop is very similar to","114:05":"but this time we have an exponentially","114:09":"weighted moving average not of the","114:11":"gradient updates but of f/8 squared","114:16":"that's the gradient squared so what the","114:19":"gradient squared times 0.1 plus the","114:24":"previous value times 0.9 so it's","114:28":"exponentially this is an exponentially","114:29":"weighted moving average of the gradient","114:31":"squared so what's this number gonna mean","114:33":"well if my gradients really small and","114:36":"consistently really small this will be a","114:39":"small number if my gradient is highly","114:43":"volatile it's going to be a big number","114:45":"or if it's just really big all the time","114:48":"it'll be a big number and why is that","114:50":"interesting because when we do a update","114:54":"this time we say wait - learning rate","115:00":"times gradient divided by the square","115:08":"root of this so in other words if our","115:11":"gradients consistently very small and","115:13":"not volatile let's take bigger jumps and","115:16":"that's kind of what we want right when","115:18":"we watched how the intercept moves so","115:21":"damn slowly but it just it's like","115:24":"obviously you need to just try it go","115:26":"faster so if I now run this after just","115:32":"five epochs this is already up to three","115:34":"right where else with the basic version","115:36":"after five epochs it's still at 1.27 and","115:43":"remember we have to get to 30 so the","115:46":"obvious thing to do and by obvious I","115:48":"mean only a couple of years ago did","115:50":"anybody actually figure this out is do","115:53":"both right so that's called Adam so Adam","115:57":"is simply keep track of the","115:59":"exponentially weighted moving average of","116:01":"the gradient squared and also keep track","116:05":"of the exponentially weighted moving","116:07":"average of my steps right and both","116:11":"divided by the exponentially weighted","116:15":"moving average of the squared terms","116:17":"and you know take point nine of a step","116:21":"in the same direction as last time so","116:23":"it's it's momentum and rmsprop that's","116:27":"court Adam and look at this okay","116:35":"five steps we're at 25 okay so you know","116:40":"these these are these optimizes people","116:42":"call them dynamic learning rates a lot","116:44":"of people have the misunderstanding that","116:46":"you don't have to set a learning rate of","116:49":"course you do right it's just like","116:52":"trying to identify parameters that need","116:56":"to move faster you know or consistently","116:58":"go in the same direction it doesn't mean","117:00":"you don't need learning rates we still","117:02":"have a learning rate okay and in fact","117:06":"you know if I run this again but","117:09":"currently my my error not distribute so","117:17":"it we trying to get to 30 comma 2 so if","117:21":"I run it again it's getting better but","117:30":"eventually now it's just moving around","117:33":"the same place","117:35":"right so you can see what's happened is","117:37":"the learning rates too high so we could","117:39":"just go in here and drop it down and run","117:42":"it some more getting pretty close now","117:47":"right so you can see how you still need","117:50":"learning rate annealing even with Adam","117:56":"okay so that spreadsheets fun to play","118:00":"around with I do have a Google sheets","118:03":"version of basic SGD that actually works","118:08":"and the macros work and everything","118:10":"Google sheets is so awful and I went so","118:13":"insane making that work I gave up I'm","118:15":"making the other ones work so I'll share","118:17":"a link to the Google sheets version oh","118:21":"my god they do have a macro language but","118:25":"it's just ridiculous so anyway if","118:28":"somebody feels like fighting it to","118:29":"actually get all the other ones to work","118:31":"we'll work it just assistant so maybe","118:34":"somebody can get this working on Google","118:36":"sheets too okay so that's weight decay","118:39":"and Adam and Adam is amazingly fast and","118:51":"we let's go back to this one but we","118:56":"don't tend to use op teamed-up","119:00":"whatever and create the optimizer","119:02":"ourselves and all that stuff because","119:03":"instead we had to use learner but learn","119:07":"is just doing those things for you but","119:10":"again there's no magic right so if you","119:12":"create and learner you say here's my","119:15":"data bunch here's my PI torch and n dot","119:19":"module instance here's my loss function","119:22":"and here are my metrics remember the","119:25":"metrics are just stuff to print out","119:27":"that's it right then you just get a few","119:31":"nice things like learned at LR fine","119:34":"starts working and it starts recording","119:35":"this and you can say fit one cycle","119:38":"instead of just fit but like these","119:40":"things really help a lot like by using","119:42":"the floating rate finder I found a good","119:44":"learning rate and then like look at this","119:46":"my loss here 0.13 here I wasn't getting","119:50":"much beneath point five right so these","119:52":"these tweets make huge differences not","119:56":"tiny differences and this is still just","119:59":"one one epoch now what does fit one","120:03":"cycle do what does it really do this is","120:08":"what it really does right and we've seen","120:11":"this chart on the left before just to","120:12":"remind you this is plotting the learning","120:16":"rate per batch right remember Adam has a","120:19":"learning rate and we use Adam by default","120:22":"or minor variation which we might try to","120:25":"talk about so the learning rate starts","120:28":"really low and it increases about half","120:31":"the time and then it decreases about","120:35":"half the time because at the very start","120:37":"we don't know where we are right so","120:40":"we're in some part of function space","120:41":"it's just bump years or hell all right","120:44":"so if you start","120:45":"jumping around those bumps have big","120:47":"gradients and it will throw you into","120:48":"crazy parts of the space right so start","120:51":"slow and then you'll gradually move into","120:53":"parts of the weight space that you know","120:56":"and they're kind of sensible and as you","120:59":"get to the points where they're sensible","121:00":"you can increase the learning rate you","121:02":"know because the the gradients jedd","121:06":"actually in the direction you want to go","121:08":"right and then as we've discussed a few","121:10":"times as you get close to the final","121:11":"answer","121:12":"you need to anneal your learning rate to","121:15":"hone in on it but here's the interesting","121:17":"thing on the left is the momentum plot","121:21":"and actually every time our learning","121:23":"rate is small our momentum is high why","121:27":"is that because if you I do have a","121:30":"learning small learning rate but you","121:31":"keep going in the same direction you may","121:34":"as well go faster right but if you're","121:37":"jumping really far don't like jump jump","121:41":"really far because it's going to throw","121:43":"you off right and then as you get to the","121:45":"end again you're fine tuning in but","121:48":"actually if you keep going the same","121:49":"direction again and again go faster yeah","121:52":"so this combination is called","121:55":"one cycle and it's just this amazing","121:58":"like it's a simple thing but it's","122:00":"astonishing like this can help you get","122:03":"what's called super convergence that can","122:05":"let you train ten times faster now this","122:08":"was just last year's paper when some of","122:10":"you may have seen the interview with","122:11":"Leslie Smith that I did last week","122:13":"amazing guy incredibly humble and also I","122:17":"should say somebody who is doing","122:19":"groundbreaking research well into his","122:22":"60s and all of these things are","122:24":"inspiring I'll show you something else","122:26":"interesting when you plot the losses","122:28":"with fast AI it doesn't look like that","122:31":"it looks like that why is that because","122:35":"fast AI calculates the exponentially","122:38":"weighted moving average of the losses","122:39":"for you all right so this this concept","122:41":"of exponentially weighted stuff it's","122:43":"just really handy and I use it all the","122:46":"and one of the things that is to make it","122:48":"easier to read these charts okay it does","122:50":"mean that these charts from faster I","122:53":"might be kind of an epoch or two sorry a","122:56":"batch or two behind","122:58":"where they should be you know there's","123:01":"that slight downside when you use an","123:02":"exponentially weighted moving average is","123:04":"you've got a little bit of history in","123:06":"but I can make it much easier to see","123:08":"what's going on so we're now at a point","123:19":"coming to the end of this collab in","123:21":"tabular section where we're going to try","123:23":"to understand all of the code in our","123:26":"tabular model so remember the tabular","123:28":"model use this data set called adult","123:31":"which is trying to predict who's going","123:33":"to make more money it's a classification","123:35":"problem and we've got a number of","123:40":"categorical variables and a number of","123:41":"continuous variables so the first thing","123:43":"we realize is we actually don't know how","123:46":"to predict a categorical variable yet","123:47":"because so far we did some hand waving","123:50":"around the fact that our loss function","123:52":"was an n dot cross entropy loss what is","123:55":"that","123:56":"let's find out and of course we're going","124:00":"to find out by looking at Microsoft","124:04":"Excel so cross-entropy loss is just","124:08":"another loss function well you already","124:10":"know 1 loss function which has means","124:12":"y hat minus y squared ok so that's not a","124:17":"good loss function for us because in our","124:19":"case we have like for M list 10 possible","124:22":"digits and we have 10 activations each","124:24":"with a probability of that digit okay so","124:29":"we need something we're predicting the","124:32":"right thing correctly and confidently","124:35":"should have very little loss predicting","124:39":"the wrong thing confidently should have","124:42":"a lot of loss so that's what we want","124:44":"okay","124:45":"so here's an example here is cat versus","124:49":"dog","124:50":"one hot encoded ok and here are my two","124:55":"activations for each one from some model","124:57":"that I built probability cat probability","125:00":"dog this one's not very confident of","125:03":"anything this one's very confident","125:05":"perfect being a cat that's right this","125:07":"one's very confident for being a cat and","125:08":"it's wrong so we want to loss that","125:11":"for this one should be a moderate loss","125:13":"because not predicting anything","125:15":"confidently is not really what we want","125:18":"so here's a point in three","125:20":"this thing's predicting the correct","125:22":"thing very confidently","125:23":"so 0.01 there's things predicting the","125:26":"wrong thing very confidently so one so","125:29":"how do we do that this is the cross","125:33":"entropy loss and it is equal to whether","125:39":"it's a cat multiplied by log of the","125:44":"probability of cat well this is actually","125:46":"an activation so I should say so it's","125:48":"multiplied by the log of the cat","125:50":"activation negative that - is it a dog","125:56":"times the log of the dog activation and","126:02":"that's it","126:03":"okay so in other words it's the sum of","126:05":"all of your one hot encoded variables","126:09":"times all of your activations so","126:14":"interestingly these ones here exactly","126:17":"the same numbers as these ones here but","126:19":"I've written it differently I've written","126:22":"up with an if function because it's","126:24":"exactly this quiz because the zeros","126:26":"don't actually add anything all right so","126:29":"actually it's exactly the same as saying","126:31":"if it's a cat then take the log of","126:36":"cattiness and if it's a dog yes or","126:40":"otherwise take the log of one minus","126:43":"cattiness in other words the log of dog","126:46":"Eunice so the sum of the one hot encoded","126:50":"times the activations is the same as an","126:54":"if function which if you think about it","126:57":"it's actually because this is just a","127:01":"matrix multiply this is we now know from","127:04":"our from our embedding discussion that's","127:06":"the same as an index lookup so you can","127:09":"also - do cross entropy you can also","127:12":"just look up the log of the activation","127:16":"for the correct answer now that's only","127:20":"going to work","127:22":"if these rows add up to one and this is","127:25":"one reason that you can get screwy","127:28":"cross-entropy numbers is this way I said","127:30":"you press the wrong button","127:31":"if they don't add up to 1 you've got a","127:33":"trouble so how do you make sure that","127:35":"they add up to 1 you make sure they add","127:37":"up to 1 by using the correct activation","127:41":"function in your last layer and the","127:43":"correct activation function to use for","127:45":"this is softmax softmax is an activation","127:48":"function where all of the activations","127:52":"add up to 1 all of the activations are","127:55":"greater than 0 and all of the","127:57":"activations are less than 1 so that's","128:00":"what we want right that's what we need","128:04":"how do you do that well let's say we","128:06":"were predicting one of five things cat","128:08":"dog plane fish building and these were","128:12":"the numbers that came out of our neural","128:13":"net for one set of predictions well what","128:18":"e to the power of that so that's one","128:21":"step in the right direction because e to","128:22":"the power of something is always bigger","128:24":"than zero so there's a bunch of numbers","128:27":"that are always bigger than zero here's","128:31":"the sum of those numbers here is a to","128:38":"the number divided by the sum of e to","128:40":"the number now this number is always","128:44":"less than one right because all of the","128:47":"things were positive so you can't","128:49":"possibly have one of the pieces be","128:51":"bigger than 100 percent of its sum okay","128:54":"and all of those things must add up to","128:58":"one right because each one of them was","129:01":"just that percentage of the total so","129:05":"so this thing softmax is equal to e to","129:09":"the activation divided by the sum of e","129:13":"to the activations","129:15":"that's called softmax and so when we're","129:19":"doing single label multi-class","129:22":"classification you generally want","129:25":"softmax as your activation function and","129:27":"you generally want cross-entropy","129:30":"as your loss now because these things go","129:33":"together in such","129:35":"friendly ways play torch we'll do them","129:39":"both for you all right so you might have","129:42":"noticed that in this eminent example I","129:45":"never added a soft max here and that's","129:50":"because if you ask for cross entropy","129:52":"loss it actually does the softmax in","129:55":"inside the loss function so it's not","129:57":"really just cross entropy loss it's","129:59":"actually softmax then cross entropy loss","130:02":"so you've probably noticed this but","130:05":"sometimes your predictions from your","130:09":"models will come out looking more like","130:12":"this pretty big numbers with negatives","130:15":"in rather than this numbers between","130:17":"norton 1 that add up to 1","130:19":"the reason would be that pi torch","130:22":"it's a pi torch model that doesn't have","130:24":"a softmax in because we're using cross","130:27":"entropy loss and so you might have to do","130:29":"the softmax for it fast AI is getting","130:34":"increasingly good at knowing when this","130:38":"is happening generally if you're using a","130:39":"loss function that we recognize when you","130:42":"get the predictions we will try to add","130:45":"the softmax in there for you but if you","130:47":"particularly if you're using a custom","130:49":"loss function that you know might call","130:52":"and end up crossing entropy loss behind","130:54":"the scenes or something like that you","130:55":"might find yourself with this situation","131:00":"we only have 3 minutes less but I'm","131:03":"going to point something out to you","131:04":"which is that next week when we finish","131:08":"off tabular which we'll do in like the","131:11":"first 10 minutes this is forward in","131:15":"tabular and it basically goes through a","131:19":"bunch of embeddings right it's going to","131:23":"call each one of those embeddings E and","131:24":"you can use it like a function of course","131:26":"so it's going to pass a nitch","131:28":"categorical variable to each embedding","131:29":"it's going to concatenate them together","131:31":"into a single matrix it's going to then","131:36":"call a bunch of layers which are","131:41":"basically a bunch of linear layers and","131:43":"then it's going to do our sigmoid trick","131:46":"and then there's only","131:49":"two new things we'll need to learn one","131:51":"is dropout and the other is the end","131:58":"can't better not and these are two","132:01":"additional regularization strategies","132:03":"right there are basically better on does","132:07":"more than just regularization but","132:08":"amongst other things it does","132:09":"regularization and the basic ways you","132:11":"regular as your model weight decay batch","132:16":"norm and dropout okay and then you can","132:21":"also avoid overfitting using something","132:23":"called data augmentation so better","132:25":"Normand dropout we're going to touch on","132:26":"at the start of next week and we're also","132:29":"going to look at data augmentation and","132:31":"then we're also going to look at what","132:33":"convolutions are and we're going to","132:34":"learn some new computer vision","132:37":"architectures and some new computer","132:39":"vision applications but basically we're","132:43":"very nearly there you already know how","132:45":"the entirety of collab py first light","132:49":"club works you know what why it's there","132:53":"and what it does and you're very close","132:55":"to knowing what the entirety of tabular","133:00":"model does and this tabular model is","133:03":"actually the one that if you run it on","133:05":"rossmann you'll get the same answer that","133:08":"I showed you in that paper you'll get","133:09":"that second place result in fact even a","133:12":"little bit better I'll show you next","133:15":"week if I remember how I actually ran","133:17":"some additional experiments where I","133:19":"figured out some minor tweaks that can","133:21":"do even slightly better than that so","133:23":"yeah we'll see you next week thanks very","133:25":"much and enjoy the smoke outside"}},61:function(e){e.exports={"00:00":"all right welcome to lesson 6 where","00:04":"we're going to do a deep dive into","00:07":"computer vision convolutional neural","00:10":"networks what is a convolution and we're","00:15":"also going to learn the final","00:16":"regularization tricks after last lesson","00:20":"learning about weight decay and /lt","00:23":"regularization","00:26":"I want to start by showing you something","00:29":"that I'm really excited about and I've","00:31":"had a small hand and helping to to","00:35":"create for those of you that saw my talk","00:38":"on ted.com you might have noticed this","00:42":"really interesting demo that we did","00:43":"about four years ago showing a way to","00:46":"quickly build models with unlabeled data","00:51":"it's been four years but we're finally","00:53":"at a point where we're we're we're ready","00:56":"to put this out in the world and let","00:58":"people use it and the first people we're","00:59":"going to let use it are you folks so the","01:04":"company is called platform delay I and","01:06":"the reason I'm mentioning it here is","01:08":"that it's going to let you create models","01:11":"on different types of data sets to what","01:13":"you can do now that is to say data sets","01:15":"that you don't have labels for yet we're","01:18":"actually going to help you label them so","01:20":"this is the first time this has been","01:24":"shown before so I'm pretty thrilled","01:29":"about it and let me give you a quick","01:35":"demo when you so if you'd go to platform","01:38":"AI and choose get started you'll be able","01:44":"to create a new project and if you","01:47":"create a new project you can either","01:48":"upload your own images uploading it at","01:52":"500 or so works pretty well you can","01:55":"upload a few thousand but you know to","01:58":"start upload 500 or so they all have to","02:00":"be in a single folder and so we're","02:04":"assuming that you've got a whole bunch","02:05":"of images that you haven't got any","02:06":"labels for or you can start with one of","02:08":"the existing collections if you want to","02:10":"play around so I've started with the","02:12":"cars","02:13":"collection kind of going back to what we","02:15":"did four years ago and so this is what","02:19":"happens when you first go into","02:22":"platformer AI and look at the collection","02:24":"of images you're uploaded a random","02:26":"sample of them will appear on the screen","02:28":"and as you'll recognize probably they","02:32":"are projected from a deep learning space","02:36":"into a 2d space using a pre trained","02:39":"model and for this initial version it's","02:42":"an image net model we're using as things","02:44":"move along","02:45":"we'll be adding more and more pre train","02:47":"models and what I'm going to do is I","02:50":"want to add labels to this data set","02:53":"representing which angle a photo of the","02:57":"car was taken from which is something","02:58":"that actually image that's going to be","03:01":"really bad at isn't it because image net","03:04":"has learnt to recognize the difference","03:06":"between cars versus bicycles and image","03:09":"net knows that the angle you take a","03:11":"photo on actually doesn't matter so we","03:13":"want to try and create labels using the","03:16":"kind of thing that actually image net","03:18":"specifically learn to ignore so the","03:22":"projection that you see we can click","03:24":"these layer buttons at the top to switch","03:26":"to user projection using a different","03:29":"layer of the neural net right and so","03:32":"here's the last layer which is going to","03:34":"be a total waste of time for us because","03:36":"it's really going to be projecting","03:38":"things based on what kind of thing it","03:40":"thinks it is and the first layer is","03:42":"probably going to be a waste of time for","03:43":"us as well because there's very little","03:46":"interesting semantic content there but","03:49":"if I go into the middle in layer 3 we","03:52":"may well be able to find some some some","03:54":"differences there so then what you can","03:57":"do is you can click on the projection","03:58":"button here and you can actually just","04:00":"press up and down rather than just","04:02":"pressing the the arrows at the top to","04:05":"switch between projections or left and","04:07":"right so switch between layers and what","04:09":"you can do is you can basically look","04:10":"around until you notice that there's a","04:14":"projection which is kind of separated","04:16":"out things you're interested in and so","04:18":"this one actually I notice that it's got","04:22":"a whole bunch of","04:27":"cars that are kind of from the top front","04:30":"front right over here okay so if we zoom","04:35":"in a little bit we can double check","04:37":"because like yeah that looks pretty good","04:39":"they're all kind of front right so we","04:41":"can click on here to go to selection","04:43":"mode and we can cut a grab a few and","04:46":"then you should check and so what we're","04:49":"doing here is we're trying to take","04:50":"advantage of the combination of human","04:52":"plus machine the the machine is pretty","04:54":"good at quickly doing calculations but","04:57":"as a human I'm pretty good at looking at","04:59":"a lot of things at once and seeing the","05:01":"odd one out so in this case I'm looking","05:02":"for cars that aren't front right and so","05:05":"by laying the one on in front of me I","05:06":"can do that really quickly it's like","05:07":"okay definitely that one so just click","05:08":"on the ones that you don't want all","05:13":"right it's all good so then you can just","05:15":"go back and so then what you can do is","05:18":"you can either put them into a new","05:19":"category but I can create a new label or","05:22":"you can click on one of the existing","05:23":"ones so before I came I just created a","05:24":"few so here's friend right so I just","05:26":"click on it here there we go okay and so","05:31":"that's the basic idea is that you kind","05:33":"of keep flicking through different","05:35":"layers or projections to try and find","05:37":"groups that represent the things you're","05:38":"interested in and then over time you'll","05:40":"start to realize that there are some","05:41":"things that are a little bit harder so","05:45":"for example I'm having trouble finding","05:46":"sides so what I can do is I can see over","05:49":"here there's a few sides so I can zoom","05:52":"in here and click on a couple of them","05:55":"like this one and this one that one that","06:02":"one okay I mean I'll say find similar","06:06":"and so this is going to basically look","06:08":"in that that projection space and not","06:12":"just at the images that are currently","06:14":"displayed but all of the images that you","06:15":"uploaded and hopefully I might be able","06:17":"to label now a few more side images at","06:21":"that point so it's going through and","06:24":"checking you know all of the images that","06:27":"you uploaded to see if any of them have","06:31":"projections in this space which similar","06:34":"to the ones I've selected and hopefully","06:36":"we'll find a few more of what I'm","06:39":"interested in","06:42":"okay so now if I want to try to find a","06:46":"projection that separates the sides from","06:49":"the front right I can click on each of","06:51":"those two and then over here this button","06:53":"is now called switch to the projection","06:55":"that maximizes the distance between the","06:57":"labels so now what this is going to do","06:59":"is try and find the best projection that","07:01":"separates out those classes and so the","07:04":"goal here is to you know help me","07:07":"visually inspect and quickly find a","07:09":"bunch of things that I can use to label","07:13":"so like they're the kind of the the key","07:15":"features and it's done a good job you","07:18":"can see down here we've now got a whole","07:20":"bunch of sides which I can now grab","07:22":"because I was having a lot of trouble","07:24":"finding them before and it's always","07:26":"worth double-checking it's kind of","07:32":"interesting to see how the neural Nets","07:34":"behave like there seems to be more","07:36":"sports cars in this group than average","07:38":"as well so it's kind of found side","07:39":"angles of sports cars so that's kind of","07:42":"interesting so then I can click all","07:43":"right so I've got those four an arrow","07:44":"clicks side and there we go","07:47":"so once you've done that a few times I","07:50":"find if you've got you know a hundred or","07:52":"so labels you can then click on the","07:56":"train model button and it'll take a","07:58":"couple of minutes and come back and show","08:00":"you your train model and after it's","08:02":"trained which I did it on a smaller","08:04":"number of labels earlier you can then","08:06":"switch this very opacity button and","08:09":"it'll actually kind of fade out the ones","08:12":"that are already predicted pretty well","08:13":"and it'll also give you a estimate as to","08:16":"how accurate it thinks the model is the","08:19":"main reason I mentioned this for you is","08:20":"that so that you can now click the","08:23":"download button and it'll download the","08:25":"predictions which is what we hope will","08:27":"be interesting to most people but what I","08:28":"think will be interesting to you as deep","08:30":"learning students is it'll download your","08:32":"labels so now you can use that labeled","08:36":"subset of data along with the unlabeled","08:39":"set that you haven't labeled yet to see","08:42":"if you can you know see if you can build","08:43":"a better model and platform a I stand","08:46":"for you see if you can use that initial","08:48":"set of data to kind of get going","08:49":"creating models and stuff which you","08:52":"weren't able to label before","08:54":"clearly there are some things that this","08:56":"systems better that than others","08:59":"for things that require you know really","09:02":"zooming in closely and taking a very","09:04":"very close inspection this isn't going","09:06":"to work very well but is really designed","09:08":"for things that the human eye can kind","09:10":"of pick up fairly readily but we'd love","09:13":"to get feedback as well and you can","09:15":"click on the Help button to get feedback","09:18":"give feedback and also there's a","09:20":"platform AI discussion topic in our","09:23":"forum where so are shocked if you can","09:25":"stand up our checks the CEO of the","09:27":"company he'll be there helping out","09:30":"answering questions and so forth so yeah","09:34":"I hope people find that useful it's been","09:37":"many years getting to this point and I'm","09:39":"glad we're we're finally there","09:46":"okay so one of the reasons I wanted to","09:50":"mention this today is that we're going","09:51":"to be doing a big dive into convolutions","09:54":"later in this lesson so I'm going to","09:56":"circle back to this to try and explain a","09:58":"little bit more about how that is","09:59":"working under the hood and give you a","10:01":"kind of a sense of what's what's going","10:03":"on but before we do we have to finish","10:06":"off last week's discussion of","10:08":"regularization and so we were talking","10:11":"about regularization specifically in the","10:13":"context of the tabular learner because","10:17":"this was the forward method sorry this","10:19":"is the init method in the tabular","10:22":"learner and our goal was to understand","10:24":"everything here and we're not quite","10:27":"there yet","10:28":"last week we were looking at the adult","10:32":"data set which is a really simple kind","10:35":"of over simple data set that's just a","10:37":"toy purposes so this lit week let's look","10:39":"at a data set that's much more","10:41":"interesting a kegel competition data set","10:43":"so we know kind of what the the best in","10:45":"the world","10:46":"and you know care girl competition was","10:47":"results tend to be much harder to beat","10:50":"than academic state-of-the-art results","10:52":"tend to be because a lot more people","10:54":"work on cowgirl competitions than most","10:56":"academic data sets so it's a really good","10:58":"challenge to try and do well on a","10:59":"caracal competition data set so this one","11:02":"the rossmann data set is if they've got","11:06":"three thousand drugs","11:08":"in Europe and you're trying to predict","11:10":"how many products they're going to sell","11:13":"in the next couple of weeks so one of","11:16":"the interesting things about this is","11:17":"that the test set for this is from a","11:21":"time period that is more recent than the","11:24":"training set and this is really common","11:26":"right if you want to predict things","11:27":"there's no point predicting things that","11:29":"are in the middle of your training set","11:30":"you want to predict things in the future","11:33":"another interesting thing about it is","11:35":"the evaluation metric they provided is","11:38":"the root mean squared percent error so","11:40":"this is just a normal root mean squared","11:42":"error except we go actual minus","11:44":"prediction divided by actual so in other","11:46":"words it's the percent error that we're","11:49":"taking the root mean squared of so","11:52":"there's a couple of interesting features","11:53":"always interesting to look at the","11:55":"so the leaderboard the winner was 0.1","11:59":"the paper that we've roughly replicated","12:02":"was point 105 106 and 10th place out of","12:09":"3,000 was 0.11 ish bit less all right so","12:20":"we're gonna skip over a little bit which","12:23":"is that the data that was provided here","12:25":"was they provided a small number of","12:29":"files but they also let competitors","12:33":"provide additional external data as long","12:36":"as they shared it with all the","12:37":"competitors and so in practice the data","12:39":"set we're going to use contains account","12:41":"remember six or seven tables the way","12:44":"that you join tables and stuff isn't","12:47":"really part of a deep learning course so","12:49":"I'm going to skip over it and instead","12:51":"I'm going to refer you to introduction","12:52":"to machine learning for coders which","12:54":"will take you step-by-step through the","12:56":"data preparation for this we've provided","12:59":"it for you","13:03":"we've provided it for you in Russman","13:07":"data clean so you'll see the whole","13:09":"process there and so you'll need to run","13:11":"through that notebook to create these","13:14":"pickle files that we read here can you","13:17":"see this in the back okay","13:20":"I just want to mention one particularly","13:24":"interesting part of the rossmann data","13:26":"clean","13:27":"notebook which is you'll see there's","13:30":"something that says add date part and I","13:32":"wanted to explain what's going on here","13:33":"I've been mentioning for a while that","13:35":"we're going to look at time series and","13:37":"pretty much everybody who I've spoken to","13:39":"about it has assumed that I'm going to","13:41":"do some kind of recurrent neural network","13:42":"but I'm not interestingly the kind of","13:47":"the main academic group that studies","13:49":"time series is econometrics and but they","13:51":"tend to study one very specific kind of","13:53":"time series which is where the only data","13:56":"you have is a sequence of time points of","13:59":"one thing like that's the only thing you","14:01":"have is one sequence in real life that's","14:04":"almost never the case normally you know","14:06":"if we would have some information about","14:07":"the store that that represents or the","14:09":"people that it represents we'd have","14:11":"metadata we'd have sequences of other","14:14":"things measured at similar time periods","14:15":"or different time periods and so most of","14:20":"the time I find in practice the the","14:24":"state-of-the-art results when it comes","14:26":"to competitions on kind of more","14:28":"real-world data sets","14:29":"don't gender you it's recurrent neural","14:30":"networks but instead they tend to take","14:32":"it's a time piece which in this case it","14:35":"was a date we were given in the data and","14:38":"they add a whole bunch of metadata so in","14:41":"our case for example we've added day of","14:43":"week so we were given a date right we've","14:46":"had a day of week year month week of","14:51":"year day of month day of week day of","14:54":"year and then a bunch of boolean ziz at","14:56":"the month start or end quarter year","14:58":"start or end elapsed time since 1970 so","15:02":"forth if you run this one function at","15:05":"date part and pass it a date it'll add","15:07":"all of these columns to your data set","15:08":"for you and so what that means is that","15:12":"let's take a very reasonable example","15:15":"purchasing behavior probably changes on","15:17":"payday payday might be the fifteenth of","15:20":"the month so if you have a thing here","15:22":"called this is day of month here right","15:24":"then it'll be able to recognize every","15:27":"time something is a fifteen there and","15:29":"associated it with a higher in this case","15:32":"embedding matrix value","15:34":"but so this way it basically the the you","15:39":"know we can't expect a neural net to do","15:41":"all of our feature engineering for us we","15:43":"can expect it to kind of find","15:44":"nonlinearities and interactions and","15:46":"stuff like that but for something like","15:47":"taking a date like this and figuring out","15:52":"that the fifteenth of the month is","15:54":"something when interesting things happen","15:56":"it's much better if we can provide that","15:58":"information for it so this is a really","16:00":"useful function to use and once you've","16:02":"done this you can treat many kinds of","16:05":"time-series problems as regular tabular","16:07":"problems I say many kinds not all you","16:11":"know if there's very complex kind of","16:12":"state involved in a time series such as","16:15":"you know equity trading or something","16:17":"like that this probably won't be the","16:19":"case or this won't be the only thing you","16:22":"need but in this case it'll get us a","16:26":"really good result and it's in practice","16:29":"most of the time I find this works well","16:31":"tabular data is normally in pandas so we","16:34":"just stored them as standard Python","16:36":"pickerel files we can read them in we","16:38":"can take a look at the first five","16:40":"records and so the key thing here is","16:42":"that we're trying to on a particular","16:44":"date for a particular store ID we want","16:48":"to predict the number of sales sales is","16:50":"the dependent variable so the first","16:55":"thing I'm going to show you is something","16:57":"called pre processes you've already","16:59":"learned about transforms transforms are","17:01":"bits of code that run every time","17:04":"something is grabbed from a data set and","17:06":"so it's really good for data","17:07":"augmentation that we'll learn about","17:08":"today which is that it's going to get a","17:11":"different random value every time it's","17:12":"sampled pre processes are like","17:15":"transforms but they're a little bit","17:18":"different which is that they run once","17:20":"before you do any training and really","17:24":"importantly they run once on the","17:27":"training set and then any kind of State","17:31":"or metadata that's created is then","17:33":"shared with the validation and test set","17:35":"let me give you an example when we've","17:37":"been doing image recognition and we've","17:40":"had a set of classes to like all the","17:42":"different pet breeds and they've been","17:44":"turned into numbers the thing that's","17:46":"actually doing that for us","17:47":"is a preprocessor that's being created","17:49":"in the background so that makes sure","17:51":"that the classes for the training set","17:53":"are the same as the classes for the","17:54":"validation and the classes of the test","17:56":"set so we're going to do something very","17:59":"similar here for example if we create a","18:02":"little small subset of a data for","18:04":"playing with this is a really good idea","18:06":"when you start with a new data set so","18:08":"I've just grabbed two thousand IDs at","18:10":"random okay and then I'm just going to","18:13":"grab a little training set in a little","18:15":"test set half and half of those 2,000","18:17":"IDs and it's going to grab five columns","18:20":"okay and then we can just play around","18:21":"with this nice and easy so here's the","18:24":"first few of those from the training set","18:26":"and you can see one of them is called","18:29":"promo interval and it has these strings","18:31":"and sometimes it's missing in pandas","18:34":"missing is na M so the first","18:40":"preprocessor I'll show you is category","18:42":"fee and category does basically the same","18:45":"thing that that classes thing for image","18:48":"recognition does for a dependent","18:49":"variable it's going to take these","18:51":"strings it's going to find all of the","18:53":"possible unique values of it and it's","18:55":"going to create a list of them and then","18:57":"it's going to turn the strings into","18:59":"numbers so if I call it on my training","19:01":"set that'll create categories there and","19:03":"then I call it on my test set passing in","19:06":"testicles true that makes sure it's","19:09":"going to use the same categories that I","19:10":"had before and now when I say dot head","19:13":"it looks exactly the same and that's","19:16":"because pandas has turned this into a","19:18":"categorical variable which internally is","19:21":"storing numbers but externally is","19:24":"showing me the strings but I can look","19:26":"inside promo interval to look at the cat","19:30":"categories this is all standard pandas","19:32":"here to show me a list of all of them","19:36":"what we would call classes in first day","19:38":"a or would be called just categories in","19:41":"pandas and so then if I look at the cat","19:43":"codes you can see here this list here is","19:48":"the numbers that are actually stored","19:49":"minus 1 minus 1 1 minus 1 1 right why am","19:53":"boy one of these minus ones the minus","19:56":"ones represent ni n they","19:59":"missing so pandas uses the special code","20:02":"- one to be mean missing now as you know","20:05":"these are going to end up in an","20:07":"embedding matrix and we can't look up","20:09":"item -1 and an embedding matrix so","20:13":"internally in first AI we add one to all","20:16":"of these another useful preprocessor is","20:20":"fixed missing and so again you can call","20:23":"it on the data frame you can call on the","20:25":"test passing in testicles true and this","20:27":"will create for everything that's","20:30":"missing anything that has a missing","20:32":"value it'll create an additional column","20:34":"with the column name underscore na so","20:36":"competition distance underscore na and","20:38":"it will set it for true for any time","20:42":"that was missing and then what we do is","20:45":"we replace competition distance with the","20:48":"median for those why do we do this well","20:51":"because very commonly the fact that","20:53":"something's missing is of itself","20:56":"interesting like you know it turns out","20:59":"the fact that this is missing helps you","21:00":"predict your outcome alright so we've","21:03":"certainly want to keep that information","21:04":"in a convenient boolean column so that","21:07":"our deep learning model can use it to","21:08":"predict things but then we need","21:10":"competition distance to be a continuous","21:13":"variable so we can use it in the","21:14":"continuous variable part of our model so","21:16":"we can replace it with almost any number","21:18":"right because if it turns out that the","21:21":"missingness is important it can use the","21:23":"interaction of competition distance na","21:25":"and competition distance to make","21:27":"predictions so that's what fixed missing","21:29":"does you don't have to manually call pre","21:33":"processes yourself when you call any","21:41":"kind of item list creating creator you","21:44":"can pass in a list of pre processes","21:46":"which you can create like this ok so if","21:50":"this is saying ok I want to feel missing","21:52":"I want to category Phi I want to","21:54":"normalize so for continuous variables","21:56":"it'll subtract the mean and divide by","21:58":"the standard deviation to help a train","21:59":"more easily and so you just say those","22:01":"are my procs and then you can just pass","22:03":"it in there and that's it and later on","22:05":"you can go data export and it'll save","22:08":"all the metadata for that data bunch so","22:11":"you can later on load it in","22:13":"knowing exactly what your category codes","22:15":"are exactly what median values used for","22:17":"replacing the missing values and exactly","22:19":"what means and standard deviations you","22:21":"normalize by okay so the main thing you","22:27":"have to do if you want to create a data","22:29":"bunch of tabular data is find out or","22:32":"tell it what are your categorical","22:33":"variables and what are your continuous","22:35":"variables and as we discussed last week","22:38":"briefly your categorical variables are","22:42":"not just strings and things but also I","22:45":"include things like day of week and","22:48":"month and day of month even though","22:51":"they're numbers and make them","22:52":"categorical variables because for","22:54":"example day of month I don't think it's","22:57":"going to have a nice smooth curve I","23:00":"think that the fifteenth of the month","23:01":"and the first of the month and the 30th","23:04":"of the month are probably going to have","23:05":"different purchasing behavior to other","23:08":"days of the month and so therefore if I","23:11":"make it a categorical variable it's","23:13":"going to end up creating an embedding","23:14":"matrix and those different days of the","23:16":"month can get different behaviors so","23:19":"you've actually got to think carefully","23:20":"about which things should be categorical","23:23":"variables and on the whole if in doubt","23:25":"and there are not too many levels in","23:28":"your category that's called the","23:29":"cardinality if your cardinality is not","23:31":"too high I would have put it as a","23:33":"categorical variable you can always try","23:35":"an H and see which works best so our","23:39":"final data frame that we're going to","23:40":"pass in is going to be a training set","23:43":"with the categorical variables and the","23:44":"continuous variables and the dependent","23:45":"variable and the date and the date we're","23:49":"just going to use to create a validation","23:51":"set where we go Stickley going to say","23:53":"the validation set is going to be the","23:55":"same number of Records at the end of the","23:58":"time period that the test set is for","24:00":"cattle and so that way we should be able","24:02":"to validate our model nicely ok so now","24:07":"we can create a tabular list so this is","24:10":"our standard data block API that you've","24:12":"seen a few times from a data frame","24:13":"passing all of that information split it","24:17":"into valid vs. train label it with a","24:19":"dependent variable and here's something","24:22":"I don't think you've seen before label","24:26":"this is our dependent variable and as","24:30":"you can see this is this is sales it's","24:32":"not a float","24:33":"it's an n64 if this was a float then","24:38":"first day I would automatically know or","24:40":"guess that you want to do a regression","24:41":"okay but this is not a float it's an int","24:45":"so first I was going to assume you want","24:46":"to do a classification so when we label","24:49":"it we have to tell it that the clasp of","24:51":"the labels we want is a list of floats","24:54":"okay not a list of categories which","24:57":"would otherwise be the default so this","24:59":"is the thing that's going to","25:00":"automatically turn this into a","25:01":"regression problem for us and then we","25:04":"create a data bunch so I wanted to","25:10":"remind you again about dock which is how","25:13":"we find out more information about this","25:15":"stuff in this case all of the labeling","25:17":"functions in the data blocks API will","25:20":"pass on any keywords they don't","25:21":"recognize to the label class so one of","25:24":"the things I've passed in here is log","25:26":"and so that's actually going to end up","25:28":"in float list and so if I go dock float","25:31":"list I can see a summary okay and I can","25:33":"even jump into the full documentation","25:35":"and it shows me here that log is","25:37":"something which if true it's going to","25:40":"take the logarithm of my dependent","25:43":"variable why am i doing that so this is","25:45":"the thing that's actually going to","25:47":"automatically take the log of my way the","25:50":"reason I'm doing that is because as I","25:53":"mentioned before the evaluation metric","25:56":"is root mean squared percentage error","25:59":"and first I'd either fastener iron or PI","26:05":"torch has a root mean squared percentage","26:07":"error loss function built in I don't","26:10":"even know if such a loss function would","26:12":"work super well but if you want to spend","26:15":"the time thinking about it you'll notice","26:16":"that this ratio if you first take the","26:20":"log of Y and Y hat then becomes a","26:22":"difference rather than the ratio so in","26:25":"other words if you take the log of Y","26:26":"then if this becomes root means great","26:30":"error so that's what we're going to do","26:32":"we're going to take the log of Y and","26:34":"then we're just going to use root mean","26:37":"square error which is the default for a","26:39":"problems we won't even have to mention","26:40":"it the reason that we have this year is","26:44":"because this is so common right","26:46":"basically anytime you're trying to","26:48":"predict something that's like a","26:50":"population or a dollar amount of sales","26:53":"these kind of things tend to have long","26:57":"tail distributions where you care more","26:59":"about percentage differences and exact","27:01":"differences you know absolute","27:02":"differences so you're very much very","27:05":"likely to want to do things with log","27:07":"equals true and to measure the root mean","27:09":"squared percent error we've learned","27:14":"about the Y range before which is going","27:17":"to use that sigmoid to help us get in","27:18":"the right range because this time the Y","27:22":"values are going to be taken the log of","27:24":"it first we need to make sure that the Y","27:26":"range we want is also the log so I'm","27:29":"going to take the maximum of the sales","27:31":"column I'm going to multiply it by a","27:34":"little bit so that cuz remember how we","27:35":"said it's nice if your range is a bit","27:37":"wider than the range of the data and","27:40":"then we're going to take the log and","27:42":"that's going to be our maximum so then","27:45":"our Y range will be from zero to a bit","27:49":"more than the maximum so now we've got","27:52":"our data bunch we can create a tabular","27:55":"from it and then we have to pass in our","27:57":"architecture and as we briefly discussed","28:00":"for a tabular model our architecture is","28:05":"literally the most basic fully connected","28:08":"network just like we showed in this","28:11":"picture it's an import matrix multiply","28:15":"non-linearity matrix multiply","28:17":"non-linearity matrix model play","28:19":"non-linearity done okay what are the","28:23":"interesting things about this is that","28:25":"this competition is three years old but","28:27":"I'm not aware of any significant","28:30":"advances at least in terms of","28:32":"architecture that would cause me to","28:34":"choose something different to what the","28:36":"third-placed folks did three years ago","28:39":"we're still basically using simple fully","28:43":"connected models for this problem now","28:48":"the intermediate wait may","28:52":"Trix is going to have to go from a 1000","28:54":"activation input to a 500 activation","28:58":"output which means it's going to have to","29:00":"be 500,000 elements in that weight","29:04":"matrix that's an awful lot for a data","29:07":"set with only a few hundred thousand","29:08":"rows so this is going to overfit and we","29:12":"need to make sure it doesn't so one way","29:14":"to make sure it does Bob","29:15":"the way to make sure it doesn't is to","29:17":"use regularization all right not to","29:20":"reduce the number of parameters to use","29:21":"regularization so one way to do that","29:24":"will be to use weight decay which first","29:27":"day I will use automatically and you can","29:29":"vary it to something other than the","29:31":"default if you wish it turns out in this","29:33":"case we're going to want more","29:35":"regularization and so we're going to","29:37":"pass in something called peas this is","29:40":"going to provide dropout and also this","29:43":"one here M prop this is going to provide","29:45":"embedding dropout so let's learn about","29:48":"what is dropout but the short version is","29:51":"dropout is a kind of regularization this","29:54":"is the dropout paper nitish how do you","30:01":"say this through vast Java","30:03":"it was surest Ava's master's thesis","30:06":"under Geoffrey Hinton and this picture","30:11":"from the original paper is a really good","30:13":"picture of what's going on this first","30:16":"picture is a picture of a standard fully","30:18":"connected Network it's a picture of this","30:21":"and what each line shows is a","30:24":"multiplication of an activation times a","30:27":"weight and then when you've got multiple","30:29":"arrows coming in that represents a sum","30:31":"so this activation here is the sum of","30:36":"all of these inputs times all of these","30:39":"activations so that's what a normal","30:41":"neural fully connected neural net looks","30:43":"like for dropout we throw that away","30:49":"we're at random we throw away some","30:53":"percentage of the activations not the","30:56":"weights right not the parameters","30:58":"remember there's only two types of","30:59":"number in a neural net parameters also","31:03":"called weights kind of and activations","31:06":"so we're going to throw away some","31:08":"activation so you can see that when we","31:10":"throw away this activation all of the","31:13":"things that were connected to it are","31:15":"gone too okay for each mini batch we","31:21":"throw away a different subset of","31:23":"activations how many do we throw away we","31:26":"throw them of each one away with a","31:28":"probability P a common value of P is 0.5","31:35":"so what does that mean and you'll see in","31:38":"this case not only have they deleted at","31:43":"random some of these in hidden layers","31:45":"but they've actually deleted some of the","31:47":"inputs as well deleting the inputs is","31:49":"pretty unusual normally we only delete","31:53":"activations in the hidden layers so what","31:58":"is this - well every time I have a mini","31:59":"batch going through I at random throw","32:03":"away some of the activations and then","32:04":"the next mini batch I put them back and","32:06":"I throw away some different ones okay so","32:09":"it means that it's no 1 activation can","32:14":"kind of memorize some part of the input","32:17":"because that's what happens if we over","32:19":"fit right if we over fit some some part","32:21":"of the model is basically learning to","32:24":"recognize a particular image rather than","32:27":"a feature in general or a particular","32:28":"item with dropout it's going to be very","32:34":"hard for it to do that in fact Geoffrey","32:39":"Hinton described one of the kind of part","32:44":"of the thinking behind this as follows","32:46":"he said he noticed every time he went to","32:47":"his bank that all the tellers and staff","32:50":"moved around and he realized the reason","32:53":"for this must be that they're trying to","32:54":"avoid fraud if they keep moving them","32:56":"around","32:57":"nobody can specialize so much in that","32:59":"one thing that they're doing that they","33:01":"can figure out kind of a conspiracy to","33:02":"defraud the bank now of course depends","33:06":"when you ask Hinton at other times he","33:08":"says that the reason for this was","33:10":"because he thought about how spiking","33:11":"neurons work and there's a view he's a","33:13":"neuroscientist by training there's a","33:16":"view that spiking neurons might help","33:17":"regularization and dropout is kind","33:20":"a way of matching this idea of biking","33:23":"I mean it's interesting when you","33:26":"actually ask people where did your idea","33:29":"for some some algorithm come from it","33:33":"basically never comes from math it","33:36":"always comes from intuition and kind of","33:39":"thinking about physical analogies and","33:40":"stuff like that so anyway the truth is a","33:43":"bunch of ideas I guess we're all flowing","33:45":"around and they came up with this idea","33:47":"of dropout but the important thing to","33:49":"know is it worked really really well","33:52":"right and so we can use it in our models","33:57":"to get generalization for free now too","34:01":"much dropout of course is reducing the","34:03":"capacity of your model so it's going to","34:05":"under fit and so you've got to play","34:06":"around with different dropout values for","34:08":"each of your layers to decide so in","34:11":"pretty much every fast AI learner","34:15":"there's a parameter called","34:16":"P's PS which will be the p-value for the","34:20":"dropout for each layer so you can just","34:22":"pass in a list or you can pass it an int","34:25":"and it'll create a list with that value","34:28":"everywhere sometimes it's a little","34:31":"different for CNN for example it","34:33":"actually if you pass in an int it will","34:35":"use that for the last layer and half","34:37":"that value for the earlier layers we","34:39":"basically try to do things or kind of","34:41":"represent best practice but you can","34:44":"always pass in your own list to get","34:45":"exactly the drop out that you want there","34:48":"is an interesting feature of drop out","34:50":"which is that we talk about training","34:54":"time and test time test time we also","34:56":"call inference time training time is","34:58":"when we're actually doing that those","35:00":"wait updates the backpropagation and the","35:02":"training time dropout works the way we","35:04":"just saw at test time we turn off","35:08":"dropout but we're not going to do","35:10":"dropout anymore because we wanted to be","35:12":"as accurate as possible we're not","35:13":"training so we can't cause it to overfit","35:15":"when we're doing inference so we remove","35:18":"dropout but what that means is if","35:20":"previously P was point OV was 0.5 then","35:24":"half the activations were being removed","35:26":"which means when they're all there now","35:28":"our overall activation level is twice","35:30":"what it used to be and so therefore in","35:33":"the paper they suggest","35:34":"multiplying all of your weights at test","35:36":"time by P interestingly you can dig into","35:42":"the PI torch source code and you can","35:44":"find the actual C code where dropout is","35:47":"implemented and here it is and you can","35:50":"see what they're doing is something","35:51":"quite interesting they first of all do a","35:54":"Bernoulli trial so a Bernoulli trial is","35:56":"with probability 1 minus P return the","36:00":"value 1 otherwise return the value 0","36:02":"that's all it means","36:03":"okay so in this case P is the","36:06":"probability of dropout so 1 minus P is a","36:09":"probability that we keep the activation","36:12":"so we end up here with either a 1 or a 0","36:15":"ok and then this is interesting we","36:19":"divide in place remember","36:21":"underscore means in place in play torch","36:23":"we divide in place that 1 or 0 by 1","36:26":"minus P if it's a 0 nothing happens it's","36:29":"still 0 if it's a 1 and P was 0.5 that","36:34":"one now becomes 2 and then finally we","36:37":"multiply in place our input by this","36:42":"noise this dropout mask so in other","36:44":"words we actually don't do in play torch","36:48":"we don't do the change at test time we","36:50":"actually do the change at training time","36:53":"which means that you don't have to do","36:54":"anything special at inference time with","36:56":"play torch it's not a spite watch it's","36:58":"quite a common pattern but it's kind of","37:01":"nice to look inside the pipe torch","37:02":"source code and see you know drop out","37:05":"this incredibly cool incredibly valuable","37:07":"thing is really just these three lines","37:09":"of code which they do in C because I","37:12":"guess it ends up a bit faster when it's","37:14":"all fused together but lots of libraries","37:16":"do it in Python and that works well as","37:18":"well you can even write your own drop","37:20":"out layer and it should give exactly the","37:23":"same results as this that'd be a good","37:26":"exercise to try see if you can create","37:28":"your own drop out layer in Python and","37:32":"see if you can replicate the results","37:33":"that we get with this drop out there","37:38":"so that's drop","37:41":"and so in this case we're going to use a","37:43":"tiny bit of drop out on the first layer","37:45":"and a little bit of drop out on the next","37:48":"layer and then we're going to use","37:50":"special drop out on the embedding layer","37:52":"now why do we do special drop out on the","37:55":"embedding layer so if you look inside","37:57":"the FASTA a source code is our tabular","38:05":"model you'll see that in the section","38:11":"that checks that there's some embeddings","38:12":"we call it embedding and then we","38:15":"concatenate the embeddings into a single","38:17":"matrix and then we call embedding","38:19":"dropout an embedding dropout is simply","38:21":"just a drop out right so it's just an","38:27":"instance of a drop out module this kind","38:31":"of makes sense right for continuous","38:33":"variables that continuous variable is","38:35":"just in one column you wouldn't want to","38:38":"do dropout on that because you're","38:39":"literally deleting the existence of that","38:41":"whole input which is almost certainly","38:42":"not what you want but for an embedding","38:45":"and embedding is just effectively a","38:49":"matrix multiplied by a one hot encoded","38:52":"matrix so it's just another layer so it","38:55":"makes perfect sense to have dropout on","38:57":"the output of the embedding because","38:59":"you're putting drop out on those","39:00":"activations of that layer and so you're","39:02":"basically saying let's delete that","39:05":"random some of the results of that","39:09":"embedding some of those activations so","39:12":"that makes sense the other reason we do","39:15":"it that way is because I did very","39:17":"extensive experiments about a year ago","39:19":"where on this data set I tried lots of","39:23":"different ways of doing clone of","39:25":"everything and you can actually see it","39:29":"here I put it all in a spreadsheet of","39:31":"course Microsoft Excel put them into a","39:33":"pivot table to summarize them all","39:34":"together to find out kind of which","39:37":"different choices and hyper parameters","39:39":"and architectures worked well and worked","39:40":"less well and then I created all these","39:43":"little graphs and these are like little","39:45":"summary training graphs for different","39:47":"combinations of high parameters and","39:48":"architectures and I found that there was","39:50":"one of them which ended up consistently","39:53":"getting a good","39:55":"predictive accuracy the kind of","39:57":"bumpiness of the training was pretty low","40:00":"and you can see on it was just a nice","40:03":"smooth curve and so like this is an","40:06":"example of the kind of experiments that","40:08":"I do that end up in the first day I","40:10":"library right so embedding embedding","40:13":"dropout was one of those things that I","40:14":"just found work really well and","40:16":"basically these the results of these","40:17":"experiments is why it looks like this","40:22":"rather than something else well it's a","40:25":"combination of these experiments but","40:26":"then why did I do these particular","40:28":"experiments well because it was very","40:30":"influenced by what worked well in the","40:33":"that cagoule Prize winners paper but","40:37":"there are quite a few parts of that","40:38":"paper I thought there were some other","40:40":"choices they could have made I wonder","40:42":"why they didn't and I tried them out and","40:44":"found out what actually works and what","40:46":"doesn't work as well and found a few","40:48":"little improvements so that's the kind","40:51":"of experiments that you can play around","40:53":"with as well when you try different","40:55":"models and architectures different","40:57":"dropouts layer numbers number of","41:00":"activations and so forth so I'm having","41:03":"created our learner we can type learned","41:05":"up model to take a look at it and as you","41:08":"would expect in that there is a whole","41:09":"bunch of embeddings each of those","41:12":"abetting matrices tells you well this is","41:15":"the number of levels of the input for","41:17":"each input right and you can match these","41:20":"with with your list cat bars","41:23":"okay so the first one will be store so","41:26":"that's not surprising there are a","41:27":"thousand 116 stores and then the second","41:30":"number of course is the size of the","41:33":"embedding and that's a number that you","41:34":"get to choose and so fast AI has some","41:38":"defaults which actually work really","41:42":"really well nearly all the time so I","41:44":"almost never changed them but when you","41:46":"create your tabular Lerner","41:48":"you can absolutely pass in an embedding","41:51":"size dictionary which Maps variable","41:54":"names to embedding sizes for anything","41:57":"where you want to override the defaults","41:59":"and then we've got our embedding dropout","42:04":"layer and then we've got a batch norm","42:07":"layer with six","42:08":"inputs okay the 16 inputs make sense","42:12":"because we have 16 continuous variables","42:17":"the length of countenance is 16 so this","42:21":"is something for our continuous","42:23":"variables and specifically it's over","42:27":"here the N conte on our continuous","42:30":"variables and BN conte is a batch norm","42:34":"one d what's that","42:35":"well the first short answer is it's one","42:39":"of the things that I experimented with","42:41":"as to having batch normal not in this","42:44":"and I found that it worked really well","42:46":"and then specifically what it is is","42:50":"extremely unclear let me describe it to","42:54":"you it's kind of a bit of regularization","42:56":"it's kind of a bit of training helper","43:00":"it's called batch normalization and it","43:04":"comes from this paper actually before I","43:08":"do this I was want to mention one other","43:09":"really funny thing dropout I mentioned","43:14":"it was a master's thesis not only was it","43:16":"a master's thesis one of the most","43:18":"influential papers of the last ten years","43:20":"it was rejected from the main neural","43:24":"Nets conference what was then called","43:26":"now Courtney rips I think this is just","43:30":"it's very interesting because it's just","43:32":"a reminder that you know a our academic","43:37":"community is generally extremely poor at","43:40":"recognizing which things are going to","43:42":"turn out to be important generally","43:46":"people are looking for stuff that are in","43:48":"the field that they're working on and","43:50":"understand so drop out kind of came out","43:52":"of left field it's kind of hard to","43:54":"understand what's going on and so that's","43:56":"kind of interesting and so you know it's","43:59":"a reminder that if you just follow you","44:03":"know as you kind of develop it beyond","44:05":"being just a practitioner into actually","44:07":"doing your own research don't just focus","44:10":"on the stuff everybody's talking about","44:12":"focus on the stuff you think might be","44:14":"interesting because the stuff","44:15":"everybody's talking about generally","44:17":"turns out not to be very interesting the","44:19":"community is very poor at","44:21":"amazing high-impact papers when they","44:26":"come out match normalization on the","44:31":"other hand was immediately recognized as","44:32":"high-impact I definitely remember","44:34":"everybody talking about it in 2015 when","44:36":"it came out and that was because it's so","44:38":"obvious they showed this picture showing","44:40":"the current then state of the art image","44:43":"net model inception this is how long it","44:46":"took them to get you know a pretty good","44:49":"result and then they tried the same","44:52":"thing with this new thing core batch","44:53":"norm and they just did it way way way","44:56":"quickly and so that was enough for","44:58":"pretty much everybody to go wow this is","45:00":"interesting and specifically they said","45:02":"this thing's called batch normalization","45:04":"and it's accelerating training by","45:06":"reducing internal covariant shift so","45:09":"what is internal covariant shift well it","45:13":"doesn't matter because this is one of","45:14":"those things where researchers came up","45:18":"with some intuition and some idea about","45:19":"the scene they wanted to try they did it","45:21":"it worked well they then post hoc added","45:24":"on some mathematical analysis to try and","45:26":"claim where it worked and it turned out","45:28":"they were totally wrong in the last two","45:30":"months there's been two papers so it","45:33":"took three years for people to really","45:34":"figure this out in the last two months","45:35":"there's been two papers that have shown","45:37":"batch normalization doesn't reduce","45:39":"covariate shift at all and even if it","45:42":"did that has nothing to do with why it","45:43":"works so so I think that's a kind of an","45:48":"interesting insight again you know which","45:50":"is like why we should be focusing on","45:52":"being practitioners and experimentalists","45:54":"and developing an intuition right what","45:58":"batch norm does is what you see in this","46:00":"picture here in this paper here are","46:03":"steps or batches right and here is loss","46:06":"and here the red line is what happens","46:10":"when you train without batch norm very","46:12":"very bumpy and here the blue line is","46:14":"what happens when you train with batch","46:16":"norm not very bumpy at all what that","46:19":"means is you can increase your learning","46:22":"rate with batch norm because these big","46:25":"bumps represent times that you're really","46:28":"at risk of your set of weights jumping","46:30":"off into some awful part of the weight","46:32":"space that it can never get out of again","46:34":"so if it's","46:35":"bumpy then you can train at a higher","46:37":"learning rate so that's actually what's","46:39":"going on and here's what it is this is","46:43":"the algorithm and it's really simple","46:45":"the algorithm is going to take a mini","46:48":"batch all right so we have a mini batch","46:51":"and remember this is a layer so the","46:54":"thing coming into it is activations okay","46:57":"so it's a layer and it's going to take","46:59":"in some activations and so that's","47:02":"evasions it's calling X 1 X 2 X 3 and so","47:06":"forth the first thing we do is we find","47:07":"the mean with those activations sum","47:10":"divided by the count let's just the mean","47:11":"and the second thing we do is we find","47:13":"the variance of those activations a","47:16":"difference squared divided by the mean","47:17":"is the variance and then we normalize so","47:19":"then the values minus the mean divided","47:22":"by the standard deviation is the","47:25":"normalized version ok it turns out that","47:28":"B it's actually not that important we","47:30":"used to think it was ok it turns out it","47:31":"not the really important bit is the next","47:33":"bit we take those values and we add a","47:39":"vector of biases they call it beta here","47:42":"and we've seen that before we've used a","47:44":"bias term before okay so we're just","47:46":"going to add a bias term as per usual","47:48":"and then we're going to use another","47:50":"thing that's a lot like a bias term but","47:53":"rather than adding it we're going to","47:54":"multiply by it so there's these","47:56":"parameters gamma and beta which are","48:00":"learnable parameters remember at a","48:02":"neural net there's only two kinds of","48:03":"number activations and parameters these","48:06":"are parameters okay they're things that","48:09":"are learnt with gradient descent this is","48:11":"just a normal bias layer data and this","48:15":"is a model Piketty of bias layer nobody","48:17":"calls it that but that's all it is right","48:18":"it's just like bias but we multiply","48:20":"rather than add that's what batch norm","48:23":"is that's what the layer does so why is","48:27":"that able to achieve this fantastic","48:30":"result I'm not sure anybody has exactly","48:35":"written this down before if they have I","48:41":"apologize for failing to cite Ray","48:43":"because I haven't seen it but let me","48:44":"explain what's actually going on here","48:47":"the value","48:49":"of our predictions y-hat is some","48:58":"function of our various weights there","49:04":"could be millions of them wait 1 million","49:07":"and it's also a function of course of","49:09":"the inputs to our layer this function","49:13":"here is our neuron that function","49:15":"whatever is going on and our neuron","49:17":"there and then our loss let's say it's","49:20":"mean squared error is just our actuals","49:22":"minus our predicted squared okay so","49:30":"let's say we're trying to predict movie","49:32":"review outcomes and they're between 1","49:35":"and 5 okay and we've been trying to","49:40":"train our model and the activations at","49:43":"the very end currently between minus 1","49:47":"and 1 so they're way off where they need","49:51":"to be the scale is off the mean is off","49:53":"so what can we do one thing we could do","49:57":"would be to try and come up with a new","50:00":"set of weights that cause the spread to","50:03":"increase and cause the mean to increase","50:05":"as well but that's going to be really","50:07":"hard to do because remember all these","50:09":"weights interact in very intricate ways","50:11":"right we've got all those nonlinearities","50:13":"and they all combine together so to kind","50:16":"of just move up it's going to require","50:18":"navigating through this complex","50:20":"landscape and we you know we use all","50:22":"these tricks like momentum and atom and","50:24":"stuff like that to help us but it still","50:26":"requires a lot of twiddling around to","50:28":"get there so that's going to take a long","50:31":"time and it's going to be bumpy but what","50:34":"if we did this what if we went times G","50:40":"Plus B we added 2 more parameter vectors","50:46":"or now it's really easy right in order","50:50":"to increase the scale that number has a","50:53":"direct gradient to increase the scale to","50:58":"change the me","50:59":"that number has a direct gradient to","51:01":"change the mean there's no interactions","51:03":"or complexities it's just straight up","51:04":"and down straight in and out and that's","51:07":"what batch Nam does right so batch norm","51:10":"is basically making it easier for it to","51:13":"do this really important thing which is","51:15":"to shift the app puts up and down and in","51:17":"and out and that's why we end up with","51:20":"these results so those details in some","51:23":"ways don't matter terribly the really","51:25":"important thing to know is you","51:27":"definitely want to use it right or if","51:30":"not it's something like it there's","51:32":"various other types of normalization","51:33":"around nowadays but batch norm works","51:37":"great","51:38":"the other main normalization type we use","51:41":"in first AI is something called weight","51:43":"norm which is a much more just in the","51:45":"last few months","51:46":"development okay so that's batch norm","51:51":"and so what we do is we create a batch","51:56":"norm layer for every continuous variable","51:59":"and conte is a number of continuous","52:00":"variables in fast AI n underscore","52:03":"something always means the count of that","52:05":"thing can't always means continuous so","52:08":"then here is where we use it we grab our","52:10":"continuous variables and we throw them","52:12":"through a batch norm layer and so then","52:14":"over here you can see it in a model one","52:19":"interesting thing is this momentum here","52:20":"this is not momentum like in","52:23":"optimization but this is momentum as in","52:25":"exponentially weighted moving average","52:28":"specifically this mean and standard","52:32":"deviation we don't actually use a","52:34":"different mean and standard deviation","52:35":"for every mini batch if we did it would","52:39":"vary so much did it be very hard to","52:41":"train so instead we take an","52:44":"exponentially weighted moving average of","52:46":"the mean and standard deviation okay and","52:49":"if you don't remember what I mean by","52:50":"that look back at last week's lesson to","52:52":"remind yourself about exponentially","52:54":"weighted moving averages which we","52:56":"implemented in excel for the momentum","53:00":"and atom gradient squared terms","53:09":"you can vary the amount of momentum in a","53:11":"batch norm layer by passing a different","53:14":"value to the constructor in plate watch","53:16":"if you use a smaller number it means","53:19":"that the mean and standard deviation","53:20":"will vary less from mini batch to mini","53:23":"batch and that will have less of a","53:25":"regularization effect a larger number","53:27":"will mean the variation will be greater","53:29":"for a mini batch to mini batch that will","53:31":"have more of a regularization effect so","53:33":"as well as this thing of training more","53:35":"nicely because it's parameterised better","53:37":"this momentum term in the mean and","53:40":"standard deviation is the thing that","53:42":"adds is nice regularization piece when","53:47":"you add batch norm you should also be","53:49":"able to use a higher learning rate so","53:52":"that's our model so then you can go ll","53:54":"find you can have a look and then you","53:57":"can go fit you can save it you can plot","54:00":"the losses you can fit a bit more and we","54:03":"end up 0.1 oh three tenths place in the","54:07":"competition was 0.108 so it's looking","54:11":"good all right again take it with a","54:17":"slight grain of salt because what you","54:20":"actually need to do is use the real","54:21":"training set and submit it to cow go but","54:24":"you can see we're very much you know","54:26":"amongst the kind of cutting-edge of","54:28":"models at least as of 2015 and as I say","54:32":"they haven't really been any","54:33":"architectural improvements since then","54:35":"there wasn't batch norm when this was","54:37":"around so the fact we added batch norm","54:38":"means that we should get better results","54:40":"and certainly more quickly and if I","54:42":"remember correctly in their model they","54:44":"had to train at a slow lower learning","54:45":"rate for quite a lot longer as you can","54:48":"see this is about less than 45 minutes","54:50":"of training so that's nice and fast","54:55":"any questions in what proportion would","55:01":"you use dropout versus other","55:03":"regularization errors like weight decay","55:05":"L two norms etc so remember that l2","55:12":"regularization and weight decay a kind","55:14":"of two ways of doing the same thing and","55:16":"we should always use the weight decay","55:17":"version not the l2 regularization","55:19":"version so there's","55:21":"when Takei there's batch norm which kind","55:24":"of has a regularizing effect there's","55:27":"data augmentation which we'll see soon","55:29":"and this drop out so that's normally","55:35":"pretty much always want so that's easy","55:39":"data augmentation we'll see in a moment","55:41":"so then it's really between dropout","55:43":"versus weight okay","55:45":"I have no idea I don't I don't think","55:48":"I've seen anybody to fight a compelling","55:50":"study of how to combine those two things","55:55":"can you always use one instead of the","55:57":"other why why not I don't think anybody","56:01":"has figured that out I think in practice","56:06":"it seems that you generally want a bit","56:10":"of both you pretty much always want some","56:14":"weight decay but you often also want a","56:17":"bit of dropout but honestly I don't know","56:20":"why I've not seen anybody really explain","56:22":"why or how to decide so this is one of","56:25":"these things you have to try out and","56:27":"kind of get a feel for what tends to","56:31":"work for your kinds of problems I think","56:34":"the defaults that we provide in most of","56:37":"our learners should work pretty well in","56:39":"most situations but yeah definitely play","56:42":"around with it okay the next kind of","56:48":"regularization we're going to look at is","56:50":"data augmentation and data augmentation","56:55":"is one of the least well studied types","56:58":"of regularization but it's the kind that","57:00":"I think I'm kind of the most excited","57:02":"about the reason I'm kind of the most","57:08":"about it is that you basically there's","57:12":"basically almost no cost to it you can","57:15":"do data augmentation and get better","57:17":"generalization without it taking longer","57:19":"to train without underfitting","57:22":"to an extent at least so let me explain","57:26":"so what we're going to do now is we're","57:29":"going to come back to a computer vision","57:30":"and we're going to come back to our pets","57:32":"data set again so let's let's load it in","57:35":"all right our pets data set the images","57:37":"were inside the images subfolder I'm","57:39":"going to call get transforms as per","57:42":"usual but when we call get transforms","57:46":"there's a whole long list of things that","57:49":"we can provide and so far we haven't","57:52":"been varying that much at all but in","57:54":"order to really understand data","57:57":"augmentation I'm going to kind of","57:58":"ratchet up all of the defaults so","58:03":"there's a parameter here for what's the","58:05":"probability of an affine transform","58:08":"happening what's the probability of a","58:10":"light lighting transfer happening so I","58:12":"set them both to one so they're all","58:13":"gonna get transformed I'm going to do","58:14":"more rotation more zoom more lighting","58:16":"transforms and more warping what are all","58:20":"those mean well you should check the","58:23":"documentation and to do that by typing","58:25":"doc and there's a doc the brief","58:27":"documentation but the real documentation","58:29":"is in dogs so I'll click on show in","58:32":"Doc's and here it is okay and so this","58:36":"tells you what all those do but","58:40":"generally the most interesting parts of","58:41":"the Doc's tend to be at the top where","58:44":"you kind of get the summaries of what's","58:46":"going on and so here there's something","58:48":"called list of transforms and here you","58:52":"can see every transform has a something","58:55":"showing you lots of different values of","58:57":"it right so here's brightness so make","59:01":"sure you read these and remember these","59:04":"notebooks you can open up and run this","59:06":"code yourself and get this output all of","59:09":"these know all of these HTML","59:11":"documentation documents are","59:13":"auto-generated from the notebooks in the","59:15":"docs underscore source directory in the","59:17":"FASTA a repo okay so you will see the","59:20":"exact same cats","59:22":"if you try this so if I really likes","59:26":"cats so there's a lot of cats in the","59:27":"documentation","59:29":"and I think you know because he's been","59:31":"so awesome at creating great","59:32":"documentation he gets to pick the cats","59:34":"so so for example looking at different","59:40":"values of brightness what I do here is I","59:44":"look to see two things the first is for","59:47":"which of these levels of transformation","59:50":"is it still clear what the picture is a","59:53":"picture of so this is kind of getting to","59:55":"a point where it's pretty unclear this","59:57":"is possibly getting a little unclear the","60:00":"second thing I do is I look at the","60:02":"actual data set that I'm modeling or","60:04":"particularly the data set that I'll be","60:06":"using as validation set and I try to get","60:08":"a sense of what the variation in this","60:10":"case in lighting is so referred like","60:13":"nearly all professionally taking photos","60:15":"I would probably want them all to be","60:17":"about in the middle but if the if the","60:20":"kind of their photos that are taken","60:23":"inside some pretty amateur photographers","60:24":"they are likely to be something they're","60:26":"very overexposed some very underexposed","60:28":"right so you should pick a value of the","60:30":"estate or augmentation for brightness","60:32":"that both allows the image to still be","60:35":"seen clearly and also represents the","60:38":"kind of data that you're going to be","60:39":"using this to model on in practice so","60:43":"you kind of see the same thing for","60:44":"contrast right it'd be unusual to have a","60:46":"data set with such ridiculous contrast","60:49":"where perhaps you do in which case you","60:51":"should use data augmentation up to that","60:52":"level but if you don't then you","60:55":"shouldn't this one called dihedral is","61:02":"just one that does every possible","61:05":"rotation and flip and so obviously most","61:07":"of your pictures are not going to be","61:09":"upside down cats","61:10":"that's so you probably would say hey","61:12":"this doesn't make sense I won't use this","61:14":"for this data set that if you're looking","61:16":"at satellite images of course you would","61:19":"on the other hand flip makes perfect","61:22":"sense so you would include that a lot","61:28":"of things that you can do with fast AI","61:30":"lets you pick a padding mode and this is","61:33":"what padding mode looks like you can","61:34":"pick zeros","61:36":"you can pick border which just","61:38":"replicates or you can pick reflection","61:41":"which as you can see is it's as if the","61:43":"last little few pixels are in a mirror","61:46":"reflections nearly always better by the","61:48":"way I don't know that anybody else has","61:51":"really studied this but we've we we have","61:53":"studied it in some depth haven't","61:55":"actually written a paper about it but","61:56":"just enough for our own purposes to say","61:58":"reflection works best most of the time","62:01":"so that's the default then there's a","62:04":"really cool bunch of perspective warping","62:06":"ones which I'll probably show you by","62:12":"using symmetric warp if you look at the","62:15":"kind of the we've added black borders to","62:17":"this so it's more obvious for what's","62:18":"going on and as you can see what","62:20":"symmetric warp is doing it's as if the","62:23":"camera is being moved above or to the","62:25":"side of the object and literally warping","62:28":"the whole thing like that right and so","62:33":"the cool thing is that as you can see","62:34":"each of these pictures it's as if this","62:37":"cat was being taken kind of from","62:39":"different angles right so they're all","62:41":"kind of optically sensible right and so","62:45":"this is a really great type of data","62:47":"augmentation it's also one which I don't","62:50":"know of any other library that does it","62:52":"or at least certainly one that does it","62:53":"in a way that's both fast and keeps the","62:56":"image crisp as it is in first AI so this","62:58":"is like if you're looking to whit win a","63:00":"cattle competition this is the kind of","63:02":"thing that's going to like get you above","63:04":"the people that aren't using the first","63:05":"area library so having looked at all","63:09":"that we are going to add this have a","63:15":"little get data function that just does","63:17":"the usual game data block stuff but","63:19":"we're going to add padding mode","63:21":"explicitly so that we can turn on","63:23":"padding mode of zeros just so we can see","63:25":"what's going on better fast AI has this","63:29":"handy little function called plot multi","63:31":"which is going to create a three by","63:33":"three grid of plots and each one will","63:35":"contain the result of calling this","63:37":"function which will receive the","63:40":"what coordinates and the axis and so I'm","63:43":"actually going to plot the exact same","63:44":"thing in every box but because this is a","63:47":"training data set it's going to use data","63:49":"augmentation and so you can see the same","63:53":"Dougy using lots of different kinds of","63:57":"data augmentation and so you can see why","63:59":"this is going to work really well","64:00":"because these pictures all look pretty","64:02":"different right but we didn't have to do","64:06":"any extra hand labeling or anything","64:08":"they're like it's like free extra data","64:11":"okay","64:12":"so data augmentation is really really","64:14":"great and one of the big opportunities","64:17":"for research is to figure out ways to do","64:20":"data augmentation in other domains so","64:23":"how can you do data augmentation with","64:26":"text data or genomic data or","64:30":"histopathology data or whatever right","64:35":"almost nobody's looking at that and to","64:37":"me it's one of the biggest opportunities","64:38":"that could let you decrease data","64:40":"requirements by like five to ten x so","64:47":"here's the same thing again but with","64:49":"reflection padding instead of zero","64:51":"padding and you can kind of see like see","64:55":"this doggies legs are actually being","64:57":"reflected at the bottom here so","65:01":"reflection padding tends to create","65:03":"images that are kind of much more","65:06":"naturally reasonable like in the real","65:08":"world you don't get black borders like","65:10":"this so they do seem to work better okay","65:14":"so because we're going to study","65:16":"convolutional neural networks we are","65:19":"going to create a convolutional neural","65:20":"network you know how to create them so","65:23":"I'll go ahead and create one","65:24":"I will fit it for a little bit they will","65:26":"unfreeze it","65:27":"I will then create a larger version of","65:30":"the data set 352 by 352 and fit for a","65:34":"little bit more and I will save it","65:38":"okay so we have a CNN and we're going to","65:42":"try and figure out what's going on","65:44":"and our CNN and the way we're going to","65:47":"try and figure it out is explicitly","65:49":"specifically that we're going to try to","65:50":"learn how to create this picture this is","65:58":"a heat map right this is a picture which","66:00":"shows me what part of the image did the","66:04":"CNN focus on when it was trying to","66:07":"decide what this picture is so we're","66:11":"going to make this heat map from scratch","66:17":"when we so we're kind of at a point now","66:21":"in the course where I'm assuming that if","66:25":"you've got to this point you know when","66:27":"you're still here thank you","66:29":"then you're interested enough that","66:31":"you're prepared to kind of dig into some","66:32":"of these details so we're actually going","66:34":"to learn how to create this heat map","66:37":"without almost any fast AI stuff we're","66:39":"going to use pure kind of tensor","66:41":"arithmetic in PI torch and we're going","66:44":"to try and use that to really understand","66:46":"what's going on so to warn you none of","66:49":"it's rocket science but a lot of its","66:51":"going to look really new so don't expect","66:53":"to get it the first time but expect to","66:56":"like listen jump into the notebook try a","67:00":"few things test things out look","67:02":"particularly at like tensor shapes and","67:04":"inputs and outputs to check your","67:05":"understanding then go back and listen","67:07":"again but and kind of try it a few times","67:09":"because you will get there right it's","67:13":"just that there's going to be a lot of","67:15":"new concepts because we haven't done","67:17":"that much stuff in pure by touch okay so","67:20":"what we're going to do is going to have","67:22":"a seven minute break and then we're","67:24":"going to come back and we're going to","67:25":"learn all about the innards of a CNN so","67:27":"I'll see you at 7:50 so let's learn: 67:33: about convolutional neural networks you","67:39":"know the funny thing is it's pretty","67:44":"unusual to get","67:45":"close to the end of a course and only","67:48":"then look at convolutions but like when","67:51":"you think about it knowing actually how","67:54":"batch norm works or how dropout works or","67:56":"how convolutions work isn't nearly as","68:00":"important as knowing how it all goes","68:03":"together and what to do with them and","68:05":"how to figure out how to do those things","68:07":"better but it's you know we're kind of","68:11":"at a point now where we want to be able","68:15":"to do things like that and although you","68:22":"know where we're adding this","68:23":"functionality directly into the library","68:25":"so you can kind of run a function to do","68:27":"that you know the more you do the more","68:29":"you'll find things that you want to do a","68:30":"little bit differently to how we do them","68:32":"or there'll be something in your domain","68:34":"where you think like oh I could do a","68:36":"slight variation of that so you're kind","68:38":"of getting to a point in your experience","68:40":"now where it helps to know how to do","68:43":"more stuff yourself and that means you","68:45":"need to understand what's really going","68:47":"on behind the scenes so what's really","68:52":"going on behind the scenes is that we","68:57":"are creating a neural network that looks","69:02":"a lot like this right but rather than","69:05":"doing a matrix multiply here and here","69:09":"and here we're actually going to do","69:12":"instead a convolution and a convolution","69:16":"is just a kind of matrix multiply which","69:20":"has some interesting properties you","69:24":"should definitely check out this website","69:26":"certo certo slash Eevee explain visually","69:29":"where we have stolen this beautiful","69:32":"animation it's actually a JavaScript","69:34":"thing that you can actually play around","69:35":"with yourself in order to show you how","69:39":"convolutions work and it's actually","69:41":"showing you a convolution as we move","69:44":"around these little red squares so","69:46":"here's here's a picture a black and","69:49":"white or grayscale picture right and so","69:51":"each 3x3 bit of this picture is this red","69:54":"thing moves around it shows you a","69:55":"different 3x3 part right it shows you","69:58":"over here the","69:59":"of the pixels right so in first ice case","70:04":"our pixel values are between Norton one","70:06":"in this case there between Norton 255","70:08":"right so here are nine pixel values this","70:12":"area is pretty white so they're pretty","70:14":"high numbers okay and so as we move","70:17":"around you can see the nine big numbers","70:20":"change and you can also see their colors","70:23":"change up here is another nine numbers","70:28":"and you can see those in the little X 1","70:32":"X 2 X 1 here 1 2 1 now what you might","70:36":"see going on is as we move this little","70:39":"red block as these numbers change we","70:41":"then multiply them by the corresponding","70:44":"numbers up here and so let's start using","70:48":"some nomenclature the thing up here we","70:51":"are going to call the kernel the","70:55":"convolutional kernel so we're going to","70:57":"take each little 3x3 part of this image","71:00":"and we're going to do an element-wise","71:02":"multiplication of each of the 9 pixels","71:05":"that we are mousing over with each of","71:09":"the 9 items in our kernel and so once we","71:13":"multiply each set together we can then","71:15":"add them all up and that is what's shown","71:18":"on the right as the little bunch of red","71:21":"things move over there you can see","71:23":"there's one red thing that appears over","71:24":"here the reason there's one red thing","71:27":"over here is because each set of 9 after","71:30":"getting through the element-wise","71:31":"multiplication with the kernel get added","71:34":"together to create one output so","71:38":"therefore the size of this image has one","71:42":"pixel less on each edge than the","71:45":"original as you can see see how there's","71:48":"black borders on it that's because at","71:50":"the edge the 3x3 kernel can't quite go","71:54":"any further","71:55":"right so the furthest you can go is to","71:57":"end up with a dot in the middle just off","72:00":"the corner ok so why are we doing this","72:05":"well perhaps you can see what's happened","72:07":"this face has turned into some white","72:11":"parts outlining the horizontal edges how","72:17":"well the how is just by doing this","72:20":"element wise multiplication of each set","72:22":"of 9 pixels with this kernel adding them","72:25":"together and sticking the result in the","72:26":"corresponding but over here why is that","72:31":"creating white spots with the horizontal","72:34":"edges are well let's think about it","72:37":"let's look up here so if we're just in","72:42":"this little bit here right then the","72:45":"spots above it all pretty white so they","72:49":"have high numbers so the bits above it","72:52":"big numbers who are getting multiplied","72:54":"by 1 to 1 so that's going to create a","72:56":"big number and the ones in the middle","72:59":"are all zeros so don't care about that","73:00":"and then the ones underneath are all","73:03":"small numbers because they're all close","73:04":"to 0 so that really doesn't do much at","73:07":"all so therefore that little set there","73:10":"is going to end up with right white okay","73:15":"whereas on the other side right down","73:18":"here you've got light pixels underneath","73:22":"so they're going to get a lot of","73:24":"negative dark pixels on top which are","73:29":"very small so not much happens","73:31":"so therefore over here we're going to","73:33":"end up with very negative so this thing","73:39":"where we take H 3x3 area and element","73:45":"wise multiply them with a kernel and add","73:52":"each of those up together to create one","73:55":"output is called a convolution that's it","74:00":"that's a completion so that might look","74:04":"familiar to you","74:05":"right because what we did back a while","74:09":"ago is we looked at that Zeiler and","74:11":"furgus paper where we saw like each","74:12":"different layer and we visualized what","74:16":"the weights were doing and remember how","74:18":"the first layer was basically like","74:19":"finding diagonal edges and gradient","74:22":"that's because that's what a convolution","74:24":"can do right H of our layers is just a","74:27":"convolution so the first layer can do","74:29":"nothing more than this kind of thing but","74:33":"the nice thing is the next layer could","74:35":"then take the results of this right and","74:37":"it could kind of combine one channel but","74:41":"so one or the output of one","74:42":"convolutional field is called a channel","74:43":"right so it could take one channel that","74:45":"found top edges and another channel that","74:48":"finds left edges and then the layer","74:51":"above that could take those two as input","74:53":"and create something that finds top left","74:56":"corners as we saw when we looked at","74:58":"those earlier and focused visualizations","75:01":"so let's take a look at this from","75:03":"another angle or quite a few other","75:05":"angles and we're going to look at a","75:07":"fantastic post tramatic or Matt Klein","75:10":"Smith who was actually a student in the","75:13":"first year that we did this course and","75:15":"he wrote this as part of his project","75:18":"work back then and what he's going to","75:22":"show here is here is our image it's a","75:25":"three by three image and our kernel is a","75:28":"two by two kernel and what we're going","75:31":"to do is we're going to apply this","75:32":"kernel to the top left 2x2 part of this","75:35":"image and so the pink bit will be","75:39":"correspondingly multiplied by the pink","75:41":"bit the green by the green and so forth","75:44":"and they all get added up together to","75:46":"create this top left in the output so in","75:51":"other words P equals alpha times a beta","75:57":"times be gamma times D Delta times e","76:02":"there it is plus B which is a bias okay","76:06":"so that's fine that's just a normal bias","76:09":"so you can see how basically each of","76:12":"these output pixels is the result of","76:15":"some different linear equation that","76:18":"makes sense and you can see these same","76:20":"four weights are being moved around","76:23":"because this is our convolutional kernel","76:26":"here","76:27":"the way of looking at it from that which","76:30":"is here is a classic neural network view","76:33":"and so P now is result of multiplying","76:38":"every one of these inputs by a weight","76:42":"and then adding them all together except","76:45":"the gray ones I've got to have a value","76:48":"of zero right because remember P was","76:52":"only connected to a B D and E a B D P so","77:01":"in other words remembering that this","77:04":"represents a matrix multiplication","77:08":"therefore we can represent this as a","77:12":"matrix multiplication so here is our","77:15":"list of pixels in our 3x3 image","77:18":"flattened out into a vector and here is","77:23":"a matrix vector multiplication plus bias","77:26":"and then a whole bunch of them we're","77:29":"just going to set to zero all right so","77:32":"you can see here we've got a zero zero","77:34":"zero zero zero which corresponds to zero","77:38":"zero zero zero zero so in other words a","77:43":"convolution is just a matrix","77:46":"multiplication where two things happen","77:48":"some of the entries are set to zero all","77:51":"the time and all of the ones are the","77:53":"same color always have the same weight","77:56":"so when you've got multiple things with","77:58":"the same weight","77:59":"that's called weight time okay so","78:04":"clearly we could implement a convolution","78:07":"using matrix multiplication but we don't","78:10":"because it's slow at swim practice our","78:13":"libraries have specific convolution","78:17":"functions that we use and they're","78:19":"basically doing this which is this which","78:24":"is this equation which is says the same","78:26":"as this matrix multiplication and as we","78:31":"discussed we have to think about padding","78:33":"because if you have a 3 by 3 kernel and","78:35":"a 3 by 3 image","78:38":"then that can only create one pixel of","78:41":"output there's only one place that this","78:43":"3x3 can go so if we want to create more","78:46":"than one pixel of output we have to do","78:48":"something called padding which is to put","78:50":"additional numbers all around the","78:53":"outside so what most libraries do is","78:56":"that they just put a layer of zeros","78:58":"normal layer a bunch of zeros of all","79:01":"around the outside so for 3x3 kernel a","79:04":"single zero on every edge piece here and","79:08":"so once you've pattern it like that you","79:10":"can now move your 3x3 kernel all the way","79:12":"across and give you the same output size","79:15":"that you started with okay now as we","79:19":"mention in fast AI we don't normally","79:22":"necessarily use zero padding where","79:25":"possible we use reflection padding","79:26":"although for these simple convolutions","79:29":"we often use zero padding because it's","79:31":"doesn't matter too much in a big image","79:34":"it doesn't make too much difference okay","79:40":"so that's what a convolution is so a","79:46":"convolutional neural network wouldn't be","79:49":"very interesting if it can only create","79:53":"top edges so we have to take it a little","79:58":"bit further so if we have an input","80:10":"and it might be you know standard kind","80:13":"of red-green-blue picture right then we","80:24":"can create a kernel a 3x3 kernel like so","80:32":"and then we could pass that kernel over","80:37":"all of the different pixels but if you","80:39":"think about it we actually don't have a","80:41":"2d and put anymore we have a 3d input a","80:44":"rank 3 tensor so we probably don't want","80:49":"to use the same kernel values for each","80:52":"of red and green and blue because for","80:55":"example if we're creating a green frog","80:56":"detector we would want more activations","80:59":"on the green then we would on the blue","81:01":"right or if we're trying to find","81:03":"something that could actually find a","81:04":"gradient that goes from green to blue","81:06":"then the different kernels for each","81:10":"channel need to have different values in","81:12":"so therefore we need to create a 3 by 3","81:17":"by 3 kernel okay so this is still our","81:24":"kernel and we're still good a very it","81:28":"across the height and the width but","81:32":"rather than doing an element-wise","81:33":"multiplication of 9 things we're going","81:37":"to do an element-wise multiplication of","81:38":"27 things 3 by 3 by 3 and we're still","81:42":"going to then add them up into a single","81:44":"number so as we pass this cube over this","81:50":"and the kind of like a little bit that's","81:52":"going to be sitting behind it right as","81:55":"we do that part of the convolution it's","81:59":"still going to create just one number","82:02":"because we do an element-wise","82:04":"multiplication of all 27 and add them","82:06":"all together so we can do that across","82:11":"the whole padded single unit padded","82:16":"input and so we started with 1 2 3 4 5","82:19":"by 5 so we're going to end up with an","82:21":"output that's also","82:23":"five by foe right","82:27":"but now input was three channels and our","82:31":"output is only one Channel","82:33":"now we're not going to be able to do","82:35":"very much with just one channel because","82:37":"all we've done now is found the top edge","82:40":"how we're going to find a side edge and","82:42":"a gradient and an area of constant","82:47":"weight well we're going to have to","82:49":"create another kernel and we're going to","82:54":"have to do that convert convolved over","82:58":"the input and that's going to create","83:00":"another 5x5 and then we can just stack","83:05":"those together across this there's","83:11":"another axis and we can do that lots and","83:13":"lots of times and that's going to give","83:15":"us another rank","83:20":"sensor output so that's what happens in","83:25":"practice now I'd in practice we start","83:28":"with an input which is H ok which is H","83:34":"by W by 4 images 3 we pass it through a","83:41":"bunch of convolutional kernels but we","83:44":"compare to pick how many we want and it","83:46":"gives us back an output of and it gives","83:50":"us back an output of height by width by","83:54":"however many kernels we had and so often","83:57":"that might be something like 16 in the","84:01":"first player and so now we've got 16","84:04":"channels they're called sixteen channels","84:10":"representing things like how much left","84:12":"egg edge was on this pixel how much top","84:14":"edge was in this pixel how much blue to","84:17":"red gradient was on this problem this","84:19":"set of 2709 pixels each with RGB and so","84:25":"then you can just do the same thing","84:26":"right you can have another bunch of","84:31":"kernels","84:34":"and that's going to create","84:37":"another output ranked 310 sir again","84:40":"height by width by whatever might still","84:44":"be 16 now what we really like to do is","84:48":"as we get deeper in the network or you","84:51":"actually want to have more and more","84:53":"channels we want to be able to find like","84:55":"a richer and richer set of features so","84:57":"that after a few as we saw in the Siler","84:59":"and Fergus paper by layer four or five","85:01":"we've kind of got eyeball detectors and","85:04":"fur detectors and things right so you","85:05":"really need a lot of channels so in","85:08":"order to avoid our memory going out of","85:10":"control","85:11":"from time to time we create a","85:14":"convolution where we don't step over","85:17":"every single set of 3x3 but instead we","85:23":"skip over two at a time so we would","85:26":"start with a 3x3 centered at 2 comma 2","85:29":"and then we'd jump over to 2 comma 4 2","85:32":"comma 6 2 comma 8 and so forth and","85:35":"that's called a stride to convolution","85:40":"and so what that does is it looks","85:44":"exactly the same right it's still just a","85:46":"bunch of kernels but we're just","85:54":"over to it it's time right we're","85:57":"skipping every alternate input pixel and","86:01":"so the output from that will be H over 2","86:06":"by W over 2 and so when we do that we","86:10":"generally create twice as many kernels","86:12":"so we can now have say 32 activations in","86:18":"each of those spots and so that's what","86:21":"modern convolutional neural networks","86:23":"kind of tend to look like right and so","86:26":"we can actually see that if we go into","86:33":"our pets and we grab our CNN right and","86:36":"we're going to take a look at this","86:38":"particular cat so if we go X comma y","86:41":"equals valid data set some index so it's","86:44":"just grab the 0th we'll go touch show","86:46":"and would print out the value of y","86:49":"apparently this cat is of category Main","86:52":"Hoon so until a week ago I was not at","86:55":"all familiar that there's a cat called a","86:57":"Maine Coon having spent all week with","86:59":"this particular cat I am now deeply","87:02":"familiar with this Maine Coon so we can","87:07":"if we go learn summary remember that our","87:12":"input we asked for was 352 by 352 pixels","87:17":"generally speaking the very first","87:19":"convolution tends to have a stride too","87:20":"so after the first layer its 176 by 176","87:25":"so this is lone dot summary we'll print","87:28":"out for you the output shape up to every","87:30":"layer 176 by 176 and the first set of","87:35":"convolutions is has 64 activations and","87:39":"we can actually see that if we type in","87:41":"learn belt model you can see here it's a","87:48":"2d con input channels and 64 output","87:53":"channels and it's tried of - okay and","88:00":"interestingly it actually starts with a","88:01":"kernel size of 7 by 7 so like nearly all","88:04":"of the convolutions are 3 by 3 so either","88:06":"all 3 by 3","88:08":"right for reasons we'll talk about in","88:10":"part two we often use a larger kernel","88:12":"for the very first one if you here's a","88:15":"larger kernel you have to use more","88:17":"padding so we have to use kernel size","88:19":"int / 2 padding to make sure we don't","88:22":"lose anything anyway so we're now have","88:27":"64 output channels and since it was","88:29":"straight - it's now 176 by 176 and then","88:33":"as we go along you'll see that from time","88:37":"to time we have go from 88 by 88 to 40","88:41":"by 40 by 40 for the grid size so that","88:44":"was a 2d con and then when we do that we","88:47":"generally double the number of channels","88:54":"so we keep going through a few more","88:57":"calms and they've as you can see they've","89:00":"got batch norm and rally that's kind of","89:01":"pretty standard and eventually we do it","89:05":"again now the Strad - cons which again","89:08":"doubles okay we can have about 512 by 11","89:11":"by 11 and that's basically where we","89:17":"finish the main part of the network we","89:19":"end up with 5 12 channels 11 by 11","89:23":"okay so we're actually at a point where","89:27":"we're going to be able to do this heat","89:28":"map now so let's try and work through it","89:30":"before we do I want to show you how you","89:34":"can do your own manual convolutions","89:38":"because it's kind of fun so we're going","89:40":"to start with this picture of a Maine","89:42":"Coon and I've created a convolutional","89:46":"kernel and so as you can see this one","89:49":"has a right edge and a bottom edge with","89:52":"positive numbers and just inside that","89:55":"it's got negative numbers so I'm","89:57":"thinking this should show me","89:58":"bottom-right edges ok so that's my","90:04":"tensor now one complexity is that that","90:08":"3x3 kernel cannot be used for this","90:15":"purpose because I need two more","90:17":"dimensions the first is I need the third","90:19":"dimension to say how to combine","90:21":"the red green and blue so what I do is I","90:27":"say don't expand this is my 3x3 and I","90:33":"pop another three on the start what","90:35":"don't expand does is it says create a 3","90:38":"by 3 by 3 tensor by simply copying this","90:42":"one 3 times I mean honestly it doesn't","90:46":"actually copy it it pretends to have","90:49":"copied it you know but it just basically","90:50":"refers to the same block of memory so it","90:53":"kind of copies it in a memory efficient","90:55":"way so this one here is now 3 copies of","91:00":"that and the reason for that is that I","91:03":"want to treat red and green and blue the","91:05":"same way for this little manual kernel","91:07":"I'm showing you and then we need one","91:10":"more access because rather than actually","91:14":"having a separate kernel like I've kind","91:16":"of printed these as if they were","91:17":"multiple kernels what we actually do is","91:21":"we use a rank 4 tensor and so the very","91:24":"first access is for the every separate","91:28":"kernel that we have so in this case I'm","91:31":"just going to create one kernel so to do","91:33":"a convolution I still have to put this","91:35":"unit access on the front so you can see","91:39":"k dot shape is now 1 comma 3 comma 3","91:41":"comma 3 so it's a 3 by 3 kernel there","91:45":"are three of them and then that's just","91:48":"the one kernel that I have so it kind of","91:50":"takes awhile to get the feel for these","91:52":"higher dimensional tensors because we're","91:54":"not used to writing out before D tensor","91:57":"but like just think of them like this","91:59":"before T tensor is just a bunch of 3d","92:02":"tensors sitting on top of each other","92:04":"ok so this is our um 40 tensor and then","92:09":"you can just call kana 2d passing in","92:14":"some image and so the image I'm going to","92:16":"use is the first part of my validation","92:18":"data set and the kernel there's one more","92:22":"trick which is that in pi torch pretty","92:26":"much everything is expecting to work on","92:28":"a mini-batch not on an individual thing","92:31":"okay so in our case we have to create a","92:35":"a batch of size 1 so our original image","92:38":"is three channels by 352 by 352 hoped by","92:42":"width that's remember paid Watchers","92:44":"channel by height by width I want to","92:46":"create a mini design I need to create a","92:48":"rank 4 tensor where the first axis is 1","92:53":"in other words it's a mini batch of size","92:55":"1 because that's what plate watch","92:57":"expects so there's something you can do","92:59":"in both pi torch and numpy which is you","93:02":"can index into an array or a tensor with","93:04":"a special value none and that creates a","93:08":"new unit access in that point point so T","93:13":"is my image of dimensions 3 by 3 52 by","93:17":"352 T none is a rank 4 tensor a mini","93:22":"batch of one image of 1 by 3 by 3 50 by","93:25":"352 and so now I can go to D and get","93:29":"back ok specifically my Maine Coon ok so","93:40":"that's how you can play around with","93:42":"convolutions yourself so how are we","93:47":"going to do this to create a heat map","93:50":"this is where things get fun remember","94:01":"mentioned was that I basically have like","94:07":"my input red-green-blue and it goes","94:13":"through a bunch of convolutional layers","94:16":"let us write a little line to say a","94:19":"convolutional layer to create","94:21":"activations which have more and more","94:24":"channels and eventually less and less","94:27":"smaller and smaller height by widths","94:35":"until eventually remember we looked at","94:37":"the summary we ended up with something","94:39":"which was 11 by 11 by 512 and there's a","94:51":"hope there's a whole bunch more layers","94:52":"that we skipped over now there are 37","95:05":"classes because remember data dot C is","95:08":"the number of classes we have and we can","95:11":"see that at the end here we end up with","95:12":"37 features in our model so that means","95:16":"that we end up with a probability for","95:18":"every one of the 37 breeds of cat and","95:21":"dog so it's a vector of length 37 that's","95:25":"our final output that we need because","95:27":"that's what we're going to compare","95:29":"implicitly to our one hot encoded matrix","95:32":"which will have a 1 in the location for","95:35":"Maine Coon yeah so somehow we need to","95:40":"get from this 11 by 11 by 512 to this 37","95:46":"and so the way we do it is we actually","95:50":"take the average of every one of these","95:53":"11 by 11 faces we just take the mean so","95:57":"we're going to take the mean of this","96:00":"first face take the mean that gets this","96:06":"one value and then we'll take","96:08":"second of the five twelve faces and take","96:10":"that mean and that'll give us one more","96:12":"value that's a we'll do that for every","96:14":"face and that will give us a five twelve","96:19":"long vector okay and so now all we need","96:25":"to do is pop that through a single","96:28":"matrix multiply of five twelve by thirty","96:33":"seven and that's going to give us an","96:38":"output vector of length thirty-seven","96:41":"okay so this step here where we take the","96:45":"average of each face is called average","96:48":"pooling so let's go back to our model","96:53":"and take a look there it is here is our","96:57":"final five twelve and here is we will","97:01":"talk about what a concat pooling is in","97:03":"part two for now we'll just focus on","97:05":"that this is a fast AI specialty","97:06":"everybody else just does this average","97:08":"pool average pool duty with an output","97:11":"size of one so here it is output average","97:15":"pool 2d with an output size of one and","97:19":"then again there's a bit of a special","97:28":"faster I think that we actually have two","97:30":"layers here but normally people then","97:31":"just have the one linear layer with the","97:35":"input of 512 and the output of 37 okay","97:42":"so what that means is that this little","97:44":"box over here where we want a one for","97:48":"Maine Coon we've got to have a box over","97:51":"here which needs to have a high value in","97:54":"that place so that the lots of below so","97:58":"if we're going to have a high value","97:59":"there the only way to get it is with","98:03":"this matrix multiplication is that it's","98:05":"going to represent a simple weighted","98:09":"linear combination of all of the 512","98:12":"values here so if we're going to be able","98:15":"to say I'm pretty confident this is a","98:17":"Maine Coon just by taking the weighted","98:21":"of inputs those inputs are going to have","98:23":"to represent features like how fluffy is","98:27":"it what color is it snows how long as","98:30":"its legs how point here it's ears you","98:32":"know all the kinds of things that can be","98:34":"used because for the other thing which","98:36":"figures out is this a bulldog it's going","98:39":"to use exactly the same kind of 512","98:42":"inputs with a different set of weights","98:44":"because that's all a matrix","98:45":"multiplication is right it's just a","98:48":"bunch of weighted sums a different","98:51":"weighted sum for each output okay so","98:55":"therefore we know that this you know","98:59":"potentially dozens or even hundreds of","99:02":"layers of convolutions must have","99:04":"eventually come up with an 11 by 11 face","99:09":"for each of these features saying in","99:12":"this little bit here how much is that","99:17":"part of the image like a pointy ear how","99:21":"much is it fluffy how much is it like a","99:24":"long leg how much is it like a very red","99:26":"nodes right so that's what all of those","99:29":"things must represent so each face is","99:31":"what we call each of these represents a","99:35":"different feature okay so the outputs of","99:41":"these we can think of as different","99:43":"features so what we really want to know","99:49":"then is not so much what's the average","99:54":"across the 11 by 11 to get this set of","99:57":"outputs but what we really want to know","100:00":"is what's in each of these 11 by 11","100:01":"spots so what if instead of averaging","100:04":"across the 11 by 11 let's instead","100:07":"average across the 512 if we average","100:13":"across the 512 that's going to give us a","100:17":"single 11 by 11 matrix and each item","100:21":"each each grid point in that 11 by 11","100:24":"matrix will be the average of how","100:27":"activated was that area when it came to","100:30":"figuring out that this was a Maine Coon","100:33":"how many","100:35":"signs of Maine Coon ish Ness was there","100:38":"in that part of the 11 by 11 grid and so","100:44":"that's actually what we do to create our","100:46":"heat map so I think maybe the easiest","100:48":"way is to kind of work backwards here's","100:52":"our heat map and it comes from something","100:55":"average activations and it's just a","100:58":"little bit of matplotlib and faster a","101:02":"faster I to show the image and then","101:05":"matplotlib to take the heat map which we","101:08":"passed in which was called average","101:09":"activations hm for heat map alpha 0.6","101:13":"means make it a bit transparent and","101:16":"matplotlib extent means expand it from","101:20":"11 by 11 to 352 by 352 he is by linear","101:24":"interpolations it's not all blocky and","101:26":"use a different color map to kind of","101:28":"highlight things that's just the","101:30":"matplotlib is not important the key","101:32":"thing here is that average activations","101:33":"is the 11 by 11 matrix we wanted here it","101:37":"is average activations touch shape is 11","101:39":"by 11 so to get there we took the mean","101:44":"of activations across dimension 0 which","101:47":"is what I just said in PI torch the","101:50":"channel dimension is the first dimension","101:52":"so the main across dimension 0 took us","101:55":"from something of size 512 by 11 by 11","101:57":"as promised","101:59":"to something of 11 by 11 so therefore","102:03":"activations axe contains the activations","102:06":"we're averaging where did they come from","102:09":"they came from something called a hook","102:12":"so a hook is a really cool more advanced","102:21":"PI torch feature that lets you as the","102:24":"name suggests hook into the PI torch","102:26":"machinery itself and run any arbitrary","102:30":"Python code you want to it's a really","102:33":"amazing and nifty thing because you know","102:36":"normally when we do a forward pass","102:39":"through a PI torch module it gives us","102:43":"this set of outputs but we know that in","102:46":"the process it's calculated these","102:49":"so why would I what I would like to do","102:52":"is I would like to hook into that","102:54":"forward pass and tell PI torch hey when","102:58":"you calculate this can you store it for","103:00":"me please okay so what is this this is","103:04":"the output of the convolutional part of","103:07":"the model so the convolutional part of","103:09":"the model which is everything before the","103:11":"average pool is basically all of that","103:16":"but and so thinking back to transfer","103:19":"learning right you remember with","103:25":"transfer learning we actually cut off","103:31":"everything after the convolutional part","103:33":"of the model and replaced it with our","103:35":"own little bit right so with fast AI the","103:39":"original convolutional part of the model","103:40":"is always going to be the first thing in","103:44":"the model and specifically it's always","103:47":"going to be called assuming so in this","103:51":"case I'm taking my model and I'm just","103:54":"going to call it M right so you can see","103:58":"M is this big thing but always at least","104:05":"in first day I always m0 will be the","104:10":"convolutional part of the model so in","104:12":"this case we created a let's go back and","104:16":"see we created a resin at 34 so the the","104:20":"main part of the resin at 34 though the","104:22":"pre-trained bit we hold on to is in m0","104:24":"and so this is basically it this is a","104:26":"printout of the rezident 84 and at the","104:29":"end of it there is the 512 activations","104:32":"so what in other words what we want to","104:34":"do is we want to grab em 0 and we want","104:41":"to hook its output so this is a really","104:45":"useful thing to be able to do so far C","104:46":"is actually created something to do it","104:48":"for you which is literally you say hook","104:50":"output and you pass in the PI torch","104:54":"module that you want to hook the output","104:56":"of and so most of the most likely the","104:58":"thing you want to hook is the","105:00":"convolutional part of the model","105:02":"and that's always going to be M 0 or","105:05":"learn model zero so we give that hawk a","105:08":"name don't worry about this part we'll","105:11":"learn about it next week so having","105:13":"hooked the output we now need to","105:16":"actually do the forward pass all right","105:18":"and so remember in PI torch to actually","105:20":"get it to calculate something which is","105:22":"called doing the forward pass you just","105:24":"act as if the model is a function right","105:27":"so we just pass in our X our X","105:30":"mini-batch so we already had a Maine","105:34":"Coon image called X right but we can't","105:38":"quite pass that into our model it has to","105:42":"be normalized and turned into a mini","105:44":"batch and put on to the GPU so first AI","105:49":"has a thing called a data bunch which we","105:51":"have in data and you can always say data","105:53":"dot one item to create a mini batch with","105:57":"one thing in it ok and as an exercise at","106:00":"home you could try to create a mini","106:02":"batch without using data dot one item so","106:05":"make sure that you kind of learn how to","106:07":"normalize and stuff yourself if you want","106:09":"to but this is how you can create a mini","106:12":"batch with just one thing in it and then","106:15":"I can pop that onto the GPU by saying","106:17":"drop CUDA that's what I passed in my","106:20":"model and so the predictions I get out","106:23":"actually don't care about right because","106:25":"the predictions is the predictions is","106:31":"this thing which is not what I want","106:32":"right so I'm not actually going to do","106:35":"anything with the predictions the thing","106:36":"I care about is the hook that it is","106:39":"created now one thing to be aware of is","106:42":"that when you hook something in playa","106:46":"torch that means every single time you","106:47":"run that model assuming you're hooking","106:50":"outputs it's storing those outputs and","106:53":"so you want to remove the hook when","106:56":"you've got what you want because","106:57":"otherwise if you use the model again","106:58":"it's going to keep hooking more and more","107:00":"outputs which will be slow and memory","107:01":"intensive so we've created this thing","107:05":"Python calls that a context manager","107:07":"you can use any hook as a context","107:09":"manager at the end of that with block","107:11":"it'll remove the hook okay so we've got","107:16":"and so now pi torch walks so fast a","107:21":"eyehooks","107:22":"always give you something called or at","107:24":"least the output hooks always give you","107:26":"something called dot stored which is","107:27":"where it stores away the thing you asked","107:28":"you to hook and so that's where the","107:30":"activations now uh okay so we did a","107:34":"forward pass after hooking the output of","107:37":"the convolutional section of the model","107:38":"we grabbed what it stored we check the","107:42":"shape it was 512 by 11 by 11 as we","107:46":"predicted we then took the mean of the","107:49":"channel axis to get an 11 by 11 tensor","107:54":"and then if we look at that that's our","108:00":"picture so there's a lot to unpack right","108:04":"lot to unpack but if you take your time","108:07":"going through these two sections the","108:09":"convolution kernel section and the","108:12":"heatmap section of this notebook like","108:13":"running those lines of code and changing","108:15":"them around a little bit and remember","108:18":"the most important thing to look at is","108:20":"shape you might have noticed when I'm","108:22":"showing you these notebooks so very","108:24":"often print out the shape and when you","108:26":"look at this shape you want to be","108:27":"looking at how many axes are there","108:30":"that's the rank of the tensor and how","108:32":"many things are there in each axis and","108:34":"try and think why right try going back","108:38":"to the printout of the summary try going","108:41":"back to the actual list of the layers","108:43":"and try and go back and think about the","108:45":"actual picture we drew and think about","108:47":"what's actually going on okay so that's","108:54":"a lot of technical content so what I'm","108:57":"going to do now is switch from technical","108:58":"content to something much more important","109:01":"unless we have some questions first okay","109:05":"because in the next lesson in the next","109:11":"lesson we're going to be looking at","109:14":"generative models both text and image","109:19":"generative models and generative models","109:22":"are where you can create a new piece","109:28":"of text or a new image or a new video or","109:33":"a new sound and as you probably are","109:35":"aware this is the area that deep","109:37":"learning has developed the most in in","109:40":"the last 12 months and we're now at a","109:42":"point where we can generate realistic","109:47":"looking videos images audio and to some","109:54":"extent even text and so there are many","110:00":"things in in this journey which have","110:04":"ethical considerations but perhaps this","110:06":"area of generative modeling is one of","110:08":"the largest ones so before I got into it","110:11":"I wanted to specifically touch on ethics","110:14":"and data science","110:16":"most of the stuff I'm showing you","110:19":"actually comes from Rachel and Rachel","110:23":"has a really cool TEDx San Francisco","110:26":"talk that you can check out on YouTube","110:29":"and a more extensive analysis of ethical","110:33":"principles and bias principles in AI","110:35":"which you can find at this talk here and","110:38":"she has a playlist that you can check","110:40":"out we've already touched on an example","110:44":"of bias which was his gender shades","110:47":"study where if you remember for example","110:51":"lighter male skin people on IBM's main","110:56":"computer vision system 99.7% accurate","111:01":"and darker females are some hundreds of","111:05":"times less accurate in terms of error so","111:08":"like extraordinary differences and so","111:11":"it's interesting to kind of like okay","111:13":"it's it's first more important to be","111:14":"aware that not only can this happen","111:17":"technically that this can happen on a","111:20":"massive companies rolled out publicly","111:24":"available highly marketed system that","111:27":"hundreds of quality control people have","111:29":"studied and lots of people are using it","111:31":"it's it's out there in the world they","111:34":"all look kind of crazy right","111:40":"so it's interesting to think about why","111:41":"and so one of the reasons why is that","111:44":"the data we feed these things but we","111:46":"tend to use be included a lot of these","111:49":"datasets kind of unthinkingly right but","111:53":"like imagenet which is the basis of like","111:54":"a lot of the computer vision stuff we do","111:57":"is over half American and Great Britain","112:01":"right like when it comes to the","112:06":"countries that actually have most of the","112:08":"population in the world I can't even see","112:12":"them here they're somewhere in these","112:13":"impossibly thin lines because remember","112:15":"these datasets are being created almost","112:17":"exclusively by people in u.s. Great","112:22":"Britain and nowadays increasingly also","112:24":"China so there's a lot of bias in the","112:30":"content we're creating because of a bias","112:32":"in the kind of people that are creating","112:34":"that content even when in theory it's","112:37":"being created in a very kind of neutral","112:39":"way but you can't argue with the data","112:41":"right it's it's obviously not neutral at","112:44":"all and so when you have biased data","112:51":"creating biased algorithms you then need","112:54":"to say like or what are we doing with","112:55":"that so we've been spend a lot of time","112:57":"talking about image recognition so a","112:59":"couple of years ago this company deep","113:01":"Lin advertised their image recognition","113:04":"system which can be used to do mass","113:08":"surveillance on large crowds of people","113:11":"find any person passing through who is a","113:15":"person of interest in theory and so","113:19":"putting aside even the question of like","113:21":"is it a good idea to have such a system","113:25":"you kind of think is it a good idea to","113:27":"have such a system where certain kinds","113:30":"of people are 300 times more likely to","113:32":"be misidentified and then thinking about","113:35":"it so this is now starting to happen in","113:39":"America these systems are being rolled","113:41":"out and so there are now systems in","113:44":"America that will identify a person of","113:47":"interest in a video and send a ping to","113:52":"the local police","113:53":"and so these systems are extremely","113:56":"inaccurate and extremely biased and what","113:59":"happens that of course is if you're in a","114:02":"predominantly black neighborhood where","114:05":"the probability of successfully","114:07":"recognizing you is much lower and you're","114:11":"much more likely to be surrounded by","114:12":"black people and so suddenly all of","114:16":"these black people are popping up as","114:17":"persons of interest or in a video of a","114:20":"person of interest all the people in the","114:22":"video are all recognized as in the","114:25":"vicinity as a person of interest you","114:27":"suddenly get all these pings going off","114:28":"the local police department causing the","114:31":"police to run down there and therefore","114:33":"likely to lead to a larger number of","114:36":"arrests which is then likely to feed","114:38":"back into the data being used to develop","114:40":"the systems so this is happening right","114:44":"and so like thankfully a very small","114:47":"number of people are actually bothering","114:49":"to look into these things I mean","114:50":"ridiculously small but at least it's","114:52":"better than nothing and so for example","114:54":"then one of the best ways that people","114:55":"get publicity is to do kind of funny","114:58":"experiments like let's try the mug shot","115:04":"image recognition system that's being","115:06":"widely used and trade against the","115:08":"members of Congress and find out that","115:10":"there are 28 members of Congress who","115:13":"would have been identified by this","115:15":"system obviously incorrectly oh I didn't","115:20":"know that okay members have black","115:22":"members of Congress not at all surprised","115:24":"to hear that Thank You Rachel we see","115:28":"this kind of bias and a lot of the","115:30":"systems we use I'm not just image","115:32":"recognition but text translation when","115:35":"you convert she as a doctor he is a","115:37":"nurse into Turkish you quite correctly","115:40":"get a gender in specific pronoun because","115:43":"that's what Turkish uses you could then","115:45":"take that and feed it back into Turkish","115:47":"with your gender in specific pronoun and","115:49":"you will now get he as a doctor she is","115:52":"in this so the bias again this is in a","115:56":"massively widely rolled out carefully","115:58":"studied system and it's not like even","116:02":"these kind of things like a little","116:03":"one-off things then get fixed quickly","116:05":"these issues have been identified in","116:07":"Google Translate for a very long time","116:08":"and they're still there and they don't","116:11":"get fixed so the the kind of results of","116:18":"this are in my opinion quite terrifying","116:22":"because what's happening is that in many","116:25":"countries including America where I'm","116:27":"speaking from now algorithms are","116:30":"increasingly being used for all kinds of","116:33":"Public Policy judicial and so forth","116:36":"surfaces for example there's a system","116:38":"called compass which is very widely used","116:40":"to decide who's going to jail and it","116:43":"does that in a couple of ways","116:45":"it tells judges what sentencing","116:47":"guidelines they should use for","116:49":"particular cases and it tells them also","116:52":"which people the system says should be","116:56":"let out on bail but here's the thing","116:59":"white people that keeps on saying let","117:03":"this person out even though they end up","117:05":"reoffending and vice versa it's","117:08":"systematically like out by double","117:10":"compared to what it should be in terms","117:13":"of getting it wrong with white people","117:16":"versus black people so this is like kind","117:23":"of horrifying because I mean amongst","117:26":"other things the data that it's using in","117:28":"this system is literally asking people","117:31":"questions about things like did any of","117:35":"your parents ever go to jail or do any","117:37":"of your friends do drugs like they're","117:40":"asking questions about other people who","117:43":"they have no control over so not only","117:45":"are these systems biased very","117:49":"systematically biased but they're also","117:52":"are being done on the basis of data","117:54":"which is totally out of your control so","117:57":"this is kind of DeJoria it seems that oh","118:00":"yeah are your parents divorced is","118:03":"another question that's being used to","118:04":"decide whether you go to jail or not","118:06":"okay so when we raise these issues kind","118:12":"of on Twitter or in talks or whatever","118:14":"there's always a few people always white","118:17":"men a few people who will always say","118:20":"like","118:21":"that's just the way the world is that's","118:23":"just reflecting what the data shows but","118:26":"when you actually look at it it's not","118:28":"right it's actually systematically","118:32":"erroneous and systematically erroneous","118:36":"against people of color minorities the","118:39":"people who are less involved in creating","118:41":"the systems that these products are","118:44":"based on sometimes this can go a really","118:49":"long way","118:50":"so for example in Myanmar there was a","118:54":"genocide of Thuringia people and that","118:58":"genocide was very heavily created by","119:01":"Facebook not because anybody at Facebook","119:04":"wanted it I mean heavens no I know a lot","119:07":"of people at Facebook I have a lot of","119:08":"friends at Facebook they're really","119:10":"trying to do the right thing right","119:11":"they're really trying to create a","119:13":"product that people like but not in a","119:16":"thought for enough way because when you","119:18":"roll out something we're literally in","119:20":"Myanmar a country that most people","119:23":"didn't have most but maybe half of","119:26":"people didn't have electricity until","119:28":"very recently and you say hey you can","119:31":"all have free internet as long as it's","119:33":"just Facebook I think carefully about","119:36":"what you're doing right and then you use","119:38":"algorithms to feed people the stuff they","119:41":"will click on and of course what people","119:42":"click on is stuff which is controversial","119:45":"stuff that makes their blood boil so","119:48":"when they actually started asking the","119:51":"generals in the Myanmar army that were","119:53":"literally throwing babies onto bonfires","119:56":"they were saying we know that these are","119:59":"not humans we know that they are animals","120:02":"because we read the news we read the","120:05":"internet but and because this is the","120:07":"that this is the stories that the","120:10":"algorithms are pushing but and the","120:12":"algorithms are pushing the stories","120:14":"because the algorithms are good they","120:16":"know how to create eyeballs how to get","120:19":"people watching and how can I get people","120:21":"clicking and again putting it Facebook","120:23":"said let's cause a massive genocide in","120:27":"Myanmar they said let's maximize the","120:30":"engagement of people in this new market","120:32":"on our platform","120:36":"so they very successfully maximized","120:39":"engagement yes please it's just it's","120:46":"important to note people warned","120:48":"executives of Facebook how the platform","120:50":"was being used to incite violence as far","120:52":"back as 2013 2014 2015 and 2015 someone","120:57":"even warned executives that Facebook","121:00":"could be used in Myanmar in the same way","121:01":"that the radio broadcast were used in","121:04":"Rwanda during the Rwandan genocide and","121:07":"as of 2015 Facebook only had four for","121:11":"contractors who spoke Burmese working","121:14":"for them they really did not put many","121:16":"resources into the issue at all even","121:19":"though they were getting very very","121:21":"alarming warnings about it so I mean why","121:25":"does this happen right the part of the","121:28":"issue is that ethics is complicated and","121:32":"you will not find Rachel or I telling","121:36":"you how to do ethics you know how do you","121:38":"fix this we don't know we can just give","121:41":"you kind of things to think about all","121:44":"right another part of a problem we keep","121:46":"hearing is it's not my problem I'm just","121:49":"a researcher I am just a techie I'm just","121:51":"building a data set I'm not part of a","121:54":"problem I'm part of this foundation","121:56":"that's far enough away that I can","121:58":"imagine that I'm not part of this right","122:00":"but you know if you're creating image","122:04":"net and you want it to be successful you","122:07":"want lots of people to use it you want","122:08":"lots of people to build products on it","122:09":"lots people to do research on top of it","122:11":"if you're trying to create something","122:13":"that people are using you want them to","122:16":"use then please try to make it something","122:18":"that won't cause massive amounts of harm","122:21":"and doesn't have massive amounts of bias","122:23":"and it can actually come back and bite","122:25":"you in the ass right","122:27":"the Volkswagen engineer who ended up","122:30":"actually encoding the thing that made","122:33":"them systematically cheat on their","122:35":"diesel emissions tests on their","122:37":"pollution tests ended up in jail not","122:41":"because it was their decision to cheat","122:44":"on the tests but because their manager","122:46":"told them to write their code","122:48":"and they wrote the code and therefore","122:50":"they were at the ones that ended up","122:52":"being criminally responsible and they","122:54":"were the ones that were jailed right so","122:56":"if you do in some way a shitty thing","123:00":"that ends up causing trouble that can","123:03":"absolutely come back around and get you","123:05":"in trouble as well sometimes it can","123:08":"cause huge amounts of trouble","123:10":"so if we go back to World War two right","123:14":"then this was one of the first great","123:17":"opportunities for IBM to show off their","123:19":"amazing amazing tabulating system and","123:22":"they had a huge client in Nazi Germany","123:25":"and Nazi Germany used this amazing new","123:28":"tabulating system to encode all of the","123:31":"different types of Jews that they had in","123:33":"the country and all the different types","123:34":"of problem people so Jews were eight","123:36":"gypsies were 12","123:39":"then different outcomes were coded","123:41":"executions were for death in a gas","123:44":"chamber was six a Swiss judge ruled that","123:50":"IBM was actively involved facilitating","123:56":"the commission of these crimes against","123:58":"humanity right so there are absolutely","124:02":"plenty of examples of people building","124:05":"data processing technology that are","124:08":"directly causing deaths sometimes","124:13":"millions of deaths right so we don't","124:16":"want to be one of those people and so","124:18":"you might have thought oh you know I'm","124:20":"just creating some data processing","124:21":"software and somebody else is thinking","124:23":"I'm just the sales person and somebody","124:24":"else is thinking","124:25":"I'm just the biz dev person opening new","124:27":"markets but it all comes together right","124:29":"so we need to care and so one of the","124:33":"things we need to care about is getting","124:35":"humans back in the loop right and so","124:39":"when we pull humans out of the loop is","124:42":"one of the first times that trouble","124:44":"happens I don't know if you remember I","124:45":"remember this very clearly when I first","124:48":"heard that Facebook was firing the human","124:51":"editors that were responsible for","124:53":"basically curating the news that ended","124:57":"up on the Facebook pages and I got to","125:01":"a time I thought that's a recipe for","125:04":"disaster because I've seen again and","125:06":"again that humans can be the person in","125:09":"the loop that can realize this isn't","125:12":"right you know it's very hard to create","125:14":"an algorithm that can recognize this","125:17":"isn't right or else humans are very good","125:19":"at that","125:20":"and we saw that's what happened right","125:21":"after Facebook fired two human editors","125:23":"the nature of stories on Facebook","125:26":"dramatically changed that and you","125:28":"started seeing this proliferation of","125:30":"conspiracy theories and the kind of the","125:33":"algorithms went crazy with recommending","125:35":"more and more controversial topics and","125:37":"of course that changed people's","125:39":"consumption behavior causing them to one","125:41":"more and more controversial topics so","125:46":"we're one of the really interesting","125:47":"places this comes in and Cathy O'Neil","125:50":"who's got a great book called reference","125:54":"of math destruction thank you Rachel","125:58":"and many others have pointed out is that","126:00":"what happens to algorithms is that they","126:04":"end up impacting people for example","126:07":"compass sentencing guidelines go to a","126:10":"judge now you can say the algorithm is","126:14":"very good we I mean it in compass this","126:17":"case it isn't it actually turned out to","126:18":"be about as bad as random because it's a","126:21":"black box and all that but even if it","126:24":"was very good","126:25":"you could then say well you know the","126:27":"judge is getting the algorithm otherwise","126:29":"they're just be getting a person people","126:30":"also give bad advice","126:31":"so what humans respond differently to","126:34":"algorithms it's very common particularly","126:37":"for a human that is not very familiar","126:40":"with the technology themselves like a","126:42":"judge just see like oh that's what the","126:45":"computer says the computer looked it up","126:47":"and it figured this out right it's","126:50":"extremely difficult to get a","126:52":"non-technical audience to look at a","126:54":"computer recommendation and come up with","126:57":"a nuanced decision-making process so","127:02":"what we see is that algorithms are often","127:05":"put into place with no appeals process","127:07":"they're often used to massively scale up","127:10":"decision making systems because they're","127:14":"and then the people that are using the","127:17":"Atlas of those algorithms tend to give","127:19":"them more credence than they deserve","127:20":"because very often they're being used by","127:22":"people that don't have the technical","127:24":"competence to judge them themselves so","127:26":"great example right was here's an","127:30":"example of somebody who lost their","127:32":"health care and they lost their health","127:35":"care because of an error in a new","127:37":"algorithm that was systematically","127:40":"failing to recognize that there are many","127:44":"people that need help with was it","127:46":"Alzheimer's cerebral palsy and diabetes","127:50":"thanks Rachel","127:51":"and so this system which had this this","127:55":"era that was later discovered was","127:57":"cutting off these people from the home","127:59":"care that they needed so that cerebal","128:01":"palsey victims loan longer had the care","128:04":"they needed so their life was destroyed","128:07":"basically and so when the person that","128:11":"created that algorithm with the error","128:13":"was asked about this and one","128:15":"specifically said should they have found","128:18":"a better way to communicate the system","128:21":"the strengths the failures and so forth","128:23":"he said yeah I should probably also dust","128:26":"under my bed that was there that was the","128:29":"level of interest they had and this is","128:32":"extremely common I hear this all the","128:35":"time and it's much easier to kind of see","128:37":"it from afar and say okay after the","128:39":"problems happened I can see that that's","128:41":"a really shitty thing to say but it can","128:42":"be very difficult when you're kind of in","128:45":"the middle of it I just want to say one","128:48":"more thing about that example and that's","128:51":"that this was a case where it was","128:53":"separate there was someone who created","128:54":"the algorithm then I think different","128:56":"people implemented the software and this","128:58":"is a note in use in over half of the 50","129:00":"states and then there was also the","129:01":"particular policy decisions made by that","129:04":"state and so there this is one of those","129:06":"situations where nobody felt responsible","129:08":"because the algorithm creators like oh","129:10":"no it's the policy decisions of the","129:11":"state that were bad you know and the","129:13":"state can be like oh no it's the ones","129:15":"who implemented the software and so","129:18":"everyone's just kind of pointing fingers","129:19":"and not taking responsibility and you","129:23":"know in some ways maybe it's unfair but","129:25":"I would argue the person who is","129:28":"creating the data set and the person who","129:30":"is implementing the algorithm is the","129:32":"person best placed to get out there and","129:36":"say hey here are the things you need to","129:38":"be careful of and make sure that they","129:40":"are part of the implementation process","129:43":"so we've also seen this with YouTube","129:46":"right it's kind of similar to what","129:48":"happened with Facebook and we're now","129:49":"seeing with heard examples of students","129:52":"watching the faster I courses who say","129:54":"hey Jeremy and Rachel watching the first","129:56":"day our courses really enjoyed them and","129:58":"at the end of one of them the YouTube","130:01":"autoplay fed me across to a conspiracy","130:03":"theory and what happens is that once the","130:08":"system decides that you like the","130:10":"conspiracy theories it's going to just","130:11":"feed you more and more and then what","130:13":"happens is that please come on just","130:18":"briefly you don't you don't even have to","130:20":"like conspiracy theories the goal is to","130:22":"get as many people hooked on conspiracy","130:24":"theories as possible as what the","130:26":"algorithms trying to do kind of whether","130:28":"or not you've expressed interest right","130:30":"and so the interesting thing again is I","130:32":"know plenty of people involved in","130:33":"YouTube's recommendation systems none of","130:35":"them are wanting to promote conspiracy","130:37":"theories but people click on them right","130:40":"and people share them and what tends to","130:44":"happen is also people that are into","130:47":"conspiracy theories consume a lot more","130:49":"YouTube media so it actually is very","130:52":"good at finding a market that watches a","130:55":"lot of hours of YouTube and then it","130:57":"makes that market watch even more so","130:59":"this is an example of a feedback loop","131:02":"and the New York Times as net is now","131:05":"describing YouTube is perhaps the most","131:06":"powerful radicalizing instrument of the","131:09":"21st century I can tell you my friends","131:12":"that worked on the YouTube","131:13":"recommendation system did not think they","131:16":"were creating the most powerful","131:18":"radicalizing instrument of the 21st","131:20":"century and to be honest most of them","131:23":"today when I talk to them still think","131:26":"they're not they think it's all","131:28":"you know not all of them but a lot of","131:31":"them now are at the point where they","131:33":"just feel like they're the victims here","131:35":"people are unfairly you know they don't","131:37":"get it they don't understand what we're","131:38":"trying to do it's very very difficult","131:41":"right out there in the heart of it so","131:43":"you've got to be thinking from rad at","131:45":"the start what are the possible","131:47":"unintended consequences of what you're","131:50":"working on and as the technical people","131:52":"involved how can you get out in front","131:54":"and make sure that people are aware of","131:56":"them and I just also need to say that in","131:59":"particular many of these conspiracy","132:00":"theories are promoting white supremacy","132:03":"they're you know kind of far-right after","132:05":"no nationalism anti-science and i think","132:08":"you know maybe five or ten years ago I","132:11":"would have thought conspiracy theories","132:12":"are more a more fringe thing but we're","132:14":"seeing the kind of huge societal impact","132:16":"it can have for many people to believe","132:18":"these know and you know partly it's you","132:21":"see them on YouTube all the time it","132:22":"starts to feel a lot more normal right","132:25":"so one of the things that people are","132:26":"doing to try to say like how to fix this","132:29":"problem is to explicitly get involved in","132:32":"talking to the people who might or will","132:34":"be impacted by the kind of decision","132:36":"making processes that you're enabling so","132:38":"for example there was a really cool","132:40":"thing recently where literally","132:43":"statisticians and data scientists got","132:46":"together with people who had been inside","132:50":"the criminal system ie had gone through","132:52":"the the bail and sentencing process of","132:54":"criminals themselves and talking to the","132:56":"lawyers who worked with them and put","132:58":"them together with the data scientists","133:00":"and actually kind of put together a","133:02":"timeline of how exactly does it work and","133:05":"where exactly the other places that","133:07":"there are inputs and how do people","133:08":"respond to them and who's involved this","133:10":"is really cool right this is the only","133:12":"way for you as a kind of a data product","133:16":"developer to actually know how your data","133:18":"products going to be working a really","133:20":"great example of a somebody who did a","133:22":"great job here was Evan s dollar at","133:24":"Meetup who said hey a lot of men are","133:29":"going to our tech meetups and if we use","133:32":"a recommendation system naively it's","133:35":"going to recommend more tech meetups to","133:37":"man which is going to cause more men to","133:40":"go to them and then when women do try to","133:41":"go they'll be like oh my god there's so","133:43":"many men here we're just going to cause","133:45":"more men to go to the tech meetups yeah","133:48":"yeah so showing recommendations to men","133:50":"and therefore not showing them to women","133:52":"yes yeah","133:54":"so so what Evan and made-up decided was","134:00":"to make an explicit product decision","134:01":"that this would not even be representing","134:06":"the actual true preferences of people it","134:08":"would be creating a runaway feedback","134:10":"loop so let's explicitly stop it right","134:12":"before it happens and and not recommend","134:17":"less made ups to women and tech meetups","134:20":"women and more tech meetups","134:21":"come in and so I think that's that's","134:23":"just it's really cool it's like it's","134:25":"saying we don't have to be slaves to the","134:27":"algorithm we actually get to decide","134:30":"another thing that people can do to help","134:34":"is regulation and normally when we kind","134:37":"of talk about regulation there's a","134:39":"natural reaction of like how do you","134:41":"regulate these things that's ridiculous","134:43":"you can't regulate AI but actually when","134:45":"you look at it again and again and this","134:47":"fantastic paper core data sheets for","134:49":"data sets has lots of examples of this","134:52":"there are many many examples of","134:54":"industries where people thought they","134:57":"couldn't be regulated people thought","134:58":"that's just how it was like cars people","135:01":"died in cars all the time because they","135:03":"literally had sharp metal knobs on","135:05":"dashboards steering columns weren't","135:07":"collapsible and all of the discussion in","135:10":"the community was that's just how cars","135:13":"are and when people died in cars it's","135:15":"because of the people but then","135:17":"eventually the regulations did come in","135:19":"and today driving is dramatically safer","135:22":"like dozens and dozens of times safer","135:25":"than it was before","135:27":"right so often there are things we can","135:29":"do through policy so to summarize we are","135:35":"part of the point three to 0.5% of the","135:38":"world that knows how to code all right","135:41":"we have a school that very few other","135:43":"people do not only that we now know how","135:45":"to code deep learning algorithms which","135:47":"is like the most powerful kind of code I","135:49":"know so I'm hoping that we can","135:51":"explicitly think about like at least not","135:55":"making the world worse and perhaps","135:56":"explicitly making it better right and so","136:00":"why is this interesting to you as an","136:02":"audience in particular and that's","136:04":"because fast AI in particular is trying","136:07":"to make it easy for domain experts to use","136:11":"deep learning and so this picture of the","136:13":"goats here is an example of one of our","136:16":"international fellows from a previous","136:18":"course who is a goat dairy farmer and","136:21":"told us that they were going to use deep","136:24":"learning on their remote Canadian Island","136:26":"to help study other disease in goats","136:29":"that and to me this is a great example","136:31":"of like a domain experts problem which","136:34":"nobody else even knows about let alone","136:36":"know that as a computer vision problem","136:38":"that can be solved with deep learning so","136:40":"in your field whatever it is you","136:44":"probably know a lot more now about the","136:48":"opportunities in your field to make it a","136:50":"hell of a lot better than it was before","136:52":"you're probably to come up with all","136:54":"kinds of cool product ideas right maybe","136:57":"be able to startup or create a new","136:59":"product group in your company or","137:00":"whatever but also let us be thinking","137:04":"about what that's going to mean in","137:06":"practice and think about where can you","137:08":"put humans in the loop right where can","137:11":"you put those pressure release valves","137:13":"who are the people you can talk to who","137:15":"could be impacted who could help you","137:17":"understand right and get the kind of","137:19":"humanities folks involved to understand","137:21":"history and psychology and sociology and","137:24":"so forth so that's our plea to you if","137:27":"you've got this far you're definitely at","137:30":"a point now where you're ready to you","137:31":"know make a serious impact on the world","137:34":"so I hope we can make sure that that's a","137:36":"positive impact see you next week"}},68:function(e,t,o){e.exports=o(359)},79:function(e,t,o){}},[[68,2,1]]]);
//# sourceMappingURL=main.986f7480.chunk.js.map