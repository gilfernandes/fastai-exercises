"0:00:00.680": "okay welcome to lesson 4 we are going to",
"0:00:06.350": "finish our journey through these kind of",
"0:00:09.450": "key applications we've already looked at",
"0:00:11.759": "a range of vision applications we've",
"0:00:14.099": "looked at classification localization",
"0:00:17.310": "image regression we've briefly touched",
"0:00:20.189": "on NLP we're going to do a deeper dive",
"0:00:23.430": "into NLP transfer learning today we're",
"0:00:26.939": "going to then look at tabular data and",
"0:00:29.340": "we're going to look at collaborative",
"0:00:31.380": "filtering which are both super useful",
"0:00:33.210": "applications and then we're going to",
"0:00:35.309": "take a complete u-turn we're going to",
"0:00:37.620": "take that collaborative filtering",
"0:00:38.730": "example and dive deeply into it to",
"0:00:41.550": "understand exactly what's happening",
"0:00:43.640": "mathematically exactly what's happening",
"0:00:45.660": "in the computer and we're going to use",
"0:00:47.219": "that to gradually go back in reverse",
"0:00:49.440": "order through the applications again in",
"0:00:52.379": "order to understand exactly what's going",
"0:00:54.660": "on behind the scenes of all of those",
"0:00:55.829": "applications before we do somebody on",
"0:01:01.829": "the forum was kind enough to point out",
"0:01:03.390": "that when we compared ourselves to the",
"0:01:06.409": "what we think might be the",
"0:01:08.369": "state-of-the-art but was recently the",
"0:01:09.840": "state of the art for camford there",
"0:01:11.549": "wasn't a fair comparison because the",
"0:01:14.010": "paper actually used a small subset of",
"0:01:16.110": "the classes and we used all of the",
"0:01:19.590": "classes so jason in our study group was",
"0:01:22.500": "kind enough to rerun the experiments",
"0:01:24.710": "with the correct subset of classes from",
"0:01:27.960": "the paper and our accuracy went up to 94",
"0:01:30.720": "percent compared to 91.5% in the paper",
"0:01:34.200": "so I think that's a really cool result",
"0:01:36.270": "and a great example of how some pretty",
"0:01:40.340": "you know pretty much just using the",
"0:01:43.049": "defaults nowadays can can get you far",
"0:01:46.079": "beyond what was the best of a year or",
"0:01:48.030": "two ago now it's certainly the best last",
"0:01:51.030": "year when we were doing this course",
"0:01:52.409": "because we started it quite quite",
"0:01:54.030": "intensely so that's really exciting so",
"0:02:01.200": "what I wanted to start with is going",
"0:02:07.240": "NLP a little bit to understand really",
"0:02:11.140": "what was going on there so first of all",
"0:02:12.849": "a quick review",
"0:02:15.610": "so remember NLP is natural language",
"0:02:18.010": "processing it's about taking text and",
"0:02:22.140": "doing something with it and text",
"0:02:25.540": "classification is particularly useful",
"0:02:27.810": "kind of practically useful applications",
"0:02:30.790": "it's what we're going to start off",
"0:02:31.930": "focusing on because classifying a text",
"0:02:35.110": "classifying a document can be used for",
"0:02:38.319": "anything from spam prevention to",
"0:02:41.700": "identifying fake news to finding a",
"0:02:46.650": "diagnosis or medical reports finding",
"0:02:51.010": "mentions of your product in Twitter so",
"0:02:54.819": "on and so forth",
"0:02:55.830": "so it's pretty interesting and actually",
"0:02:58.720": "there was a great example there was a",
"0:03:02.560": "great example during the week from one",
"0:03:04.690": "of our students who is a lawyer and he",
"0:03:10.690": "mentioned on the forum that he had a",
"0:03:13.859": "really great results from classifying",
"0:03:16.750": "legal texts using this NLP approach and",
"0:03:21.160": "I thought this was a great example so",
"0:03:22.209": "this is the post that they presented at",
"0:03:25.359": "an academic conference this week",
"0:03:27.269": "describing the approach and actually",
"0:03:30.340": "this series of three steps that you see",
"0:03:34.150": "here and I'm sure you recognize these",
"0:03:35.320": "classification matrix this series of",
"0:03:38.200": "three steps here is what we're going to",
"0:03:40.959": "start by digging into so we're going to",
"0:03:44.500": "start out with a movie review like this",
"0:03:46.720": "one and going to decide whether it's",
"0:03:48.989": "positive or negative sentiment about the",
"0:03:52.720": "movie that is the problem we have in the",
"0:03:58.480": "training set 25,000 movie reviews so",
"0:04:04.900": "we've got 25,000 movie reviews and for",
"0:04:08.859": "each one we have like one bit of",
"0:04:10.600": "information they liked it or they didn't",
"0:04:13.269": "like it and that's we're going to look",
"0:04:14.829": "into a lot more detail of today and in",
"0:04:17.290": "the current lessons our neural networks",
"0:04:19.859": "remember they're just a bunch of matrix",
"0:04:22.710": "multiplies and simple nonlinearities",
"0:04:25.520": "particularly replacing negatives with",
"0:04:27.629": "zeros those weight matrices start out",
"0:04:30.750": "random and so if you start out with with",
"0:04:34.020": "some random parameters and try to train",
"0:04:38.389": "those parameters to learn how to",
"0:04:40.650": "recognize positive versus negative movie",
"0:04:42.719": "reviews",
"0:04:43.430": "you only have 20 literally 25,000 ones",
"0:04:46.800": "and zeros to actually tell you I like",
"0:04:48.360": "this one I don't like that one that's",
"0:04:49.919": "clearly not enough information to learn",
"0:04:53.330": "basically how to speak English how to",
"0:04:55.740": "speak English well enough to recognize",
"0:04:57.710": "they liked this or they didn't like this",
"0:05:00.180": "and sometimes that can be pretty nuanced",
"0:05:03.360": "right the English language often",
"0:05:04.800": "particularly would like movie reviews",
"0:05:06.479": "people because these are like online",
"0:05:08.819": "movie reviews on IMDB people can often",
"0:05:11.159": "like use sarcasm it could be really",
"0:05:12.930": "quite tricky so it for a long time until",
"0:05:16.979": "in fact until very recently like this",
"0:05:19.289": "year neural nets didn't do a good job at",
"0:05:24.120": "all of this kind of classification",
"0:05:27.300": "problem and and that was why there's not",
"0:05:29.219": "enough information available so the",
"0:05:33.750": "trick hopefully you can all guess it's",
"0:05:36.089": "to use transfer learning it's always the",
"0:05:38.279": "trick so last year in this course I",
"0:05:42.629": "tried something crazy which was I",
"0:05:44.909": "thought what if I try transfer learning",
"0:05:46.909": "to demonstrate that it can work for an",
"0:05:49.319": "LP as well and and I tried it out and it",
"0:05:53.460": "worked extraordinarily well and so here",
"0:05:55.800": "we are a year later and transfer",
"0:05:58.050": "learning in NLP is absolutely the the",
"0:06:00.690": "hit thing now and so I'm going to",
"0:06:02.219": "describe to you what happens the key",
"0:06:05.159": "thing is we're going to start with the",
"0:06:07.409": "same kind of thing that we used for",
"0:06:11.009": "computer vision a pre trained model",
"0:06:12.839": "that's been trained to do something",
"0:06:14.669": "different to what we're doing with it",
"0:06:16.500": "and so for imagenet that was originally",
"0:06:20.430": "built as a model to predict which of a",
"0:06:22.830": "thousand categories each photo falls",
"0:06:25.229": "into and people then fine-tune that for",
"0:06:27.569": "all kinds of different things as we've",
"0:06:28.860": "seen so we're going to start with a pre",
"0:06:31.740": "trained model that's going to do",
"0:06:32.789": "something else",
"0:06:33.779": "not movie review classification we're",
"0:06:36.389": "going to start with a pre train model",
"0:06:37.679": "which is called a language model a",
"0:06:39.710": "language model is a very very specific",
"0:06:42.869": "meeting in NLP and it's this a language",
"0:06:45.749": "model is a model that learns to predict",
"0:06:47.580": "the next word of a sentence and to",
"0:06:51.689": "predict the next word of a sentence you",
"0:06:53.429": "actually have to know quite a lot about",
"0:06:55.319": "English assuming you're doing it in",
"0:06:58.409": "English and quite a lot of world",
"0:07:00.449": "knowledge by world knowledge a different",
"0:07:02.369": "example here's your language model and",
"0:07:04.379": "as read I'd like to eat a hot what",
"0:07:08.430": "obviously",
"0:07:10.020": "dog right it was a heart what",
"0:07:14.819": "probably day right now previous",
"0:07:17.939": "approaches to NLP use something called",
"0:07:20.159": "engrams largely which is basically",
"0:07:22.229": "saying how often do these pairs or",
"0:07:24.449": "triplets of words tend to appear next to",
"0:07:26.729": "each other",
"0:07:27.269": "and engrams are terrible at this kind of",
"0:07:29.610": "thing as you can see there's not enough",
"0:07:31.080": "information here to decide what the next",
"0:07:33.659": "word probably is but with a neural net",
"0:07:36.809": "you're absolutely can so here's the nice",
"0:07:40.169": "thing if you train a neural net to",
"0:07:43.289": "predict the next word of a sentence then",
"0:07:47.399": "you actually have a lot of information",
"0:07:49.319": "rather than having a single bit for",
"0:07:51.719": "every 2000 word movie review liked it or",
"0:07:54.240": "different like it every single word you",
"0:07:57.209": "can try and predict the next word so in",
"0:07:59.550": "a 2,000 word movie review",
"0:08:01.469": "there are 1999 opportunities to predict",
"0:08:05.579": "the next word better still you don't",
"0:08:09.779": "just have to look at movie reviews",
"0:08:11.039": "because really the hard thing isn't so",
"0:08:14.369": "much is does this person like the movie",
"0:08:16.740": "or not but how do you speak English and",
"0:08:20.490": "so you can learn how do you speak",
"0:08:22.409": "English roughly from some much bigger",
"0:08:25.680": "set of documents and so what we did was",
"0:08:28.439": "we started with Wikipedia and Stephen",
"0:08:32.250": "Merritt II and some of his colleagues",
"0:08:33.689": "built something called the wiki text 103",
"0:08:35.880": "data set which is simply a subset of",
"0:08:39.389": "most of the largest articles from",
"0:08:41.939": "Wikipedia with a little bit of",
"0:08:44.459": "pre-processing that's available for",
"0:08:45.930": "download",
"0:08:46.950": "and so you're basically grabbing",
"0:08:48.140": "Wikipedia and then I built a language",
"0:08:50.700": "model on all of Wikipedia right so I've",
"0:08:53.160": "just built a neural net which would",
"0:08:55.019": "predict the next word in every",
"0:08:57.769": "significantly sized Wikipedia article",
"0:09:00.060": "and that's a lot of information if I",
"0:09:03.060": "remember correctly it's something like a",
"0:09:04.079": "billion tokens all right so we've got a",
"0:09:06.360": "billion separate things to predict every",
"0:09:08.910": "time we make a mistake on one of those",
"0:09:10.260": "predictions we get the loss can get we",
"0:09:13.950": "get gradients from that and we can",
"0:09:15.420": "update our weights and make them better",
"0:09:16.680": "and better until we can get pretty good",
"0:09:18.390": "at predicting the next word of Wikipedia",
"0:09:21.050": "why is that useful because at that point",
"0:09:23.850": "I've got a model that knows probably how",
"0:09:25.680": "to complete sentences like this and so",
"0:09:28.019": "it knows quite a lot about English and",
"0:09:30.420": "quite a lot about how the world works",
"0:09:32.700": "what kinds of things tend to be hot in",
"0:09:35.130": "different situations for instance I mean",
"0:09:37.790": "ideally it would learn things like in",
"0:09:41.600": "1996 in a speech to the United Nations",
"0:09:44.600": "United States President blah said now",
"0:09:49.110": "that would be a really good language",
"0:09:50.220": "model because it would actually have to",
"0:09:51.540": "know who was this United States",
"0:09:53.730": "president in that year so like getting",
"0:09:55.680": "really good at training language models",
"0:09:58.170": "is a great way to learn a lot about or",
"0:10:01.110": "teacher neural-net",
"0:10:01.890": "a lot about you know what is our world",
"0:10:05.940": "what's in our world how do things work",
"0:10:08.070": "in our world so it's a really",
"0:10:09.540": "fascinating topic and it's actually one",
"0:10:12.300": "that philosophers have been studying for",
"0:10:14.310": "hundreds of years now there's actually a",
"0:10:16.110": "whole theory of philosophy which is",
"0:10:18.180": "about like what can be learned from",
"0:10:21.000": "studying language alone so it turns out",
"0:10:24.930": "empirically quite a lot and so here's",
"0:10:27.810": "the interesting thing you can start by",
"0:10:29.130": "training a language model on all of",
"0:10:30.480": "Wikipedia and then we can make that",
"0:10:32.339": "available to all of you just like a pre",
"0:10:34.800": "trained imagenet model her vision we've",
"0:10:36.660": "now made available a pre trained",
"0:10:38.190": "wikitext model for NLP not because it's",
"0:10:41.790": "particularly useful of itself predicting",
"0:10:43.589": "the next word of sentences is somewhat",
"0:10:46.110": "useful but not normally what we want to",
"0:10:48.510": "do but it tells us it's a it's a model",
"0:10:51.839": "that understands a lot about language",
"0:10:53.220": "and a lot about what language describes",
"0:10:55.760": "so then we can take that and we can do",
"0:10:59.520": "transfer learning to create a new",
"0:11:02.339": "language model that's specifically good",
"0:11:05.430": "at predicting the next word of movie",
"0:11:07.860": "reviews so if we can build a language",
"0:11:12.690": "model that's good at predicting the next",
"0:11:14.699": "word of movie reviews pre trained with",
"0:11:17.520": "the wikitext model right then that's",
"0:11:20.310": "going to understand a lot about my",
"0:11:22.290": "favorite actor is Tom who write or you",
"0:11:26.819": "know I thought the photography was",
"0:11:29.190": "fantastic but I wasn't really so happy",
"0:11:30.959": "about the director whatever right it's",
"0:11:34.020": "going to learn a lot about specifically",
"0:11:35.670": "how movie reviews are written it'll even",
"0:11:39.029": "learned things like what are the names",
"0:11:40.410": "of some popular movies so that would",
"0:11:45.149": "then mean we can still use a huge corpus",
"0:11:48.360": "of lots of movie reviews even if we",
"0:11:50.100": "don't know whether they're positive or",
"0:11:51.630": "negative right to learn a lot about how",
"0:11:53.279": "movie reviews are written so for all of",
"0:11:54.720": "this pre training and all of this",
"0:11:56.279": "language model fine-tuning we don't need",
"0:11:58.110": "any labels at all",
"0:11:59.130": "it's what the researcher Yan Lacan calls",
"0:12:02.640": "self supervised learning in other words",
"0:12:05.220": "it's a classic supervisor model we have",
"0:12:07.589": "labels",
"0:12:08.250": "right but the labels are not things that",
"0:12:09.990": "somebody else have created they're kind",
"0:12:11.730": "of built into the data set itself so",
"0:12:14.399": "this is really really neat because at",
"0:12:16.410": "this point we've now got something",
"0:12:17.670": "that's good at understanding movie",
"0:12:19.319": "reviews and we can fine-tune that with",
"0:12:22.500": "transfer learning to do the thing we",
"0:12:24.449": "want to do which in this case is to",
"0:12:26.519": "classify movie reviews to be positive or",
"0:12:28.380": "negative and so my hope was when I tried",
"0:12:30.839": "this last year that at that point 25,000",
"0:12:33.959": "ones and zeros would be enough feedback",
"0:12:36.329": "to fine-tune that model and it turned",
"0:12:39.180": "out it absolutely was all right Rachel",
"0:12:43.079": "let's go with a question does the",
"0:12:47.970": "language model approach work for text in",
"0:12:50.100": "forums that are informal English",
"0:12:51.839": "misspelled words are slang or short form",
"0:12:54.540": "like S six instead of Samsung S six yes",
"0:13:01.290": "absolutely it does particularly if you",
"0:13:04.079": "start with your wikitext model and then",
"0:13:07.290": "fine tune it with your we call it a",
"0:13:09.390": "target corpus",
"0:13:10.600": "so your tech or purse is just a bunch of",
"0:13:12.310": "documents right could be emails or",
"0:13:15.009": "tweets or medical reports or whatever so",
"0:13:19.060": "you could fine tune it so it can learn a",
"0:13:23.230": "bit about the specifics of the slang if",
"0:13:25.240": "you know or abbreviations or whatever",
"0:13:27.550": "that didn't appear in the full corpus",
"0:13:29.500": "and so interestingly this is one of the",
"0:13:32.019": "big things that people were surprised",
"0:13:33.490": "about when we did this research last",
"0:13:35.139": "year",
"0:13:35.529": "people thought that learning from",
"0:13:37.930": "something like Wikipedia wouldn't be",
"0:13:40.089": "that helpful because it's not that",
"0:13:42.009": "representative of how people tend to",
"0:13:43.360": "write but it turns out it's extremely",
"0:13:45.399": "helpful because there's a much bigger",
"0:13:47.319": "difference between Wikipedia and random",
"0:13:50.410": "words than there is between like",
"0:13:52.329": "wikipedia and read it say so it kind of",
"0:13:55.959": "gets you 99% of the way there",
"0:14:01.230": "so these language models themselves can",
"0:14:05.290": "be quite powerful so for example there",
"0:14:06.819": "was a blog post from what are they",
"0:14:10.779": "called SwiftKey swiftlet SwiftKey the",
"0:14:15.069": "folks that do the mobile phone",
"0:14:17.079": "predictive text keyboard and they",
"0:14:19.300": "described how they kind of rewrote their",
"0:14:22.620": "their underlying model to use neural",
"0:14:25.360": "nets so and now this was a year or two",
"0:14:27.639": "ago now most phone keyboards seem to do",
"0:14:30.160": "this you'll be typing away on your",
"0:14:31.180": "mobile phone and in the predictions",
"0:14:33.160": "there'll be something telling you what",
"0:14:34.420": "words you might want next so that's a",
"0:14:36.130": "language model in your phone another",
"0:14:39.399": "example was the researcher on drake",
"0:14:41.290": "apathy who's now runs all this stuff at",
"0:14:45.130": "Tesla Beck when he has a PhD student he",
"0:14:48.370": "created a language model of text in",
"0:14:51.639": "latex documents and created these",
"0:14:54.220": "automatic generation of latex documents",
"0:14:57.610": "that then became these kind of",
"0:14:58.990": "automatically generated papers that's",
"0:15:00.850": "pretty cute so we're not really that",
"0:15:04.329": "interested in the output of the language",
"0:15:06.040": "model ourselves we're just interested in",
"0:15:07.810": "it because it's helpful with this",
"0:15:09.730": "process so um we briefly looked at the",
"0:15:16.420": "process last week so that's like just",
"0:15:18.730": "have a reminder right that the basic",
"0:15:21.399": "process is we're going to start with",
"0:15:23.300": "the the data in some format so for",
"0:15:27.290": "example we've prepared a little IMDB",
"0:15:29.330": "sample that you can use where it's in",
"0:15:30.950": "CSV file so you can read it in with",
"0:15:33.020": "pandas and see there's negative or",
"0:15:35.690": "positive the text of each movie review",
"0:15:38.060": "and boolean of is it in the validation",
"0:15:40.790": "set or the training set so there's an",
"0:15:43.010": "example of a movie review and so you can",
"0:15:45.590": "just go text date a bunch from CSV to",
"0:15:47.750": "grab a language model specific data",
"0:15:51.110": "bunch and then you can create a learner",
"0:15:52.760": "from that in the usual way and fit it",
"0:15:54.760": "you can save there's a data bunch which",
"0:15:58.730": "means that the pre-processing that is",
"0:16:00.440": "done you don't have to do it again you",
"0:16:02.210": "can just load it so what goes on behind",
"0:16:07.040": "the scenes well what happens behind the",
"0:16:09.350": "scenes if we now load it as a",
"0:16:11.000": "classification data bunch that's going",
"0:16:13.490": "to allow us to see the labels as well",
"0:16:15.700": "then as we described it basically",
"0:16:18.470": "creates a separate unit we call it a",
"0:16:21.290": "token for each separate part of a word",
"0:16:24.830": "so most of them are just small words but",
"0:16:27.290": "sometimes if it's like an apostrophe s",
"0:16:28.880": "from its you know get its own token",
"0:16:33.010": "every bit of punctuation tends to get",
"0:16:35.510": "its own pro cone like a comma or a",
"0:16:36.980": "full-stop and so forth and then the next",
"0:16:43.190": "thing that we do is a numerical ization",
"0:16:45.290": "which is where we find what are all of",
"0:16:47.810": "the unique tokens that appear here and",
"0:16:52.100": "we create a big list of them here's the",
"0:16:53.990": "first ten in order of frequency and that",
"0:16:55.880": "big list of unique possible tokens is",
"0:16:58.790": "called the vocabulary no it's called a",
"0:17:00.350": "vocab and so what we then do is we",
"0:17:02.930": "replace the tokens with the ID of where",
"0:17:08.660": "is that token in the vocab okay and that",
"0:17:11.150": "that's numerical ization here's the",
"0:17:14.990": "thing though as you'll learn every word",
"0:17:18.260": "in our vocabulary and so to avoid that",
"0:17:26.630": "weight matrix getting too huge we",
"0:17:29.750": "restrict the vocab to no more than by",
"0:17:33.500": "default 60,000 words and if a word",
"0:17:36.230": "doesn't",
"0:17:36.770": "appear more than two times we don't put",
"0:17:38.990": "it in the vocab either so we kind of",
"0:17:40.820": "keep the vocab to a reasonable size in",
"0:17:43.550": "that way and so when you see these xx",
"0:17:48.590": "UNK that's an unknown token so when you",
"0:17:53.510": "see those unknown tokens it just means",
"0:17:55.309": "this was something that was not a common",
"0:18:00.350": "enough word to appear in our vocab okay",
"0:18:04.670": "so there is the numerical lowest version",
"0:18:06.590": "we also have a couple of other special",
"0:18:08.420": "tokens like XX field this is a special",
"0:18:12.800": "thing where if you've got like title",
"0:18:15.200": "summary abstract body like separate",
"0:18:18.230": "parts of a document each one will get a",
"0:18:20.240": "separate field and so they will get",
"0:18:21.860": "numbered also you'll find if there's",
"0:18:24.170": "something in all caps it gets lower",
"0:18:25.790": "cased and a token called xx cap will get",
"0:18:28.010": "added to it personally I more often use",
"0:18:34.520": "the data block API because you get kind",
"0:18:38.360": "of there's less to remember about",
"0:18:40.010": "exactly what data bunch to use and what",
"0:18:41.630": "parameters and so forth and it can be a",
"0:18:43.700": "bit more flexible so another approach to",
"0:18:45.860": "doing this is to just decide what kind",
"0:18:48.860": "of list you're creating so what's your",
"0:18:50.960": "independent variable so in this case my",
"0:18:52.910": "independent variable is text",
"0:18:54.770": "what is it coming from a CSV how do you",
"0:18:57.740": "want to split it into validation versus",
"0:19:00.290": "training so in this case column number",
"0:19:02.720": "two was the is validation flag how do",
"0:19:06.530": "you want to label it with positive or",
"0:19:09.559": "negative sentiment for example so column",
"0:19:11.420": "0 had that and then turn that into a",
"0:19:13.460": "database that's going to do the same",
"0:19:15.050": "thing okay",
"0:19:18.890": "so now let's grab the whole data set",
"0:19:23.480": "which has 25,000 reviews in trading",
"0:19:26.679": "25,000 reviews in validation and then",
"0:19:29.870": "50,000 what they call unsupervised movie",
"0:19:32.870": "reviews so fifty thousand movie reviews",
"0:19:34.640": "that haven't been scored at all so there",
"0:19:39.350": "it is positive negative unsupervised so",
"0:19:45.380": "we're going to start as we described",
"0:19:49.000": "with the language model now the good",
"0:19:52.190": "news is we don't have to train the",
"0:19:53.540": "wikitext 103 language model not that",
"0:19:56.330": "it's difficult you can use exactly the",
"0:19:57.950": "same steps you see here just download",
"0:19:59.780": "the wiki text 103 corpus and run the",
"0:20:03.830": "same code but it takes two or three days",
"0:20:06.620": "on a decent GPU so not much point you",
"0:20:10.160": "doing it you may as well start with",
"0:20:11.720": "hours even if you've got a big corpus of",
"0:20:13.940": "like medical documents or legal",
"0:20:15.620": "documents you should still start with",
"0:20:17.360": "wikitext 103 like there's just no reason",
"0:20:19.520": "to start with random weights it's always",
"0:20:21.800": "good to use transfer learning if you can",
"0:20:26.590": "so we're going to start then at this",
"0:20:29.030": "point which is fine-tuning our IMDB",
"0:20:32.030": "language language model so we can say",
"0:20:34.220": "okay it's a list of text files and the",
"0:20:36.679": "full IMDB actually is not in a CSV each",
"0:20:40.929": "each document is a separate text file so",
"0:20:43.910": "that's why we use a different",
"0:20:44.630": "constructor for our independent variable",
"0:20:46.640": "text files list say where it is and in",
"0:20:49.730": "this case we have to make sure we just",
"0:20:50.960": "don't include the train and test folders",
"0:20:52.820": "and we randomly split it by 0.1 now this",
"0:20:58.820": "is interesting",
"0:20:59.420": "10% why are we randomly splitting it by",
"0:21:01.610": "10% rather than using the predefined",
"0:21:03.770": "train and test they gave us this is one",
"0:21:06.679": "of the cool things about transfer",
"0:21:07.910": "learning even though our test set or a",
"0:21:11.030": "validation set has to be held aside it's",
"0:21:13.670": "actually only the labels that we have to",
"0:21:16.100": "keep aside so we're not allowed to use",
"0:21:17.840": "the labels and the test set so if you",
"0:21:20.030": "think about saying like a capital",
"0:21:20.929": "competition you certainly can't use the",
"0:21:22.730": "labels because they don't even give them",
"0:21:24.020": "to you",
"0:21:24.440": "but you can certainly use the",
"0:21:26.390": "independent variables so in this case",
"0:21:28.220": "you could absolutely use the text that",
"0:21:30.920": "is in the the test set to train your",
"0:21:33.530": "language model so this is a good trick",
"0:21:35.390": "right is actually when you do the",
"0:21:36.950": "language model concatenate the training",
"0:21:39.559": "and test set together and then just let",
"0:21:42.080": "out a smaller validation set so you've",
"0:21:44.540": "got more data to train your language",
"0:21:47.000": "model so that's a little trick and so if",
"0:21:49.700": "you're doing NLP stuff on kaggle for",
"0:21:52.400": "example or you know you've just got a",
"0:21:54.800": "smaller subset of labelled data make",
"0:21:58.040": "sure that you use all of the text you",
"0:22:00.140": "have to train",
"0:22:01.100": "your language model because there's no",
"0:22:02.240": "reason not to how are we going to label",
"0:22:05.299": "it well remember a language model kind",
"0:22:07.400": "of has its own labels so the text itself",
"0:22:09.500": "is label so label for language model",
"0:22:11.690": "does that for us and create a data bunch",
"0:22:14.419": "and save it and that takes a few minutes",
"0:22:17.230": "to tokenize and numerical s so since it",
"0:22:23.000": "takes a few minutes we save it later on",
"0:22:24.530": "you can just load it no need to run that",
"0:22:26.360": "again so here's what it looks like and",
"0:22:30.500": "at this point things are going to look",
"0:22:32.240": "very familiar we create a learner but",
"0:22:35.809": "instead of creating a CNN learner we're",
"0:22:39.860": "going to create a language model learner",
"0:22:42.400": "so behind the scenes this is actually",
"0:22:45.140": "not going to create a CNN a",
"0:22:46.520": "convolutional neural network it's going",
"0:22:48.590": "to create an AR and in a recurrent",
"0:22:50.390": "neural network so we're going to be",
"0:22:51.860": "learning exactly how they're built over",
"0:22:53.840": "the coming lessons but in short they're",
"0:22:57.080": "the same basic structure the input goes",
"0:22:59.900": "into a weight matrix a matrix multiply",
"0:23:03.200": "that then you replace the negatives with",
"0:23:05.659": "zeroes and it goes into another matrix",
"0:23:07.130": "multiply and so forth a bunch of times",
"0:23:09.320": "so it's the same basic structure so as",
"0:23:15.020": "usual when we create a learner you have",
"0:23:17.870": "to pass in two things the data so here's",
"0:23:20.210": "our language model data and in this case",
"0:23:24.070": "what pre-trade model we want to use and",
"0:23:26.950": "so here the pre-trade model is the",
"0:23:29.929": "wikitext 1:03 model that will be",
"0:23:32.150": "downloaded for you from first AI if you",
"0:23:34.669": "haven't used it before just like the",
"0:23:36.230": "same thing with things like image net",
"0:23:38.299": "pre-trained models are downloaded for",
"0:23:39.710": "you this here sets the amount of dropout",
"0:23:44.450": "we haven't talked about that yet we've",
"0:23:46.429": "talked briefly about this idea that",
"0:23:47.840": "there's something called regularization",
"0:23:48.740": "and you can reduce the regularization to",
"0:23:51.049": "avoid underfitting",
"0:23:52.429": "so for now just know that by using a",
"0:23:55.580": "number lower than 1 is because when I",
"0:23:58.400": "first tried to run this I was under",
"0:24:00.169": "fitting and so if you reduced that",
"0:24:01.940": "number then it will avoid under fitting",
"0:24:05.950": "okay so we've got a loner we can LR find",
"0:24:08.419": "looks pretty standard and so then we can",
"0:24:12.290": "see it one cycle",
"0:24:13.940": "so what's happening here is we are just",
"0:24:16.720": "fine-tuning the last layers so normally",
"0:24:22.370": "after we fine-tune the last layers the",
"0:24:25.490": "next thing we do is we go",
"0:24:27.370": "unfreeze and train the whole thing and",
"0:24:32.420": "so here it is",
"0:24:33.200": "unfreeze and train the whole thing and",
"0:24:35.780": "as you can see even on a pretty beefy",
"0:24:37.310": "GPU that takes 2 or 3 hours and in fact",
"0:24:41.480": "I'm still under fitting all right so I",
"0:24:45.050": "probably tonight I might train it",
"0:24:46.730": "overnight and train to a little bit",
"0:24:47.870": "better because you can see oh I guess",
"0:24:52.130": "I'm not underfitting oh I'm guessing I",
"0:24:54.950": "could probably train this a bit longer",
"0:24:56.300": "because you can see the accuracy hasn't",
"0:24:57.800": "started going down again that's I",
"0:24:59.810": "wouldn't mind trying to train that a bit",
"0:25:01.280": "longer but the accuracy it's interesting",
"0:25:03.830": "point three means you know we're",
"0:25:06.470": "guessing the next word of the movie",
"0:25:08.360": "review correctly about a third of the",
"0:25:10.070": "time so that sounds like a pretty high",
"0:25:12.500": "number the idea that you can actually",
"0:25:13.910": "guess the next word that often so it's a",
"0:25:17.840": "good sign that my language model is",
"0:25:20.150": "doing pretty well for kind of more",
"0:25:23.690": "limited domain documents like medical",
"0:25:27.620": "transcripts and legal transcripts you'll",
"0:25:29.990": "often find this accuracy Gertz gets a",
"0:25:32.240": "lot higher so sometimes this can be even",
"0:25:35.600": "50% or more but you know point three or",
"0:25:39.530": "more is is pretty good so you can now",
"0:25:44.920": "run learn dot predict and pass in the",
"0:25:48.530": "start of a sentence and it will try and",
"0:25:50.990": "finish off that sentence for you now I",
"0:25:53.600": "should mention we this is not designed",
"0:25:56.390": "to be a good text generation system this",
"0:25:59.780": "is really more designed to kind of check",
"0:26:01.280": "that it seems to be creating something",
"0:26:03.350": "that's vaguely sensible there's a lot of",
"0:26:06.200": "tricks that you can use to generate much",
"0:26:08.900": "higher quality text none of which we're",
"0:26:11.030": "using here right but you can kind of see",
"0:26:14.240": "that it's it's it's you know certainly",
"0:26:19.520": "not random words that it's generating it",
"0:26:21.260": "sounds vaguely English like even though",
"0:26:23.270": "it doesn't make any sense",
"0:26:25.460": "so at this point we have a movie review",
"0:26:30.500": "model so now we're gonna save that in",
"0:26:38.000": "order to load it into our classifier to",
"0:26:41.870": "be a pre trained model for the",
"0:26:43.070": "classifier but I actually don't want to",
"0:26:44.900": "save the whole thing a lot of this you",
"0:26:47.420": "know kind of the second half as we'll",
"0:26:48.980": "learn the second half of the language",
"0:26:50.570": "model is all about predicting the next",
"0:26:53.210": "word rather about rather than about",
"0:26:55.190": "understanding the sentence so far so the",
"0:26:58.040": "bit which is specifically about",
"0:26:59.360": "understanding the sentence so far is",
"0:27:01.160": "called the encoder so I just saved that",
"0:27:04.370": "alright so and again we're going to",
"0:27:06.110": "learn the details of this there coming",
"0:27:08.090": "weeks",
"0:27:09.320": "Rena's going to save the encoder so the",
"0:27:11.390": "bit that understands the sentence rather",
"0:27:14.270": "than the bit that generates the word so",
"0:27:18.710": "now we're ready to create our classifier",
"0:27:20.840": "so step one as per usual is to create a",
"0:27:23.390": "data bunch and we're going to do",
"0:27:24.920": "basically exactly the same thing bring",
"0:27:26.960": "it in okay and here's our path but we",
"0:27:30.500": "want to make sure that it uses exactly",
"0:27:32.930": "the same vocab that are used for the",
"0:27:35.060": "language model if word number 10 was ver",
"0:27:38.690": "in the language model we need to make",
"0:27:40.820": "sure that word number 10 is the in the",
"0:27:43.040": "classifier because otherwise the",
"0:27:45.980": "pre-trained model is going to be totally",
"0:27:48.410": "meaningless so that's why we pass in the",
"0:27:51.650": "vocab from the language model to make",
"0:27:54.020": "sure that this data bunch is going to",
"0:27:55.400": "have exactly the same vocab that's an",
"0:27:57.290": "important step split by folder and this",
"0:28:01.580": "time label so remember the last time we",
"0:28:03.950": "had split randomly okay but this time we",
"0:28:07.130": "need to make sure that the labels of the",
"0:28:08.930": "test set are not touched so we split by",
"0:28:11.000": "folder and then this time we label it",
"0:28:14.210": "not for a language model but we label",
"0:28:16.120": "these classes and then finally create a",
"0:28:21.440": "data bunch and remember sometimes you'll",
"0:28:24.890": "find that you ran out of GPU memory this",
"0:28:27.860": "will very often happen to you if you so",
"0:28:30.950": "I was running this in an 11 gig machine",
"0:28:32.840": "so you should make sure this numbers a",
"0:28:34.460": "bit lower if you run out of memory you",
"0:28:36.620": "may also want to make sure you restart",
"0:28:38.550": "the notebook and kind of started just",
"0:28:40.320": "from here so batch size 50 is as high as",
"0:28:43.440": "I could get on an 11 gig card if you are",
"0:28:45.960": "using a p2 or p3 on Amazon or the kad on",
"0:28:52.160": "Google for example I think you'll get 16",
"0:28:54.690": "gigs so you might be able to make this a",
"0:28:55.980": "bit higher cut it up to 64 so you can",
"0:28:58.950": "find whatever batch size fits on your",
"0:29:01.050": "card so here's our data bunch as we saw",
"0:29:05.460": "before and the labels so this time",
"0:29:08.550": "rather than creating a language model",
"0:29:11.070": "learner we're creating a text classifier",
"0:29:13.110": "learner but again same thing pass in the",
"0:29:15.240": "data that we want figure out how much",
"0:29:17.520": "regularization we need again if you're",
"0:29:19.790": "overfitting then you can increase this",
"0:29:22.800": "number if you're under fitting you can",
"0:29:24.090": "decrease the number and most importantly",
"0:29:26.820": "load in a pre trained model and remember",
"0:29:29.700": "specifically it's just this this half of",
"0:29:31.710": "the model called the encoder which is",
"0:29:33.630": "the bit that we want to load in and",
"0:29:36.180": "freeze now I find find the learning rate",
"0:29:40.770": "and fit for a little bit and we're",
"0:29:43.890": "already up nearly to 92% accuracy after",
"0:29:47.240": "less than three minutes of training so",
"0:29:50.220": "this is a nice thing in your particular",
"0:29:53.010": "domain whether it be law or medicine or",
"0:29:57.060": "journalism or government or whatever you",
"0:29:59.880": "probably only need to train your domains",
"0:30:02.460": "language model once and that might take",
"0:30:06.540": "you know overnight to Train well but",
"0:30:10.170": "once you've got it you can now very",
"0:30:12.360": "quickly create all kinds of different",
"0:30:14.400": "classifiers and models with that in you",
"0:30:17.850": "know in this case already a pretty good",
"0:30:19.290": "model after three minutes right so so",
"0:30:22.290": "when you first start doing this you",
"0:30:23.640": "might find it a bit it's like annoying",
"0:30:26.340": "that your first models take four hours",
"0:30:29.040": "more or more to create that language",
"0:30:31.260": "model but the key thing to remember is",
"0:30:32.970": "you only have to do that once for your",
"0:30:35.280": "entire kind of domain of stuff that",
"0:30:37.110": "you're interested in and then you can",
"0:30:38.790": "build lots of different classifiers and",
"0:30:41.010": "other models on top of that in a few",
"0:30:42.480": "minutes okay",
"0:30:45.740": "all right so we can save that to make",
"0:30:48.150": "sure you directly run it again and then",
"0:30:49.950": "here's something interesting now I'm",
"0:30:51.300": "gonna explain this more",
"0:30:52.440": "just a few minutes I'm not gonna say",
"0:30:54.720": "unfreeze instead of going to save fries",
"0:30:57.240": "- and what that says is unfreeze the",
"0:31:00.180": "last two layers don't unfreeze the whole",
"0:31:03.000": "thing and so we've just found it really",
"0:31:05.310": "helps with these text classification not",
"0:31:08.550": "to unfreeze the whole thing but to",
"0:31:10.200": "unfreeze one layer at a time",
"0:31:12.330": "so unfreeze the last two layers train it",
"0:31:15.150": "a little bit more and freeze the next",
"0:31:17.970": "layer again train a little bit more",
"0:31:20.510": "unfreeze the whole thing train it a",
"0:31:23.010": "little bit more you'll also see I'm",
"0:31:25.680": "passing in this thing Momentum's equals",
"0:31:28.440": "point eight point seven we're going to",
"0:31:30.840": "learn exactly what that means in the",
"0:31:33.450": "next week or two probably next week but",
"0:31:36.120": "for now and we may even automate it so",
"0:31:39.210": "maybe by the time you watch the video of",
"0:31:40.710": "this this won't even be necessary",
"0:31:41.850": "anymore basically we found for training",
"0:31:46.020": "recurrent neural networks our own ends",
"0:31:48.420": "it really helps to decrease the momentum",
"0:31:51.420": "a little bit so that's what that is",
"0:31:54.630": "so that gets us a ninety four point for",
"0:31:57.470": "accuracy after about half an hour or",
"0:32:00.660": "less of training actually quite a lot",
"0:32:02.550": "less of training the actual classifier",
"0:32:05.240": "and we can actually get this quite a bit",
"0:32:09.930": "better with a few tricks I don't know if",
"0:32:12.330": "we learned all the tricks this part it",
"0:32:14.490": "might be next part but even this very",
"0:32:16.410": "simple kind of standard approach is",
"0:32:19.440": "pretty great if we compare it to last",
"0:32:23.490": "year's state of the art on IMDb's is",
"0:32:26.880": "from The Cove paper from McCann at L at",
"0:32:30.030": "Salesforce Research their paper was",
"0:32:33.600": "ninety one point eight percent accurate",
"0:32:35.460": "in the best paper they could find they",
"0:32:38.430": "found a fairly domain-specific sentiment",
"0:32:41.310": "in analysis paper from 2017 they've got",
"0:32:44.100": "ninety four point one and here we've got",
"0:32:47.520": "ninety four point four and the best",
"0:32:50.250": "models I've been able to build since",
"0:32:51.750": "have been about ninety five ninety five",
"0:32:54.090": "point one so if you're looking to do",
"0:32:57.420": "text classification this you know really",
"0:32:59.990": "standardized transfer learning approach",
"0:33:03.509": "works work super well any questions",
"0:33:06.820": "Rachel okay so that was that was an LP",
"0:33:14.139": "and we'll be learning more about NLP",
"0:33:15.879": "later in this course but now I wanted to",
"0:33:18.700": "switch over and look at tabular now",
"0:33:22.720": "tabular data is pretty interesting",
"0:33:24.609": "because it's the stuff that for a lot of",
"0:33:27.429": "you is actually what you use day-to-day",
"0:33:29.320": "at work in spreadsheets and relational",
"0:33:32.559": "databases just come close I guess hey so",
"0:33:38.619": "where does the magic number of 2.6 to",
"0:33:41.950": "the fourth in the learning rate come",
"0:33:44.049": "from yeah good question so the learning",
"0:33:50.590": "rate is various various things divided",
"0:33:57.460": "by 2.6 to the fourth",
"0:34:00.549": "the reason it's to the fourth you will",
"0:34:03.820": "learn about at the about the end of",
"0:34:06.129": "today so let's focus on the 2.6 why 2.6",
"0:34:13.589": "basically this as we're as we're going",
"0:34:16.690": "to see in more detail later day this",
"0:34:18.730": "this number there are the difference",
"0:34:20.980": "between the bottom of the slice and the",
"0:34:22.540": "top of the slice is basically what's the",
"0:34:24.399": "difference between how quickly the",
"0:34:26.109": "lowest layer of the model learns versus",
"0:34:28.540": "the highest layer of their model learns",
"0:34:30.720": "so this is called discriminative",
"0:34:32.649": "learning rates and so really the",
"0:34:34.450": "question is like as you go from layer to",
"0:34:36.970": "layer",
"0:34:37.540": "how much do I decrease the learning rate",
"0:34:39.579": "by when we found out that for NLP are n",
"0:34:44.260": "ends that the answer is 2.6 how do we",
"0:34:47.470": "find out that it's 2.6 I ran lots and",
"0:34:51.309": "lots of different models like a year ago",
"0:34:54.700": "or so using lots of different sets of",
"0:34:57.190": "hyper parameters of various types drop",
"0:34:59.170": "out learning rates and discriminative",
"0:35:01.630": "learning rate and so forth and then I",
"0:35:03.430": "created something called a random forest",
"0:35:05.170": "which is the kind of model where I",
"0:35:07.299": "attempted to predict how accurate my NLP",
"0:35:10.329": "classifier would be based on the hyper",
"0:35:12.730": "parameters and then I",
"0:35:15.880": "used random forest interpretation",
"0:35:17.470": "methods to basically figure out what the",
"0:35:21.040": "optimal parameter settings were and I",
"0:35:23.500": "found out that the answer for this",
"0:35:25.000": "number was 2.6 so that's actually not",
"0:35:28.690": "something I've published or I don't",
"0:35:30.820": "think I've even talked about it before",
"0:35:31.780": "so there's a new piece of information",
"0:35:33.790": "you can actually a few months after I",
"0:35:38.260": "did this I think David marady and",
"0:35:41.620": "somebody else did publish a paper",
"0:35:44.050": "describing a similar approach so the",
"0:35:46.000": "basic idea may be out there already some",
"0:35:49.780": "of that idea comes from a researcher",
"0:35:52.090": "named Frank Hatter and one of his",
"0:35:54.490": "collaborators they did some interesting",
"0:35:56.800": "work showing how you can use random",
"0:35:58.360": "forests to actually find optimal",
"0:36:01.030": "hyperparameters so it's kind of a neat",
"0:36:03.370": "trick you know a lot of people are very",
"0:36:06.490": "interested in this in court auto ml",
"0:36:08.110": "which is this idea of like building",
"0:36:10.450": "models to figure out how to train your",
"0:36:12.190": "model we're not big fans of it on the",
"0:36:15.580": "whole but we do find that building",
"0:36:18.490": "models to better understand how your",
"0:36:21.640": "hyper parameters work and then finding",
"0:36:23.380": "like those rules of thumb like oh",
"0:36:25.030": "basically it can always be two-point-six",
"0:36:27.600": "quite helpful so that's just something",
"0:36:31.780": "we're kind of been playing with okay so",
"0:36:40.380": "yeah so let's talk about tabular data so",
"0:36:42.880": "tabular data such as you might see in a",
"0:36:46.450": "spreadsheet or a relational database you",
"0:36:48.490": "know or a financial report it can",
"0:36:51.370": "contain all kinds of different things it",
"0:36:56.290": "can contain all kinds of different",
"0:36:57.310": "things and I kind of tried to make a",
"0:36:58.570": "little list of some of the kinds of",
"0:36:59.860": "things that I've seen tabular data",
"0:37:02.410": "analysis used for using neural nets for",
"0:37:07.930": "analyzing tabular data is or at least",
"0:37:11.980": "last year when I first presented this",
"0:37:13.650": "was maybe we started this two years ago",
"0:37:16.990": "yeah when we first presented this people",
"0:37:20.110": "were deeply skeptical and they thought",
"0:37:21.610": "it was a terrible idea to use neural",
"0:37:23.650": "nets to analyze tabular data because",
"0:37:25.870": "like everybody knows that you should use",
"0:37:28.369": "logistic regression or random forests or",
"0:37:30.529": "gradient boosting machines all of which",
"0:37:32.539": "have their place but certain certain",
"0:37:34.190": "types of things but since that time you",
"0:37:37.219": "know it's become clear that the commonly",
"0:37:42.319": "held wisdom is is wrong it's not true",
"0:37:45.440": "that neural nets are not useful for",
"0:37:46.819": "tabular data in fact the extremely",
"0:37:48.859": "useful now we've shown this in in quite",
"0:37:51.170": "a few of our courses but what's really",
"0:37:54.529": "kind of also helped is that some really",
"0:37:58.910": "effective organizations have started",
"0:38:01.759": "publishing papers and posts and stuff",
"0:38:04.009": "describing how they've been using neural",
"0:38:05.869": "nets for analyzing tabular data um one",
"0:38:09.259": "of the key things that comes up again",
"0:38:11.539": "and again is that although feature",
"0:38:14.779": "engineering doesn't go away it certainly",
"0:38:17.450": "becomes simpler right so Pinterest for",
"0:38:19.819": "example replaced the gradient boosting",
"0:38:21.349": "machines that they were using to decide",
"0:38:23.420": "how to put stuff on their homepage with",
"0:38:26.630": "neural nets and they presented at a",
"0:38:29.029": "conference this approach and they",
"0:38:30.440": "described how it really made engineering",
"0:38:32.930": "a lot easier because a lot of the hand",
"0:38:35.859": "created features weren't necessary",
"0:38:39.049": "anymore you still need some but it was",
"0:38:41.989": "just simpler right so they ended up",
"0:38:43.880": "something that was more accurate and but",
"0:38:46.099": "perhaps even more importantly it",
"0:38:47.660": "required less maintenance right so I",
"0:38:52.219": "wouldn't say you know it's the only tool",
"0:38:55.369": "that you need in your toolbox for",
"0:38:56.779": "analyzing tabular data but you know",
"0:38:58.849": "where else I used to use random forests",
"0:39:02.440": "99% of the time when I was doing machine",
"0:39:05.239": "learning with tabular data I knew or",
"0:39:08.420": "Nets 90% of the time it's it's it's kind",
"0:39:12.769": "of my standard first go-to approach now",
"0:39:15.049": "and it tends to be pretty reliable",
"0:39:18.079": "pretty effective one of the things",
"0:39:21.289": "that's made it difficult is that until",
"0:39:23.089": "now there hasn't been an easy way to",
"0:39:27.799": "kind of create and train tabular neural",
"0:39:29.930": "Nets like nobody's really made it",
"0:39:31.369": "available on a library so we've actually",
"0:39:33.799": "just created fast AI tabula and I think",
"0:39:39.920": "this is pretty",
"0:39:40.390": "the first time that's become really easy",
"0:39:42.000": "to to use neural nets with tabular data",
"0:39:46.990": "and so let me show you how easy it is",
"0:39:50.910": "this is actually coming directly from",
"0:39:53.559": "the examples folder in the FASTA guy",
"0:39:56.410": "repo I haven't changed at all and as per",
"0:39:59.440": "usual as well as importing first AI you",
"0:40:02.140": "should import your application so in",
"0:40:04.269": "this case it's tabular we assume that",
"0:40:09.880": "your data is in a panda's data frame a",
"0:40:13.089": "panda's data frame is kind of the",
"0:40:15.609": "standard format for tabular data in",
"0:40:17.559": "Python and it's lots of ways to get it",
"0:40:20.710": "in there but probably the most common",
"0:40:22.089": "might be PD don't read CSV but you know",
"0:40:25.510": "whatever your data is in you can",
"0:40:27.039": "probably get it into a panda's data",
"0:40:28.150": "frame easily enough okay what are the",
"0:40:41.559": "10% of cases where you would not default",
"0:40:44.170": "to neural nets good question I guess I",
"0:40:53.710": "still tend to kind of give them a try",
"0:40:57.299": "but yeah I don't know it's it's it's",
"0:41:03.579": "kind of like as you do things for a",
"0:41:05.259": "while you start to get a sense of the",
"0:41:07.809": "areas where things don't quite work as",
"0:41:10.420": "well I have to think about that during",
"0:41:11.710": "the week I don't think I have a rule of",
"0:41:13.059": "thumb but I would say you may as well",
"0:41:15.910": "try both like I would say try a random",
"0:41:19.000": "forest and try on your own net they're",
"0:41:20.410": "both pretty quick and easy to run and",
"0:41:21.609": "see how it looks and if they're roughly",
"0:41:25.869": "similar I might go and dig into H and",
"0:41:27.880": "see if I can make them better and better",
"0:41:29.019": "but you know if the random forest is",
"0:41:31.180": "doing way better I'd probably just stick",
"0:41:33.309": "with that use whatever works so I",
"0:41:42.000": "currently have the wrong notebook in the",
"0:41:45.450": "lesson repo so I'll update it after the",
"0:41:48.060": "class so sorry about that so we start",
"0:41:53.430": "with the data in a data frame and so",
"0:41:57.330": "we've got a little thing adult sample",
"0:42:02.849": "it's a it's a classic old data set I",
"0:42:05.369": "have to dig up the citation for it so",
"0:42:06.960": "I've got put it in this sum in this",
"0:42:08.640": "notebook but it's a pretty small simple",
"0:42:11.369": "old data set that's good for",
"0:42:13.670": "experimenting with basically and it's",
"0:42:16.590": "CSV file so you can read it into a data",
"0:42:19.320": "frame with pandas read CSV PD don't read",
"0:42:22.140": "CSV if your data is in a relational",
"0:42:26.250": "database pandas can read from that if",
"0:42:28.200": "it's in spark or Hadoop pandas can read",
"0:42:30.630": "from that pandas can read from most",
"0:42:32.160": "stuff that you can throw at it so that's",
"0:42:34.650": "why we kind of use it as a default",
"0:42:37.020": "starting point and as per usual you know",
"0:42:41.340": "it's I think it's nice to use the data",
"0:42:43.710": "block API and so in this case the list",
"0:42:48.900": "that we're trying to create is a tabular",
"0:42:51.060": "list and we're going to create it from a",
"0:42:53.400": "data frame and so you can tell it what",
"0:42:55.650": "the data frame is and what the path that",
"0:42:57.780": "you're going to use to kind of save",
"0:42:58.800": "models and intermediate steps is and",
"0:43:00.710": "then you need to tell it what are your",
"0:43:03.450": "categorical variables and what are your",
"0:43:05.940": "continuous variables so we're going to",
"0:43:08.190": "be learning a lot more about what that",
"0:43:10.109": "means to the neural net next week but",
"0:43:14.430": "for now the quick summary is this your",
"0:43:17.880": "independent variables are the things",
"0:43:19.560": "that you're using to make predictions",
"0:43:21.060": "with right so things like education and",
"0:43:24.000": "marital status and age and so forth some",
"0:43:30.030": "of those variables like age are",
"0:43:33.750": "basically numbers they could be any",
"0:43:36.210": "number you know you could be thirteen",
"0:43:38.609": "point three six years old or nineteen",
"0:43:40.770": "point four years old or whatever where",
"0:43:43.140": "else things like marital status options",
"0:43:47.190": "that can be selected from a discrete",
"0:43:49.200": "group married single divorce whatever",
"0:43:52.740": "sometimes those options might be",
"0:43:55.170": "a lot more like occupation there's a lot",
"0:43:57.270": "of possible occupations and sometimes",
"0:44:01.950": "they might be binary could be just true",
"0:44:04.020": "or false but anything which you can",
"0:44:07.200": "select the the answer from a small group",
"0:44:10.380": "of possibilities is called a categorical",
"0:44:13.710": "variable and so we're going to need to",
"0:44:17.099": "use a different approach in the neural",
"0:44:18.809": "net to modeling categorical variables to",
"0:44:21.390": "what we use for continuous variables for",
"0:44:23.220": "categorical variables we're going to be",
"0:44:24.450": "using something called embeddings which",
"0:44:26.280": "we'll be learning about later today for",
"0:44:29.190": "continuous variables they could just be",
"0:44:31.440": "sent into the neural net just like",
"0:44:33.059": "pixels in a neural net can because like",
"0:44:34.980": "pixels in a neural net are already",
"0:44:36.359": "numbers these continuous things are",
"0:44:38.819": "already numbers as well so that's that's",
"0:44:41.640": "easy okay so that's why you have to tell",
"0:44:44.270": "the tabular list from data frame which",
"0:44:50.160": "ones are which there are some other ways",
"0:44:53.130": "to do that by pre-processing them in",
"0:44:55.380": "pandas to make things categorical",
"0:44:58.260": "variables but it's kind of nice to have",
"0:44:59.849": "one API for doing everything you don't",
"0:45:01.680": "have to think too much about it then",
"0:45:05.400": "we've got something which is a lot like",
"0:45:07.880": "transforms in in computer vision",
"0:45:13.309": "transforms in computer vision do things",
"0:45:15.359": "like flip a photo when it's access or",
"0:45:18.329": "turn it a bit or brighten it or",
"0:45:19.829": "normalize it",
"0:45:21.470": "but for tabular data instead of having",
"0:45:26.030": "transforms we have things called",
"0:45:27.750": "processes and they're nearly identical",
"0:45:30.150": "but the key difference which is quite",
"0:45:31.799": "important is that a processor is",
"0:45:34.109": "something that happens ahead of time",
"0:45:36.359": "right so we basically pre-process the",
"0:45:39.059": "data frame rather than doing it as we go",
"0:45:43.049": "right so transformations are really that",
"0:45:46.380": "data augmentation where you want to like",
"0:45:48.180": "randomize it and do it differently each",
"0:45:49.950": "time where else processes the things",
"0:45:52.049": "that you want to do once ahead of time",
"0:45:54.089": "so we have a number of processes in the",
"0:45:58.770": "Farseer library and the ones we're going",
"0:46:00.780": "to use this time are fill missing so",
"0:46:03.420": "that's going to look for missing values",
"0:46:07.450": "and deal with them some way we're going",
"0:46:11.320": "to find categorical variables and turn",
"0:46:14.080": "them into pandas categories and we're",
"0:46:16.930": "going to do normalization ahead of time",
"0:46:18.610": "which is to take continuous variables",
"0:46:20.260": "and subtract their mean and divided by",
"0:46:23.530": "them by their standard deviation so",
"0:46:25.180": "they're 0 1 variables the way we deal",
"0:46:32.080": "with missing data we'll talk more about",
"0:46:35.100": "next week but in short we replace it",
"0:46:38.350": "with a median and add a new column which",
"0:46:41.140": "is a binary column of saying whether",
"0:46:43.090": "that was missing or not normalization",
"0:46:46.570": "there's an important thing here which is",
"0:46:48.850": "in fact for all of these things whatever",
"0:46:51.490": "you do to the training set you need to",
"0:46:55.690": "do exactly the same thing to the",
"0:46:56.980": "validation set and the test set so",
"0:46:59.470": "whatever you replaced your missing",
"0:47:01.600": "values with you need to replace them",
"0:47:03.250": "with exactly the same thing in the",
"0:47:04.720": "validation set so first AI handles all",
"0:47:06.910": "these details for you they're the kinds",
"0:47:09.460": "of things that if you have to do it",
"0:47:10.360": "manually at least if you like me you'll",
"0:47:12.250": "screw it up",
"0:47:12.970": "lots of times until you finally get it",
"0:47:14.590": "right so that's what these processes",
"0:47:18.490": "here then we're going to split into",
"0:47:23.880": "training versus validation sets and in",
"0:47:27.310": "this case we do it by providing a list",
"0:47:31.300": "of indexes so the index is from 800 to",
"0:47:33.490": "1,000 it's very common I don't quite",
"0:47:36.550": "remember the details of this data set",
"0:47:37.960": "but it's very common for wanting to keep",
"0:47:41.110": "your validation sets to be contiguous",
"0:47:42.730": "groups of things like if they're map",
"0:47:45.280": "tiles there should be the map tiles that",
"0:47:46.870": "are next to each other if their time",
"0:47:49.210": "periods they should be time period you",
"0:47:51.280": "know days that are next to each other if",
"0:47:52.840": "their video frames there should be video",
"0:47:54.640": "frames next to each other",
"0:47:55.720": "because otherwise you're kind of",
"0:47:56.650": "cheating right so it's often a good idea",
"0:47:59.080": "to use split by DX and to grab a range",
"0:48:02.830": "that's next to each other if your data",
"0:48:04.660": "has some kind of structure like that or",
"0:48:06.910": "find some other way to structure it in",
"0:48:08.500": "that way all right so that's now given",
"0:48:12.190": "us a training and a validation set we",
"0:48:14.230": "now need to add labels and in this case",
"0:48:16.480": "the labels can come straight from the",
"0:48:18.040": "data frame we grabbed earlier so we just",
"0:48:19.600": "have to tell it which column it",
"0:48:20.740": "and so the dependent variable is I think",
"0:48:23.530": "it's whether they're making over $50,000",
"0:48:26.430": "salary that's the thing we're trying to",
"0:48:28.630": "predict in this case we'll talk about",
"0:48:32.920": "test sets later but in this case we can",
"0:48:34.900": "have a test set and finally get our data",
"0:48:38.380": "bunch so at that point we have something",
"0:48:42.700": "that looks like this",
"0:48:43.480": "okay so there is our there is our data",
"0:48:49.170": "and then to use it it looks very",
"0:48:53.440": "familiar you get a loner in this case",
"0:48:56.859": "it's a tabular learner passing in the",
"0:48:59.349": "data some information about your",
"0:49:01.180": "architecture and some metrics Andrew",
"0:49:04.750": "then call fit you have some questions",
"0:49:08.770": "all right let's hit the questions how to",
"0:49:15.550": "combine an LP tokenize data with",
"0:49:18.190": "metadata such as tabular data with fast",
"0:49:20.589": "AI for instance for imbd classification",
"0:49:24.250": "how to use information like who the",
"0:49:25.810": "actors are your maid Jean right it",
"0:49:27.880": "cetera",
"0:49:31.349": "yeah we're not quite up for that yet so",
"0:49:33.490": "we need to learn a little bit more about",
"0:49:35.349": "how euronet architecture as well work",
"0:49:38.170": "and but conceptually it's kind of the",
"0:49:42.099": "same as the way we combine categorical",
"0:49:44.349": "variables and continuous variables",
"0:49:45.490": "basically in the neural network you can",
"0:49:47.950": "have two different sets of inputs",
"0:49:52.500": "merging together into some layer could",
"0:49:55.510": "go into an early layer or into a later",
"0:49:57.460": "layer it kind of depends if it's like",
"0:50:00.119": "text and an image and some metadata you",
"0:50:03.460": "probably want the text going into an",
"0:50:04.720": "errand in the image going into a CNN the",
"0:50:07.869": "metadata going into some kind of tabular",
"0:50:09.609": "model like this and then you'd have them",
"0:50:11.230": "basically all concatenated together and",
"0:50:13.119": "then go through some fully connected",
"0:50:14.320": "layers train them into end will probably",
"0:50:18.550": "largely get into that in part two in",
"0:50:20.980": "fact we made entirely get in that into",
"0:50:22.599": "part part two I'm not sure if we have",
"0:50:24.040": "time to cover it in in part one but",
"0:50:27.240": "conceptually it's it's a fairly simple",
"0:50:30.940": "extension of what we'll be learning in",
"0:50:32.440": "the next three weeks",
"0:50:35.339": "next question is do you think things",
"0:50:37.660": "like scikit-learn annex G boost will",
"0:50:40.299": "eventually become outdated will everyone",
"0:50:42.549": "use deep learning tools in the future",
"0:50:44.410": "except for maybe small datasets I have",
"0:50:49.869": "no idea I'm not good at making",
"0:50:51.459": "predictions I I'm not a machine learning",
"0:50:56.529": "model",
"0:50:57.339": "I mean XJ boost is a really nice piece",
"0:51:03.369": "of software there's quite a few really",
"0:51:05.619": "nice pieces of software for gradient",
"0:51:07.059": "boosting in particular they have some",
"0:51:10.329": "really nice features or actually random",
"0:51:11.920": "forests in particular has some really",
"0:51:13.179": "nice features for interpretation which",
"0:51:15.099": "I'm sure will find similar versions for",
"0:51:17.859": "neural nets but they don't necessarily",
"0:51:19.809": "exist yet so I don't know so now they're",
"0:51:25.150": "both useful tools scikit-learn you know",
"0:51:31.390": "is a library that's often used for kind",
"0:51:34.569": "of pre-processing and running models",
"0:51:37.619": "yeah I mean again it's it's hard to",
"0:51:40.479": "predict where things will end up it's",
"0:51:42.489": "it's kind of in some ways it's more",
"0:51:43.900": "focused on some older approaches to",
"0:51:47.099": "modeling but I don't know they keep on",
"0:51:50.679": "adding new things so we'll see I keep",
"0:51:54.160": "trying to incorporate more scikit-learn",
"0:51:55.779": "stuff into fast AI and then I keep",
"0:51:57.609": "finding ways I think I can do it better",
"0:51:59.380": "and I throw it away again so so that's",
"0:52:02.229": "why there's still no scikit-learn",
"0:52:04.049": "dependencies in fast AI I keep finding",
"0:52:07.959": "other ways to do self okay so we're",
"0:52:16.029": "gonna learn what layers equals means",
"0:52:18.359": "either towards the end of class today or",
"0:52:20.769": "the start of class next week but this is",
"0:52:22.959": "where we're basically defining our",
"0:52:24.969": "architecture just like when we chose",
"0:52:26.650": "ResNet 34 or whatever for convinence",
"0:52:31.109": "will look at more about metrics in a",
"0:52:33.369": "moment but just to remind you metrics",
"0:52:35.619": "are just the things that get printed out",
"0:52:36.910": "they don't change our model at all so in",
"0:52:39.579": "this case we're saying I want you to",
"0:52:40.630": "print out the accuracy to see how we're",
"0:52:42.279": "doing",
"0:52:45.440": "okay so that's how to do tabular this is",
"0:52:49.620": "going to work really well because we're",
"0:52:50.790": "going to hit our break soon and the idea",
"0:52:53.520": "was that after three and a half lessons",
"0:52:55.140": "we're going to hit the end of all of the",
"0:52:57.480": "quick overview of applications and then",
"0:52:59.070": "we're going to go down the other side I",
"0:53:00.300": "think we're going to be to the minute",
"0:53:01.860": "we're going to hit it right because the",
"0:53:04.170": "next one is collaborative filtering okay",
"0:53:08.670": "so collaborative filtering is where you",
"0:53:14.790": "have information about who bought what",
"0:53:19.890": "or who liked what you know it's",
"0:53:22.440": "basically something where you have",
"0:53:24.740": "something like a user or a reviewer or",
"0:53:28.260": "whatever and information about what",
"0:53:32.750": "they've bought or what they've written",
"0:53:34.740": "about or what they reviewed right so in",
"0:53:36.870": "the most basic version of collaborative",
"0:53:38.340": "filtering you just have two columns",
"0:53:41.250": "something like user ID and movie ID and",
"0:53:44.940": "that just says this user bought that",
"0:53:46.590": "movie this user bought that movie this",
"0:53:48.090": "user for that review so for example",
"0:53:49.410": "Amazon has a really big list of user IDs",
"0:53:53.070": "and product IDs are like what did you",
"0:53:55.050": "buy then you can add additional",
"0:53:57.060": "information to that table such as oh",
"0:54:00.390": "they left a review what review did they",
"0:54:03.150": "give it so it's now like user ID movie",
"0:54:05.940": "ID number of stars you could add a",
"0:54:09.900": "timecode so like this user bought this",
"0:54:13.410": "product at this time and gave it this",
"0:54:16.350": "review but they're all basically the",
"0:54:18.900": "same kind of structure so there's kind",
"0:54:22.170": "of like two ways you could draw that",
"0:54:25.380": "collaborative filtering structure one is",
"0:54:29.510": "kind of a two-column approach where",
"0:54:32.580": "you've got like user and I don't know",
"0:54:35.790": "movie all right and you've got user ID",
"0:54:38.910": "movie oh do you know each each pair",
"0:54:40.920": "basically describes that user watch that",
"0:54:43.890": "movie possibly also plus number of stars",
"0:54:48.530": "you know three or one whatever well the",
"0:54:53.550": "other way you could write it",
"0:54:57.680": "would be you could have like all the",
"0:54:59.820": "users down here and all the movies along",
"0:55:10.470": "here right and and then you know you can",
"0:55:20.100": "look and find a particular cell in there",
"0:55:22.710": "to find out you know could be the rating",
"0:55:26.580": "of that user for that movie or there's",
"0:55:28.560": "just a one there if that user watch that",
"0:55:30.480": "movie or whatever so there's like two",
"0:55:32.040": "different ways of representing the same",
"0:55:34.710": "information conceptually it's often",
"0:55:39.960": "easier to think of it this way right but",
"0:55:44.340": "most of the time you won't store it that",
"0:55:46.440": "way explicitly because most of the time",
"0:55:48.600": "you'll have what's called a very sparse",
"0:55:50.010": "matrix which is to say most users",
"0:55:53.340": "haven't watched most movies or most",
"0:55:56.960": "customers haven't purchased most",
"0:55:59.310": "products so if you store it as a matrix",
"0:56:02.160": "where every combination of customer and",
"0:56:05.580": "product is a separate cell in that",
"0:56:07.350": "matrix it's going to be enormous so you",
"0:56:09.960": "tend to store it like this or you can",
"0:56:13.380": "store it as a matrix using some kind of",
"0:56:15.360": "special sparse matrix format and if that",
"0:56:18.840": "sounds interesting you should check out",
"0:56:20.250": "Rachel's computational linear algebra",
"0:56:22.830": "course on first AI where we have lots",
"0:56:25.680": "and lots and lots of information about",
"0:56:27.270": "sparse matrix storage approaches for now",
"0:56:30.840": "though we're just going to kind of keep",
"0:56:33.060": "it in this format on the left hand side",
"0:56:35.460": "so for collaborative filtering there's a",
"0:56:40.530": "really nice dataset called movie lens",
"0:56:48.260": "created by the group lens group very",
"0:56:51.870": "hopefully and you can download various",
"0:56:53.580": "different sizes 20 million ratings a",
"0:56:57.750": "hundred thousand ratings we've actually",
"0:56:59.910": "created a an extra small version for",
"0:57:03.090": "playing around with which is what we'll",
"0:57:04.380": "start with today and then",
"0:57:08.910": "probably next week we'll use the bigger",
"0:57:11.250": "version but so you can grab the small",
"0:57:14.609": "version using your RL ml sample and it's",
"0:57:18.269": "a CSV so you can read it with pandas and",
"0:57:24.349": "here it is right it's basically a list",
"0:57:26.700": "of user IDs we don't actually know",
"0:57:28.109": "anything about who these users are",
"0:57:29.460": "there's some movie IDs there is some",
"0:57:32.789": "information about what the movies are",
"0:57:33.990": "but we won't look at that until next",
"0:57:35.130": "week and then there's the rating and",
"0:57:37.650": "then there's the timestamp",
"0:57:40.470": "we're going to ignore the timestamp now",
"0:57:45.440": "so that's a subset of our data that's",
"0:57:48.240": "the head so the head in pandas is just",
"0:57:50.789": "the first few rows so now that we've got",
"0:57:55.349": "a data frame I mean the nice thing about",
"0:57:56.819": "collaborative filtering is is it's it's",
"0:58:00.210": "incredibly simple like that's all the",
"0:58:01.589": "data that we need so you can now go",
"0:58:04.440": "ahead and say get collaborative learner",
"0:58:07.980": "and you can actually just pass in the",
"0:58:09.450": "data frame directly the the architecture",
"0:58:14.549": "you have to tell it how many factors you",
"0:58:15.960": "want to use and we're going to learn",
"0:58:17.099": "what that means after the break and then",
"0:58:20.190": "something that can be helpful is to tell",
"0:58:21.630": "it what the range of scores are and",
"0:58:24.240": "we're going to see how that helps up the",
"0:58:25.710": "brick as well now in this case the",
"0:58:27.539": "minimum score is zero it's an excellent",
"0:58:29.099": "score is five so now that you've got a",
"0:58:31.170": "learner you can go ahead and call fit",
"0:58:35.339": "one cycle and trains for a few a pox and",
"0:58:40.740": "there it is so at the end of it you now",
"0:58:43.349": "have something where you can pick a user",
"0:58:46.349": "ID and a movie ID and guess whether or",
"0:58:50.220": "not that user will like that movie",
"0:58:53.089": "there's a lot of so this is obviously a",
"0:58:56.579": "super useful application that a lot of",
"0:59:00.150": "you are probably going to try over",
"0:59:01.769": "during the week in past classes a lot of",
"0:59:03.630": "people have taken this collaborative",
"0:59:05.460": "filtering approach back to their",
"0:59:06.599": "workplaces and and discovered that using",
"0:59:10.529": "it in practice is much more tricky than",
"0:59:13.019": "this because in practice you have",
"0:59:14.670": "something called the cold start problem",
"0:59:16.190": "so the cold start problem is that the",
"0:59:18.779": "time you particularly want to be good at",
"0:59:22.110": "recommending movies is when you have a",
"0:59:24.060": "new user and the time you particularly",
"0:59:26.340": "care about recommending a movie is when",
"0:59:30.210": "it's a new movie but at that point you",
"0:59:32.250": "don't have any data in your",
"0:59:33.360": "collaborative filtering system and it's",
"0:59:34.800": "really hard as I say this we don't",
"0:59:39.270": "currently have anything built into fast",
"0:59:40.980": "AI to handle the cold start problem and",
"0:59:43.470": "that's really because the cold start",
"0:59:45.120": "problem the only way I know of to solve",
"0:59:47.340": "it in fact the anyway I think that",
"0:59:48.600": "conceptually you can solve it is to have",
"0:59:50.730": "a second model which is not a",
"0:59:52.590": "collaborative filtering model but a",
"0:59:54.030": "metadata driven model for new users or",
"0:59:57.720": "new movies I don't know if Netflix still",
"1:00:02.640": "does this but certainly what they used",
"1:00:03.840": "to do when I signed up to Netflix was",
"1:00:06.240": "they started showing me lots of movies",
"1:00:08.250": "and saying have you seen this did you",
"1:00:10.320": "like it have you seen this did you like",
"1:00:11.670": "it you know and so they fixed the cold",
"1:00:14.700": "start problem through the UX so there",
"1:00:17.130": "was no you know called start problem",
"1:00:19.110": "they found like 20 really common movies",
"1:00:22.320": "and asked me if I liked them they used",
"1:00:24.210": "my replies to those 20 to show me 20",
"1:00:26.250": "more that I might have seen and you know",
"1:00:28.350": "by the time I had gone through 60 I",
"1:00:30.180": "wasn't you know there was no cold start",
"1:00:32.520": "problem anymore and for new movies it's",
"1:00:35.880": "not really a problem because like the",
"1:00:37.470": "first hundred users who haven't seen the",
"1:00:39.630": "movie you know go in and say whether",
"1:00:41.790": "they liked it and then the next hundred",
"1:00:43.770": "thousand the next million it's not a",
"1:00:46.170": "cold start problem anymore",
"1:00:47.910": "but the other thing you can do if you",
"1:00:50.450": "for whatever reason kind of can't go",
"1:00:52.680": "through that UX of like asking people",
"1:00:54.930": "did you like those things so for example",
"1:00:56.670": "if you're selling products and you don't",
"1:00:58.680": "really want to show them like a big",
"1:01:00.600": "selection of your products and say did",
"1:01:02.220": "you like this because you just want them",
"1:01:03.630": "to buy you could instead try and use a",
"1:01:06.150": "metadata based kind of tabular model you",
"1:01:08.940": "know what what geography did they come",
"1:01:11.280": "from maybe you know their age and sex",
"1:01:13.320": "you know you can try and make some",
"1:01:14.670": "guesses about the initial",
"1:01:16.070": "recommendations",
"1:01:17.190": "that's so collaborative filtering is",
"1:01:19.350": "specifically for once you have a bit of",
"1:01:22.980": "information about your users and movies",
"1:01:25.440": "or customers and products or or whatever",
"1:01:30.980": "yeah",
"1:01:36.720": "how does the language model trained in",
"1:01:39.340": "this manner perform on code-switch data",
"1:01:41.620": "such as Hindi written in English words",
"1:01:44.200": "or text with a lot of emojis and then do",
"1:01:48.220": "it the second question there certainly",
"1:01:52.170": "yeah that's a good question so text with",
"1:01:57.880": "emojis it'll be fine",
"1:02:01.480": "there's not many emojis in Wikipedia and",
"1:02:06.430": "where they are in Wikipedia it's more",
"1:02:08.320": "like a Wikipedia page amount about the",
"1:02:11.230": "emoji rather than the emoji being used",
"1:02:12.790": "in you know sensible place but you can",
"1:02:16.470": "insured through this language model fine",
"1:02:23.530": "tuning where you take a corpus of text",
"1:02:26.140": "where people are using emojis in usual",
"1:02:28.180": "ways and so you fine-tune the wiki text",
"1:02:30.580": "language model to your reddit or Twitter",
"1:02:33.430": "or whatever language model and there",
"1:02:35.800": "aren't that many emojis right if you",
"1:02:37.390": "think about it there's like hundreds of",
"1:02:39.670": "thousands of possible words that people",
"1:02:41.530": "can be using but a small number of",
"1:02:43.180": "possible emojis so it'll very quickly",
"1:02:45.040": "learn how those emojis are being used so",
"1:02:48.970": "that's that's a piece of cake",
"1:02:54.150": "so I'm not very familiar with Hindi but",
"1:02:56.500": "I'll take an example I'm very familiar",
"1:02:57.910": "with which is Mandarin in Mandarin you",
"1:03:00.910": "could have a model that's trained with",
"1:03:02.680": "Chinese characters so there's kind of",
"1:03:05.680": "five or six thousand Chinese characters",
"1:03:08.080": "in common use but there's also a",
"1:03:09.940": "romanization of those characters called",
"1:03:11.860": "an opinion and it's a bit tricky because",
"1:03:14.170": "although there's a nearly direct mapping",
"1:03:18.670": "from the character to the pinyin I mean",
"1:03:21.310": "there is a direct mapping the",
"1:03:22.510": "pronunciations not exactly direct there",
"1:03:25.360": "isn't a direct mapping from the pinyin",
"1:03:27.280": "to the character because one pinyin is",
"1:03:30.820": "was corresponds to multiple characters",
"1:03:33.240": "so the first thing to note is that if",
"1:03:36.910": "you're going to use this approach for",
"1:03:42.780": "Chinese you would need to start with",
"1:03:45.860": "his language model so actually first AI",
"1:03:49.910": "has something called a model zoo where",
"1:03:52.760": "we're adding more and more language",
"1:03:54.830": "models for different languages and also",
"1:03:57.220": "increasingly for different domain areas",
"1:04:00.200": "like English medical texts or even",
"1:04:03.260": "language models for things other than",
"1:04:04.820": "NLP like genome sequences molecular data",
"1:04:08.650": "musical midi notes and so forth so you",
"1:04:13.250": "would obviously start there to then",
"1:04:17.590": "convert that you know that'll be in you",
"1:04:20.750": "know either simplified or traditional",
"1:04:21.860": "chinese to then convert that into a if",
"1:04:24.170": "you want to do pinyin you could either",
"1:04:26.930": "kind of map the vocab directly or as",
"1:04:33.080": "you'll learn these multi-layer models",
"1:04:35.360": "it's only the first layer that basically",
"1:04:37.570": "converts the the tokens into a set of",
"1:04:43.070": "vectors you can actually throw that away",
"1:04:44.930": "and fine tune just a the first layer of",
"1:04:49.220": "the model so that second part is going",
"1:04:51.920": "to require a bit more few more weeks of",
"1:04:54.710": "learning before you exactly understand",
"1:04:56.510": "how to do that and so forth but if",
"1:04:58.280": "there's something you're interested in",
"1:04:59.240": "doing we can talk about it on the forum",
"1:05:01.160": "because it's a kind of a nice test of",
"1:05:04.700": "understanding so what about time series",
"1:05:10.670": "on tabular data is there an RNN model",
"1:05:13.640": "involved in tabular models so we're",
"1:05:19.190": "going to look at time series tabular",
"1:05:22.220": "data next week and but the short answer",
"1:05:25.880": "is generally speaking you don't use a",
"1:05:30.080": "RNN for time series tabular data but",
"1:05:33.650": "instead you extract a bunch of columns",
"1:05:35.540": "for things like day of week is it a",
"1:05:38.750": "weekend is it a holiday was the store",
"1:05:41.900": "open stuff like that and it turns out",
"1:05:44.120": "that adding those extra columns which",
"1:05:47.570": "you can do somewhat automatically",
"1:05:51.280": "basically gives you state-of-the-art",
"1:05:53.120": "results there are some good uses of RN",
"1:05:57.290": "ends for",
"1:05:59.420": "for time series but not really for these",
"1:06:02.240": "kind of tabular style time series like",
"1:06:05.450": "you know retail store logistics",
"1:06:09.290": "databases and stuff like that okay and",
"1:06:14.960": "is there a source to learn more about",
"1:06:16.760": "the cold start problem I'm gonna have to",
"1:06:23.840": "look that up if you know a good resource",
"1:06:28.010": "please pin turn it on the forums okay",
"1:06:33.880": "okay so that is both the break in the",
"1:06:39.380": "middle of lesson four it's the halfway",
"1:06:41.540": "point of the course and it's the point",
"1:06:46.520": "at which we have now seen an example of",
"1:06:49.220": "all the key applications and so the rest",
"1:06:51.230": "of this course is going to be digging",
"1:06:54.410": "deeper into how they actually work",
"1:06:55.910": "behind the scenes more of the theory",
"1:06:58.490": "more of how the code the source code is",
"1:07:00.950": "written and so forth so it's a good time",
"1:07:04.370": "to have a nice break come back and",
"1:07:10.030": "furthermore it's my birthday today so",
"1:07:13.250": "it's really you know a special moment so",
"1:07:17.710": "yeah so let's have a break and come back",
"1:07:21.290": "at five past eight so Microsoft Excel",
"1:07:31.430": "this is one of my favorite ways to",
"1:07:34.240": "explore data and understand models now",
"1:07:41.090": "make sure I put this in the repo and",
"1:07:43.840": "actually this one we can probably",
"1:07:46.310": "largely do in Google sheets I've tried",
"1:07:49.100": "to move as much as I can over the last",
"1:07:51.740": "few weeks into Google sheets but I just",
"1:07:53.240": "keep finding it's just such a terrible",
"1:07:55.040": "product so I yeah you know please try to",
"1:08:01.430": "find a copy of Microsoft Excel because",
"1:08:03.200": "there's nothing close I've tried",
"1:08:05.390": "everything anyway spreadsheets get up",
"1:08:12.440": "a bad rap from people that basically",
"1:08:15.290": "don't know how to use them just like",
"1:08:16.760": "people who better they'll spend their",
"1:08:18.110": "lives on Excel and then they start using",
"1:08:19.610": "Python and they're like what the hell is",
"1:08:20.900": "this stupid thing I mean you know it",
"1:08:23.090": "takes thousands of hours to get really",
"1:08:24.890": "good at spreadsheets but a few dozen",
"1:08:27.950": "hours to get competent at them and once",
"1:08:30.410": "you're competent at them you can see",
"1:08:32.930": "everything in front of you it's all laid",
"1:08:34.550": "out it's it's really great I'll give you",
"1:08:38.990": "one spreadsheet tip today which is if",
"1:08:41.300": "you hold down the ctrl key or command",
"1:08:43.730": "key on your keyboard and press the arrow",
"1:08:45.470": "keys",
"1:08:46.130": "here's control right it takes you to the",
"1:08:49.220": "end of a block of a table that you're in",
"1:08:52.370": "and like it's by far the best way to",
"1:08:54.940": "move around the place so there you go so",
"1:08:59.320": "in this case you know I want to like",
"1:09:01.850": "skip around through this table so I can",
"1:09:03.710": "hit ctrl down right to get to the bottom",
"1:09:06.380": "right control left up to get to the top",
"1:09:08.780": "left cuz I skip around and see what's",
"1:09:10.610": "going on so here's hey wait so here's",
"1:09:13.730": "some data and as we talked about one way",
"1:09:20.000": "to look at collaborative filtering data",
"1:09:21.470": "is like this and so what we did was we",
"1:09:25.370": "grabbed from the movie lens data the",
"1:09:28.760": "people that watched the most movies and",
"1:09:30.560": "the movies that were the most watched",
"1:09:33.020": "and just filtered the data set down to",
"1:09:35.920": "those 15 and as you can see when you do",
"1:09:42.080": "it that way it's not sparse anymore",
"1:09:43.640": "there's just a small number of yeah",
"1:09:46.610": "there's a small number of gaps right so",
"1:09:52.250": "this is something that we can now build",
"1:09:56.300": "a model with",
"1:10:00.010": "and so how can we build a model like",
"1:10:03.910": "what we want to do is we want to create",
"1:10:05.830": "something which can predict for user",
"1:10:10.030": "true 9-3 will they like movie 49 for",
"1:10:15.640": "example okay",
"1:10:16.929": "so we've got to come up with some way of",
"1:10:19.989": "you know some function that can",
"1:10:22.570": "represent that decision and so here's a",
"1:10:29.650": "simple possible approach and so we're",
"1:10:31.780": "going to take this idea of doing some",
"1:10:33.610": "matrix multiplications so I've created",
"1:10:36.460": "here a random matrix so here's one",
"1:10:42.400": "matrix of random numbers and I've",
"1:10:44.530": "created here and other matrix of random",
"1:10:49.060": "numbers more specifically for each movie",
"1:10:53.739": "I've created five random numbers and for",
"1:10:58.570": "each user I've created five random",
"1:11:03.280": "numbers and so we could say then that",
"1:11:09.210": "user 14 movie 27 did they like it or not",
"1:11:17.980": "well they're parading what we could do",
"1:11:20.670": "would be to multiply together this",
"1:11:24.489": "vector and that vector we can do a dot",
"1:11:26.260": "product right and here's the dot product",
"1:11:31.150": "right and so then we can basically do",
"1:11:33.699": "that for every possible thing in here",
"1:11:38.530": "we've got the dot product and you know",
"1:11:40.960": "thanks to spreadsheets we can just do",
"1:11:43.900": "that in one place and copy it over and",
"1:11:45.340": "it fills in the whole thing for us why",
"1:11:48.730": "would we do it this way well this is the",
"1:11:51.760": "basic starting point of a neural net",
"1:11:54.310": "isn't it a basic starting point of a",
"1:11:55.870": "neural net is that you take the matrix",
"1:11:58.630": "multiplication of two matrices and",
"1:12:01.540": "that's that's what your first layer",
"1:12:03.989": "always is and so we just have to come up",
"1:12:07.000": "with some way of saying like well what",
"1:12:08.650": "are two matrices that we can multiply",
"1:12:11.699": "and",
"1:12:13.360": "clearly you know you need a matrix for a",
"1:12:19.540": "user you know or a vector for a user a",
"1:12:23.260": "matrix for all the users and a vector",
"1:12:27.250": "for a movie or a matrix for all the",
"1:12:30.820": "movies and multiply them together and",
"1:12:35.380": "you get some numbers right like so they",
"1:12:40.300": "don't mean anything yet they're just",
"1:12:41.650": "random right but we can now use gradient",
"1:12:45.010": "descent to try to make these numbers and",
"1:12:49.530": "these numbers give us results that are",
"1:12:54.720": "closer to what we wanted so how do we do",
"1:13:00.010": "that well we set this up now as a as a",
"1:13:04.750": "linear model all right so the next thing",
"1:13:07.420": "we need is a loss function so we can",
"1:13:11.440": "calculate our loss function by saying",
"1:13:13.330": "well okay movie 3 for user ID 14 should",
"1:13:27.460": "have been a rating of 3 with this random",
"1:13:30.010": "matrices it's actually a rating of 0.9 1",
"1:13:32.730": "so we can find the sum of squared errors",
"1:13:34.930": "would be 3 minus 0.9 1 squared and then",
"1:13:45.220": "we can add them up so there's actually a",
"1:13:48.630": "sum squared in excel already some X",
"1:13:55.510": "minus y squared so we can use just some",
"1:13:57.430": "X minus y squared function passing in",
"1:14:00.090": "those two ranges and then divide by the",
"1:14:04.330": "count to get the mean so here is a",
"1:14:07.300": "number that is the mean that's exactly",
"1:14:10.990": "the square root of the mean squared",
"1:14:13.390": "error so like you sometimes you'll see",
"1:14:15.610": "people talk about MSE so that's the mean",
"1:14:18.010": "squared error sometimes you'll see our",
"1:14:20.380": "MSE that's the root mean squared error",
"1:14:22.780": "so since I've got a square root at the",
"1:14:24.400": "front this is the",
"1:14:26.889": "root mean square error so we have a loss",
"1:14:31.920": "so now all we need to do is use gradient",
"1:14:35.980": "descent to try to modify our weight",
"1:14:39.580": "matrices to make that loss smaller so",
"1:14:45.219": "Excel will do that for me I have other",
"1:14:51.850": "them installed so it's probably worth",
"1:14:54.070": "knowing how to do that",
"1:14:55.239": "so we have to install add-ins not",
"1:15:01.150": "solvers there okay this is obviously",
"1:15:03.520": "forgotten where it was oh yeah okay",
"1:15:07.420": "so the gradient descent solver in Excel",
"1:15:11.050": "is called solver and it just does normal",
"1:15:13.270": "gradient descent so you just go data",
"1:15:15.040": "solver you need to make sure that in",
"1:15:17.020": "your settings that you've enabled the",
"1:15:19.179": "solver extension it comes with Excel and",
"1:15:21.010": "all you need to do is say which cell",
"1:15:23.460": "represents my loss function so there it",
"1:15:26.560": "is c41 right so which where is your loss",
"1:15:29.440": "function stored which cells contain your",
"1:15:33.790": "your variables right since so you can",
"1:15:37.119": "see here I've got H 90 into V 23 which",
"1:15:42.219": "is up here and B 25 to have 39 which is",
"1:15:45.520": "over there and then you can just say",
"1:15:49.869": "okay set your loss function to a minimum",
"1:15:53.560": "by changing those cells and solve and",
"1:15:59.040": "you'll see the starts a 2.81 and you can",
"1:16:03.040": "see the numbers going down and so all",
"1:16:05.170": "that's doing is using gradient descent",
"1:16:07.560": "exactly the same way that we did when we",
"1:16:10.060": "did it manually in the notebook the",
"1:16:12.250": "other day okay but it's it's rather than",
"1:16:14.980": "solving the means grid error for a at B",
"1:16:19.210": "in the a at X in the Python instead it",
"1:16:24.489": "is solving the loss function here which",
"1:16:27.460": "is the mean squared error if the dot",
"1:16:29.469": "product of each of those vectors by each",
"1:16:31.239": "of these vectors and so there it goes",
"1:16:36.210": "so we'll let that run for a little while",
"1:16:38.980": "and see what happens",
"1:16:42.340": "but basically in in micro here is a",
"1:16:45.070": "simple way of creating a neural network",
"1:16:50.469": "which is really in this case it's like",
"1:16:52.090": "just a single linear layer with gradient",
"1:16:58.030": "descent to solve a collaborative",
"1:16:59.499": "filtering problem so let's go back and",
"1:17:04.869": "see what we do over here",
"1:17:08.349": "so over here we used get collab learner",
"1:17:14.489": "okay so the the function that was called",
"1:17:18.340": "in the notebook was get collab learner",
"1:17:21.340": "and so as you dig deeper into deep",
"1:17:25.479": "learning one of the really good ways to",
"1:17:27.340": "dig deeper into deep deep learning is to",
"1:17:29.380": "dig into the fast AI source code and see",
"1:17:33.039": "what's going on and so if you're going",
"1:17:34.389": "to be able to do that you need to know",
"1:17:36.400": "how to use your editor well enough to",
"1:17:38.650": "dig through the source code right and",
"1:17:40.199": "basically there's two main things you",
"1:17:42.369": "need to know how to do one is to jump to",
"1:17:44.409": "a particular symbol like a particular",
"1:17:45.939": "class or function by like by its name",
"1:17:48.849": "and the other is that when you're",
"1:17:50.349": "looking at a particular symbol to be",
"1:17:51.639": "able to jump to its its implementation",
"1:17:53.619": "so for example in this case I want to",
"1:17:55.539": "find Det collab Lana so in most in most",
"1:18:03.189": "editors including the one I use VM you",
"1:18:05.079": "can set it up so that you can kind of",
"1:18:06.610": "hit tap or something and it jumps",
"1:18:10.749": "through all the possible completions and",
"1:18:12.400": "you can hit enter and it jumps and it",
"1:18:15.999": "jumps straight to the definition for you",
"1:18:18.039": "alright so here is the definition of get",
"1:18:20.889": "collab alona and as you can see it's",
"1:18:25.570": "pretty small as these things tend to be",
"1:18:29.110": "and the keys in this case it kind of",
"1:18:32.860": "wraps data frame and automatically",
"1:18:34.780": "creates the data bunch for you because",
"1:18:36.189": "it's so simple but the key thing it does",
"1:18:38.289": "then is to create a model the whole",
"1:18:40.360": "particular kind which is an embedding",
"1:18:42.820": "bias model passing in the various things",
"1:18:46.090": "you asked for so you want to find out in",
"1:18:48.429": "your editor how you jump to the",
"1:18:49.719": "definition of that which",
"1:18:51.810": "in vim you just hit control right square",
"1:18:55.440": "bracket and here is the definition of",
"1:18:59.610": "embedding bias and so now we have",
"1:19:05.510": "everything on screen at once and as you",
"1:19:08.250": "can see there's not much going on in so",
"1:19:14.310": "the models that are being created for",
"1:19:16.170": "you by first AI are actually paid watch",
"1:19:19.670": "models and a PI torch model is called an",
"1:19:25.100": "NN module that's the name in hi torch of",
"1:19:29.190": "their models it's a little more nuanced",
"1:19:32.190": "than that but that's a good starting",
"1:19:33.330": "point for now and when a PI torch and",
"1:19:37.470": "end module is is run when you calculate",
"1:19:41.820": "the value know the result of that layer",
"1:19:44.100": "or neural net or whatever specifically",
"1:19:46.200": "it always calls a method for you called",
"1:19:48.720": "forward so it's in here that you get to",
"1:19:52.020": "find out how this thing's actually",
"1:19:53.880": "calculated when the model is built at",
"1:19:57.930": "the start it calls this thing called",
"1:20:00.740": "underscore underscore in it and the",
"1:20:03.180": "supportt underscore and as I think we've",
"1:20:05.310": "briefly mentioned before in - people",
"1:20:08.010": "tend to call this dunder init double",
"1:20:10.350": "underscore in it so dunder init is how",
"1:20:12.840": "we create the model and forward is how",
"1:20:16.350": "we run the model one thing if you're",
"1:20:19.950": "watching carefully you might notice is",
"1:20:21.960": "there's nothing here saying - how to",
"1:20:24.330": "calculate the gradients of the model and",
"1:20:27.240": "that's because height which does it for",
"1:20:29.520": "us okay so you only have to tell it how",
"1:20:31.770": "to calculate the output of your model",
"1:20:33.660": "and PI torch will go ahead and calculate",
"1:20:37.680": "the gradients for you",
"1:20:40.500": "and so in this case the model contains a",
"1:20:48.000": "set of weights through a user a set of",
"1:20:51.300": "weights for an item a set of biases for",
"1:20:54.450": "a user a set of biases for an item and",
"1:20:56.820": "each one of those is called",
"1:20:59.010": "is coming from this thing called get",
"1:21:01.680": "embedding",
"1:21:07.150": "so let's see get embedding so here is",
"1:21:12.340": "the definition of get embedding and all",
"1:21:16.870": "it does basically is it calls this",
"1:21:19.410": "height watch thing called n n dot",
"1:21:21.969": "embedding so in pi torch they have a lot",
"1:21:24.969": "of like standard neural network layers",
"1:21:27.730": "set up for you so gates and embedding",
"1:21:30.760": "and then this thing here is it just",
"1:21:34.570": "randomizes it so this is something which",
"1:21:36.489": "creates normal random numbers through",
"1:21:40.390": "the embedding so what's an embedding and",
"1:21:43.960": "embedding not surprisingly is a matrix",
"1:21:47.110": "of weights specifically it's a matrix of",
"1:21:51.070": "weights specifically an embedding is a",
"1:22:00.190": "matrix of weights that looks something",
"1:22:02.770": "like this",
"1:22:03.489": "it's a matrix of weights which you can",
"1:22:06.310": "basically look up into and grab one item",
"1:22:11.290": "out of it right so basically any kind of",
"1:22:15.310": "weight matrix and we're going to be",
"1:22:16.870": "digging into this in a lot more detail",
"1:22:18.850": "in the coming lessons but an embedding",
"1:22:21.310": "matrix is just a weight matrix that is",
"1:22:23.890": "designed to be something that you kind",
"1:22:25.390": "of index into it as an array and grab",
"1:22:28.440": "one vector out of it all right that's",
"1:22:31.960": "what an embedding matrix is and so in",
"1:22:35.680": "our case we have an embedding matrix for",
"1:22:38.290": "a user and an embedding matrix for a",
"1:22:41.950": "movie and here we have been taking the",
"1:22:46.140": "dot product of them all right but if you",
"1:22:49.239": "think about it that's not quite enough",
"1:22:51.870": "because we're missing this idea that",
"1:22:54.310": "like maybe there are certain movies that",
"1:22:57.400": "everybody likes more maybe there are",
"1:23:00.460": "some users that just tend to like movies",
"1:23:02.800": "more all right so I don't really just",
"1:23:04.750": "want to multiply these two vectors",
"1:23:07.210": "together but I really want to add a",
"1:23:09.280": "single number of like how popular is",
"1:23:12.310": "this movie and add a single number of",
"1:23:14.650": "like how much does this user like",
"1:23:17.100": "is in general so those are called bias",
"1:23:19.140": "terms remember how I said like there's",
"1:23:22.050": "this kind of idea of like bias and we",
"1:23:24.210": "the way we dealt with that in our",
"1:23:26.130": "gradient descent notebook was we added a",
"1:23:27.930": "column of ones okay but what we tend to",
"1:23:31.320": "do in practice is we actually explicitly",
"1:23:35.730": "say I want to add a bias term so we",
"1:23:40.350": "don't just want to have prediction",
"1:23:43.470": "equals dot product of these two things",
"1:23:46.890": "we want to say it's the dot product of",
"1:23:48.480": "those two things plus a bias term for a",
"1:23:51.930": "movie plus a bias term for user ID so",
"1:23:57.170": "that's basically what happens we when we",
"1:24:00.210": "set up the model we set up the embedding",
"1:24:03.420": "matrix for the users and the embedding",
"1:24:05.970": "matrix for the items and then we also",
"1:24:09.120": "set up the bias vector for the users and",
"1:24:11.130": "the bias vector for the items and then",
"1:24:14.250": "when we calculate the model we literally",
"1:24:17.840": "just multiply the two together just like",
"1:24:23.160": "we did right we just take that that",
"1:24:25.350": "product call it dot right and then we",
"1:24:28.530": "add the bias and then putting aside the",
"1:24:34.140": "min and Max score for a moment that's",
"1:24:35.970": "what we return so you can see that our",
"1:24:38.940": "model is literally doing what we did",
"1:24:44.010": "here with the tweak that we're also",
"1:24:46.980": "adding a bias right so it's it's an",
"1:24:53.280": "incredibly simple linear model and for",
"1:25:01.010": "for these kinds of collaborative",
"1:25:03.030": "filtering problems this kind of simple",
"1:25:05.550": "linear model actually tends to work",
"1:25:08.580": "pretty well and then there's one tweak",
"1:25:15.300": "that we do at the end which is that in",
"1:25:18.150": "our case we said that there's a min",
"1:25:19.770": "score of zero and a max score of five",
"1:25:23.969": "and so here's something to point out",
"1:25:29.989": "here's something to point out so if you",
"1:25:33.120": "have you know a range so you'd like you",
"1:25:40.590": "do that dot product and you add on the",
"1:25:42.000": "two biases and that gives you you know",
"1:25:44.460": "that can give you any possible number",
"1:25:46.050": "along the number line from very negative",
"1:25:48.180": "through to very positive numbers but we",
"1:25:50.580": "know that we always want to end up with",
"1:25:52.739": "a number between zero and five let's say",
"1:25:56.820": "that's five and of course this is zero",
"1:26:00.380": "so what if we match that number line",
"1:26:05.330": "like so",
"1:26:07.699": "to this function okay and so the shape",
"1:26:13.500": "of that function is called a sigmoid",
"1:26:19.190": "right and so it's gonna asymptote to",
"1:26:23.880": "five and it's gonna asymptote to zero",
"1:26:26.580": "and so that way whatever whatever number",
"1:26:31.199": "comes out of our dot product and adding",
"1:26:34.080": "the biases if we then stick it through",
"1:26:36.030": "this function it's never going to be",
"1:26:37.980": "higher than five and never going to be",
"1:26:39.239": "smaller than zero now strictly speaking",
"1:26:42.590": "that's not necessary right because our",
"1:26:47.540": "parameters could learn a set of weights",
"1:26:51.060": "that gives about the right number right",
"1:26:53.340": "so why would we do this extra thing if",
"1:26:56.340": "it's not necessary well the reason is we",
"1:26:58.860": "wouldn't make his life as easy for our",
"1:27:00.570": "model as possible",
"1:27:03.170": "so if we actually set it up so it's",
"1:27:08.850": "impossible for it to ever predict too",
"1:27:10.680": "much or ever predict too little then it",
"1:27:13.260": "can spend more of its weights predicting",
"1:27:15.719": "the thing we care about which is",
"1:27:16.860": "deciding who's going to like what movie",
"1:27:18.360": "so this is an idea we're going to keep",
"1:27:20.850": "coming back to when it comes to like",
"1:27:22.320": "making neural networks work better is",
"1:27:26.250": "it's about all these little decisions",
"1:27:27.930": "that we make to basically make it easier",
"1:27:30.390": "for the network to learn the right thing",
"1:27:33.350": "so that's the last tweak here we",
"1:27:36.430": "as we take the result of this dot",
"1:27:42.250": "product plus biases we put it through a",
"1:27:45.250": "sigmoid and so a sigmoid is just a",
"1:27:47.800": "function it's basically 1 over 1 plus e",
"1:27:49.720": "to the X the definition doesn't much",
"1:27:51.760": "matter but it just has the shape that I",
"1:27:53.590": "just mentioned and that goes between 0 &",
"1:27:57.880": "1 and if you then multiply that by max",
"1:28:00.160": "minus min plus min then that's going to",
"1:28:03.160": "give you something that's between min",
"1:28:04.720": "score and Max score so that means that",
"1:28:08.440": "this tiny little neural network I mean",
"1:28:12.310": "it's a push to call it a neural network",
"1:28:13.750": "but it is it's a neural network with",
"1:28:15.430": "with one weight matrix and no none when",
"1:28:19.270": "the arrow DS so it's kind of the world's",
"1:28:20.860": "most boring neural network with a",
"1:28:23.830": "sigmoid at the end that's actually",
"1:28:26.220": "because it does have a non-linearity the",
"1:28:28.390": "sigmoid at the end is the non-linearity",
"1:28:29.950": "just it only has one layer of weights",
"1:28:33.600": "that actually turns out to give close to",
"1:28:40.510": "state-of-the-art performance like I've",
"1:28:42.490": "looked up online to find out like what",
"1:28:44.410": "are the best results people have on this",
"1:28:46.270": "movie lends 100k database and the",
"1:28:49.060": "results I get from this little thing",
"1:28:50.760": "better than any of the results I can",
"1:28:53.200": "find from like the standard commercial",
"1:28:54.910": "products that you can download that are",
"1:28:56.410": "specialized for this and the trick seems",
"1:28:58.690": "to be that adding this little sigmoid",
"1:29:00.270": "makes a big difference and did you have",
"1:29:04.870": "a question there was a question",
"1:29:10.830": "you set up your VIN and I've already",
"1:29:12.480": "linked here dot them RC but I wanted to",
"1:29:14.610": "know if you had more to say about that",
"1:29:16.730": "they really like your setup you like my",
"1:29:20.100": "setup there's almost nothing in my setup",
"1:29:23.150": "it's pretty bare honestly yeah I I mean",
"1:29:29.880": "whatever you're doing with your editor",
"1:29:31.200": "you probably want it to look like this",
"1:29:32.580": "which is like when you've got a class",
"1:29:35.460": "that you're not currently working on it",
"1:29:37.020": "should be this is called folded this is",
"1:29:38.760": "what folding right it should be closed",
"1:29:40.440": "up so you can't see it and so you",
"1:29:44.070": "basically want something where it's easy",
"1:29:46.530": "to close and open fold so them already",
"1:29:48.720": "does all this for you and then as I",
"1:29:52.710": "mentioned you also want something where",
"1:29:53.820": "you can kind of jump to the definition",
"1:29:55.170": "of things which in VM it's called using",
"1:29:58.710": "tags so for the jump to the definition",
"1:30:01.170": "of learner basically them already does",
"1:30:03.390": "all this for you you just have two",
"1:30:05.270": "instructions that my VMRC is minimal I",
"1:30:07.860": "basically hardly use any extensions or",
"1:30:10.470": "anything",
"1:30:11.510": "another great editor who uses a vs code",
"1:30:14.730": "Visual Studio code it's free and it's",
"1:30:18.150": "it's awesome and it has all the same",
"1:30:20.760": "features that you're seeing that vim",
"1:30:22.980": "does basically the s code does all of",
"1:30:24.810": "those things as well I quite like using",
"1:30:30.600": "vim because I can use it on the remote",
"1:30:31.980": "machine and play around but you can of",
"1:30:35.250": "course just clone get onto your the git",
"1:30:40.290": "repo into your local computer and open",
"1:30:41.790": "it up and vs code to play around with it",
"1:30:43.680": "just don't like don't try and look",
"1:30:46.890": "through the code just on github or",
"1:30:48.300": "something like that's going to drive you",
"1:30:49.680": "crazy you need to be able to open it and",
"1:30:51.720": "close it and jump and jump back maybe",
"1:30:55.740": "people can create some threads on the",
"1:30:58.110": "forum for them tips fierce code tips",
"1:31:00.990": "sublime tips whatever yeah for me I",
"1:31:04.830": "would say like if you're gonna pick an",
"1:31:06.990": "editor if you want to use something on",
"1:31:09.270": "your local I would go with vs code today",
"1:31:11.280": "I think it's the best if you want to use",
"1:31:13.230": "something on the terminal side I would",
"1:31:15.480": "go with them or Emacs to me there",
"1:31:18.600": "they're clear winners",
"1:31:25.940": "so what I wanted to close with today is",
"1:31:28.680": "to kind of take this collaborative",
"1:31:31.440": "filtering example and describe how we're",
"1:31:33.540": "going to build on top of it for the next",
"1:31:34.890": "three lessons to create the more complex",
"1:31:37.980": "neural networks we've been seeing and so",
"1:31:40.020": "roughly speaking you know this is the",
"1:31:44.310": "bunch of concepts that we need to learn",
"1:31:46.230": "about let's think about let's think",
"1:31:59.370": "about",
"1:31:59.750": "what happens when when you're using a",
"1:32:06.050": "CNN - or you know whatever a neural",
"1:32:08.840": "network to do image recognition",
"1:32:11.890": "basically let's take a single pixel",
"1:32:14.510": "right you've got lots of pixels but",
"1:32:16.130": "let's take a single pixel so you've got",
"1:32:19.220": "a red a green and a blue pixel okay and",
"1:32:26.800": "so each one of those is some number",
"1:32:29.270": "between Norton 255 well we kind of",
"1:32:31.600": "normalized them so they're you know",
"1:32:34.640": "floating point between well with the",
"1:32:36.860": "mean of 0 and a standard deviation of 1",
"1:32:38.450": "but let's just do that you know let's",
"1:32:40.400": "say whatever they're like do that not to",
"1:32:43.130": "255 fish and so it's like 10 20 30",
"1:32:47.780": "whatever okay so what do we do with",
"1:32:54.920": "these well what we do is we take we",
"1:32:57.590": "basically treat that as a vector and we",
"1:33:01.370": "multiply it by a matrix right so this",
"1:33:06.440": "matrix depending on how you think of the",
"1:33:09.380": "rows and the columns let's trade the",
"1:33:11.300": "matrix is having three rows and then how",
"1:33:15.620": "many columns well you get to pick right",
"1:33:19.430": "you get to pick just like with the",
"1:33:21.610": "collaborative filtering version I",
"1:33:23.540": "decided to pick a vector of size five",
"1:33:27.380": "for each of my embedding vectors right",
"1:33:30.140": "so that would mean that that that's an",
"1:33:31.520": "embedding basically of size five right",
"1:33:35.270": "you can get to pick how big your weight",
"1:33:37.040": "matrix is so let's make it size five",
"1:33:40.390": "okay so this is three five five so",
"1:33:46.460": "initially this weight matrix contains",
"1:33:49.280": "random numbers remember when we looked",
"1:33:51.680": "up get embedding weight matrix just now",
"1:33:53.510": "and there were like two lines the first",
"1:33:54.890": "line is like create the matrix and the",
"1:33:56.390": "second was fill it with random numbers",
"1:33:58.040": "that's what we do",
"1:33:59.450": "right I mean lore gets hidden behind the",
"1:34:01.910": "scenes by fast AI and PI torch that's",
"1:34:03.920": "all it's doing just creating a matrix of",
"1:34:06.620": "random numbers when you set it up and",
"1:34:09.890": "the number of rows has to be three to",
"1:34:12.770": "match the",
"1:34:13.179": "and the number of columns can be as big",
"1:34:15.130": "as you like and so after you multiply",
"1:34:16.679": "the vector the input vector by that",
"1:34:19.389": "weight matrix you're going to end up",
"1:34:21.510": "with a vector of size five so people",
"1:34:29.619": "often asked like how much linear algebra",
"1:34:31.749": "do I need to know to be able to do deep",
"1:34:34.719": "learning this is the amount you need",
"1:34:36.459": "right so and and if you're not familiar",
"1:34:39.099": "with this that's that's fine you need to",
"1:34:41.739": "know about matrix products now you don't",
"1:34:45.070": "need to know a lot about them you just",
"1:34:46.360": "need to know like math and like",
"1:34:48.090": "computationally what are they what do",
"1:34:51.010": "they do and you've got to be very",
"1:34:52.929": "comfortable with like if a you know a",
"1:34:54.969": "matrix of size bla times a matrix of",
"1:34:57.309": "size bla gives a matrix of size bla like",
"1:34:59.709": "powder the dimensions match up so if you",
"1:35:02.260": "have three and they remember in num PI",
"1:35:05.920": "and PI torch we use at times three by",
"1:35:09.519": "five gives a vector of size five okay",
"1:35:12.719": "and then what happens next it goes",
"1:35:15.849": "through an activation function such as r",
"1:35:19.510": "lu which is just max zero comma X and",
"1:35:27.219": "spits out a new vector which is of",
"1:35:30.130": "course going to be exactly the same size",
"1:35:32.650": "because no activation function changes",
"1:35:36.459": "the size that it only changes the",
"1:35:38.979": "contents so that's still a size five",
"1:35:43.709": "what happens next",
"1:35:45.510": "we multiply by",
"1:35:47.269": "another matrix and again it can be any",
"1:35:50.900": "number of columns but the number of rows",
"1:35:53.179": "has to map nicely so it's going to be",
"1:35:54.980": "five by whatever but oh so maybe this",
"1:36:01.099": "one has you know five say by ten and so",
"1:36:07.730": "that's going to give some output which",
"1:36:13.550": "will be size ten and again we put that",
"1:36:16.880": "through value and again that gives us",
"1:36:20.360": "something of the same size okay and then",
"1:36:24.309": "we can put that through another H matrix",
"1:36:30.619": "actually just to make this a bit clearer",
"1:36:32.690": "you'll see why in a moment I'm going to",
"1:36:33.800": "use eight not ten just so that these",
"1:36:39.579": "let's say we're doing digit recognition",
"1:36:41.539": "right so there are ten possible digits",
"1:36:44.690": "so my last weight matrix has to be ten",
"1:36:52.699": "in size because then my that's going to",
"1:36:56.090": "mean my final output is a vector of ten",
"1:36:59.510": "in size and remember if you're doing",
"1:37:01.880": "that digit recognition what happens did",
"1:37:04.579": "we take our actuals right which is ten",
"1:37:13.940": "in size and like if the number that",
"1:37:16.280": "we're trying to predict was the number",
"1:37:17.630": "three that's our like that's the thing",
"1:37:22.639": "we're trying to predict then that means",
"1:37:25.940": "that there is a three zero zero zero in",
"1:37:30.199": "the third position right so what happens",
"1:37:35.900": "is our neural net runs along okay it's",
"1:37:41.179": "starting with our input and going wait",
"1:37:44.480": "mate",
"1:37:44.760": "Rick's value white bag tricks value",
"1:37:47.070": "weight matrix final output and then we",
"1:37:51.690": "compare these two together to see how",
"1:37:56.940": "close they are how Plus they match using",
"1:37:58.860": "some loss function and we'll learn about",
"1:38:00.360": "all the loss functions that we use next",
"1:38:02.070": "week for now the only one we've learned",
"1:38:03.809": "his means great error and yeah we",
"1:38:07.559": "compare the actual you can think of them",
"1:38:12.150": "as probabilities for each of the 10 to",
"1:38:14.400": "the actual each of the 10 to get a loss",
"1:38:16.139": "and then we find the gradients of every",
"1:38:19.260": "one as the weight matrices with respect",
"1:38:20.760": "to that and we update the weight",
"1:38:22.530": "matrices so the main thing I wanted to",
"1:38:24.269": "show right now is the terminology we use",
"1:38:26.909": "because it's really important these",
"1:38:31.139": "things contain numbers specifically they",
"1:38:36.900": "initially matrices containing random",
"1:38:39.179": "numbers and we can refer to these yellow",
"1:38:41.849": "things as in pi touch they're called",
"1:38:47.039": "parameters",
"1:38:50.900": "sometimes we'll refer to them as weights",
"1:38:55.010": "although weights is slightly less",
"1:38:57.719": "accurate because they can also be biases",
"1:38:59.699": "right but you know we kind of use the",
"1:39:02.070": "terms a little bit interchangeably but",
"1:39:03.510": "strictly speaking we should call them",
"1:39:04.829": "parameters and then after each of those",
"1:39:07.679": "metrics products that calculates a",
"1:39:10.289": "vector of numbers so here are some",
"1:39:13.199": "numbers that are calculated by this one",
"1:39:17.130": "here are some numbers that are",
"1:39:18.599": "calculated by a weight matrix multiply",
"1:39:23.449": "and then there are some other sets of",
"1:39:27.300": "numbers that are calculated as a result",
"1:39:29.309": "of a rail you as well as an activation",
"1:39:31.019": "function okay either one",
"1:39:46.639": "is called Accord activations so",
"1:39:52.530": "activations and parameters both refer to",
"1:39:55.920": "numbers right they are numbers the",
"1:39:58.230": "parameters are numbers that are stored",
"1:40:01.980": "they're used to make a calculation",
"1:40:05.570": "activations are the result of a",
"1:40:08.730": "calculation the numbers that are",
"1:40:10.019": "calculated right so they're the two key",
"1:40:13.019": "things you need to remember so use these",
"1:40:16.170": "terms right and use them correctly and",
"1:40:23.610": "accurately right and if you read these",
"1:40:26.010": "terms they mean these very specific",
"1:40:28.139": "things so don't mix them up in your head",
"1:40:30.840": "and remember they're nothing weird and",
"1:40:33.030": "magical they're very simple things an",
"1:40:35.849": "activation is the result of either a",
"1:40:39.059": "matrix multiply or an activation",
"1:40:41.460": "function okay and a parameter are the",
"1:40:45.210": "numbers inside the weights inside the",
"1:40:47.010": "matrices that we multiply by okay that's",
"1:40:49.710": "it and then there are some special",
"1:40:52.800": "layers so every one of these things that",
"1:40:56.610": "does a calculation all of these things",
"1:40:59.420": "that does a calculation are all called",
"1:41:04.619": "layers they're the layers of our neural",
"1:41:08.610": "net so every layer results in a set of",
"1:41:11.610": "activations because there's a",
"1:41:13.139": "calculation that results in a set of",
"1:41:15.170": "results okay",
"1:41:18.559": "there's a special layer at the start",
"1:41:20.670": "which is called the input layer and then",
"1:41:24.360": "at the end you just have a set of",
"1:41:26.340": "activations okay and we can refer to",
"1:41:29.190": "those special I mean they're not special",
"1:41:30.929": "mathematically but they're semantically",
"1:41:32.610": "special we can call those the outputs",
"1:41:35.900": "right so the important point to realize",
"1:41:38.280": "here is the outputs of a neural net and",
"1:41:40.409": "not actually like mathematically special",
"1:41:43.110": "they're just the activations of a layer",
"1:41:45.530": "and so what we did in our collaborative",
"1:41:48.239": "filtering example we did something",
"1:41:49.860": "interesting we actually added an",
"1:41:54.809": "additional activation function right at",
"1:41:58.170": "the very end",
"1:42:00.080": "right we added an extra activation",
"1:42:02.400": "function which was sigmoid and",
"1:42:06.780": "specifically it was a scaled sigmoid",
"1:42:08.430": "curve between 0 & 5 right and that's",
"1:42:10.350": "really common right it's very common to",
"1:42:13.290": "have an activation function as your last",
"1:42:15.330": "layer and it's almost never going to be",
"1:42:18.090": "a rel you because it's very unlikely",
"1:42:19.950": "that what you actually want is something",
"1:42:21.570": "that stops the truncates at zero it's",
"1:42:24.600": "very often going to be a sigmoid or",
"1:42:26.280": "something similar because it's very",
"1:42:27.720": "likely that actually what you want is",
"1:42:29.190": "something that's between two values okay",
"1:42:31.950": "and kind of scaled in that way so that's",
"1:42:35.550": "nearly it right so we've got inputs",
"1:42:38.970": "weights activations activation functions",
"1:42:42.180": "which we sometimes call nonlinearities",
"1:42:44.420": "output and then the function that",
"1:42:47.100": "compares those two things together right",
"1:42:50.040": "is called the loss function which so far",
"1:42:53.580": "we've used MSE yeah okay",
"1:43:00.570": "and that's if that's enough for today so",
"1:43:02.490": "what we're going to do what we're going",
"1:43:05.130": "to do next week is we're going to kind",
"1:43:07.800": "of add in a few more extra bits in which",
"1:43:10.110": "is we're going to learn the loss",
"1:43:11.280": "function that's used for classification",
"1:43:12.690": "which is called cross-entropy",
"1:43:14.700": "we're going to use the activation",
"1:43:16.740": "function that's used for single label",
"1:43:18.750": "classification which is called softmax",
"1:43:20.760": "and we're also going to learn exactly",
"1:43:22.620": "what happens when we do fine tuning in",
"1:43:26.220": "terms of how these layers actually what",
"1:43:28.170": "happens with unfreeze and what happens",
"1:43:29.880": "when we create transfer learning so",
"1:43:32.720": "thanks everybody",
"1:43:34.320": "looking forward to seeing you next week"
}
