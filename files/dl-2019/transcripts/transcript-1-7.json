{
"0:00:01.530": "welcome to lesson seven the last lesson",
"0:00:04.290": "of part one this will be a pretty",
"0:00:10.800": "intense lesson and so don't let that",
"0:00:14.099": "bother you because partly what I want to",
"0:00:15.660": "do is to kind of give you enough things",
"0:00:19.289": "to think about to keep you busy until",
"0:00:21.680": "platt - and so in fact some of the",
"0:00:25.830": "things we cover today I'm not going to",
"0:00:28.109": "tell you about some of the details I've",
"0:00:29.670": "just point out a few things where I'll",
"0:00:31.019": "say like okay that we're not talking",
"0:00:32.309": "about yet that not and we're not talking",
"0:00:33.450": "about that",
"0:00:34.079": "and so then come back in part two to get",
"0:00:36.510": "the details on some of these extra extra",
"0:00:39.000": "pieces right so well you know today will",
"0:00:41.489": "be a lot of material pretty quickly you",
"0:00:45.480": "might require a few viewings to fully",
"0:00:48.510": "understand at all a few experiments and",
"0:00:50.489": "so forth and that's kind of intentional",
"0:00:52.020": "and trying to give you stuff to to keep",
"0:00:54.000": "you amused for a couple of months wanted",
"0:00:59.699": "to start by showing some core work done",
"0:01:02.460": "by a couple of students Reshma and in",
"0:01:05.460": "patters Eero one who have developed an",
"0:01:08.820": "Android and an iOS app and so check out",
"0:01:12.840": "Reshma's post on the forum about that",
"0:01:16.530": "because they have a demonstration of how",
"0:01:18.060": "to create a both Android and iOS apps",
"0:01:21.360": "that are actually on the Play Store and",
"0:01:22.799": "on the Apple App Store so that's pretty",
"0:01:26.130": "cool first first ones I know of that are",
"0:01:28.320": "on the App Store's that are using first",
"0:01:29.700": "AI and let me also say a huge thank you",
"0:01:33.900": "to Rushmore for all of the work she does",
"0:01:35.670": "both for the fast AI community and the",
"0:01:38.280": "machine learning community or generally",
"0:01:40.140": "and also the women in machine learning",
"0:01:41.640": "community in particular she does a lot",
"0:01:44.490": "of fantastic work including providing",
"0:01:47.009": "lots of fantastic documentation and",
"0:01:49.710": "tutorials and community organizing and",
"0:01:51.689": "so many other things so thank you rush",
"0:01:54.090": "me and congrats on getting this app out",
"0:01:56.640": "there we have lots of less than",
"0:02:05.759": "seven-minute bucks today as you see and",
"0:02:08.099": "we're going to start with the one",
"0:02:13.069": "so the first notebook we're going to",
"0:02:14.810": "look at is lesson seven ResNet amnesty",
"0:02:17.810": "and what I want to do is look at some of",
"0:02:21.530": "the stuff we started talking about last",
"0:02:22.849": "week around convolutions and",
"0:02:24.560": "convolutional neural networks and start",
"0:02:26.390": "building on top of them to create a",
"0:02:28.459": "fairly modern deep learning architecture",
"0:02:31.790": "largely from scratch when I say from",
"0:02:34.459": "scratch I'm not going to re-implement",
"0:02:35.870": "things we already know how to implement",
"0:02:37.310": "but kind of use the pre-existing ply",
"0:02:40.129": "torch bits of those so we're going to",
"0:02:43.040": "use the EM list data set which so URLs",
"0:02:47.720": "that amnesty has the whole emne status",
"0:02:49.489": "set often we've done stuff with a subset",
"0:02:51.169": "of it",
"0:02:52.370": "so in there there's a training folder",
"0:02:54.169": "and a testing folder and as I read this",
"0:02:58.519": "in I'm going to show some more details",
"0:03:00.680": "about pieces of the data blocks API so",
"0:03:02.750": "that you see how to kind of see what's",
"0:03:04.400": "going on normally with the date betablox",
"0:03:06.319": "API we've kind of said bla bla bla bla",
"0:03:09.230": "and done it all in one cell but let's do",
"0:03:10.939": "them one cell at a time so first thing",
"0:03:14.000": "you say is what kind of item list do you",
"0:03:16.250": "have so in this case it's an item list",
"0:03:18.109": "of images and then where are you getting",
"0:03:21.199": "the list of file names from in this case",
"0:03:23.180": "by looking in a folder recursively and",
"0:03:26.120": "that's where it's coming from you can",
"0:03:29.150": "pass in arguments that end up going to",
"0:03:31.069": "pillow because pillow or PIL is the",
"0:03:33.019": "thing that actually opens that for us",
"0:03:34.940": "and in this case these are black and",
"0:03:37.220": "white rather than RGB so you have to use",
"0:03:40.159": "pillows convert mode equals L for more",
"0:03:42.680": "details refer to the Python imaging",
"0:03:45.440": "library documentation to see what",
"0:03:47.840": "they're convert modes are but this one",
"0:03:49.669": "is going to be a grayscale which is what",
"0:03:53.060": "M lists is so inside an item list is an",
"0:03:57.500": "item's attribute and the items attribute",
"0:04:00.260": "is kind of the thing that you gave it",
"0:04:02.540": "it's the thing that it's going to use to",
"0:04:04.430": "create your items in this case the thing",
"0:04:06.290": "you gave it really is a list of file",
"0:04:07.849": "names that's what it got from the folder",
"0:04:11.109": "okay when you show images normally it",
"0:04:15.409": "shows them in RGB and so in this case we",
"0:04:18.680": "want to use a binary color map so in",
"0:04:20.599": "first AI you can set a default color map",
"0:04:22.669": "for more information about C map and",
"0:04:24.770": "color maps",
"0:04:25.870": "to the matplotlib documentation and so",
"0:04:28.600": "this will set the default color map for",
"0:04:30.639": "a faster I okay so our image item list",
"0:04:34.419": "contains 70,000 items and it's a bunch",
"0:04:36.940": "of images that are 1 by 28 by 28",
"0:04:40.030": "remember that pipe torch puts channel",
"0:04:41.830": "first so there one channel 28 for 28 you",
"0:04:45.250": "might think we're way out there just 28",
"0:04:46.720": "by 28 matrices rather than a 1 by 28 by",
"0:04:50.229": "28 rank 3 tensor it's just easier that",
"0:04:54.010": "way all the comp 2d stuff and so forth",
"0:04:57.790": "works on rank 3 tensors so you want to",
"0:05:00.760": "you want to include that unit axis at",
"0:05:03.370": "the start and so first day I will do",
"0:05:05.440": "that for you even when it's reading one",
"0:05:07.870": "channel images so the dot items",
"0:05:12.460": "attribute contains the things that's",
"0:05:14.320": "kind of red to build the image which in",
"0:05:16.930": "this case is the file name but if you",
"0:05:19.000": "just index into an item list directly",
"0:05:20.650": "you'll get the actual image object okay",
"0:05:23.260": "and so the actual image object has a",
"0:05:24.699": "show method and so there's there's the",
"0:05:26.860": "image so once you've got an image item",
"0:05:29.320": "list you then split it into training",
"0:05:31.810": "versus validation you nearly always want",
"0:05:34.599": "validation if you don't you can actually",
"0:05:36.729": "use the dot nose split method to create",
"0:05:39.940": "a kind of empty validation set you can't",
"0:05:43.120": "skip it entirely you have to say how to",
"0:05:45.340": "split and one of the options is no split",
"0:05:47.979": "right and so remember that's always the",
"0:05:49.870": "order first create your item list then",
"0:05:52.360": "decide how to split in this case we're",
"0:05:54.370": "gonna do it based on folders in this",
"0:05:58.120": "case the the validation folder for EM",
"0:06:01.720": "list is called testing so in kind of",
"0:06:04.960": "fast AI parlance we use the same kind of",
"0:06:07.210": "parlance that kaggle does which is the",
"0:06:09.220": "training set is what you train on the",
"0:06:11.710": "validation set has labels and you do it",
"0:06:14.349": "for testing that your models working the",
"0:06:16.479": "test set doesn't have labels and you use",
"0:06:20.050": "it for doing inference or submitting to",
"0:06:22.750": "a competition or sending it off to",
"0:06:24.639": "somebody who's held out those labels for",
"0:06:26.860": "you know event or testing or whatever",
"0:06:28.960": "okay so just because a folder in your",
"0:06:31.449": "data set is called testing doesn't mean",
"0:06:33.699": "it's a test set right this one has",
"0:06:35.169": "labels so it's a validation set",
"0:06:38.950": "okay so if you want to do inference on",
"0:06:40.960": "lots you know lots of things at a time",
"0:06:42.700": "rather than one thing at a time you want",
"0:06:44.800": "to use the test equals in in fast AI to",
"0:06:49.300": "say this is stuff which has no labels",
"0:06:51.100": "and I'm just using for inference okay so",
"0:06:55.110": "my split data is a training set and a",
"0:06:59.680": "validation set as you can see so inside",
"0:07:03.100": "the training set there's a folder for",
"0:07:06.040": "each image for each class so now we can",
"0:07:09.700": "take that split data and say label from",
"0:07:13.060": "folder so first you create the Animus",
"0:07:15.190": "then you spit it then you label it and",
"0:07:18.130": "so you can see now we have an X and a Y",
"0:07:21.100": "and the Y are category objects category",
"0:07:26.140": "object is just a class basically so if",
"0:07:30.610": "you index into a label list such as lol",
"0:07:35.050": "trained as a label list you will get",
"0:07:37.090": "back an independent variable independent",
"0:07:40.810": "variable X & Y so this case the X will",
"0:07:43.630": "be an image object which I can show and",
"0:07:46.240": "the Y will be a category object which I",
"0:07:48.760": "can read that's the number it's the",
"0:07:52.120": "number 8 category and there's the 8 next",
"0:07:56.890": "thing we can do is to add transforms in",
"0:07:59.890": "this case we're not going to use the",
"0:08:01.300": "normal get transforms function because",
"0:08:04.360": "we're doing digit recognition and digit",
"0:08:07.090": "recognition like you wouldn't want to",
"0:08:08.410": "flip it left right",
"0:08:09.730": "that would change the meaning of it you",
"0:08:11.560": "wouldn't want to rotate it too much that",
"0:08:13.180": "would change the meaning of it also",
"0:08:14.920": "because these images are so small kind",
"0:08:16.810": "of doing zooms and stuff is going to",
"0:08:18.220": "make them so fuzzy used to be unreadable",
"0:08:19.570": "so normally for small images of digits",
"0:08:23.650": "like this you just add a bit of random",
"0:08:25.210": "padding so I'll use the random padding",
"0:08:27.070": "function which actually returns two",
"0:08:30.520": "transforms so a bit that does the",
"0:08:32.650": "padding and the D that does the random",
"0:08:34.000": "crop so you have to use star to say put",
"0:08:36.220": "both these transforms in this list so",
"0:08:39.220": "now we can call transform this empty",
"0:08:42.280": "array here is referring to the",
"0:08:43.780": "validation set transforms so no",
"0:08:45.790": "transforms for the validation set now",
"0:08:49.360": "we've got a transformed",
"0:08:52.590": "list we can pick a batch size and choose",
"0:08:55.740": "data bunch we can choose normalize in",
"0:08:59.400": "this case we're not using a pre-trained",
"0:09:00.930": "model so there's no reason to use",
"0:09:03.210": "imagenet stats here and so if you call",
"0:09:06.840": "normalize like this without passing in",
"0:09:10.680": "stats it will all grab a batch of data",
"0:09:13.380": "at random and use that to decide what",
"0:09:16.140": "normalization stats to use that's a good",
"0:09:18.779": "idea",
"0:09:19.110": "if you're not using a pre-trained model",
"0:09:23.000": "okay so we've got a dead data bunch and",
"0:09:25.320": "so in that data bunch is a data set",
"0:09:29.070": "which we've seen already but what is",
"0:09:34.170": "interesting is that the training data",
"0:09:35.700": "set now has data augmentation because",
"0:09:37.529": "you've got transforms so plot multi is a",
"0:09:40.290": "faster Oh function that we're all plot",
"0:09:42.480": "the result of calling some function for",
"0:09:45.300": "each of this row by column grid so in",
"0:09:48.089": "this case my function is just grab and",
"0:09:50.550": "grab the first image from the training",
"0:09:51.990": "set and because each time you grab",
"0:09:54.570": "something from the training set it's",
"0:09:55.980": "going to load it from disk and it's",
"0:09:57.990": "going to transform it on the fly right",
"0:10:01.110": "so people sometimes ask like how many",
"0:10:04.160": "transformed versions of the image do you",
"0:10:06.330": "create and the answer is kind of",
"0:10:08.100": "infinite each time we grab one thing",
"0:10:10.950": "from the data set we do a random",
"0:10:12.750": "transform on the fly",
"0:10:14.730": "okay so potentially you everyone will",
"0:10:16.740": "look a little bit different so you can",
"0:10:19.440": "see here if we plot the result of that",
"0:10:21.390": "lots of times we get",
"0:10:22.620": "eights in slightly different positions",
"0:10:25.020": "because we did random padding you can",
"0:10:28.920": "always grab a batch of data then from",
"0:10:31.050": "the data bunch because remember a data",
"0:10:33.780": "bunch has data loaders and data loaders",
"0:10:36.360": "things that you grab a batch at a time",
"0:10:38.640": "and so you can then grab our X patch and",
"0:10:41.580": "a Y batch look at their shape batch size",
"0:10:44.550": "by channel by row by column all fast a a",
"0:10:48.330": "data bunches have a show batch which",
"0:10:50.130": "will show you what's in it in some",
"0:10:54.120": "sensible way okay so that's a quick walk",
"0:10:58.260": "through with the data block API stuff to",
"0:10:59.970": "grab our data so let's start out",
"0:11:02.959": "creating a simple CNN",
"0:11:06.769": "simple confident so the input is 28 by",
"0:11:10.999": "28 so let's define I like to define when",
"0:11:16.129": "I'm creating architectures a function",
"0:11:17.869": "which kind of does the things that I do",
"0:11:19.879": "again and again and again I don't want",
"0:11:21.170": "to call it with the same arguments",
"0:11:22.429": "because I'll forget I'll make a mistake",
"0:11:23.869": "so in this case all of my convolutions",
"0:11:26.749": "are going to be kernel size 3 stride 2",
"0:11:29.629": "padding 1 so let's just create a simple",
"0:11:32.059": "function to do a cons with those",
"0:11:34.160": "parameters so you try to have a",
"0:11:36.230": "convolution it's skipping over one pixel",
"0:11:41.059": "so it's doing jumping jumping two steps",
"0:11:43.699": "each time so that means that each time",
"0:11:46.249": "we have a convolution it's going to have",
"0:11:48.019": "the grid size so I've put a comment here",
"0:11:51.350": "showing what the new grid size is after",
"0:11:53.869": "each one so after the first convolution",
"0:11:56.600": "we have one channel coming in because",
"0:11:58.910": "it's remember it's a grayscale image",
"0:12:00.709": "with one channel and then how many",
"0:12:02.809": "channels coming out whatever you like",
"0:12:05.199": "right so remember you always get to pick",
"0:12:07.429": "how many filters you create regardless",
"0:12:11.179": "of whether it's a fully connected layer",
"0:12:13.069": "in which case it's just the the width of",
"0:12:15.470": "the matrix you're multiplying by or in",
"0:12:17.959": "this case with a 2d cons it's just how",
"0:12:20.480": "many how many filters do you want so I",
"0:12:23.959": "picked 8 and so after this it's dried 2",
"0:12:26.329": "so the 28 by 28 image is now a 14 by 14",
"0:12:30.279": "feature map with 8 channels so",
"0:12:33.559": "specifically therefore it's an 8 by 14",
"0:12:35.720": "by 14 tensor of activations then we'll",
"0:12:41.449": "do batch norm then would devalue so the",
"0:12:43.970": "number of input filters to the next con",
"0:12:46.100": "has to equal the number of output",
"0:12:47.689": "filters from the previous conf and we",
"0:12:50.389": "can just keep increasing the number of",
"0:12:51.799": "channels because we're doing stride to",
"0:12:54.199": "it's going to keep decreasing the grid",
"0:12:56.149": "size notice here it goes from 7 to 4",
"0:12:59.509": "because if you're doing a stride to",
"0:13:02.240": "convey over 7 it's going to be kind of",
"0:13:05.259": "math dot ceiling of 7/2 patch norm rail",
"0:13:12.169": "you confer now down to 2 by 2 personal",
"0:13:15.470": "really akan we're now down to 1 by 1",
"0:13:17.600": "right so after this",
"0:13:20.180": "we have a batch side of the picture map",
"0:13:25.790": "of let's say ten by one by one does that",
"0:13:34.370": "make sense we've got a grid size of one",
"0:13:35.990": "now so it's not a vector of length 10",
"0:13:39.440": "its a rank 3 tensor of 10 by 1 by 1 so",
"0:13:46.190": "our loss functions expect generally a",
"0:13:49.100": "vector not a rank 3 tensor so you can",
"0:13:52.460": "check flatten at the end and flatten",
"0:13:54.860": "just means remove any unit axes so that",
"0:13:59.570": "will make it now just a vector of length",
"0:14:02.180": "10 which is what we always expect so",
"0:14:06.110": "that's how we can create a CNN so then",
"0:14:10.490": "we can return that into a learner by",
"0:14:11.960": "passing in the data and the model and",
"0:14:14.270": "the loss function and if optionally some",
"0:14:17.960": "metrics so we're going to use",
"0:14:19.880": "cross-entropy as usual so we can then",
"0:14:22.610": "call own dot summary and confirm after",
"0:14:24.770": "that first cond we're down to 14 by 14",
"0:14:27.110": "and after the second column 7 by 7 and 4",
"0:14:31.400": "by 4 2 by 2 1 by 1 the flatten comes out",
"0:14:37.310": "calling it a lambda but that as you can",
"0:14:39.470": "see it gets rid of the 1 by 1 then it's",
"0:14:41.270": "now just a length 10 vector for each",
"0:14:45.440": "item in the bench so 128 by 10 matrix of",
"0:14:48.590": "the whole mini batch so just to confirm",
"0:14:52.400": "that this is working ok we can grab that",
"0:14:55.370": "mini batch of X that we created earlier",
"0:14:58.460": "there's so many vetch of X pop it onto",
"0:15:02.000": "the GPU and call the model directly",
"0:15:04.880": "remember any PI torch module we can",
"0:15:07.430": "pretend as a function and that gives us",
"0:15:10.580": "back as we hoped a 128 by 10 resolved ok",
"0:15:14.780": "so that's how you can directly get some",
"0:15:16.610": "predictions out now find fit one cycle",
"0:15:21.020": "and bang we already have a 98.6%",
"0:15:24.470": "accurate confident and this is trained",
"0:15:29.840": "from scratch of course it's not",
"0:15:31.070": "pre-trained we literally",
"0:15:32.390": "created our own architecture about the",
"0:15:34.040": "simplest possible architecture you can",
"0:15:35.570": "imagine 18 seconds to train so that's",
"0:15:37.670": "how easy it is to create a pretty",
"0:15:39.710": "accurate digit detector",
"0:15:42.410": "so let's refactor that a little rather",
"0:15:46.520": "than saying clowns metronome really all",
"0:15:49.970": "the time",
"0:15:51.170": "first day I already has something called",
"0:15:52.940": "con underscore lair which lets you",
"0:15:55.730": "create cons batch normal you",
"0:15:58.720": "accommodations and it has various other",
"0:16:00.920": "options to do other tweaks to it but the",
"0:16:03.380": "basic version is just exactly what I",
"0:16:05.570": "just showed you so we can refactor that",
"0:16:07.730": "like so so that's exactly the same",
"0:16:10.520": "euronet and so you know let's just try",
"0:16:15.380": "it a little bit longer and it's actually",
"0:16:17.870": "99.1 percent accurate if we train it for",
"0:16:20.660": "all over minute so that's cool so how",
"0:16:26.570": "can we improve this well what we really",
"0:16:28.820": "want to do is create a deeper Network",
"0:16:33.020": "and it's a very easy way to create a",
"0:16:35.300": "deeper Network would be after every",
"0:16:38.270": "stride to cons add a stride one cons",
"0:16:41.570": "because the straight one comes doesn't",
"0:16:43.550": "change the feature map size at all so",
"0:16:46.070": "you can add as many as you like right",
"0:16:48.340": "but there's a problem there's a problem",
"0:16:53.630": "and the problem was pointed out in this",
"0:16:55.730": "paper very very very influential paper",
"0:16:58.280": "called deep learning deep residual",
"0:17:00.110": "learning for image recognition by coming",
"0:17:02.810": "her and colleagues at then at Microsoft",
"0:17:05.270": "Research and they did something",
"0:17:07.250": "interesting they said let's look at the",
"0:17:08.750": "training error",
"0:17:09.589": "so forget generalization even let's just",
"0:17:11.720": "look at the training error of a network",
"0:17:14.720": "train on so far 10 and let's try one",
"0:17:18.890": "network of 20 layers just basic 3x3",
"0:17:21.860": "funds it's just basically the same",
"0:17:23.360": "network I just showed you but without",
"0:17:26.540": "batch norm let's try train to 20 layer",
"0:17:30.560": "one and a 56 layer one on the training",
"0:17:33.740": "set so the 56 layer one has a lot more",
"0:17:36.350": "parameters it's got a lot more of these",
"0:17:37.880": "trade one comes in the middle so the one",
"0:17:40.820": "with more parameters should seriously",
"0:17:42.890": "over fit right so you would expect",
"0:17:46.430": "the 56 layer one to zip down to zero ish",
"0:17:49.520": "training error pretty quickly and that",
"0:17:51.530": "is not what happens it is worse than the",
"0:17:54.200": "shallower network so when you see",
"0:17:56.480": "something weird happen really good",
"0:17:59.000": "researchers don't go oh no it's not",
"0:18:01.700": "working",
"0:18:02.180": "they go that's interesting so cutting",
"0:18:05.930": "her said that's interesting what's going",
"0:18:09.890": "on and he said I don't know but what I",
"0:18:14.840": "do know is this I could take this 56",
"0:18:18.380": "layer Network and make a new version of",
"0:18:22.400": "it which is identical but has to be at",
"0:18:25.070": "least as good as the 20 layer network",
"0:18:27.140": "and here's how every two convolutions",
"0:18:31.550": "I'm going to add together the input to",
"0:18:37.070": "those two convolutions add it together",
"0:18:39.440": "with the result of those two",
"0:18:42.910": "convolutions so in other words he's",
"0:18:46.160": "saying instead of saying output equals",
"0:18:51.820": "con two of cons one of X instead he's",
"0:18:59.750": "saying output equals x plus con of two",
"0:19:04.910": "of cons one of s so that fifty six",
"0:19:14.060": "layers worth of convolutions in in that",
"0:19:17.290": "his theory was has to be at least as",
"0:19:20.600": "good as the twenty layer version because",
"0:19:23.000": "it could always just set com2 and cons",
"0:19:27.050": "one to a bunch of zero waits for",
"0:19:29.900": "everything except for the first 20",
"0:19:31.340": "layers because because they're X the",
"0:19:34.640": "input could just go straight through so",
"0:19:38.060": "this thing here is as you see called an",
"0:19:41.840": "identity connection it's the identity",
"0:19:45.260": "function nothing happens at all it's",
"0:19:47.330": "also known as a skip connection so that",
"0:19:50.000": "was a theory right that's what the paper",
"0:19:51.950": "describes as the intuition behind this",
"0:19:54.590": "is what would happen if we created",
"0:19:57.500": "something",
"0:19:58.560": "which has to train at least as well as a",
"0:20:01.020": "20 layer neural network because it kind",
"0:20:03.300": "of contains that 28 layer neural network",
"0:20:05.160": "is literally a path you can just skip",
"0:20:07.680": "over all the convolutions and so what",
"0:20:11.430": "happens and what happened was he won",
"0:20:16.260": "imagenet that year he easily won",
"0:20:18.630": "imagenet that year and in fact you know",
"0:20:21.360": "even today you know we had that",
"0:20:25.640": "record-breaking result on image net",
"0:20:28.020": "speed training ourselves you know in the",
"0:20:29.910": "last year we used this to you know res",
"0:20:33.540": "net has been revolutionary and anytime",
"0:20:38.670": "here's a trick if you're interested in",
"0:20:40.290": "doing some research in the whole",
"0:20:41.550": "research anytime you find some model for",
"0:20:46.350": "anything with recite medical image",
"0:20:47.880": "segmentation or you know some kind of",
"0:20:51.090": "gain or whatever you know and it was",
"0:20:54.390": "written a couple of years ago they might",
"0:20:58.200": "have forgotten to put rest nets in res",
"0:21:00.150": "block res blocks this is what we",
"0:21:02.280": "normally call a res block they might",
"0:21:04.230": "have forgotten what res blocks in so",
"0:21:06.090": "replace their convolutional path with a",
"0:21:09.870": "bunch of res blocks and you'll almost",
"0:21:11.220": "always get better results faster it's a",
"0:21:14.820": "good trick",
"0:21:16.040": "so at Europe's which Rachel and I and",
"0:21:19.680": "David or just came back from and Sylvia",
"0:21:22.730": "we saw a new presentation where they",
"0:21:27.660": "actually figured out how to visualize",
"0:21:29.640": "the loss surface of a neural net which",
"0:21:33.270": "is really cool this is a fantastic paper",
"0:21:35.250": "and anybody who's watching this lesson 7",
"0:21:39.020": "is at a point where they will understand",
"0:21:41.520": "most of the most important concepts in",
"0:21:43.590": "this paper you could read this now you",
"0:21:45.810": "won't necessarily get all of it but I'm",
"0:21:47.460": "sure you'll find it again enough to find",
"0:21:49.710": "an interesting and so the the big",
"0:21:52.530": "picture was this one here's what happens",
"0:21:54.510": "if you if you draw a picture we're kind",
"0:21:57.270": "of X&Y",
"0:21:58.220": "here are two projections of the of the",
"0:22:01.590": "white space and Z is the loss and so as",
"0:22:05.250": "you move through the white space rest at",
"0:22:07.980": "a 56 layer neural network without skip",
"0:22:10.860": "connections is very very bumpy",
"0:22:12.620": "and that's why this got nowhere because",
"0:22:17.270": "it just got stuck in all these hills and",
"0:22:19.580": "bellies the exact same network with",
"0:22:23.750": "identity connections with skip",
"0:22:25.370": "connections has this lost landscape",
"0:22:28.059": "right so that's it's kind of interesting",
"0:22:31.159": "how how how her recognized back in 2015",
"0:22:36.490": "you know this shouldn't happen here's a",
"0:22:39.980": "way that must fix it and it took three",
"0:22:41.929": "years before people were able to say oh",
"0:22:44.510": "this is kind of why it fixed it it kind",
"0:22:47.870": "of reminds me of the batch normal",
"0:22:49.159": "discussion we had a couple of weeks ago",
"0:22:50.980": "people realizing a little bit after the",
"0:22:53.870": "fact sometimes what's what's going on",
"0:22:55.760": "and why it helps so in our code we can",
"0:23:06.460": "create a res block in just the way I",
"0:23:09.200": "described we create a tenant module we",
"0:23:12.380": "create two con Flair's remember a con",
"0:23:14.480": "flair is kind of 2d that's normal you so",
"0:23:21.470": "I come to derail your veteran or so",
"0:23:23.870": "creator of those and then in forward we",
"0:23:25.909": "go conf one of ex-cons two of that and",
"0:23:29.090": "then add X there's a res Bach function",
"0:23:34.370": "already in fast AI so you can just call",
"0:23:37.789": "res block instead and you just pass in",
"0:23:41.659": "something saying how many filters do you",
"0:23:44.149": "want so yeah so there's the wrist block",
"0:23:47.840": "that I defined in a notebook and so with",
"0:23:51.529": "that look with that res block we can now",
"0:23:53.840": "take every one of those I've just copied",
"0:23:56.360": "the previous CNN and after every con to",
"0:24:00.020": "except the last one I added a res block",
"0:24:02.320": "so this is great now got three times as",
"0:24:05.210": "many layers so it should be able to do",
"0:24:07.309": "more compute right but it shouldn't be",
"0:24:09.679": "any harder to optimize so what happens",
"0:24:13.870": "well let's just refactor it one more",
"0:24:16.070": "time since I go come to res block so",
"0:24:18.380": "many times let's just pop that into a",
"0:24:20.860": "little mini sequential model here and so",
"0:24:24.440": "I can refactor that like so",
"0:24:25.950": "like keep refactoring your architectures",
"0:24:28.380": "if you're trying novel architectures",
"0:24:29.700": "because you'll make less mistakes very",
"0:24:31.890": "few people do this most research codes",
"0:24:33.600": "you look at is is clunky as all hell and",
"0:24:37.260": "people often make mistakes in that way",
"0:24:39.030": "so don't don't do that be you know",
"0:24:40.860": "you're all coders so use your coding",
"0:24:43.800": "skills to make life easier",
"0:24:47.130": "okay so there's my ResNet ish",
"0:24:51.110": "architecture and ela find as usual fit",
"0:24:57.330": "for a while and I get ninety nine point",
"0:25:02.820": "five four so that's interesting because",
"0:25:07.710": "we've trained this literally from",
"0:25:09.660": "scratch with an architecture we built",
"0:25:11.640": "from scratch I didn't look at this",
"0:25:13.290": "architecture anywhere it's just the",
"0:25:14.670": "first thing that came to mind but in",
"0:25:17.760": "terms of where that puts us point four",
"0:25:19.890": "five percent error is around about the",
"0:25:23.430": "state of the art for this data set as of",
"0:25:26.180": "three or four years ago now you know",
"0:25:30.090": "today M just is considered a kind of",
"0:25:31.740": "trivially easy data set so I'm not",
"0:25:34.830": "saying like well we've broken some",
"0:25:36.480": "records here people have got beyond",
"0:25:38.480": "0.45% error but what I'm saying is that",
"0:25:41.250": "you know we can't you know this kind of",
"0:25:45.240": "resonate is a genuinely extremely useful",
"0:25:50.820": "network still today and this is this is",
"0:25:53.010": "really all we use in our first image net",
"0:25:56.160": "training still and one of the reasons as",
"0:25:58.380": "well is that it's so popular so the the",
"0:26:01.590": "vendors of the library spend a lot of",
"0:26:03.090": "time optimizing it so things tend to",
"0:26:05.550": "work fast where are some more modern",
"0:26:09.690": "style architectures using things like",
"0:26:12.150": "separable or group convolutions tend not",
"0:26:14.910": "to actually train very quickly in",
"0:26:16.320": "practice if you look at the definition",
"0:26:21.780": "of res block in the FASTA code you'll",
"0:26:24.660": "see it looks a little bit different to",
"0:26:25.890": "this and that's because i've created",
"0:26:28.710": "something called a merge layer and a",
"0:26:30.990": "merge layer is something which in the",
"0:26:33.510": "forward just keeps dense for a moment",
"0:26:35.820": "the forward says X plus X",
"0:26:39.260": "a ridge so you can see that some coming",
"0:26:42.380": "ResNet ish going on here what is X dot",
"0:26:44.960": "orig well if you create a special kind",
"0:26:47.990": "of sequential model called a sequential",
"0:26:49.760": "e^x so this is like the fastes",
"0:26:52.510": "sequential extended it's just like a",
"0:26:54.890": "normal sequential model but we store the",
"0:26:57.380": "input in X dot orig right and so this",
"0:27:02.810": "this here is the quench really ex-con",
"0:27:05.030": "flour corn flour merge layer will do",
"0:27:09.440": "exactly the same that's this okay so you",
"0:27:12.710": "can create your own variations of ResNet",
"0:27:15.740": "blocks very easily with just sequential",
"0:27:18.140": "ax and merge layer so there's something",
"0:27:22.790": "else here which is when you create your",
"0:27:24.170": "merge layer you can optionally set dense",
"0:27:26.900": "equals true what happens if you do well",
"0:27:29.810": "if you do it doesn't go X plus X dot",
"0:27:32.120": "image that goes cat X comma X dot orig",
"0:27:35.450": "in other words rather than putting a",
"0:27:39.080": "plus in this connection it does a",
"0:27:41.990": "concatenate so that's pretty interesting",
"0:27:45.470": "because what happens is that you have",
"0:27:47.810": "your your input coming into your res",
"0:27:53.000": "block and once you use concatenate",
"0:27:55.280": "instead of plus it's not called a res",
"0:27:57.110": "block anymore it's called a dense block",
"0:27:58.910": "and it's not quite a ResNet any what",
"0:28:01.130": "more is called a dense net so the dense",
"0:28:03.350": "net was invented about a year after the",
"0:28:06.560": "ResNet and if you read the dense net",
"0:28:08.420": "paper it can sound incredibly complex",
"0:28:10.280": "and different but actually it's",
"0:28:11.720": "literally identical but plus here is",
"0:28:14.510": "replaced with with cat so you have your",
"0:28:17.750": "input coming into your dense block right",
"0:28:19.850": "and you've got a kind of few",
"0:28:21.190": "convolutions in here and then you've got",
"0:28:23.750": "some output coming out and then you've",
"0:28:26.480": "got your identity connection and",
"0:28:28.010": "remember it doesn't plus it con cats so",
"0:28:31.190": "this is the channel access it gets a",
"0:28:33.710": "little bit bigger all right and then so",
"0:28:36.170": "we do another dense block right and at",
"0:28:38.870": "the end of that we have you know all of",
"0:28:42.650": "this coming in drop sorry we have okay",
"0:28:47.270": "so at the end of that we have you know",
"0:28:49.070": "the result of the convolution as per",
"0:28:50.660": "usual but this time",
"0:28:52.790": "identity bloc is that big right so you",
"0:28:57.770": "can see that what happens is that with",
"0:28:59.510": "dense blocks it's getting bigger and",
"0:29:01.520": "bigger and bigger and kind of",
"0:29:03.050": "interestingly the exact input is still",
"0:29:07.460": "here right so that actually no matter",
"0:29:10.670": "how deep you get the original input",
"0:29:12.830": "pixels are still there and the original",
"0:29:14.510": "layer 1 features are still there in the",
"0:29:15.890": "original layer of two features are still",
"0:29:17.240": "there so as you can imagine dense Nets",
"0:29:21.320": "are very memory intensive there are ways",
"0:29:24.440": "to manage this the best from time to",
"0:29:26.270": "time you can have a regular convolution",
"0:29:28.430": "that squishes your channels back down",
"0:29:30.200": "but they are memory intensive but they",
"0:29:33.860": "have very few parameters so for dealing",
"0:29:38.180": "with small datasets",
"0:29:39.350": "you should definitely experiment with",
"0:29:41.660": "dense blocks and dense Nets they tend to",
"0:29:45.860": "work really well on small datasets also",
"0:29:49.610": "because it's possible to kind of keep",
"0:29:51.200": "those original input pixels all the way",
"0:29:53.330": "down the path they work really well for",
"0:29:55.250": "segmentation right because for",
"0:29:57.170": "segmentation you know you kind of want",
"0:29:59.060": "to be able to reconstruct the original",
"0:30:02.200": "resolution of your picture so having all",
"0:30:04.790": "of those original pixels still there is",
"0:30:06.440": "super helpful so so that's that's",
"0:30:18.220": "residents and the main one of the main",
"0:30:20.270": "reasons other than fact that rez nets",
"0:30:21.770": "are awesome to tell you about them is",
"0:30:23.510": "that these skipped connections are",
"0:30:25.040": "useful in other places as well and there",
"0:30:28.880": "it's particularly useful in other places",
"0:30:30.680": "and other ways of designing",
"0:30:31.790": "architectures for segmentation so in",
"0:30:35.630": "building this lesson I always kind of I",
"0:30:38.870": "keep trying to take old papers and",
"0:30:41.990": "saying like imagining like what would",
"0:30:44.120": "that person have done if they had access",
"0:30:46.160": "to all the modern techniques we have now",
"0:30:48.320": "and I try to kind of rebuild them in a",
"0:30:50.420": "more modern style so I've been really",
"0:30:52.040": "rebuilding this next architecture going",
"0:30:54.770": "to look at called a unit in a more",
"0:30:56.720": "modern style recently and got to the",
"0:30:59.930": "point now I keep showing you this",
"0:31:02.960": "semantic segmentation paper with the",
"0:31:06.980": "state of the art for camford which was",
"0:31:09.220": "91.5 this week I got it up to 94.1 using",
"0:31:15.950": "the architecture I'm about to show you",
"0:31:17.270": "so we just we keep pushing this further",
"0:31:19.250": "and further and further and it's really",
"0:31:21.860": "was all about you know adding all of the",
"0:31:26.900": "modern tricks many of which I'll show",
"0:31:30.500": "you today some of which we will see in",
"0:31:32.690": "part two so what we're going to do to",
"0:31:37.010": "get there is we're going to use this",
"0:31:38.810": "unit so we've used a unit before I've",
"0:31:42.020": "improved it a bit since then so we've",
"0:31:45.710": "used a unit before we used it when we",
"0:31:47.360": "did the camp fit segmentation but we",
"0:31:48.800": "didn't understand what it was doing so",
"0:31:51.320": "we're now in a position where we can",
"0:31:52.610": "understand what I was doing and so the",
"0:31:59.300": "first thing we need to do is kind of",
"0:32:00.920": "understand the basic idea of how you can",
"0:32:03.680": "do segmentation so if we go back to our",
"0:32:09.770": "canvas notebook in our camping notebook",
"0:32:15.890": "you'll remember that basically what we",
"0:32:17.330": "were doing is we were taking these",
"0:32:18.530": "photos and adding a class to every",
"0:32:22.730": "single pixel and somebody go data touch",
"0:32:24.800": "show batch for something which is a",
"0:32:26.810": "segmentation item list it will",
"0:32:30.200": "automatically show you these color-coded",
"0:32:33.140": "pixels so here's the thing like in order",
"0:32:39.050": "to color code this as a pedestrian you",
"0:32:43.730": "know but this as a bicyclist it needs to",
"0:32:47.690": "know what it is there needs to actually",
"0:32:49.610": "know that's what a pedestrian looks like",
"0:32:51.170": "and it needs to know that's exactly",
"0:32:52.400": "where the pedestrian is and this is the",
"0:32:53.660": "arm of the pedestrian and not part of",
"0:32:55.100": "their shopping basket it needs to really",
"0:32:57.290": "understand a lot about this picture to",
"0:33:00.590": "do this task and it really does through",
"0:33:02.750": "this task like when you looked at the",
"0:33:04.610": "results of our top model it's it's you",
"0:33:09.740": "know I can't see a single pixel by",
"0:33:12.770": "looking at it by eye I know there's a",
"0:33:14.210": "few wrong but I can't see",
"0:33:15.770": "ones that are wrong is that accurate so",
"0:33:18.650": "how does it do that so the way that",
"0:33:20.630": "we're doing it to get these really",
"0:33:22.940": "really good results is not surprisingly",
"0:33:26.530": "using pre-training so we start with a",
"0:33:30.260": "ResNet 34 and you can see that here unit",
"0:33:36.920": "learner data comma model start ResNet 34",
"0:33:40.280": "and if you don't say pre-trained equals",
"0:33:42.710": "false by default you get pre-trained",
"0:33:44.960": "equals true because why not so we start",
"0:33:49.460": "with a resonate 34 which starts with a",
"0:33:55.430": "big image so in this case this is from",
"0:33:58.580": "the unit paper now they're images they",
"0:34:01.040": "started with one channel by 572 by 572",
"0:34:04.760": "this is for medical imaging segmentation",
"0:34:07.570": "so after your stride to cons you and",
"0:34:12.020": "they're doubling the number of channels",
"0:34:13.340": "to 128 and they're having the size so",
"0:34:16.429": "they're now down to 280 by 280 in this",
"0:34:19.940": "original unit paper they didn't add any",
"0:34:22.310": "padding so they lost the pixel on each",
"0:34:24.530": "side each time they did a con that's why",
"0:34:26.270": "you're losing these two but so basically",
"0:34:28.340": "half the size and then half the size and",
"0:34:31.340": "then half the size and then half the",
"0:34:33.409": "size until they're down to 28 by 28 with",
"0:34:37.520": "1024 channels right so that's that's",
"0:34:40.580": "what the unit's down the sampling path",
"0:34:45.020": "this is called the down sampling path",
"0:34:46.190": "look like ours is just a ResNet 34 so",
"0:34:50.810": "you can see it here learn dot summary",
"0:34:54.260": "right this is literally a resinate 34 so",
"0:35:01.130": "you can see that the size keeps having",
"0:35:03.200": "channels keep going up and so forth",
"0:35:07.160": "okay so eventually you've got down to a",
"0:35:10.850": "point where if you use a unit",
"0:35:12.530": "architecture it's 28 by 28 with 1,024",
"0:35:15.770": "channels with the resonant architecture",
"0:35:17.630": "with a 224 pixel input it would be 512",
"0:35:22.910": "channels by 7 by 7 so it's a pretty",
"0:35:25.280": "small grid size on this feature map",
"0:35:28.559": "somehow we've got to end up with",
"0:35:31.599": "something which is the same size as our",
"0:35:34.779": "original picture so how do we do that",
"0:35:38.440": "how do you do computation which",
"0:35:42.130": "increases the grid size well we don't we",
"0:35:46.480": "don't have a way to do that in our",
"0:35:47.859": "current bag of tricks",
"0:35:48.910": "we can use a stride one conf to do",
"0:35:51.640": "computation and keeps grid size or a",
"0:35:53.789": "stride to con to do computation and half",
"0:35:57.250": "the grid size so how do we double the",
"0:35:59.440": "grid size we do a stride 1/2 conf also",
"0:36:04.779": "known as a deconvolution also known as a",
"0:36:08.170": "transposed convolution there is a",
"0:36:11.529": "fantastic paper called a guide to",
"0:36:14.230": "convolution arithmetic fatigue learning",
"0:36:15.760": "that shows a great picture of exactly",
"0:36:18.010": "what does a 3x3 kernel stride 1/2 cons",
"0:36:21.910": "look like and it's literally this if you",
"0:36:24.460": "have a 2x2 input so the blue squares are",
"0:36:27.640": "the 2x2 input you add not only 2 pixels",
"0:36:32.650": "of padding all around the outside but",
"0:36:35.859": "you also add a pixel of padding between",
"0:36:39.869": "every pixel and so now if we put this",
"0:36:44.470": "3x3 kernel here and then here and then",
"0:36:48.339": "here usually other 3x3 kernels just",
"0:36:50.049": "moving across it in the usual way you",
"0:36:52.210": "will end up going from a 2x2 output to a",
"0:36:56.880": "5x5 output so if you only added one",
"0:36:59.980": "pixel of padding around the outside you",
"0:37:02.019": "would add up end up with a 3x3 output",
"0:37:05.289": "right so that's very 4x4 so this is how",
"0:37:11.140": "you can increase the resolution this was",
"0:37:19.200": "the way people did it until maybe a year",
"0:37:24.819": "or two ago that's another trick for",
"0:37:28.450": "improving things you find online because",
"0:37:30.970": "this is actually a dumb way to do it and",
"0:37:33.039": "it's kind of obvious it's a dumb way to",
"0:37:34.269": "do it for a couple of reasons one is",
"0:37:35.619": "that like hello look at this nearly all",
"0:37:38.650": "of those pixels are white they're nearly",
"0:37:40.990": "all zeros",
"0:37:42.040": "so like what a waste what a waste of",
"0:37:44.589": "time what a waste of computation",
"0:37:46.960": "there's just nothing going on there I'm",
"0:37:48.970": "also this one when you get down to like",
"0:37:54.690": "that 3x3 area two out of the nine pixels",
"0:37:58.930": "are non-white but this one one out of",
"0:38:02.320": "the nine at lone white so they're kind",
"0:38:03.910": "of like there's different amounts of",
"0:38:05.320": "information going into different parts",
"0:38:07.329": "of your convolution so like this it just",
"0:38:10.089": "doesn't make any sense to kind of throw",
"0:38:13.359": "away information like this and they're",
"0:38:15.070": "going to do all this unnecessary",
"0:38:15.839": "computation and have different parts of",
"0:38:17.740": "the convolution having access to",
"0:38:19.329": "different amounts of information so what",
"0:38:23.890": "people generally do nowadays is",
"0:38:26.109": "something really simple which is if you",
"0:38:28.450": "have a let's say a two by two input with",
"0:38:32.320": "these are your pixel values a a B C and",
"0:38:36.480": "D and you want to create a four by four",
"0:38:44.070": "why not just do this a a a a b b b b CC",
"0:38:51.310": "CC d D D D so I've now upscaled from two",
"0:38:57.130": "by two to four by four I haven't done",
"0:38:59.470": "any interesting computation but now on",
"0:39:01.720": "top of that I could just do a Strad one",
"0:39:05.589": "convolution and now I have done some",
"0:39:08.079": "computation right so an up sample this",
"0:39:11.349": "is called nearest neighbor interpolation",
"0:39:13.800": "nearest neighbor interpolation so you",
"0:39:20.890": "can just do that's super fast just",
"0:39:22.960": "that's taken to a nearest neighbor",
"0:39:24.490": "interpolation and then a stride one conf",
"0:39:27.010": "and now you've got some computation",
"0:39:29.050": "which is actually kind of using you know",
"0:39:32.319": "there's no zeros here this is kind of",
"0:39:34.690": "nice because it gets a mixture of A's",
"0:39:36.250": "and B's which is kind of what you would",
"0:39:37.599": "want and so forth another approach is",
"0:39:41.349": "instead of using nearest neighbor",
"0:39:42.670": "interpolation you can use bilinear",
"0:39:44.950": "interpolation which basically means",
"0:39:47.349": "instead of copying a to all those",
"0:39:49.210": "different cells you take a kind of a",
"0:39:51.099": "weighted average",
"0:39:51.819": "if the cells around it so for exam",
"0:39:54.530": "if you were you know looking at what",
"0:39:58.700": "should go here he would kind of go like",
"0:40:00.740": "oh it's about 3/8 2 C's 1d and 2 B's and",
"0:40:06.170": "you could have taken the average not",
"0:40:07.850": "exactly but roughly just a weighted",
"0:40:09.920": "average by linear interpolation you'll",
"0:40:11.750": "find in any you know all over the place",
"0:40:13.850": "it's is pretty standard technique",
"0:40:15.610": "anytime you look at a picture on your",
"0:40:18.530": "computer screen and change its size it's",
"0:40:20.510": "doing bilinear interpolation so you can",
"0:40:22.340": "do that and then a strike one conf so",
"0:40:26.300": "that was what people were using worst",
"0:40:28.310": "what people still tend to use that's as",
"0:40:31.550": "much as are going to teach you this part",
"0:40:33.890": "in part two will actually learn what the",
"0:40:36.290": "first day I library is actually doing",
"0:40:38.270": "behind the scenes which is something",
"0:40:40.580": "called a pixel shuffle also known as sub",
"0:40:43.400": "pixel convolutions it's got not",
"0:40:45.410": "dramatically more complex but complex",
"0:40:47.060": "enough that I won't cover it today",
"0:40:48.350": "there's a same basic idea all of these",
"0:40:50.180": "things is something which is basically",
"0:40:52.490": "letting us do a convolution that ends up",
"0:40:55.130": "with something that's twice the size and",
"0:40:57.830": "so that gives us our up sampling path",
"0:41:01.400": "right so that lets us go from 28 by 28",
"0:41:05.830": "to 54 by 54 and keep on doubling the",
"0:41:10.070": "size so that's good and that was that",
"0:41:16.670": "was it until unit came along that's what",
"0:41:19.640": "people did and it didn't work real well",
"0:41:21.920": "which is not surprising because like in",
"0:41:24.500": "this 28 by 28 feature map how the hell",
"0:41:28.340": "is it going to have enough information",
"0:41:29.360": "to reconstruct a 572 by 572 output space",
"0:41:34.670": "you know that's a really tough ask so",
"0:41:37.820": "you tended to end up with these things",
"0:41:39.320": "that lack fine detail so what dollar for",
"0:41:48.170": "on a burger and a towel did was they",
"0:41:52.970": "said hey let's add a skip connection an",
"0:41:55.990": "identity connection and amazingly enough",
"0:41:59.000": "this was before res Nets existed so this",
"0:42:03.050": "was like a really big leap really",
"0:42:06.770": "impressive",
"0:42:07.830": "and so but rather than adding a skip",
"0:42:09.510": "connection that skipped every two",
"0:42:12.260": "convolutions they added skip connections",
"0:42:15.390": "where these gray lines are in other",
"0:42:17.850": "words they added a skip connection from",
"0:42:19.350": "the same part of the downsampling path",
"0:42:21.630": "to the same-sized bit in the up sampling",
"0:42:25.050": "path and they didn't add that's why you",
"0:42:28.530": "can see the white and the blue next to",
"0:42:30.540": "each other they didn't add they",
"0:42:31.970": "concatenated so basically these are like",
"0:42:34.620": "dense blocks right but the Skip",
"0:42:37.260": "connections are skipping over larger and",
"0:42:39.660": "larger amounts of the architecture so",
"0:42:43.020": "that over here you've literally got",
"0:42:48.200": "nearly the input pixels themselves",
"0:42:51.770": "coming into the computation of these",
"0:42:54.570": "last couple of layers and so that's",
"0:42:56.280": "going to make it super handy through",
"0:42:58.380": "resolving the fine details in these",
"0:43:00.240": "segmentation tasks because you've",
"0:43:01.920": "literally got all of the fine details on",
"0:43:04.560": "the downside you don't have very many",
"0:43:07.050": "layers of computation going on here just",
"0:43:09.900": "for right so you better hope that by",
"0:43:12.630": "that stage you've done all the",
"0:43:14.340": "computation necessary to figure out is",
"0:43:16.440": "this the bicyclist or is this a",
"0:43:17.700": "pedestrian but you can then add on top",
"0:43:20.130": "of that something saying like is this",
"0:43:21.570": "you know is this exact pixel where their",
"0:43:23.910": "nose finishes or is that the start of",
"0:43:25.500": "the tree so that works out really well",
"0:43:30.150": "and that's a unit so this is the unit",
"0:43:35.930": "code from fast AI and the key thing that",
"0:43:40.260": "comes in is the encoder the encoder",
"0:43:44.780": "refers to that part in other words in",
"0:43:52.590": "our case a ResNet 34 in most cases they",
"0:43:57.570": "have this specific older style",
"0:44:00.180": "architecture but like I said replace any",
"0:44:02.880": "older style architecture bits where the",
"0:44:04.470": "ResNet bits and life improves",
"0:44:06.470": "particularly if they're pre trained so",
"0:44:08.490": "that certainly happened for us so we",
"0:44:10.110": "start with our encoder so our layers of",
"0:44:11.880": "our unit is an encoder then batch norm",
"0:44:14.010": "then rally and then middle con which is",
"0:44:18.120": "just con flare comma con flare member",
"0:44:21.000": "Khan",
"0:44:21.450": "is a conf rally veteran on in faster go",
"0:44:25.260": "and so that middle con is these two",
"0:44:30.119": "extra steps here at the bottom okay just",
"0:44:32.880": "doing a little bit of computation you",
"0:44:34.680": "know it's kind of nice to add more",
"0:44:36.329": "layers of computation where you can so",
"0:44:39.000": "encode a batch or Lu and then to",
"0:44:40.829": "convolutions and then we enumerate",
"0:44:43.349": "through these indexes what are these",
"0:44:46.170": "indexes I haven't included the code but",
"0:44:48.180": "these are basically we figure out what",
"0:44:50.579": "is the layer number where each of these",
"0:44:54.230": "stripe to comes occurs and we just store",
"0:44:57.660": "it in an array of indexes so then we can",
"0:45:00.060": "loop through that and we can basically",
"0:45:02.339": "say for each one of those points create",
"0:45:04.619": "a unit block telling us how many",
"0:45:08.040": "upsampling channels that are and how",
"0:45:09.780": "many cross connection these these things",
"0:45:12.750": "here are called cross connections at",
"0:45:14.430": "least that's what I call them so that's",
"0:45:17.940": "really the main works going on in the in",
"0:45:20.220": "the unit block as I said there's quite a",
"0:45:23.430": "few tweaks we do as well as the fact we",
"0:45:25.560": "use a much better encoder we also use",
"0:45:27.900": "some tweaks in all of our app sampling",
"0:45:29.819": "using this pixel shuffle we use another",
"0:45:31.859": "tweak called ICN our and then and then",
"0:45:34.349": "another tweak which I just did in the",
"0:45:35.880": "last week is to not just take the result",
"0:45:38.970": "of the convolutions and pass it across",
"0:45:40.740": "but we actually grab the input pixels",
"0:45:42.900": "and make them another cross connection",
"0:45:45.180": "that's what this last cross is here you",
"0:45:48.060": "can see we're literally appending a res",
"0:45:50.460": "block with the original inputs so you",
"0:45:53.760": "can see I merge layer so really all the",
"0:45:57.510": "works going on a new net block and unit",
"0:46:00.540": "block is it has to store the the",
"0:46:04.700": "activations at each of these",
"0:46:06.329": "downsampling points and the way to do",
"0:46:09.119": "that as we learn in the last lesson is",
"0:46:11.250": "with hooks so we we put hooks into the",
"0:46:15.150": "resinate 34 to store the activations",
"0:46:18.359": "each time there's a strata to cons and",
"0:46:21.329": "so that's you can see here we we grab",
"0:46:23.460": "the hook okay and we grab the result of",
"0:46:27.599": "the stored value in that hook and we",
"0:46:30.060": "literally just go torch doc hat so we",
"0:46:32.310": "concatenate",
"0:46:35.540": "the upsampled convolution with the",
"0:46:42.420": "result of the hook which we Chuck",
"0:46:44.550": "through batch norm and then we do two",
"0:46:46.620": "convolutions to it and actually you know",
"0:46:49.940": "something you could play with at home is",
"0:46:52.050": "pretty obvious here anytime you see two",
"0:46:54.360": "convolutions like this there's an",
"0:46:55.740": "obvious question is what if we used a",
"0:46:57.240": "resident block instead so you could try",
"0:46:59.520": "replacing those two comes with a",
"0:47:01.290": "resinate block you might find you get",
"0:47:03.090": "even better results they're the kind of",
"0:47:05.400": "things I look for when I look at an",
"0:47:07.290": "architecture is like oh two columns in a",
"0:47:09.360": "row probably should be a ResNet block",
"0:47:14.660": "okay so that's that's unit and you know",
"0:47:22.650": "it's amazing to think you know it",
"0:47:24.840": "preceded ResNet to preceded dense net",
"0:47:27.590": "it's been it wasn't even published in a",
"0:47:30.780": "major machine learning venue it was",
"0:47:33.480": "actually published in Mekhi which is a",
"0:47:35.660": "specialized medical image computing",
"0:47:37.800": "conference for years actually you know",
"0:47:41.130": "it was largely unknown outside of the",
"0:47:43.110": "medical imaging community and actually",
"0:47:45.390": "what happened was tackle competitions",
"0:47:48.210": "for segmentation kept on being easily",
"0:47:50.940": "won by people using units and that was",
"0:47:52.740": "the first time I saw it getting noticed",
"0:47:54.450": "outside the medical imaging community",
"0:47:56.010": "and then gradually a few people in the",
"0:47:57.900": "academic machine learning community",
"0:47:59.370": "started noticing and now everybody loves",
"0:48:02.700": "unit which I'm glad because it's just",
"0:48:05.090": "it's just awesome so yeah so identity",
"0:48:12.030": "connections regardless of whether",
"0:48:14.100": "they're a plus style or a concat style",
"0:48:17.780": "we're incredibly useful they can",
"0:48:20.250": "basically get us close to the state of",
"0:48:22.170": "the art on lots of important tasks so I",
"0:48:27.780": "want to use them on another task now and",
"0:48:30.900": "so the next task I want to look at is",
"0:48:33.440": "image restoration so image restoration",
"0:48:36.980": "refers to starting with an image at this",
"0:48:40.770": "time we're not going to create a",
"0:48:41.520": "segmentation mask but we're going to try",
"0:48:43.860": "and create a a better image",
"0:48:47.330": "and there's lots of kind of versions of",
"0:48:48.500": "better there could be different image so",
"0:48:50.750": "the kind of things we can do with this",
"0:48:52.070": "kind of image generation would be take a",
"0:48:54.290": "low res image make it high res take a",
"0:48:57.380": "black-and-white image make a color take",
"0:48:59.720": "an image where something's being cut out",
"0:49:02.000": "of it and trying to replace the cutout",
"0:49:04.130": "thing take a photo and try and turn it",
"0:49:07.340": "into what looks like a line drawing take",
"0:49:09.290": "a photo and try and make it look like a",
"0:49:10.940": "Monet painting these are all examples of",
"0:49:13.250": "kind of image to image generation tasks",
"0:49:15.050": "which you all know how to do after this",
"0:49:17.750": "part of class so in our case we're going",
"0:49:22.850": "to try to do image restoration which is",
"0:49:26.510": "going to start with low resolution poor",
"0:49:29.960": "quality JPEGs with writing written over",
"0:49:33.560": "the top of them and get them to replace",
"0:49:36.050": "them with high resolution good quality",
"0:49:38.690": "pictures in which the the text has been",
"0:49:41.300": "removed two questions okay let's go",
"0:49:50.770": "why do you compat before calling comp to",
"0:49:54.110": "comp one not after because if you did",
"0:50:01.790": "kind of one Conte you know if you did",
"0:50:03.380": "your combs before you concat then",
"0:50:05.750": "there's no way for the channels of the",
"0:50:08.240": "two parts to interact with each other",
"0:50:10.850": "you don't get any you know so remember",
"0:50:13.940": "in a 2d conf it's really 3d right it's",
"0:50:18.380": "moving across two dimensions but in each",
"0:50:21.560": "case it's doing a dot product of all",
"0:50:25.820": "three dimensions of a rank three tensor",
"0:50:27.830": "row by column by Channel so generally",
"0:50:32.480": "speaking we want as much interaction as",
"0:50:34.460": "possible we want to say you know this",
"0:50:37.640": "part of the down sampling path and this",
"0:50:39.260": "part of the up sampling path if you look",
"0:50:40.820": "at the combination of them you find",
"0:50:42.230": "these interesting things so generally",
"0:50:44.320": "you know you you want to have as many",
"0:50:47.600": "interactions going on as possible in",
"0:50:50.030": "each computation that you do",
"0:50:55.589": "is concatenating every layer together in",
"0:50:57.779": "a dense Network when the size of the",
"0:50:59.759": "image feature Maps is changing through",
"0:51:01.769": "the layers that's a great question so if",
"0:51:08.039": "you have a stride to cons you can't keep",
"0:51:11.699": "dense knitting right so that's what",
"0:51:15.119": "actually happens in a dense net is you",
"0:51:16.559": "kind of go like dense block growing",
"0:51:18.749": "dense block growing dense block growing",
"0:51:20.309": "so you getting more and more channels",
"0:51:21.209": "and then you do a stride to cons without",
"0:51:25.920": "a dense block and so now it's kind of",
"0:51:29.160": "gone and then you just do a few more",
"0:51:30.420": "dense blocks and then it's gone so in",
"0:51:33.140": "practice a dense block doesn't actually",
"0:51:36.180": "keep all the information all the way",
"0:51:37.859": "through but just every up into every one",
"0:51:40.829": "of these stride to comes and there's",
"0:51:45.630": "kind of various ways of doing these",
"0:51:46.890": "bottlenecking layers where you're",
"0:51:48.420": "basically saying hey let's let's reset",
"0:51:51.299": "it also helps us keep memory under",
"0:51:53.549": "control because at that point we can",
"0:51:54.779": "decide how many channels we actually",
"0:51:56.819": "want good questions thank you back so in",
"0:52:04.349": "order to create something which can turn",
"0:52:06.170": "crappy images into nice images we need a",
"0:52:10.049": "data set containing nice versions of",
"0:52:12.569": "images and crappy versions of the same",
"0:52:14.219": "images so the easiest way to do that is",
"0:52:16.469": "to start with some nice images and crap",
"0:52:19.109": "fi them and so the way to crap fi them",
"0:52:21.179": "is to create a function called crap fi",
"0:52:23.579": "which contains your krappa fication",
"0:52:25.559": "logic so Mike ratification logic you can",
"0:52:30.029": "pick your own is that I open up my nice",
"0:52:32.910": "image I resize it to be really small 96",
"0:52:35.969": "by 96 pixels with bilinear interpolation",
"0:52:40.219": "I then pick a random number between 10",
"0:52:43.199": "and 70 I draw that number into my image",
"0:52:48.420": "at some random location and then I save",
"0:52:52.289": "that image with a JPEG quality of that",
"0:52:55.559": "random number and a JPEG quality of 10",
"0:52:58.739": "is like absolute rubbish a JPEG quality",
"0:53:02.729": "of 70 is not bad at all okay so I end up",
"0:53:07.939": "where",
"0:53:09.019": "if high quality images low quality",
"0:53:11.149": "images that look something like these",
"0:53:14.749": "and so you can see this one you know",
"0:53:17.269": "there's the image and this is after",
"0:53:19.459": "transformation so that's why it's been",
"0:53:20.949": "flipped and you won't always see the",
"0:53:23.299": "image because we're zooming into them so",
"0:53:26.479": "a lot of the time the image is cropped",
"0:53:28.819": "out",
"0:53:29.959": "so yeah it's trying to figure out how to",
"0:53:31.759": "take this incredibly jpg artifactory",
"0:53:33.890": "thing with with text written over the",
"0:53:35.659": "top and turn it into into this so I'm",
"0:53:38.390": "using the Oxford pets data set again the",
"0:53:40.969": "same one we used in lesson 1 so there's",
"0:53:43.459": "nothing more high qualities and pictures",
"0:53:45.079": "of dogs and cats I think we can all",
"0:53:46.549": "agree with that",
"0:53:48.489": "the krappa fication process can take a",
"0:53:51.109": "while but fast AI has a function called",
"0:53:54.619": "parallel and if you pass parallel a",
"0:53:57.289": "function name and a list of things to",
"0:53:59.719": "run that function on it will run that",
"0:54:02.179": "function on them all in parallel so this",
"0:54:05.569": "actually can run pretty quickly",
"0:54:11.079": "the way you write this function is where",
"0:54:14.119": "you get to do all the interesting stuff",
"0:54:15.679": "in this assignment try and think of an",
"0:54:19.609": "interesting krappa fication which does",
"0:54:21.619": "something that you want to do right so",
"0:54:23.269": "if you want to you know colorize",
"0:54:25.880": "black-and-white images you would replace",
"0:54:27.559": "it with black-and-white if you want",
"0:54:29.179": "something which can you know take like",
"0:54:31.579": "large cutout blocks of image and replace",
"0:54:34.339": "them with kind of hallucinatin image you",
"0:54:37.549": "know add a big black box to these if you",
"0:54:40.729": "want something which can kind of take",
"0:54:42.109": "old families photos scans that have been",
"0:54:44.419": "like folded up and have crinkles in try",
"0:54:46.549": "and find a way of like adding dust",
"0:54:48.979": "prints and crinkles and so forth right",
"0:54:50.899": "and anything that you don't include in",
"0:54:54.709": "crap fi your model won't learn to fix",
"0:54:57.769": "because every time it sees that in your",
"0:55:00.169": "photos the input and output will be the",
"0:55:01.729": "same so it won't consider that to be",
"0:55:03.559": "something worthy of fixing okay",
"0:55:06.619": "so so we now want to create a model",
"0:55:10.939": "which can take an input photo that looks",
"0:55:15.409": "like that and outputs something that",
"0:55:18.289": "looks like that so obviously what we",
"0:55:20.839": "want to do is",
"0:55:21.829": "is a unit because we already know that",
"0:55:23.359": "units can do exactly that kind of thing",
"0:55:25.249": "and we just need to pass the unit that",
"0:55:28.999": "data okay so our data is just literally",
"0:55:32.479": "the file names of each of those from",
"0:55:35.029": "each of those two folders do some",
"0:55:37.910": "transforms data bunch normalize or use",
"0:55:41.779": "imagenet stats because we're going to",
"0:55:43.369": "use a pre trained model why are we using",
"0:55:45.829": "a pre trained model well because like if",
"0:55:47.959": "you're going to get rid of this 46 you",
"0:55:50.329": "need to know what probably was there and",
"0:55:52.880": "to know what probably was there you need",
"0:55:54.349": "to know what this is a picture of back",
"0:55:56.420": "because otherwise how can you possibly",
"0:55:57.529": "know what it ought to look like so you",
"0:55:59.589": "know let's use a pre trained model that",
"0:56:01.969": "knows about these kinds of things so we",
"0:56:04.880": "create our unit with that data the",
"0:56:07.489": "architecture is ResNet 34 these three",
"0:56:13.130": "things are important and interesting and",
"0:56:15.559": "useful but I'm going to leave them to",
"0:56:17.180": "part two okay for now you should always",
"0:56:19.729": "include them when you use a unit for",
"0:56:22.940": "this kind of problem and so now we're",
"0:56:27.799": "going to add this whole thing I'm",
"0:56:29.119": "calling a generator okay it's going to",
"0:56:30.469": "generate this is clarity of modeling",
"0:56:32.660": "they're kind of there's not a really",
"0:56:34.999": "formal definition but it's basically",
"0:56:36.499": "something where the thing we're",
"0:56:37.339": "outputting is like a real object in this",
"0:56:40.519": "case an image it's not just a number so",
"0:56:44.029": "we're going to create a generator",
"0:56:46.039": "learner which is this unit learner and",
"0:56:49.309": "then we can fit we're using MSC loss",
"0:56:52.489": "right so in other words what's the mean",
"0:56:54.499": "squared error between the actual pixel",
"0:56:56.630": "value that it should be in the pixel",
"0:56:58.309": "value that we predicted MSE lost",
"0:57:00.890": "normally expects two vectors in our case",
"0:57:04.670": "we have two images so we have a version",
"0:57:07.099": "called MSC loss flat which simply",
"0:57:09.319": "flattens out those images into a big",
"0:57:11.569": "long vector there's there's never any",
"0:57:14.329": "reason not to use this even if you do",
"0:57:16.249": "have a vector it works fine if you don't",
"0:57:17.959": "have a work vector it'll also work fine",
"0:57:19.579": "so we're already you know down to 0.05",
"0:57:22.849": "mean squared error on the pixel values",
"0:57:25.130": "which is not bad after one minute 35",
"0:57:28.569": "like all things in fast day I pretty",
"0:57:31.369": "much because we're doing transfer",
"0:57:33.589": "learning by default when you create the",
"0:57:35.360": "it'll freeze the the pre-trained part",
"0:57:39.410": "and the pre-trained part of a unit is",
"0:57:42.850": "this putt the downsampling part that's",
"0:57:46.040": "where the resident is so let's unfreeze",
"0:57:48.490": "that and train a little more and look at",
"0:57:54.740": "that so with you know three minutes of",
"0:57:59.540": "four minutes of training we've got",
"0:58:01.610": "something which is basically doing a",
"0:58:03.380": "perfect job of removing numbers it's",
"0:58:07.610": "certainly not doing a good job of up",
"0:58:09.830": "sampling but it's definitely doing a",
"0:58:14.660": "nice you know sometimes when it removes",
"0:58:15.860": "a number it maybe leaves a little bit of",
"0:58:17.210": "JPEG artifact but you're certainly doing",
"0:58:20.240": "something pretty useful and so if all we",
"0:58:21.710": "wanted to do was kind of watermark",
"0:58:24.380": "removal would be finished we're not",
"0:58:28.490": "finished because we actually want this",
"0:58:31.160": "thing to look more like this thing so",
"0:58:35.000": "how we got to do that the problem the",
"0:58:39.650": "reason that we're not making as much",
"0:58:41.240": "progress with that as we'd like is that",
"0:58:43.430": "our loss function doesn't really",
"0:58:45.950": "describe what we want because actually",
"0:58:47.270": "the the mean squared error between the",
"0:58:50.390": "pixels of this and this is actually very",
"0:58:53.450": "small right if you actually think about",
"0:58:55.820": "it most of the pixels are very nearly",
"0:58:58.160": "the right color but we're missing the",
"0:59:00.740": "texture of the pillow and we're missing",
"0:59:02.840": "the eyeballs entirely pretty much right",
"0:59:05.330": "and we're missing the texture of the fur",
"0:59:07.390": "right so we want we want some loss",
"0:59:11.420": "function that does a better job than",
"0:59:14.150": "pixel mean squared error loss of saying",
"0:59:17.420": "like is this a good quality picture of",
"0:59:20.540": "this thing so there's a fairly general",
"0:59:25.580": "way of answering that question and it's",
"0:59:30.080": "something called a generative",
"0:59:32.680": "adversarial Network or can and again",
"0:59:37.810": "tries to solve this problem by using a",
"0:59:40.820": "loss function which actually calls",
"0:59:43.810": "another model and let me describe it to",
"0:59:47.240": "you",
"0:59:51.800": "so we've got our crappy image right and",
"0:59:55.290": "we've already created a generator it's",
"0:59:57.600": "not a great one but it's not terrible",
"0:59:58.980": "right and that's creating predictions",
"1:00:01.470": "like like this we have a high-res image",
"1:00:09.680": "like that and we can compare the",
"1:00:12.990": "high-res image to the prediction with",
"1:00:15.800": "with pixel MSE okay",
"1:00:19.070": "we could also train another model which",
"1:00:22.830": "we would variably call variously call",
"1:00:25.140": "either the discriminator or The Critic",
"1:00:27.060": "they both mean the same thing I'll call",
"1:00:29.640": "it a critic we could try and build a",
"1:00:31.980": "binary classification model that takes",
"1:00:35.940": "all the pairs of the generated image and",
"1:00:38.250": "the real high-res image and tries to",
"1:00:41.480": "classify learn to classify which is",
"1:00:44.760": "which you know so look at some picture",
"1:00:47.369": "and say like hey what do you think is",
"1:00:50.280": "that a high-res cat or is that a",
"1:00:51.900": "generated cat how about this one is that",
"1:00:53.670": "a high-res cat or a generated cat so",
"1:00:55.260": "just a regular standard binary",
"1:00:58.290": "cross-entropy e classified so we know",
"1:01:01.680": "how to do that already so if we had one",
"1:01:05.190": "of those we could now train we could",
"1:01:08.730": "fine tune the generator and rather than",
"1:01:12.090": "using pixel MSE is the loss the loss",
"1:01:15.210": "could be how good are we at fooling the",
"1:01:18.300": "critic so can we create generated images",
"1:01:23.369": "that the critic thinks are real so that",
"1:01:28.050": "would be a very good plan right because",
"1:01:30.930": "if it can do that if if the loss",
"1:01:32.880": "function is am I fooling the critic that",
"1:01:35.600": "then it's going to learn to create",
"1:01:37.859": "images which the critic can't tell",
"1:01:40.350": "whether they're real or fake so we could",
"1:01:44.790": "do that for a while train a few batches",
"1:01:48.290": "but the critic isn't that great the",
"1:01:52.350": "reason the critic is that isn't that",
"1:01:53.550": "great is because it wasn't that hard",
"1:01:54.780": "like these images are really shitty so",
"1:01:56.609": "it's really easy to tell the difference",
"1:01:57.859": "alright so after we train the generator",
"1:02:00.960": "a little bit more using the",
"1:02:02.630": "critic as the loss function the",
"1:02:05.720": "generators going to get really good",
"1:02:06.799": "they're falling the critic so now we're",
"1:02:10.160": "going to stop training the generator and",
"1:02:11.809": "we'll drain the critic some more on",
"1:02:13.789": "these newly generated images so now that",
"1:02:17.029": "the generators better it's now a tougher",
"1:02:19.369": "task for the critic to the side which is",
"1:02:21.680": "real and which is fake so again so we're",
"1:02:23.690": "trained that a little bit more and then",
"1:02:26.089": "once we've done that and the critics now",
"1:02:27.740": "pretty good at recognizing the",
"1:02:28.880": "difference between the better generated",
"1:02:30.230": "images and the originals well we'll go",
"1:02:33.529": "back and we'll fine-tune the generator",
"1:02:35.000": "some more using the better discriminator",
"1:02:37.700": "the better critic as the loss function",
"1:02:39.619": "and so we'll just go ping pong ping pong",
"1:02:41.509": "backwards and forwards that's again well",
"1:02:47.779": "that's our version of again I don't know",
"1:02:49.670": "if anybody's written this before we've",
"1:02:52.579": "we've created a new version of again",
"1:02:54.440": "which is kind of a lot like the original",
"1:02:56.900": "Gans but we have this this neat trick",
"1:02:59.029": "where we pre train the generator and we",
"1:03:01.430": "pre train the critic",
"1:03:02.809": "I mean games have been kind of in the",
"1:03:05.359": "news a lot they're pretty fashionable",
"1:03:08.450": "tall and if you've seen them you may",
"1:03:10.400": "have heard that they're a real pain to",
"1:03:12.920": "Train but it turns out we realized that",
"1:03:16.309": "really most of the pain of training them",
"1:03:18.200": "was at the start if you don't have a pre",
"1:03:20.990": "trained generator and you don't have a",
"1:03:22.640": "pre trained critic then it's basically",
"1:03:25.029": "the blind leading the blind right you're",
"1:03:27.859": "basically like the critics well the",
"1:03:29.750": "generators trying to generate something",
"1:03:31.099": "which falls a critic but the critic",
"1:03:32.480": "doesn't know anything at all so it's",
"1:03:33.980": "basically got nothing to do and then the",
"1:03:35.930": "critics kind of try to decide whether",
"1:03:37.279": "the generated images are real or not and",
"1:03:38.900": "that gets really obvious so it does does",
"1:03:40.819": "it and so they kind of like don't go",
"1:03:43.759": "anywhere for ages and then once they",
"1:03:46.819": "finally start picking up steam they go",
"1:03:49.130": "along pretty quickly so if you can find",
"1:03:52.190": "a way to generate things without using",
"1:03:55.099": "again like means quit there are pixel",
"1:03:57.200": "loss and discriminate things without",
"1:03:59.210": "using a can like predict on that first",
"1:04:02.359": "generator you can make a lot of progress",
"1:04:04.059": "so let's create the critic so to create",
"1:04:08.750": "just a totally standard fast AI binary",
"1:04:12.619": "classification model we need two folders",
"1:04:15.170": "one folders contain",
"1:04:16.500": "high-res images one folder containing",
"1:04:18.810": "generated images we already have the",
"1:04:21.300": "folder with high-res images so we just",
"1:04:23.280": "have to save our generated images so",
"1:04:26.250": "here's a teeny tiny bit of code that",
"1:04:28.350": "does that we're going to create a",
"1:04:30.960": "directory called image gen pop it into a",
"1:04:34.500": "variable called path gen we're good a",
"1:04:37.800": "little function called save Preds that",
"1:04:39.810": "takes a data loader and we're going to",
"1:04:42.120": "grab all of the file names because",
"1:04:43.560": "remember that in an item list the dot",
"1:04:45.450": "items contains the file names if it's an",
"1:04:48.360": "image item list so here's the final file",
"1:04:51.210": "names in that data loaders data set and",
"1:04:54.360": "so now let's go through each batch of",
"1:04:56.970": "the data loader and let's grab a batch",
"1:05:00.510": "of predictions for that batch and then",
"1:05:04.050": "reconstruct akil's true means it's",
"1:05:05.910": "actually going to create fast AI image",
"1:05:07.680": "objects for each of those each thing in",
"1:05:10.650": "the in the batch and so then we'll go",
"1:05:12.450": "through each of those predictions and",
"1:05:14.090": "save them and the name will save it with",
"1:05:16.890": "is the name of the original file but",
"1:05:20.820": "we're going to pop it into our new",
"1:05:21.840": "directory so that's it that's how you",
"1:05:27.120": "save predictions and so you can see I'm",
"1:05:29.160": "kind of increasingly not just using",
"1:05:32.550": "stuff that's already in the first day I",
"1:05:33.900": "library but try to show you how to write",
"1:05:35.460": "stuff yourself right and generally",
"1:05:38.550": "doesn't require heaps of code to do that",
"1:05:41.700": "and so if you come back for part two",
"1:05:43.440": "this is what you know platen matza part",
"1:05:46.620": "two were kind of like here's how you use",
"1:05:48.180": "things inside the library and of course",
"1:05:50.340": "here's how we wrote the library so",
"1:05:52.610": "increasingly writing our own code okay",
"1:05:57.000": "so save those predictions and lend this",
"1:05:59.940": "just to a PIL dot image to open on the",
"1:06:02.400": "first one and yep there it is okay so",
"1:06:05.250": "there's an example of a generated image",
"1:06:07.650": "so now I can train a critic in the usual",
"1:06:11.130": "way it's really annoying to have to",
"1:06:14.370": "restart TripIt a notebook to refresh",
"1:06:16.320": "your reclaim GPU memory so one easy way",
"1:06:19.080": "to handle this is if you just set",
"1:06:21.090": "something that you knew was using a lot",
"1:06:22.650": "of GPU to none like this learner and",
"1:06:25.680": "then just go GC collect that tells",
"1:06:28.590": "Python to do",
"1:06:30.020": "a memory garbage collection and after",
"1:06:33.230": "that you'll generally be fine you'll be",
"1:06:37.010": "able to use all of your GPU remember",
"1:06:39.320": "again if you're using nvidia SMI to",
"1:06:41.870": "actually look at your GPU memory you",
"1:06:44.360": "won't see it clear because plate watch",
"1:06:46.640": "still has a kind of allocated cache but",
"1:06:50.000": "it makes it available so you should find",
"1:06:52.250": "this is how you can avoid restarting",
"1:06:54.350": "your notebook okay",
"1:06:56.390": "so we're going to create a critic it's",
"1:06:57.890": "just an image item list from folder in",
"1:07:00.170": "the totally usual way and the classes",
"1:07:03.380": "will be the image gen and images will do",
"1:07:08.150": "a random split because we want to know",
"1:07:09.710": "how well we're doing with a critic to",
"1:07:11.210": "have a validation set",
"1:07:12.320": "we just label it from folder in the",
"1:07:14.510": "usual way",
"1:07:15.350": "that's and transforms data bunch",
"1:07:17.210": "normalized so it's a totally standard",
"1:07:19.610": "object classifier okay so we've got a",
"1:07:26.450": "totally standard classifier so here's",
"1:07:30.380": "what some of it looks like so here's one",
"1:07:32.420": "from the real images real images",
"1:07:34.520": "generated images generated images okay",
"1:07:37.730": "so that's it's going to try and figure",
"1:07:39.320": "out which class is which okay so we're",
"1:07:45.830": "going to use Brian airy cross HB as",
"1:07:48.440": "usual however we're not going to use a",
"1:07:55.960": "res net here and the reason we'll get",
"1:08:00.020": "into in more detail in part two but",
"1:08:02.450": "basically when you're doing again you",
"1:08:07.160": "need to be particularly careful that the",
"1:08:11.170": "the generator and the critic can't kind",
"1:08:14.450": "of both push in the same direction and",
"1:08:16.460": "like increase the weights out of control",
"1:08:19.069": "so we have to use them in called",
"1:08:20.870": "spectral normalization to make Gans work",
"1:08:24.020": "nowadays well learn about that in part",
"1:08:26.270": "two so anyway if you say Gann critic",
"1:08:29.089": "that will give you first a a will give",
"1:08:31.339": "you a binary classifier suitable begins",
"1:08:34.580": "I strongly suspect we probably can use a",
"1:08:37.250": "resonate here we just have to create a",
"1:08:38.779": "pre trained ResNet with spectral norm",
"1:08:40.549": "hope to do that pretty soon",
"1:08:42.929": "we'll see how we go but as of now this",
"1:08:45.390": "is kind of the best approach there's",
"1:08:48.150": "this thing called game critic again",
"1:08:52.049": "critic uses a slightly different way of",
"1:08:57.620": "averaging the the different parts of the",
"1:09:01.650": "image when it does the loss so anytime",
"1:09:03.659": "you're doing again at the moment you",
"1:09:05.279": "have to wrap your loss function with",
"1:09:06.719": "adaptive loss again we'll look at the",
"1:09:09.299": "details in part two for now just know",
"1:09:11.759": "this is what you have to do and it'll",
"1:09:12.960": "work so other than that slightly odd",
"1:09:16.230": "loss function and that slightly odd",
"1:09:18.210": "architecture everything else is the same",
"1:09:19.770": "we can call that to create our critic",
"1:09:23.089": "because we have this slightly different",
"1:09:25.620": "architecture and slightly different loss",
"1:09:27.210": "function we did a slightly different",
"1:09:28.890": "metric this is the equivalent gain",
"1:09:31.469": "version of accuracy the critics and then",
"1:09:34.409": "we can train it and you can see it's 98%",
"1:09:37.140": "accurate at recognizing that kind of",
"1:09:42.270": "crappy thing from that kind of nice",
"1:09:43.469": "thing but of course we don't see the",
"1:09:45.900": "numbers here anymore right because these",
"1:09:47.310": "are the generated images that generate",
"1:09:48.870": "already knows how to get rid of those",
"1:09:50.190": "numbers that are written on top okay so",
"1:09:55.460": "let's finish up this game now that we",
"1:09:58.590": "have pre trained the generator and",
"1:10:01.260": "pre-trained the critic we now need to",
"1:10:04.080": "get it to kind of ping pong between",
"1:10:06.449": "training a little bit of each and the",
"1:10:09.390": "amount of time you spend on each of",
"1:10:11.219": "those things and the learning rates you",
"1:10:13.350": "use is still a little bit on the fuzzy",
"1:10:16.590": "side so we've created a again learner",
"1:10:21.810": "for you which you just pass in your",
"1:10:24.900": "generator and your critic which we've",
"1:10:27.840": "just just simply loaded here from the",
"1:10:29.699": "ones we just trained and it will go",
"1:10:33.420": "ahead and when you go learned up fit it",
"1:10:36.179": "will do that for you it'll figure out",
"1:10:38.010": "how much time to train the generator and",
"1:10:39.840": "then when to switch to training the",
"1:10:40.980": "discriminator the critic it'll go back",
"1:10:42.840": "on and forward these weights here is",
"1:10:46.350": "that what we actually do is we don't",
"1:10:49.020": "only use the critic as the loss function",
"1:10:51.330": "if we only use the critic as a loss",
"1:10:53.310": "function the game could get very good at",
"1:10:56.429": "creating",
"1:10:57.000": "pictures that look like real pictures",
"1:11:00.480": "but they actually have nothing to do",
"1:11:02.400": "with the original picture the original",
"1:11:04.170": "photo at all so we actually add together",
"1:11:06.540": "the pixel loss and the critic loss and",
"1:11:10.530": "so those two losses are kind of on",
"1:11:14.010": "different scales so we multiply the",
"1:11:16.160": "pixel loss by something between about 50",
"1:11:19.980": "and about 300 again something in that",
"1:11:22.500": "range generally works pretty well",
"1:11:26.780": "something else with cans cans hate",
"1:11:30.690": "momentum when you're training them it",
"1:11:33.180": "kind of doesn't make sense to train them",
"1:11:34.500": "with her mentum because you keep",
"1:11:35.520": "switching between generator and critic",
"1:11:37.440": "so it's kind of tough maybe there are",
"1:11:39.450": "ways to use momentum but I'm not sure",
"1:11:40.800": "anybody's figured it out so this number",
"1:11:43.230": "here when you create an atom optimizer",
"1:11:45.600": "is where the momentum goes so you should",
"1:11:47.850": "set that to zero so anyway if you're",
"1:11:49.590": "doing games use these hyper parameters",
"1:11:51.920": "it should work okay so so that's what",
"1:12:00.540": "can learner does and so then you can go",
"1:12:02.490": "fit and it trains for a while and one of",
"1:12:05.940": "the tough things about ganz is that",
"1:12:08.730": "these loss numbers they're meaningless",
"1:12:13.530": "you can't expect them to go down right",
"1:12:16.110": "because as the generator gets better it",
"1:12:19.170": "gets harder for the discriminator the",
"1:12:21.810": "critic and then as the credit gets",
"1:12:23.370": "better it's harder for the generator so",
"1:12:25.620": "the numbers should stay about the same",
"1:12:28.970": "okay so that's one of the tough things",
"1:12:32.190": "about training ganz is it's kind of hard",
"1:12:34.170": "to know how are they doing so the only",
"1:12:36.750": "way to know how are they doing is to",
"1:12:39.810": "actually take a look at the results from",
"1:12:41.610": "time to time I haven't and so if you put",
"1:12:44.780": "show image equals true here it'll",
"1:12:47.400": "actually print out a sample after every",
"1:12:49.140": "epoch I haven't put that in the notebook",
"1:12:51.030": "because it makes it too big for the repo",
"1:12:53.760": "but you can try that so I've just put",
"1:12:56.100": "the results at the bottom and here it is",
"1:13:00.020": "so pretty beautiful I would say we",
"1:13:05.940": "already knew how to get rid of the",
"1:13:07.190": "numbers but we're now don't really have",
"1:13:09.510": "that kind of",
"1:13:10.240": "back to where it used to be and it's",
"1:13:12.490": "it's definitely sharpening up this",
"1:13:15.520": "little kitty cat quite nicely it's not",
"1:13:22.240": "great always like there's some weird",
"1:13:24.960": "kind of noise going on here certainly a",
"1:13:30.640": "lot better than the horrible original",
"1:13:32.050": "like this is a tough job to turn that",
"1:13:34.840": "into that but there are some really",
"1:13:38.290": "obvious problems like here these things",
"1:13:41.680": "ought to be eyeballs and they're not so",
"1:13:46.150": "why aren't they well our critic doesn't",
"1:13:50.020": "know anything about eyeballs and even if",
"1:13:52.330": "it did it wouldn't know that eyeballs",
"1:13:55.030": "are particularly important you know we",
"1:13:56.650": "care about eyes like when we see a cat",
"1:13:58.600": "with that eyes it's a lot less cute I",
"1:14:05.250": "mean I'm more of a dog person but you",
"1:14:07.810": "know it's it just doesn't know that this",
"1:14:14.800": "is a feature that that matters",
"1:14:17.610": "particularly because the critic remember",
"1:14:19.840": "is not a pre trained network so I kind",
"1:14:22.300": "of suspect that if we replace the critic",
"1:14:24.670": "with a pre trained network that's been",
"1:14:26.200": "pre trained on imagenet but is also",
"1:14:27.700": "compatible with gans it might do a",
"1:14:29.260": "better job here but it's definitely a",
"1:14:33.480": "shortcoming of this approach so I'm",
"1:14:36.970": "going to have a break Oh question first",
"1:14:39.910": "and then we'll have a break and then",
"1:14:42.250": "after the break I will show you how to",
"1:14:44.140": "find the cat's",
"1:14:45.460": "eyeballs again for what kind of problems",
"1:14:49.900": "do you not want to use units",
"1:14:55.680": "well unit so for when the the size of",
"1:15:00.160": "your output you know is is similar to",
"1:15:04.630": "the size of your input and kind of",
"1:15:06.510": "aligned with it",
"1:15:08.620": "there's no point kind of having cross",
"1:15:10.090": "connections if that level of spatial",
"1:15:12.910": "resolution in the output isn't necessary",
"1:15:15.370": "or useful so yeah any kind of generative",
"1:15:19.180": "modeling and you know segmentation is",
"1:15:21.700": "kind of generative modeling right it's",
"1:15:23.290": "it's Jen",
"1:15:23.860": "rating a picture which is a mask of the",
"1:15:26.650": "original objects yeah so probably",
"1:15:30.280": "anything where you want that kind of",
"1:15:31.659": "that kind of resolution of the output to",
"1:15:35.110": "be of the same kind of fidelity as a",
"1:15:37.869": "resolution of the input obviously",
"1:15:39.670": "something like a classifier makes no",
"1:15:41.020": "sense right you you're in a classifier",
"1:15:44.190": "you just want the down sampling path",
"1:15:46.420": "because at the end you just want a",
"1:15:48.250": "single number which is like is it a dog",
"1:15:49.780": "or a cat or what kind of pet is it or",
"1:15:52.510": "whatever great okay so let's get back",
"1:15:56.920": "together at five past eight just before",
"1:16:00.489": "we leave Dan's I just mentioned there's",
"1:16:01.900": "another notebook you might be interested",
"1:16:03.850": "in looking at which is less than 7w",
"1:16:07.480": "again when games started a few years ago",
"1:16:12.699": "people generally use them to kind of",
"1:16:16.690": "create images out of thin air which I",
"1:16:20.350": "personally don't think is a particularly",
"1:16:22.659": "useful or interesting thing to do but",
"1:16:27.040": "it's kind of a good I don't know it's a",
"1:16:28.239": "good research exercise I guess so",
"1:16:30.610": "we implemented this this w again paper",
"1:16:33.610": "which is kind of really the first one to",
"1:16:35.800": "do a somewhat adequate job somewhat",
"1:16:37.960": "easily and so you can see how to do that",
"1:16:40.360": "with the first AI library it's kind of",
"1:16:43.600": "interesting because the data set we use",
"1:16:47.650": "is this else on bedrooms data set which",
"1:16:51.100": "we've provided in our URLs which just as",
"1:16:54.520": "you can see has bedrooms lots and lots",
"1:16:57.219": "and lots of bedrooms and the approach",
"1:17:03.909": "you'll see in the pros here that Silva",
"1:17:06.070": "wrote the the the approach that we use",
"1:17:08.530": "in this case is to just say can we",
"1:17:12.100": "create a bedroom and so what we actually",
"1:17:14.980": "do is that the the input to the",
"1:17:20.679": "generator isn't an image that we clean",
"1:17:22.989": "up we actually feed to the generator",
"1:17:25.090": "random noise and so then the generators",
"1:17:29.020": "task is can you turn random noise into",
"1:17:32.710": "something which the critic can't tell",
"1:17:34.330": "the difference between that output and a",
"1:17:35.980": "real bedroom",
"1:17:37.960": "and so we're not doing any pre training",
"1:17:40.600": "here or any of the stuff that makes this",
"1:17:42.100": "kind of fast and easy so this is a very",
"1:17:49.060": "traditional approach but you can still",
"1:17:50.680": "see you still just go you know again",
"1:17:52.570": "learner and there's actually a double",
"1:17:53.920": "you can version which is you know this",
"1:17:55.960": "kind of older style approach but you",
"1:17:58.300": "just passing the data in the generator",
"1:17:59.740": "and the critic in the usual way",
"1:18:01.660": "and you call fit and you'll see in this",
"1:18:06.040": "case we have show image on you know",
"1:18:08.530": "after epoch one it's not creating great",
"1:18:11.200": "bedrooms or two or three and you can",
"1:18:12.760": "really see that in the early days of",
"1:18:14.140": "these kinds of games it doesn't do a",
"1:18:15.970": "great job of anything but eventually",
"1:18:18.960": "after you know a couple of hours of",
"1:18:22.270": "training producing somewhat like bedroom",
"1:18:27.220": "ish things you know so anyway it's a",
"1:18:30.190": "notebook you can never play with and",
"1:18:31.830": "it's a bit of fun so I was very excited",
"1:18:40.690": "when we got faster I to the point in the",
"1:18:43.450": "last week or so that we had Gans working",
"1:18:48.910": "in a way we're kind of API wise they're",
"1:18:51.190": "far more concise and more flexible than",
"1:18:54.010": "any other library that exists but also",
"1:18:57.880": "kind of disappointed with them they take",
"1:18:59.710": "a long time to train and the outputs sto",
"1:19:01.960": "like so so and so the next step was like",
"1:19:04.600": "well can we get rid of cans entirely so",
"1:19:07.960": "the first step with with that I mean",
"1:19:09.490": "obviously the thing we really want to do",
"1:19:11.110": "is come up with a better loss function",
"1:19:13.150": "we want a loss function that does a good",
"1:19:15.610": "job of saying this is a high-quality",
"1:19:16.840": "image without having to go all the over",
"1:19:20.950": "game trouble and preferably it also",
"1:19:22.630": "doesn't just say it's a high-quality",
"1:19:23.890": "image but it's an image which actually",
"1:19:26.560": "looks like the thing it's meant to so",
"1:19:29.260": "the real trick here comes back to this",
"1:19:30.910": "paper from a couple of years ago",
"1:19:32.700": "perceptual losses of real-time style",
"1:19:34.840": "transfer and super resolution Justin",
"1:19:37.810": "Johnson at our curve this thing they",
"1:19:40.420": "call perceptual losses it's a nice paper",
"1:19:42.640": "but I hate this term because they're",
"1:19:45.370": "nothing particularly perceptual about",
"1:19:46.930": "them I would call them feature losses so",
"1:19:49.120": "in the fast AI library you'll see",
"1:19:50.989": "this referred to as feature losses and",
"1:19:53.269": "it shares something with Ganz which is",
"1:19:55.820": "that after we go through our generator",
"1:19:59.300": "which they call the image transform net",
"1:20:01.429": "and you can see it's got this kind of",
"1:20:02.780": "unit shaped thing they didn't actually",
"1:20:04.610": "use new nets because at the time this",
"1:20:06.920": "came out nobody in the machine learning",
"1:20:08.119": "world knew about units nowadays of",
"1:20:11.059": "course we use units about anyway",
"1:20:13.280": "something unit ish i should mention like",
"1:20:16.670": "in these kind of these architectures",
"1:20:19.460": "where you have a down sampling path",
"1:20:20.780": "followed by table sampling path the down",
"1:20:22.999": "sampling path is very often called the",
"1:20:25.130": "encoder as you saw in our code actually",
"1:20:28.130": "we call that the encoder and the up",
"1:20:30.469": "sampling path is very often called the",
"1:20:32.480": "decoder in generative models more you",
"1:20:36.289": "know generally including generative text",
"1:20:39.230": "models neural translation stuff like",
"1:20:41.989": "that they didn't be called the encoder",
"1:20:43.489": "and the decoder two pieces right so we",
"1:20:46.010": "have this um this generator and we want",
"1:20:49.219": "a loss function that says you know is",
"1:20:52.489": "the thing that it's created like the",
"1:20:54.920": "thing that we want and so the way they",
"1:20:56.989": "do that is they take the prediction",
"1:20:58.909": "remember Y hat is what we normally use",
"1:21:00.769": "for a prediction from a model we take",
"1:21:02.960": "the prediction and we put it through a",
"1:21:04.940": "pre trained image net network so at the",
"1:21:09.289": "time that this came out the pre-training",
"1:21:11.090": "network at work they were using was vgg",
"1:21:14.170": "people still take that's a kind of old",
"1:21:16.369": "now but people still tend to use it",
"1:21:18.320": "because it works fine for this process",
"1:21:22.360": "so they take the prediction and they put",
"1:21:24.619": "it through vgg the pre trained imagenet",
"1:21:27.949": "network it doesn't matter too much which",
"1:21:29.389": "one it is and so normally the output of",
"1:21:31.849": "that would tell you hey is this",
"1:21:33.980": "generated thing you know a dog or a cat",
"1:21:37.639": "or an airplane or a or a fire engine or",
"1:21:40.460": "whatever right but in the process of",
"1:21:43.249": "getting to that final classification it",
"1:21:45.920": "goes through lots of different layers",
"1:21:46.820": "and in this case they've color-coded all",
"1:21:49.280": "the layers with the same grid size in",
"1:21:51.980": "the feature map with the same color so",
"1:21:53.690": "every time we switch colors we're",
"1:21:55.550": "switching grid size so there's a stride",
"1:21:57.079": "to convey or in VG's case they still",
"1:21:59.479": "used to use some Mac spalling layers",
"1:22:01.070": "which kind of similar idea",
"1:22:04.429": "and so what we could do is say hey let's",
"1:22:06.530": "not take the final output of the vgg",
"1:22:09.559": "model on this generated image but let's",
"1:22:13.699": "take home is something in the middle",
"1:22:16.059": "let's take the activations of some layer",
"1:22:19.130": "in the middle",
"1:22:20.019": "so those activations you know it might",
"1:22:23.150": "be a feature map of like 256 channels by",
"1:22:27.639": "28 by 28 say and so those kind of 28 by",
"1:22:31.610": "28 grid cells will kind of roughly",
"1:22:33.709": "semantically say things like hey in this",
"1:22:35.539": "in this part of that 28 by 28 grid is",
"1:22:38.209": "there something that looks kind of furry",
"1:22:39.679": "or is there something that looks kind of",
"1:22:41.389": "shiny or is there something that was",
"1:22:42.920": "kind of circular is there something that",
"1:22:44.119": "kind of looks like an eyeball or",
"1:22:45.979": "whatever so what we do is that we then",
"1:22:48.079": "take the target so that the actual Y",
"1:22:52.189": "value and we put it through the same",
"1:22:53.840": "pre-trained vgg network now we can pull",
"1:22:55.999": "out the activations of the same layer",
"1:22:57.409": "and then we do a mean square error",
"1:22:59.090": "comparison so it'll say like okay in the",
"1:23:02.989": "real image grid cell 1 1 of that 28 by",
"1:23:06.469": "28 feature map you know is is furry and",
"1:23:12.760": "mu and round shaped and in the generated",
"1:23:16.459": "image it's very and blue and not round",
"1:23:19.489": "shaped so it's kind of like an okay",
"1:23:21.429": "match so that ought to go a long way",
"1:23:25.939": "towards fixing our eyeball problem",
"1:23:28.369": "because in this case the feature Maps",
"1:23:30.619": "going to say this eyeballs here it's",
"1:23:33.079": "right here but there isn't here so do a",
"1:23:36.619": "better job of that please make better",
"1:23:38.329": "idols so that's the idea okay and so",
"1:23:41.269": "that's what we call feature losses or",
"1:23:43.429": "Johnson a tower called perceptual losses",
"1:23:47.260": "so so to do that we're going to use the",
"1:23:59.480": "since seven super res notebook and this",
"1:24:03.200": "time the task we're going to do is kind",
"1:24:05.840": "of the same as the previous task but I",
"1:24:08.060": "wrote this notebook a little bit before",
"1:24:09.710": "the game notebook before I came up with",
"1:24:12.290": "the idea of like putting text honours",
"1:24:14.030": "from having a random JPEG quality so the",
"1:24:16.640": "JPEG quality is always 60 there's no",
"1:24:18.920": "text written on top and it's 96 by 96 so",
"1:24:22.700": "and it's before I realized what a great",
"1:24:25.160": "word crap a PHY is so it's called resize",
"1:24:28.150": "so here's our crappy images and our",
"1:24:32.390": "original images kind of a similar task",
"1:24:35.989": "to what we had before so I'm going to",
"1:24:40.460": "try and create a loss function which",
"1:24:43.690": "does this so the first thing i do is i",
"1:24:49.550": "define a base loss function which is",
"1:24:53.930": "basically an account i got to compare",
"1:24:55.340": "the pixels and the features you know and",
"1:24:58.130": "the choices mainly like MSC or l1",
"1:25:01.180": "doesn't matter too much which you choose",
"1:25:03.140": "I tend to like l1 better than MSC",
"1:25:05.720": "actually so I picked l1 right so anytime",
"1:25:08.930": "you see base loss we mean l1 loss that",
"1:25:12.080": "you could use MSE loss as well so let's",
"1:25:15.230": "create a vgg model right so just using",
"1:25:17.930": "the pre-trained model in vgg there's a",
"1:25:21.350": "attribute called dot features which",
"1:25:23.180": "contains the convolutional part of the",
"1:25:26.000": "model so here's the convolutional part",
"1:25:29.420": "of the vgg model because we don't need",
"1:25:31.130": "the head because we only want the",
"1:25:33.460": "intermediate activations so then we'll",
"1:25:36.170": "check that on the GPU",
"1:25:37.070": "we'll put it into eval mode because",
"1:25:39.440": "we're not training it and we'll turn off",
"1:25:42.400": "requires grad because we don't want to",
"1:25:44.720": "update the weights of this model we're",
"1:25:46.370": "just using it for inference right for",
"1:25:49.070": "the loss so then let's enumerate through",
"1:25:52.310": "all the children of that model and find",
"1:25:54.470": "all of the max pooling layers because in",
"1:25:56.750": "this in the vgg model that's where the",
"1:25:58.760": "grid size changes and as you can see",
"1:26:01.820": "from this picture we kind of want to",
"1:26:03.590": "grab features from every time just",
"1:26:07.220": "before the grid size changes so we grab",
"1:26:09.500": "layer I minus 1 that's the layer before",
"1:26:12.110": "it changes",
"1:26:13.130": "so there's our list of layer numbers",
"1:26:16.670": "just before the max Pauling lives and so",
"1:26:21.320": "all of those are values not surprisingly",
"1:26:26.200": "so those are where we want to grab some",
"1:26:29.420": "features from and so we put that in",
"1:26:32.090": "blocks it's just a list of ID's so",
"1:26:34.370": "here's our feature loss plus which is",
"1:26:37.040": "going to implement this idea so",
"1:26:40.160": "basically we when we call the feature",
"1:26:42.830": "loss class we're going to pass it some",
"1:26:46.190": "pre trained model and so that's going to",
"1:26:48.200": "be called M feet that's the model which",
"1:26:51.440": "contains the features which we want to",
"1:26:53.600": "generate for what our feature loss on so",
"1:26:56.180": "we can go ahead and grab all of the",
"1:26:58.940": "layers from that network that we want",
"1:27:02.450": "the losses for that we left or that we",
"1:27:04.130": "want the features for to create the",
"1:27:05.930": "losses so we're going to need to hawk",
"1:27:08.510": "all of those outputs because remember",
"1:27:10.790": "that's how we grab intermediate layers",
"1:27:13.010": "in pi torch is by hooking them so this",
"1:27:15.950": "is going to contain our our hooked",
"1:27:18.980": "outputs so now in the forward of feature",
"1:27:24.260": "loss we're going to call make features",
"1:27:27.170": "passing in the target so this is our",
"1:27:29.450": "actual Y which is just going to call",
"1:27:31.400": "that vgg model and go through all of the",
"1:27:34.070": "stored activations and just grab a copy",
"1:27:37.970": "of them and so we're going to do that",
"1:27:39.980": "both for the target call that out feet",
"1:27:42.170": "and for the input so that's the output",
"1:27:45.080": "of our generator in feet and so now",
"1:27:50.080": "let's calculate the l1 loss between the",
"1:27:54.470": "pixels because we still want the pixel",
"1:27:56.660": "lost a little bit and then let's also go",
"1:27:59.360": "through all of those layers features and",
"1:28:05.570": "get the l1 loss on them right so we're",
"1:28:08.180": "basically going through every one of",
"1:28:09.800": "these end of each block and grabbing the",
"1:28:14.750": "activations and getting the l1 on each",
"1:28:17.840": "one so that's going to end up in this",
"1:28:23.120": "list called feature losses which are",
"1:28:26.330": "then",
"1:28:26.930": "sum them all up okay and you know by the",
"1:28:29.270": "way the reason to do it as a list is",
"1:28:30.890": "because we've got this nice little",
"1:28:32.120": "callback that if you put them into a",
"1:28:34.580": "thing called metrics in your loss",
"1:28:36.710": "function it'll print out all of the",
"1:28:38.540": "separate layer loss amounts for you",
"1:28:43.310": "which is super handy so that's it that's",
"1:28:47.450": "our perceptual loss or feature loss plus",
"1:28:50.330": "and so now we can just go ahead and",
"1:28:52.430": "train a unit in the usual way with our",
"1:28:54.500": "data and pre-trained architecture which",
"1:28:56.540": "is a resonance ID for passing in our",
"1:28:58.460": "loss function which is using our pre",
"1:29:01.130": "trained vgg model and this is that",
"1:29:03.380": "callback I mentioned lost metrics which",
"1:29:05.150": "is going to print out all the different",
"1:29:06.800": "layers losses for us these are two",
"1:29:10.100": "things that we'll learn about in part",
"1:29:11.390": "two of the course but you should use",
"1:29:12.980": "them allow find I just created a little",
"1:29:17.000": "function called do fit that does fit one",
"1:29:18.920": "cycle and then saves the model and then",
"1:29:21.350": "shows the results so as per usual",
"1:29:24.380": "because we're using a pre trained",
"1:29:26.150": "network in our unit we start with frozen",
"1:29:28.790": "layers for the down sampling path train",
"1:29:32.360": "for a while and as you can see we get",
"1:29:34.310": "not only the loss but also the pixel",
"1:29:36.830": "loss and the loss at each of our feature",
"1:29:38.630": "layers and then also something we'll",
"1:29:40.970": "learn about in part two called gram loss",
"1:29:43.780": "which I don't think anybody's used for",
"1:29:47.600": "super ears before as far as I know but",
"1:29:49.400": "as you'll see it turns out great so",
"1:29:51.670": "that's eight minutes so much faster than",
"1:29:54.800": "it can and already as you can see this",
"1:29:57.830": "is our output modeled out pretty good so",
"1:30:01.090": "then we unfreeze and train some more and",
"1:30:05.660": "it's a little bit better and then let's",
"1:30:08.360": "switch up to double the size and so we",
"1:30:11.030": "need to also have the batch size to",
"1:30:12.590": "avoid writing a GPU memory and freeze",
"1:30:15.230": "again and train some more so it's now",
"1:30:17.810": "taking half an hour even better and then",
"1:30:21.830": "unfreeze and train some more so all in",
"1:30:24.740": "all we've done about an hour and 20",
"1:30:26.270": "minutes of training and look at that",
"1:30:30.010": "it's it's it's done it like I mean those",
"1:30:33.110": "it's it knows that eyes are important so",
"1:30:35.840": "it's really made an effort it knows that",
"1:30:37.190": "fur is important so it's really made an",
"1:30:39.260": "effort so it's",
"1:30:40.159": "with something with like JPEG artifacts",
"1:30:41.989": "around the ears and all this mess and",
"1:30:46.340": "like eyes that are just kind of vague",
"1:30:48.949": "light blue things and it just it really",
"1:30:51.050": "created a lot of texture this cat is",
"1:30:54.739": "clearly kind of like looking over the",
"1:30:56.480": "top of one of those little chlorine",
"1:30:58.489": "frames covered in fuzz so it actually",
"1:31:00.800": "recognized that this thing is probably",
"1:31:02.949": "kind of a capita materials it's created",
"1:31:05.630": "a capital e material for us so I mean",
"1:31:08.030": "that's just remarkable",
"1:31:11.139": "so talking of remarkable we can now so I",
"1:31:17.090": "I've never seen outputs like this before",
"1:31:22.300": "without again so I was just so excited",
"1:31:25.670": "when we were able to generate this and",
"1:31:27.500": "so quickly one GPU hour-and-a-half so",
"1:31:31.310": "like if you create your own crap",
"1:31:32.840": "efficacious functions and train this",
"1:31:35.270": "model your build stuff that nobody's",
"1:31:37.489": "built before because like nobody else's",
"1:31:39.320": "that I know of is doing it this way so",
"1:31:42.650": "there are huge opportunities I think so",
"1:31:44.750": "check this out what we can now do is we",
"1:31:47.449": "can now instead of starting with our low",
"1:31:51.020": "res I actually stored another set at",
"1:31:54.260": "size 256 which are called medium res so",
"1:31:57.679": "let's see what happens if we up size a",
"1:31:59.300": "medium res so we're going to grab our",
"1:32:02.210": "medium res data and here is here is our",
"1:32:09.920": "medium res stored photo and so can we",
"1:32:13.699": "improve this so you can see there's",
"1:32:15.409": "still a lot of room for improvement like",
"1:32:16.909": "you see the the lashes here are very",
"1:32:20.360": "pixelated place where there should be",
"1:32:22.460": "hair here is just kind of fuzzy so watch",
"1:32:25.280": "this area as I hit down on my keyboard",
"1:32:27.310": "bump look at that it's done it you know",
"1:32:31.460": "it's taken a medium res image and it's",
"1:32:33.409": "made a totally clear thing here you know",
"1:32:37.250": "the thirds reappeared light look at the",
"1:32:39.170": "eyeball let's go back the eyeball here",
"1:32:42.050": "is just kind of a general blue thing",
"1:32:45.190": "here it's added all the right texture",
"1:32:48.710": "you know so I just think this is super",
"1:32:53.179": "exciting you know",
"1:32:53.989": "here's a model I trained in an hour and",
"1:32:56.269": "a half using standard stuff that you've",
"1:32:59.360": "all learnt about a you NetApp retrain",
"1:33:01.400": "model feature loss function and we've",
"1:33:04.999": "got something which can turn that into",
"1:33:07.460": "that or you know this absolute mess into",
"1:33:13.820": "this and like it's really exciting to",
"1:33:15.679": "think what what could you do with that",
"1:33:18.739": "right so one of the inspirations here",
"1:33:21.670": "has been a guy called Jason integer and",
"1:33:26.860": "Jason was a student in the course last",
"1:33:31.280": "year and what he did very sensibly was",
"1:33:39.249": "decided to focus basically nearly quit",
"1:33:43.519": "his job and work four days a week for",
"1:33:45.110": "really six days a week on studying deep",
"1:33:46.699": "learning and as you should do he created",
"1:33:49.849": "a kind of capstone project and his",
"1:33:51.409": "project was to combine Ganz and feature",
"1:33:55.489": "losses together and his krappa fication",
"1:33:58.300": "approach was to take color pictures and",
"1:34:03.380": "make the black and white so he took the",
"1:34:05.630": "whole of image net created a black and",
"1:34:07.309": "white image net and then trained a model",
"1:34:09.139": "to recolor eyes it and he's put this up",
"1:34:11.300": "as do defy and now he's got these actual",
"1:34:14.329": "old photos from the 19th century",
"1:34:17.630": "that he's turning into color and like",
"1:34:21.610": "what this is doing is incredible like",
"1:34:24.260": "like look at this the model thought oh",
"1:34:26.210": "that's probably some kind of copper",
"1:34:27.590": "kettle so I'll make it like copper",
"1:34:29.210": "colored and oh these pictures are on the",
"1:34:31.699": "wall they're probably let different",
"1:34:33.199": "colors to the wall and maybe that looks",
"1:34:35.929": "a bit like a mirror maybe it would be",
"1:34:38.510": "reflecting stuff outside you know",
"1:34:42.260": "these things might be vegetables",
"1:34:43.999": "vegetables are often red you know let's",
"1:34:45.829": "make them red it's it's extraordinary",
"1:34:49.300": "what it's done and you could totally do",
"1:34:52.909": "this too like you can take our feature",
"1:34:55.369": "loss and our gam loss and combine them",
"1:34:58.309": "so I'm very grateful to Jason because",
"1:35:00.650": "he's helped us build this this lesson",
"1:35:03.800": "has been really nice because we've been",
"1:35:04.999": "able to help him to because he hadn't",
"1:35:08.130": "realize that he can use all this",
"1:35:09.239": "pre-training and stuff and so hopefully",
"1:35:10.920": "you'll see two older phi in the next",
"1:35:12.750": "couple of weeks be even better at the",
"1:35:15.179": "older fication but hopefully you all can",
"1:35:17.550": "now add other kinds of D Kappa fication",
"1:35:20.929": "methods as well so I'm you know I like",
"1:35:26.790": "every course if possible to show",
"1:35:30.840": "something totally new because then every",
"1:35:33.690": "student has the chance to basically",
"1:35:35.159": "build things that had never been built",
"1:35:36.510": "before so this is this is kind of that",
"1:35:38.850": "thing you know but between the much",
"1:35:41.219": "better segmentation results and these",
"1:35:42.840": "much simpler and faster",
"1:35:44.070": "d krappa fication results I think you",
"1:35:46.020": "can build some really cool stuff do you",
"1:35:48.060": "have a question is it possible to use",
"1:35:56.130": "similar ideas to unit and ganz for NLP",
"1:35:59.340": "for example if I want to tag the verbs",
"1:36:01.679": "and nouns in a sentence or create a",
"1:36:03.449": "really good Shakespeare generator yeah",
"1:36:08.690": "pretty much we don't fully know yet it's",
"1:36:11.940": "a pretty new area but there's a lot of",
"1:36:14.010": "opportunities there and we'll be looking",
"1:36:16.500": "at some in in a moment actually",
"1:36:23.060": "so I actually tried training this",
"1:36:27.139": "actually tried testing this on this",
"1:36:29.190": "remember this picture I showed you with",
"1:36:31.230": "a slide last lesson and it's a really",
"1:36:34.199": "rubbishy looking picture and I thought",
"1:36:35.400": "what would happen if we tried running",
"1:36:36.659": "this just through the exact same model",
"1:36:39.060": "and it changed it from that to that so I",
"1:36:43.830": "thought that was a really good example",
"1:36:44.670": "you can see something it didn't do which",
"1:36:47.190": "is this weird discoloration it didn't",
"1:36:49.620": "fix it because I didn't crap a PHY",
"1:36:51.510": "things with weird discoloration right so",
"1:36:53.610": "if you want to create really good image",
"1:36:55.050": "restoration like I say you did really",
"1:36:56.969": "good gratification okay so um here's",
"1:37:02.969": "what we've learned so far right in in",
"1:37:06.120": "the course some of the main things so",
"1:37:08.250": "we've learnt that neural nets consist of",
"1:37:13.440": "Sandwich layers of are fine functions",
"1:37:15.120": "which are basically matrix",
"1:37:16.620": "multiplications slightly more general",
"1:37:18.360": "version and nonlinearities like rel you",
"1:37:20.730": "and we",
"1:37:21.909": "that the results of those calculations",
"1:37:23.860": "are called activations and the things",
"1:37:26.499": "that go into those calculations that we",
"1:37:28.599": "learn accord parameters and that the",
"1:37:30.820": "parameters are initially randomly",
"1:37:32.860": "initialized or we copy them over from a",
"1:37:35.229": "pre-trained model and then we train them",
"1:37:37.059": "with SGD or faster versions and we",
"1:37:40.599": "learned that convolutions are a",
"1:37:42.400": "particular affine function that work",
"1:37:43.900": "great for auto correlated data so things",
"1:37:47.050": "like images and stuff we learn about",
"1:37:48.820": "batch norm drop out data orientation and",
"1:37:51.400": "weight decay as ways of regularizing",
"1:37:54.429": "models and also batch norm helps train",
"1:37:56.229": "models more quickly and then today we've",
"1:37:58.179": "learned about res slash dense blocks",
"1:38:01.829": "we've all of us you learn a lot about",
"1:38:03.760": "image classification regression",
"1:38:05.130": "embeddings categorical and continuous",
"1:38:07.539": "variables collaborative filtering",
"1:38:10.050": "language models and NLP classification",
"1:38:12.729": "and then kind of segmentation unit and",
"1:38:14.860": "gains so go over these things and make",
"1:38:19.209": "sure that you feel comfortable with each",
"1:38:21.369": "of them if you've only watched this",
"1:38:22.959": "series once you definitely won't people",
"1:38:26.199": "normally watch it you know three times",
"1:38:27.969": "or so to really understand the detail so",
"1:38:32.559": "one thing that doesn't that doesn't get",
"1:38:36.010": "here is our it ends so that's the last",
"1:38:39.309": "thing we're gonna do there it is okay so",
"1:38:43.619": "marinades I'm going to introduce a",
"1:38:45.489": "little kind of diagrammatic method here",
"1:38:46.869": "to explain our ends and the diagrammatic",
"1:38:49.090": "method I'll start by showing you a basic",
"1:38:50.739": "neural net with a single hidden layer",
"1:38:52.769": "square means an input so that'll be",
"1:38:57.429": "batch size by number of inputs right so",
"1:39:01.269": "kind of you know batch size by number of",
"1:39:06.669": "inputs an arrow means a layer broadly",
"1:39:12.820": "defined such as matrix product followed",
"1:39:15.550": "by value a circle is activations okay so",
"1:39:21.909": "in this case we have one set of hidden",
"1:39:24.309": "activations and so given that the import",
"1:39:27.969": "was number of inputs this here is a",
"1:39:30.849": "matrix of number of inputs by number of",
"1:39:33.369": "activations so the output will be",
"1:39:35.739": "a batch size by a number of activations",
"1:39:38.010": "it's really important you know how to",
"1:39:40.179": "calculate these shapes right so go learn",
"1:39:42.130": "dot summary lots to see all the shapes",
"1:39:46.260": "so then here's another arrow so that",
"1:39:48.820": "means it's another layer matrix product",
"1:39:51.070": "followed by non-linearity in this case",
"1:39:52.929": "we go into the output so we use soft Max",
"1:39:54.639": "and then triangle means an output okay",
"1:39:59.289": "and so this matrix product will be",
"1:40:01.150": "number of activations by a number of",
"1:40:02.679": "classes so our output is batch size by",
"1:40:04.780": "number classes",
"1:40:05.499": "okay so let's reuse the that key",
"1:40:10.179": "remember triangle Airport circle is",
"1:40:12.869": "activations hidden state we also call",
"1:40:16.900": "that and rectangle is important so let's",
"1:40:20.800": "now imagine that we wanted to create a",
"1:40:23.949": "get a big document split it in two sets",
"1:40:27.550": "of three words at a time and grab each",
"1:40:30.130": "set of three words and then try to",
"1:40:31.480": "predict the third word using the first",
"1:40:35.170": "two words so if we had the data set in",
"1:40:38.110": "place we could grab word one as an",
"1:40:41.050": "import chuck it through an embedding",
"1:40:42.699": "right create some activations pass that",
"1:40:46.570": "through a matrix product and a",
"1:40:50.920": "non-linearity grab the second word put",
"1:40:55.900": "it through an embedding and then we",
"1:40:57.820": "could either add those two things",
"1:40:59.980": "together or concatenate them generally",
"1:41:02.440": "speaking when you see kind of two sets",
"1:41:04.989": "of activations coming together in a",
"1:41:07.329": "diagram you normally have a choice of",
"1:41:09.519": "concatenate or or add and that's going",
"1:41:13.480": "to create the second bunch of",
"1:41:14.590": "activations and then you could put it",
"1:41:16.510": "through one more fully connected layer",
"1:41:20.409": "and softmax to create an output so that",
"1:41:23.530": "would be a totally standard fully",
"1:41:26.289": "connected neural net with one very minor",
"1:41:28.960": "tweak which is concatenated or adding at",
"1:41:31.300": "this point which we could use to try to",
"1:41:33.610": "predict the third word of every from",
"1:41:37.059": "pairs of two words okay so remember",
"1:41:41.469": "arrows represent layer operations",
"1:41:44.690": "and I removed on this one the specifics",
"1:41:48.110": "of what they are because they're always",
"1:41:49.730": "an ephah in function followed by a",
"1:41:51.079": "non-linearity okay let's go further what",
"1:41:58.310": "if we wanted to predict word for using",
"1:42:01.190": "words one and two and three it's",
"1:42:03.079": "basically the same picture as last time",
"1:42:04.670": "except with one extra input and one",
"1:42:06.409": "extra circle but I want to point",
"1:42:08.239": "something out which is each time we go",
"1:42:13.099": "from rectangle to circle we're doing the",
"1:42:16.130": "same thing we're doing an embedding",
"1:42:17.920": "which is just a particular kind of",
"1:42:20.510": "matrix model play where you have a",
"1:42:22.579": "one-pot encoded input each time we go",
"1:42:25.310": "from circle to circle we're basically",
"1:42:27.739": "taking one piece of hidden state run",
"1:42:31.010": "through activations and turning it into",
"1:42:32.420": "another set of activations by saying",
"1:42:34.699": "we're now at the next word and then when",
"1:42:37.610": "we go from circle to triangle we're",
"1:42:39.710": "doing something else again which is",
"1:42:41.060": "we're saying let's convert the hidden",
"1:42:43.130": "state these activations into an output",
"1:42:45.400": "so it would make sense so you can see",
"1:42:47.900": "I've colored each of those errors",
"1:42:49.250": "differently so each of those arrows",
"1:42:51.590": "should probably use the same weight",
"1:42:54.469": "matrix because it's doing the same thing",
"1:42:57.110": "so why would you have a different set of",
"1:42:59.150": "embeddings for each word or a different",
"1:43:01.280": "set of a different matrix to multiply by",
"1:43:04.550": "to go from this hidden state to this",
"1:43:05.900": "hidden state versus this one okay so",
"1:43:09.250": "this is what we're going to build so",
"1:43:13.579": "we're now going to jump into human",
"1:43:21.530": "numbers which is less than seven human",
"1:43:23.030": "numbers and this is a data set that I",
"1:43:24.980": "created which literally just contains",
"1:43:26.630": "all the numbers from one to nine",
"1:43:29.270": "thousand hundred 99 written out in",
"1:43:31.250": "English okay and we're going to try and",
"1:43:33.440": "create a language model that can predict",
"1:43:35.179": "the next word in this document it's just",
"1:43:37.190": "a toy example for this purpose so in",
"1:43:42.590": "this case we only have one document and",
"1:43:44.929": "that one document is the list of numbers",
"1:43:46.429": "so we can use a text list to create an",
"1:43:50.329": "item list with text in for the training",
"1:43:51.980": "and the validation in this case the",
"1:43:53.719": "validation set is the numbers from 8,000",
"1:43:55.639": "onwards and the training set is 1 to",
"1:43:57.739": "8,000",
"1:43:59.090": "we can combine them together turn that",
"1:44:02.090": "into a data bunch so we only have one",
"1:44:05.150": "document so train zero is the document",
"1:44:07.340": "grab its dot txt that's how you grab the",
"1:44:09.860": "contents of a text list and here are the",
"1:44:11.900": "first 80 characters",
"1:44:14.869": "it starts with a special token xx POS",
"1:44:17.630": "anything starting with xx is a special",
"1:44:19.639": "fast a token the OS is the beginning of",
"1:44:22.670": "stream token it basically says this is",
"1:44:24.889": "the start of a document and it's very",
"1:44:26.750": "helpful in NLP to know when documents",
"1:44:29.900": "start so that your models can learn to",
"1:44:31.610": "recognize them",
"1:44:33.260": "the validation set contains 13,000",
"1:44:35.599": "tokens so 13 thousand words or",
"1:44:38.719": "punctuation marks because everything",
"1:44:40.550": "between spaces is a separate token the",
"1:44:44.659": "batch size that we asked for was 64 and",
"1:44:52.790": "then by default it uses something called",
"1:44:54.590": "be PTT of 70 be PTT as we briefly",
"1:44:57.739": "mentioned stands for back prop through",
"1:45:00.050": "time that's the sequence links so for",
"1:45:03.590": "each of our so we're there to our kind",
"1:45:06.050": "of 64 document segments we split it up",
"1:45:10.520": "into lists of 70 words that we look at",
"1:45:14.330": "at one time so what we do is we grab",
"1:45:17.810": "this for the validation set entire",
"1:45:20.090": "string of 13,000 tokens and then we",
"1:45:24.290": "split it into 64 roughly equal sized",
"1:45:29.060": "sections okay people very very very",
"1:45:31.730": "often think I'm saying something",
"1:45:33.170": "different I did not say they are of",
"1:45:34.639": "length 64 they're not they're 64 equally",
"1:45:39.409": "sized roughly segments so we take the",
"1:45:42.500": "first one 64th of the document piece one",
"1:45:45.409": "second 64 space - okay and then for each",
"1:45:51.500": "of those",
"1:45:52.810": "1/64 of the document we then split those",
"1:45:55.670": "into pieces of length 70 so each batch",
"1:46:01.179": "right so let's now say okay for those",
"1:46:04.880": "13,000 tokens how many batches are there",
"1:46:07.369": "well divide by batch size and divide by",
"1:46:10.280": "70",
"1:46:11.739": "there's about 2.9 batches so three",
"1:46:13.989": "there's going to be three batches so",
"1:46:15.390": "let's grab an iterator for a data loader",
"1:46:17.830": "grab one two three batches the X and the",
"1:46:21.700": "y and let's add up the number of",
"1:46:24.520": "elements and we get back slightly less",
"1:46:27.190": "than this because there's a little bit",
"1:46:29.170": "left over at the end that doesn't quite",
"1:46:30.580": "make up a full batch okay so this is the",
"1:46:35.140": "kind of stuff you should play around",
"1:46:36.010": "with a lot lots of shapes and sizes and",
"1:46:38.140": "stuff and iterators as you can see it's",
"1:46:41.680": "95 by 64 I claimed it was going to be 70",
"1:46:45.310": "by 64 that's because our data loader for",
"1:46:49.480": "language models slightly randomizes the",
"1:46:52.810": "PTT just to give you a bit more kind of",
"1:46:55.150": "shuffling get bit more randomization it",
"1:46:57.280": "helps the model and so here you can see",
"1:47:01.600": "the first batch of X yeah remember we've",
"1:47:07.630": "numeric alized all these and here's the",
"1:47:10.630": "first batch of Y and you'll see here",
"1:47:12.880": "this is 2 18 10 11 8 this is 18 10 11 8",
"1:47:17.230": "so this one is offset by 1 from here",
"1:47:21.640": "because that's what we want to do with a",
"1:47:23.200": "language model we want to predict the",
"1:47:25.600": "next word so after two should come up 18",
"1:47:29.290": "and after 18 should come 10 right you",
"1:47:34.450": "can grab the vocab for this data set and",
"1:47:36.969": "a vocab has a text defy so if we call it",
"1:47:39.520": "exactly the same look at the same thing",
"1:47:40.840": "but with text fi that'll just look it up",
"1:47:42.520": "in the vocab so here you can see xx POS",
"1:47:45.910": "8001 where else in the why there's no xx",
"1:47:49.750": "POS is just 8,000 one so after xx POS is",
"1:47:52.510": "8 after 8 these thousand after thousand",
"1:47:54.820": "is 1 okay",
"1:47:57.420": "and so then after we get 8023 comes x 2",
"1:48:02.469": "and look at this we're always looking at",
"1:48:04.180": "column 0 so this is the first batch the",
"1:48:07.420": "first mini batch comes 8024 and then X 3",
"1:48:11.219": "all the way up to 8000 40 right and so",
"1:48:15.760": "then we can go right back to the start",
"1:48:18.250": "but look at batch 1 right so index 1",
"1:48:22.180": "which is better number 2 and now we can",
"1:48:24.250": "continue",
"1:48:25.329": "a slight skip from 8042 8000 46 that's",
"1:48:28.960": "because the last mini batch wasn't quite",
"1:48:30.429": "complete so what this means is that",
"1:48:33.690": "every mini batch so every yeah every",
"1:48:38.020": "mini batch joins up with a previous mini",
"1:48:40.900": "batch you know so you can go straight",
"1:48:42.610": "from x1 0 to X 2 0 to continue 8023 8024",
"1:48:48.040": "right and so he took the same thing for",
"1:48:51.599": "colon comma 1 you'll also see they join",
"1:48:54.429": "up so all the mini batches join up so",
"1:48:58.989": "that's the data we can do show better to",
"1:49:01.210": "see it and here is our model which is",
"1:49:09.159": "doing this right so here is this is just",
"1:49:18.400": "the code copied over right so it content",
"1:49:21.909": "contains one embedding ie the green",
"1:49:25.869": "arrow one hidden to hidden brown arrow",
"1:49:30.670": "layer and one hidden to output right so",
"1:49:34.239": "each colored arrow has a single matrix",
"1:49:38.639": "okay and so that in the forward paths we",
"1:49:42.969": "take our first input X 0 and put it",
"1:49:46.179": "through input to hidden the green arrow",
"1:49:49.030": "okay create our first set of activations",
"1:49:51.820": "which we call H assuming that there is",
"1:49:55.809": "the second word because like sometimes",
"1:49:57.579": "we might be at the end of a batch where",
"1:49:59.530": "there isn't a second word assume there",
"1:50:00.849": "is a second word then we would add to H",
"1:50:03.369": "the result of x1 put through the green",
"1:50:07.059": "arrow",
"1:50:07.360": "remember that's H and then we would say",
"1:50:12.639": "okay our new H is the result of those",
"1:50:17.199": "two add it together put through our",
"1:50:21.190": "hidden to hidden orange arrow and then",
"1:50:23.440": "rel you then batch them and then for the",
"1:50:25.510": "second word do exactly the same thing",
"1:50:27.849": "and then finally blue arrow put it",
"1:50:30.699": "through H oh all right so that's how we",
"1:50:32.469": "convert our diagram to code so now",
"1:50:37.209": "new here at all so now let's to okay and",
"1:50:44.229": "and just you know so we can check that",
"1:50:45.639": "in the learner and we can train it 46",
"1:50:47.679": "percent okay let's take this code and",
"1:50:49.719": "recognize it's pretty awful",
"1:50:52.479": "there's a lot of duplicate code and as",
"1:50:54.519": "coders when we see duplicate code what",
"1:50:56.110": "do we do we refactor so we should",
"1:50:58.599": "reflect to this into a loop so here we",
"1:51:01.929": "are we've refactored it into a loop so",
"1:51:04.809": "now we're going for each X I and X and",
"1:51:06.789": "doing it in the loop guess what",
"1:51:09.209": "that's an hour and in an hour it in is",
"1:51:12.909": "just a refactoring it's not anything new",
"1:51:18.189": "this is now a narrative okay and let's",
"1:51:22.389": "refactor our diagram from this to this",
"1:51:26.469": "this is the same diagram okay but I've",
"1:51:30.309": "just replaced it with my loop does the",
"1:51:34.209": "same thing so here here it is it's got",
"1:51:37.030": "exactly the same unit literally exactly",
"1:51:38.769": "the same just popped a loop here before",
"1:51:41.439": "I start I just have to make sure that",
"1:51:42.880": "I've got some you know a bunch of zeros",
"1:51:44.800": "to add to and of course I get exactly",
"1:51:48.010": "the same result when I train it okay so",
"1:51:51.659": "next thing that you might think then and",
"1:51:54.159": "one nice thing about the loop though is",
"1:51:55.659": "now this will work even if I'm not",
"1:51:57.550": "predicting the fourth word from the",
"1:51:59.139": "previous three but the ninth word to the",
"1:52:01.209": "previous eight it'll work for any",
"1:52:02.590": "arbitrarily length long sequence just",
"1:52:05.289": "nice so let's up the BP TT to 20 since",
"1:52:08.860": "we can now and let's say I'll say okay",
"1:52:12.659": "instead instead of just predicting the",
"1:52:19.920": "length word from the previous n minus",
"1:52:22.840": "one let's try to predict the second word",
"1:52:25.599": "from the first in the third from the",
"1:52:27.189": "second and the fourth from the third and",
"1:52:28.689": "so forth right because previously like",
"1:52:30.760": "look at our loss function previously we",
"1:52:32.949": "were comparing the result of our model",
"1:52:35.110": "to just the last word of the sequence it",
"1:52:37.809": "is very wasteful because there's a lot",
"1:52:39.280": "of words in the sequence so let's",
"1:52:40.869": "compare every word in X to every word in",
"1:52:44.409": "Y so to do that we need to change this",
"1:52:47.499": "so it's not just one triangle at the end",
"1:52:49.719": "of the loop",
"1:52:50.709": "but the triangle is inside this right so",
"1:52:55.510": "that in other words after every loop",
"1:52:58.030": "predict loop predict loop predict so",
"1:53:04.530": "here's this code it's the same as the",
"1:53:06.789": "previous code but now I've created an",
"1:53:08.260": "array and every time I go through the",
"1:53:11.199": "loop I append HOH to the array so now",
"1:53:15.489": "for n inputs I create n outputs so I'm",
"1:53:18.999": "predicting after every word previously I",
"1:53:21.760": "had 46% now I have 40% why is it worse",
"1:53:26.289": "well it's worse because now like when",
"1:53:30.550": "I'm trying to predict the second word I",
"1:53:32.110": "only have one word of state to use okay",
"1:53:35.860": "so like and when I'm looking at the",
"1:53:37.479": "third word I only have two words of",
"1:53:39.039": "state to use so it's a much harder",
"1:53:40.840": "problem for it to solve so the obvious",
"1:53:44.920": "way to fix this then would you know the",
"1:53:47.170": "key problem is here I go H equals torch",
"1:53:49.119": "zeros like I reset my state zero every",
"1:53:52.389": "time I start another be PTT sequence",
"1:53:55.809": "well let's not do that let's keep H",
"1:53:58.949": "right and we can because remember each",
"1:54:01.449": "batch connects to the previous batch",
"1:54:03.639": "it's not shuffled like happens in you",
"1:54:07.420": "know image classification so let's take",
"1:54:09.429": "this exact model and replicate it again",
"1:54:11.199": "but let's move the creation of H into",
"1:54:13.719": "the constructor okay there it is so it's",
"1:54:17.229": "now self dot H okay and so this is now",
"1:54:19.809": "exactly the same code but at the end",
"1:54:21.820": "let's put the new H back into self dot H",
"1:54:24.239": "okay so it's now doing the same thing",
"1:54:26.439": "but it's not throwing away that state",
"1:54:29.709": "and so therefore now we actually get",
"1:54:33.130": "above the original we get all the way up",
"1:54:35.019": "to 54 percent accuracy so this is what a",
"1:54:39.189": "real iron tin looks like they you know",
"1:54:42.729": "you you always want to keep that state",
"1:54:45.639": "right but just keep remembering there's",
"1:54:47.229": "nothing different about an RNA and it's",
"1:54:49.869": "a totally normal fully connected neural",
"1:54:51.579": "net okay it's just that you've got a",
"1:54:53.499": "loop you refactored what you could do",
"1:54:59.709": "though is at the end of your every loop",
"1:55:03.369": "you",
"1:55:04.090": "could not just spit out an output but",
"1:55:05.650": "you could spit it out into another",
"1:55:07.510": "errand in so you have an errand in going",
"1:55:09.820": "into an errand and that's nice because",
"1:55:11.260": "we've now got more layers of computation",
"1:55:13.180": "you would expect that to work better",
"1:55:16.890": "well to get there let's do some more",
"1:55:19.450": "refactoring so let's take this code and",
"1:55:23.080": "replace it with the equivalent built in",
"1:55:25.750": "pipe torch code which is you just say",
"1:55:29.530": "that so n n dot R and n basically says",
"1:55:31.930": "do the loop for me okay we've still got",
"1:55:34.210": "the same embedding we've still got the",
"1:55:36.040": "same output still got the same batch",
"1:55:37.720": "norm we've still got the same",
"1:55:39.010": "initialization of H but we just got rid",
"1:55:41.260": "of the loop so one of the nice things",
"1:55:43.840": "about our a10 is that you can now say",
"1:55:46.350": "how many layers you want so this is the",
"1:55:50.410": "same accuracy of course so here I'm",
"1:55:53.320": "going to do it with two layers but",
"1:55:56.230": "here's the thing when you think about",
"1:55:58.240": "this right think about it without the",
"1:56:01.120": "loop it looks like this right",
"1:56:04.180": "it's like keeps on going and we've got a",
"1:56:06.730": "BP GT of 20 so there's 20 layers of this",
"1:56:09.730": "and we know from that visualizing the",
"1:56:13.450": "lost landscapes paper that deep networks",
"1:56:15.760": "have awful bumpy lost surfaces so when",
"1:56:20.710": "you start creating long timescales and",
"1:56:24.610": "multiple layers these things get",
"1:56:28.020": "impossible to train so there's a few",
"1:56:32.260": "tricks you can do one thing is you can",
"1:56:33.640": "add skip connections of course about",
"1:56:37.630": "what people normally do is instead they",
"1:56:39.730": "put inside instead of just adding these",
"1:56:43.150": "together they actually use a little mini",
"1:56:45.340": "neural net to decide how much of the",
"1:56:48.490": "green arrow to keep and how much of the",
"1:56:50.050": "orange arrow to keep and when you do",
"1:56:52.450": "that you get something that's either",
"1:56:53.980": "called giu or an L STM depending on the",
"1:56:57.700": "details of that little neural net and",
"1:56:59.020": "we'll learn about the details of those",
"1:57:00.490": "neural nets in part 2 they really don't",
"1:57:02.590": "matter though frankly so we can now say",
"1:57:05.620": "let's create a GI u instead it says just",
"1:57:07.750": "like what we had before but it'll handle",
"1:57:10.410": "longer sequences in deeper networks",
"1:57:12.550": "let's use two layers bump and we're up",
"1:57:16.480": "to 75%",
"1:57:19.869": "okay so that's how it ends and the main",
"1:57:27.440": "reason what it's show it to you was to",
"1:57:28.909": "remove the the last remaining piece of",
"1:57:31.760": "magic and this is one of like the least",
"1:57:34.869": "magical things we have in deep learning",
"1:57:36.949": "it's just a refactored fully connected",
"1:57:39.199": "Network",
"1:57:40.579": "so don't let our own ends ever ever put",
"1:57:43.250": "you off and with this approach where you",
"1:57:47.599": "basically have a sequence of n inputs",
"1:57:49.670": "and a sequence of n outputs which we've",
"1:57:51.619": "been using for language modeling you can",
"1:57:53.329": "use that for other tasks right for",
"1:57:55.310": "example the sequence of outputs could be",
"1:57:57.619": "for every word there could be something",
"1:57:59.329": "saying is there something that I is",
"1:58:01.070": "sensitive and I want to anonymize or not",
"1:58:02.949": "you know so like is this private private",
"1:58:06.409": "data or not or it could be a part of",
"1:58:08.659": "speech tag for that word or it could be",
"1:58:12.469": "something saying you know how should",
"1:58:15.739": "that word be formatted or whatever and",
"1:58:18.679": "so these are called sequence labeling",
"1:58:20.119": "tasks and so you can use this same",
"1:58:22.190": "approach for pretty much any sequence",
"1:58:24.590": "labeling task or you can do what I did",
"1:58:27.349": "in the earlier lesson which is once you",
"1:58:29.719": "finish building your language model you",
"1:58:33.440": "can throw away their kind of this h0 bit",
"1:58:38.090": "and instead pop their a standard",
"1:58:41.139": "classification head and then you can now",
"1:58:44.389": "do NLP classification which as you saw",
"1:58:46.550": "earlier what if you stayed at the out",
"1:58:49.190": "results even on long documents so this",
"1:58:54.469": "is a super valuable technique and not",
"1:58:57.139": "remotely metrical okay so that's it",
"1:59:01.699": "right that's that's deep learning or at",
"1:59:04.790": "least you know the kind of the practical",
"1:59:06.679": "pieces from my point of view having",
"1:59:12.199": "watched this one time you won't get it",
"1:59:17.300": "all and I don't recommend that you do",
"1:59:19.610": "watch this so slowly that you get it all",
"1:59:21.560": "the first time but you go back and look",
"1:59:24.290": "at it again take your time and there'll",
"1:59:26.869": "be bits that you go like oh now I see",
"1:59:28.909": "what he's saying and",
"1:59:30.120": "you'll be able to like implement things",
"1:59:31.350": "you couldn't implement before and you'll",
"1:59:32.880": "be able to dig in more than you thought",
"1:59:34.290": "so like definitely go back and do it",
"1:59:35.490": "again and as you do write rack code not",
"1:59:39.840": "just for yourself but put it on github",
"1:59:41.220": "right it doesn't matter if you think",
"1:59:43.590": "it's great code or not you know the fact",
"1:59:45.630": "that you're writing code and sharing it",
"1:59:48.330": "is impressive and the feedback you'll",
"1:59:51.600": "get if you tell people on the forum you",
"1:59:53.280": "know hey I wrote this code it's not",
"1:59:55.200": "great but you know it's my first effort",
"1:59:57.530": "anything you see jump out at you people",
"2:00:00.840": "will say like oh that bit was done well",
"2:00:02.400": "hey but you do know for this bit you",
"2:00:04.380": "could have used this library and",
"2:00:05.460": "Safety's in time you'll learn a lot by",
"2:00:07.400": "interacting with your peers as you've",
"2:00:11.760": "noticed I've started introducing more",
"2:00:13.200": "and more papers now part two will be a",
"2:00:15.630": "lot of papers and so it's a good time to",
"2:00:17.850": "start reading some of the papers that",
"2:00:21.000": "have been introduced in this in this",
"2:00:22.680": "section all the bits that say like",
"2:00:25.140": "derivation and theorems and lemmas you",
"2:00:27.240": "can skip them I do they add almost",
"2:00:29.850": "nothing to your understanding of",
"2:00:31.560": "practical tech learning right",
"2:00:32.940": "but the bits that say like you know why",
"2:00:36.510": "are we solving this problem and what are",
"2:00:38.340": "the results and so forth really",
"2:00:40.800": "interesting and then you know try and",
"2:00:43.200": "write English prose not know English",
"2:00:49.380": "prose that you want to be read by Geoff",
"2:00:50.940": "Hinton and Yann LeCun",
"2:00:51.990": "but English prose that you want to be",
"2:00:53.700": "written read by you as of six months ago",
"2:00:56.160": "right because there's a lot more people",
"2:00:58.410": "in the audience of you as well six",
"2:01:01.110": "months ago then there is of Geoffrey",
"2:01:03.180": "Hinton Danielle Loughran right that's",
"2:01:04.950": "that's the person you best understand",
"2:01:06.960": "you know what they need right go and get",
"2:01:11.700": "help and help others",
"2:01:12.780": "tell us about your success stories but",
"2:01:16.050": "perhaps the most important one is get",
"2:01:17.670": "together with others that people's",
"2:01:19.560": "learning works much better if you've got",
"2:01:21.630": "that social experience so start a book",
"2:01:25.140": "club get involved in meetups create",
"2:01:27.660": "study groups and build things right and",
"2:01:32.280": "again they it doesn't have to be amazing",
"2:01:35.430": "like just build something that do you",
"2:01:38.430": "think the world would be a little bit",
"2:01:39.480": "better if that what existed or you think",
"2:01:42.030": "it would be kind of slightly delightful",
"2:01:44.130": "to your two-year-old to see that thing",
"2:01:45.600": "or you just want to show it to your",
"2:01:47.460": "brother the next time they come around",
"2:01:48.540": "to see what you're doing whatever right",
"2:01:50.159": "like just finish something you know",
"2:01:54.090": "finish something and then try and make",
"2:01:57.060": "it a bit better so for example something",
"2:02:01.469": "I just saw this afternoon is the Elan",
"2:02:03.929": "Elan musk twitch ener ATAR okay so",
"2:02:09.360": "looking at lots of older tweets creating",
"2:02:11.580": "a language model from from Elon Musk and",
"2:02:14.429": "then creating new tweets such as",
"2:02:16.469": "humanity will also have an option to",
"2:02:18.750": "publish on its own journey as an only in",
"2:02:20.909": "civilization it will always like all",
"2:02:23.880": "human being Mars is no longer possible",
"2:02:26.540": "hey I will definitely be the Central",
"2:02:29.219": "Intelligence Agency okay so this is",
"2:02:31.889": "great I love this and I love that Dave",
"2:02:34.920": "Smith wrote and said these are my",
"2:02:37.440": "first-ever commits thanks for teaching a",
"2:02:40.230": "finance guy how to build an app in 8",
"2:02:42.389": "weeks right so you know I think this is",
"2:02:46.290": "awesome and I think like clearly a lot",
"2:02:48.719": "of care and passion is being put into",
"2:02:50.520": "this project you know will it",
"2:02:55.670": "systematically change the future",
"2:02:57.630": "direction of society as a whole maybe",
"2:02:59.699": "not you know but maybe Elon will look at",
"2:03:02.460": "this and think like oh you know like I",
"2:03:04.440": "maybe I need to rethink my method of",
"2:03:05.880": "pros I don't know I think it's I think",
"2:03:08.280": "it's great",
"2:03:09.420": "and so yeah create something put it out",
"2:03:12.510": "there put a bit of yourself into it or",
"2:03:16.530": "get involved in fast AI the first thing",
"2:03:19.620": "I project there's a lot going on you",
"2:03:21.120": "know you can help with documentation and",
"2:03:23.010": "tests which might sound boring but you'd",
"2:03:25.739": "be surprised how incredibly not boring",
"2:03:27.480": "it is to like take a piece of code that",
"2:03:29.159": "hasn't been properly documented and",
"2:03:31.050": "research it and understand it and ask",
"2:03:33.239": "Sylvia and I on the forum what's going",
"2:03:35.429": "on why did you write it this way we'll",
"2:03:37.080": "send you off to the papers that we were",
"2:03:38.429": "implementing you know writing a test",
"2:03:40.500": "requires deeply understanding that part",
"2:03:42.780": "of the machine learning world to really",
"2:03:44.400": "understand how it's meant to work so",
"2:03:46.710": "that's what was interesting stairs",
"2:03:48.929": "Backman has created this nice dev",
"2:03:50.850": "projects index which you can like go",
"2:03:53.219": "onto the forum in the FASTA I dev",
"2:03:55.560": "section and find",
"2:03:57.460": "get to the dev project section and find",
"2:03:59.500": "like give some stuff going on that you",
"2:04:01.270": "might want to get involved in or maybe",
"2:04:02.740": "there's stuff you want to exist you",
"2:04:03.790": "could add your own create a study group",
"2:04:06.580": "you know Deena's already created a study",
"2:04:08.440": "group for San Francisco starting in",
"2:04:10.000": "January this is how easy it is to create",
"2:04:11.500": "a study group right go on the forum find",
"2:04:13.930": "your little time zone subcategory and",
"2:04:15.700": "add a post thing let's create a study",
"2:04:17.860": "group okay but make sure you you know",
"2:04:20.950": "give people like a little Google sheet",
"2:04:22.600": "to sign up some way to actually do",
"2:04:24.280": "something you know a great example is",
"2:04:27.820": "Pierre who's been doing a fantastic job",
"2:04:29.560": "in Brazil of running study groups for",
"2:04:33.610": "the last couple of classes of the course",
"2:04:34.900": "and you know he keeps posting these",
"2:04:37.720": "pictures of people having a good time",
"2:04:39.610": "and learning deep learning together",
"2:04:41.460": "creating wiki's together creating",
"2:04:43.810": "projects together great experience and",
"2:04:46.870": "then come back for part two",
"2:04:48.400": "right where we'll be looking at all of",
"2:04:52.210": "this interesting stuff in particular",
"2:04:54.280": "going deep into the first day our code",
"2:04:56.650": "base to understand how did we build it",
"2:04:58.240": "exactly will actually go through as we",
"2:05:01.180": "were building it we created notebooks of",
"2:05:03.490": "like here where here's where we were at",
"2:05:05.140": "each stage so we're actually going to",
"2:05:06.280": "see the software development process",
"2:05:07.450": "itself we'll talk about the process of",
"2:05:09.550": "doing research how to read academic",
"2:05:12.220": "papers how to turn math into code and",
"2:05:14.050": "then a whole bunch of additional types",
"2:05:17.110": "of models that we haven't seen yet so",
"2:05:19.300": "it'll be kind of like going beyond",
"2:05:21.040": "practical deep learning into actually",
"2:05:23.520": "cutting edge research so we've got five",
"2:05:28.060": "minutes to take some questions we had an",
"2:05:31.480": "AMA going on online and so we're going",
"2:05:34.750": "to have time for a couple of the",
"2:05:36.850": "highest-ranked AMA questions from the",
"2:05:38.620": "community and the first one is by",
"2:05:40.480": "Jeremy's request although it's not the",
"2:05:42.610": "highest ranked what's your typical day",
"2:05:44.950": "like how do you manage your time across",
"2:05:47.140": "so many things that you do yeah I",
"2:05:51.430": "thought that I hear that all the time so",
"2:05:53.830": "I thought I should answer it and I think",
"2:05:55.750": "I got a few votes because I think people",
"2:06:01.600": "who come to our study group",
"2:06:02.740": "are always shocked at how disorganized",
"2:06:06.460": "and incompetent I am and so I often get",
"2:06:09.790": "people saying like Oh",
"2:06:10.699": "Wow I thought you were like this deep",
"2:06:12.440": "learning role model and I'll get to see",
"2:06:14.150": "how to be like you and now I'm not sure",
"2:06:15.739": "what it'd be like you at all",
"2:06:17.739": "so yeah it's for me it's all about just",
"2:06:24.409": "having a good time with it I never",
"2:06:26.179": "really have many plans I just try to",
"2:06:28.639": "finish what I start",
"2:06:30.499": "if you're not having fun with it it's",
"2:06:32.809": "really really hard to continue because",
"2:06:34.489": "there's a lot of frustration in deep",
"2:06:36.440": "learning because it's not like writing a",
"2:06:37.820": "web app where it's like you know",
"2:06:39.769": "authentication check you know back-end",
"2:06:43.929": "service watchdog check okay user",
"2:06:49.190": "credentials check you know like you just",
"2:06:50.749": "you're making progress where else for",
"2:06:52.880": "stuff like this",
"2:06:53.840": "Dan stuff that we've been doing the last",
"2:06:55.880": "couple of weeks it's just like it's not",
"2:06:58.219": "working it's not working it's not",
"2:07:00.170": "working no it also didn't work it also",
"2:07:02.570": "didn't work until oh my god it's amazing",
"2:07:05.239": "it's a cat that's kind of what it is",
"2:07:07.190": "right so you don't get that regular",
"2:07:09.079": "feedback so yeah you know you got to",
"2:07:13.280": "have fun with it",
"2:07:14.630": "and so so Mike yeah my day is kind of",
"2:07:18.369": "you know and the other thing I do I'll",
"2:07:20.690": "say I don't I don't do any meetings",
"2:07:23.449": "I don't do phone calls I don't do",
"2:07:25.579": "coffees I don't watch TV at okay",
"2:07:28.010": "computer games I spend a lot of time",
"2:07:30.380": "with my family a lot of time exercising",
"2:07:32.659": "and a lot of time reading and coding and",
"2:07:36.530": "doing things I like so you know I think",
"2:07:41.769": "the you know the main thing is just",
"2:07:43.699": "finish finish something like properly",
"2:07:47.479": "finish it so when you get to that point",
"2:07:49.519": "where you think 80% of the way through",
"2:07:50.900": "but you haven't quite created to read me",
"2:07:52.729": "yet and the install process is still a",
"2:07:55.099": "bit clunky and you know this is what 99%",
"2:07:57.679": "of github projects look like you'll see",
"2:07:59.449": "the readme says to do you know complete",
"2:08:03.380": "baseline experiments document blah blah",
"2:08:06.650": "blah it's like don't be that person like",
"2:08:09.349": "just do something properly and finish it",
"2:08:12.829": "and maybe get some other people around",
"2:08:14.360": "you to work with you so that you're all",
"2:08:15.800": "doing it together and you know get it",
"2:08:18.199": "done",
"2:08:22.070": "what are the up-and-coming deep learning",
"2:08:24.020": "machine learning things that you are",
"2:08:25.460": "most excited about also you've mentioned",
"2:08:28.040": "last year that you are not a believer in",
"2:08:29.780": "reinforcement learning do you still feel",
"2:08:31.820": "the same way yeah I still feel exactly",
"2:08:35.300": "the same way as I did three years ago",
"2:08:36.890": "when we started this which is it's all",
"2:08:40.310": "about transfer learning its",
"2:08:41.810": "underappreciated its under-researched",
"2:08:44.090": "every time we put transfer learning into",
"2:08:45.710": "anything we make it much better you know",
"2:08:48.620": "our academic paper on transfer learning",
"2:08:51.680": "for NLP has you know helped be one piece",
"2:08:55.010": "of kind of changing the direction of NLP",
"2:08:56.630": "this year it made it all the way to the",
"2:08:59.000": "New York Times just a stupid obvious",
"2:09:01.550": "little thing that we threw together so I",
"2:09:04.610": "remain excited about that I remain",
"2:09:06.560": "unexcited about reinforcement learning",
"2:09:08.690": "for most things I don't see it used by",
"2:09:12.260": "normal people for normal things for",
"2:09:14.420": "nearly anything it's an incredibly",
"2:09:16.400": "inefficient way to solve problems which",
"2:09:18.410": "often solved more simply and more",
"2:09:20.720": "quickly in other ways probably has a",
"2:09:22.810": "maybe a role in the world but a limited",
"2:09:27.290": "one and not in most people's day-to-day",
"2:09:30.560": "work for someone planning to take part -",
"2:09:40.490": "and 2019 what would you recommend doing",
"2:09:42.710": "learning practicing until the part two",
"2:09:44.690": "course starts just code",
"2:09:48.740": "yeah just code all the time I know it's",
"2:09:51.590": "perfectly possible I hear from people",
"2:09:52.970": "who get to this point of the course and",
"2:09:54.860": "they haven't actually written any code",
"2:09:55.970": "yet and if that's you it's okay you know",
"2:09:59.390": "you've just go through and do it again",
"2:10:01.400": "and this time do code and and look at",
"2:10:05.240": "the input the shapes of your inputs and",
"2:10:07.430": "look at your outputs to make sure you",
"2:10:08.720": "know how to grab a mini batch and look",
"2:10:10.130": "at its main standard deviation and plot",
"2:10:12.830": "it and you know there's this so much",
"2:10:16.430": "material that we've covered if you can",
"2:10:19.870": "get to a point where you can you know",
"2:10:22.720": "rebuild those notebooks from scratch",
"2:10:27.490": "without too much cheating when I say",
"2:10:30.350": "from scratch I mean using the first day",
"2:10:31.730": "library not from scratch from scratch",
"2:10:34.690": "you know you're you're be in the top",
"2:10:37.760": "echelon of practitioners because you'll",
"2:10:39.710": "be able to do all of these things",
"2:10:40.820": "yourself and that's really really rare",
"2:10:42.590": "and that'll put you in a great position",
"2:10:44.720": "for part two nine o'clock be honest do",
"2:10:48.710": "one more and where do you see the fast",
"2:10:51.590": "day Iowa library going in the future say",
"2:10:53.990": "in five years well like I said I don't",
"2:10:58.250": "make plans I just I just piss around so",
"2:11:02.320": "I mean our only plan for fast AI you",
"2:11:07.370": "know as an you know organization is to",
"2:11:11.420": "make deep learning accessible as a tool",
"2:11:13.790": "for normal people to use for normal",
"2:11:16.340": "stuff",
"2:11:17.630": "so as long as we need to code we failed",
"2:11:20.600": "at that so the big goal you know cuz",
"2:11:23.260": "ninety-nine point eight percent of the",
"2:11:25.970": "world can't code so the main goal would",
"2:11:29.360": "be to get to a point where it's not a",
"2:11:30.620": "library but it's a piece of software",
"2:11:32.000": "that doesn't require a code it certainly",
"2:11:34.070": "shouldn't require a goddamn lengthy hard",
"2:11:38.660": "working course like this one you know so",
"2:11:41.180": "I want to get rid of the course I want",
"2:11:43.100": "to get rid of the code I want to make it",
"2:11:45.020": "so you can just do useful stuff quickly",
"2:11:47.720": "and and easily so that's that's",
"2:11:50.400": "maybe five years yeah maybe longer all",
"2:11:53.219": "right well I hope to see you all back",
"2:11:54.570": "here for part two",
"3:11:55.409": "thank you"
}
