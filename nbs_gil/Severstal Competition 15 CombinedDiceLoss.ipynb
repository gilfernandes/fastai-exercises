{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from fastai.vision import *\n",
    "from fastai import *\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from fastai.vision.models.cadene_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv('/root/.fastai/data/severstal/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/root/.fastai/data/severstal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/root/.fastai/data/severstal/train_images.zip'),\n",
       " PosixPath('/root/.fastai/data/severstal/sample_submission.csv'),\n",
       " PosixPath('/root/.fastai/data/severstal/test_images.zip'),\n",
       " PosixPath('/root/.fastai/data/severstal/train.csv'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images'),\n",
       " PosixPath('/root/.fastai/data/severstal/test_images')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/root/.fastai/data/severstal/train_images/5e581254c.jpg'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images/fd2f7b4f4.jpg'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images/82f4c0b69.jpg')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = get_image_files(path/'train_images')\n",
    "train_images[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check maximum size of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img_max_size(folder):\n",
    "    max_height = 0\n",
    "    max_width = 0\n",
    "    for train_image in train_images:\n",
    "        img = open_image(train_image)\n",
    "        if max_height < img.shape[1]:\n",
    "            max_height = img.shape[1]\n",
    "        if max_width < img.shape[2]:\n",
    "            max_width = img.shape[2]\n",
    "    return max_height, max_width\n",
    "\n",
    "def show_image(images, index):\n",
    "    img_f = images[index]\n",
    "    print(type(img_f))\n",
    "    img = open_image(img_f)\n",
    "    print(img)\n",
    "    img.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = Path('/kaggle/mask')\n",
    "if not os.path.exists(mask_path):\n",
    "    os.makedirs(str(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_encoded_to_array(encoded_pixels):\n",
    "    pos_array = []\n",
    "    len_array = []\n",
    "    splits = encoded_pixels.split()\n",
    "    pos_array = [int(n) - 1 for i, n in enumerate(splits) if i % 2 == 0]\n",
    "    len_array = [int(n) for i, n in enumerate(splits) if i % 2 == 1]\n",
    "    return pos_array, len_array\n",
    "        \n",
    "def convert_to_pair(pos_array, rows):\n",
    "    return [(p % rows, p // rows) for p in pos_array]\n",
    "\n",
    "def create_positions(single_pos, size):\n",
    "    return [i for i in range(single_pos, single_pos + size)]\n",
    "\n",
    "def create_positions_pairs(single_pos, size, row_size):\n",
    "    return convert_to_pair(create_positions(single_pos, size), row_size)\n",
    "\n",
    "def convert_to_mask(encoded_pixels, row_size, col_size, category):\n",
    "    pos_array, len_array = convert_encoded_to_array(encoded_pixels)\n",
    "    mask = np.zeros([row_size, col_size])\n",
    "    for(p, l) in zip(pos_array, len_array):\n",
    "        for row, col in create_positions_pairs(p, l, row_size):\n",
    "            mask[row][col] = category\n",
    "    return mask\n",
    "\n",
    "def save_to_image(masked, image_name):\n",
    "    im = PIL.Image.fromarray(masked)\n",
    "    im = im.convert(\"L\")\n",
    "    image_name = re.sub(r'(.+)\\.jpg', r'\\1', image_name) + \".png\"\n",
    "    real_path = mask_path/image_name\n",
    "    im.save(real_path)\n",
    "    return real_path\n",
    "\n",
    "def open_single_image(path):\n",
    "    img = open_image(path)\n",
    "    img.show(figsize=(20,20))\n",
    "    \n",
    "def get_y_fn(x):\n",
    "    return mask_path/(x.stem + '.png')\n",
    "\n",
    "def group_by(train_images, train_pd):\n",
    "    tran_dict = {image.name:[] for image in train_images}\n",
    "    pattern = re.compile('(.+)_(\\d+)')\n",
    "    for index, image_path in train_pd.iterrows():\n",
    "        m = pattern.match(image_path['ImageId_ClassId'])\n",
    "        file_name = m.group(1)\n",
    "        category = m.group(2)\n",
    "        tran_dict[file_name].append((int(category), image_path['EncodedPixels']))\n",
    "    return tran_dict\n",
    "\n",
    "def display_image_with_mask(img_name):\n",
    "    full_image = path/'train_images'/img_name\n",
    "    print(full_image)\n",
    "    open_single_image(full_image)\n",
    "    mask_image = get_y_fn(full_image)\n",
    "    mask = open_mask(mask_image)\n",
    "    print(full_image)\n",
    "    mask.show(figsize=(20, 20), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_categories_mask = group_by(train_images, train_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mask files and save these to kaggle/mask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 256\n",
    "image_width = 1600\n",
    "if not os.path.exists(mask_path/'0002cc93b.png'):\n",
    "    for image_name, cat_list in grouped_categories_mask.items():\n",
    "        masked = np.zeros([image_height, image_width])\n",
    "        for cat_mask in cat_list:\n",
    "            encoded_pixels = cat_mask[1]\n",
    "            if pd.notna(cat_mask[1]):\n",
    "                masked += convert_to_mask(encoded_pixels, image_height, image_width, cat_mask[0])\n",
    "        if np.amax(masked) > 4:\n",
    "            print(f'Check {image_name} for max category {np.amax(masked)}')\n",
    "        save_to_image(masked, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limited_dihedral_affine(k:partial(uniform_int,0,3)):\n",
    "    \"Randomly flip `x` image based on `k`.\"\n",
    "    x = -1 if k&1 else 1\n",
    "    y = -1 if k&2 else 1\n",
    "    if k&4: return [[0, x, 0.],\n",
    "                    [y, 0, 0],\n",
    "                    [0, 0, 1.]]\n",
    "    return [[x, 0, 0.],\n",
    "            [0, y, 0],\n",
    "            [0, 0, 1.]]\n",
    "\n",
    "dihedral_affine = TfmAffine(limited_dihedral_affine)\n",
    "\n",
    "def get_extra_transforms(max_rotate:float=3., max_zoom:float=1.1,\n",
    "                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "    p_lightings = [p_lighting, p_lighting + 0.2, p_lighting + 0.4, p_lighting + 0.6, p_lighting + 0.7]\n",
    "    max_lightings = [max_lighting, max_lighting + 0.2, max_lighting + 0.4, max_lighting + 0.6, max_lighting + 0.7]\n",
    "    res = [rand_crop(), dihedral_affine(), \n",
    "           symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine),\n",
    "           rotate(degrees=(-max_rotate,max_rotate), p=p_affine),\n",
    "           rand_zoom(scale=(1., max_zoom), p=p_affine)]\n",
    "    res.extend([brightness(change=(0.5*(1-mp[0]), 0.5*(1+mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    res.extend([contrast(scale=(1-mp[0], 1/(1-mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    #       train                   , valid\n",
    "    return (res, [crop_pad()])\n",
    "\n",
    "def get_simple_transforms(max_rotate:float=3., max_zoom:float=1.1,\n",
    "                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "    res = [\n",
    "        rand_crop(),\n",
    "        symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine),\n",
    "        rotate(degrees=(-max_rotate,max_rotate), p=p_affine),\n",
    "        rand_zoom(scale=(1., max_zoom), p=p_affine)\n",
    "          ]\n",
    "    #       train                   , valid\n",
    "    return (res, [crop_pad()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (path/'train_images').ls()\n",
    "src_size = np.array(open_image(str(train_images[0])).shape[1:])\n",
    "valid_pct = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = array(['0', '1', '2', '3', '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_bunch(bs, size):\n",
    "    src = (SegmentationItemList.from_folder(path/'train_images')\n",
    "       .split_by_rand_pct(valid_pct=valid_pct)\n",
    "       .label_from_func(get_y_fn, classes=codes))\n",
    "    data = (src.transform(get_simple_transforms(), size=size, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "    return src, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = src_size//2\n",
    "src, data = create_data_bunch(bs, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create learner and training\n",
    "Starting with low resolution training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['0']\n",
    "\n",
    "def acc_camvid(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    comparison = argmax[mask]==target[mask]\n",
    "    return torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "\n",
    "def acc_camvid_with_zero_check(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        if(torch.sum(argmax[b]).item() == 0.0 and torch.sum(target[b]).item() == 0.0):\n",
    "            total[b] = 1\n",
    "        else:\n",
    "            mask = target[b] != void_code\n",
    "            comparison = argmax[b][mask]==target[b][mask]\n",
    "            total[b] = torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def calc_dice_coefficients(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        if sum_seg + sum_gt == 0:\n",
    "            return torch.tensor(1.0)\n",
    "        return (torch.sum((seg[gt == cat] / cat).float()) * 2.0) / (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats)])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i] = calc_dice_coefficient(argmax, target, c)\n",
    "    return total_avg.mean()\n",
    "\n",
    "\n",
    "def dice_coefficient(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "def calc_dice_coefficients_2(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        return (torch.sum((seg[gt == cat] / cat).float())), (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats), 2])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i][0], total_avg[i][1] = calc_dice_coefficient(argmax, target, c)\n",
    "    total_sum = total_avg.sum(axis=0)\n",
    "    if (total_sum[1] == 0.0):\n",
    "        return torch.tensor(1.0)\n",
    "    return total_sum[0] * 2.0 / total_sum[1]\n",
    "\n",
    "\n",
    "def dice_coefficient_2(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients_2(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def accuracy_simple(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDiceLoss(nn.Module):\n",
    "    def __init__(self, zero_cat_factor=0.1):\n",
    "        super().__init__()\n",
    "        self.zero_cat_factor = zero_cat_factor\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.dice_loss(target, input, self.zero_cat_factor)\n",
    "\n",
    "    def dice_loss(self, target, output, eps=1e-7, zero_cat_factor=0.1):\n",
    "        '''\n",
    "        Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "        Assumes the `channels_last` format.\n",
    "\n",
    "        # Arguments\n",
    "            target: b x 1 x X x Y( x Z...) ground truth\n",
    "            output: b x c x X x Y( x Z...) Network output, must sum to 1 over c channel (such as after softmax)\n",
    "            epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "\n",
    "        # References\n",
    "            V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation\n",
    "            https://arxiv.org/abs/1606.04797\n",
    "            More details on Dice loss formulation\n",
    "            https://mediatum.ub.tum.de/doc/1395260/1395260.pdf (page 72)\n",
    "\n",
    "            Adapted from https://github.com/Lasagne/Recipes/issues/99#issuecomment-347775022\n",
    "        '''\n",
    "\n",
    "        # skip the batch and class axis for calculating Dice score\n",
    "        num_classes = output.shape[1]\n",
    "        y_true = F.one_hot(target.long().squeeze(), num_classes)\n",
    "        y_pred = F.softmax(output, dim=1).permute(0, 2, 3, 1)\n",
    "        y_true = y_true.type(y_pred.type())\n",
    "        y_true = y_true.permute(0, 3, 1, 2)\n",
    "        y_true[:,0,:] *= zero_cat_factor # Factor used to take power away from the zeroth category\n",
    "        y_true = y_true.permute(0, 2, 3, 1)\n",
    "        axes = tuple(range(1, len(y_pred.shape)-1))\n",
    "        numerator = 2. * torch.sum(y_pred * y_true, axes)\n",
    "        denominator = torch.sum(y_pred ** 2 + y_true ** 2, axes)\n",
    "        # When intersection and cardinality are all zero you have 100% score and not 0% score\n",
    "        # For this we use the eps parameter\n",
    "        loss_array = ((numerator + eps) / (denominator + eps))\n",
    "        loss_array = (loss_array).mean(dim=0)\n",
    "        return ((1 - torch.mean(loss_array)) + F.cross_entropy(output, target.squeeze())) / 2.\n",
    "\n",
    "    def __del__(self): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import callbacks\n",
    "\n",
    "def train_learner(learn, slice_lr, epochs=10, pct_start=0.8, best_model_name='best_model', \n",
    "                  patience_early_stop=4, patience_reduce_lr = 3):\n",
    "    learn.fit_one_cycle(epochs, slice_lr, pct_start=pct_start, \n",
    "                    callbacks=[callbacks.SaveModelCallback(learn, monitor='dice_coefficient',mode='max', name=best_model_name),\n",
    "                              callbacks.EarlyStoppingCallback(learn=learn, monitor='dice_coefficient', patience=patience_early_stop),\n",
    "                              callbacks.ReduceLROnPlateauCallback(learn=learn, monitor='dice_coefficient', patience=patience_reduce_lr),\n",
    "                              callbacks.TerminateOnNaNCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=accuracy_simple, acc_camvid_with_zero_check, dice_coefficient, dice_coefficient_2\n",
    "wd=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedDiceLoss()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "# learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([1.0, .5, .5, .5, .5]).cuda())\n",
    "learn.loss_func = CombinedDiceLoss(zero_cat_factor=0.5)\n",
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model_dir = Path('/kaggle/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = to_fp16(learn, loss_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEJCAYAAACzPdE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd5hU5dnH8e+9FXZZlrb0jhQRKbIURRETRTQqGiv2SqxRk+hrjIlvLHlTjbHFoCJqAhoVjCV2UQRE2KU3YUMvsov0vuV+/5jRjLgLCzuzZ2b397muuZh5znNm7nmuZX972nPM3REREamqpKALEBGRmkGBIiIiUaFAERGRqFCgiIhIVChQREQkKhQoIiISFTELFDNrY2YTzWyRmS0ws1vL6XOJmc0NP6aaWa+IZSvMbJ6ZzTazvFjVKSIi0ZESw/cuAX7q7jPNLAvIN7P33X1hRJ/lwInuvtnMTgNGAQMilp/k7htjWKOIiERJzALF3dcD68PPt5vZIqAVsDCiz9SIVaYBravymU2aNPH27dtX5S1ERGqV/Pz8je6eE433iuUWyjfMrD3QB/j8AN2uAd6OeO3Ae2bmwN/cfVQF7z0SGAnQtm1b8vK0d0xEpLLMbGW03ivmgWJm9YBXgdvcfVsFfU4iFCjHRzQPcvd1ZtYUeN/MFrv7pP3XDQfNKIDc3FzNIyMiEpCYnuVlZqmEwuQf7j6+gj49gaeB4e7+1dft7r4u/G8hMAHoH8taRUSkamJ5lpcBzwCL3P2hCvq0BcYDl7n7koj2zPCBfMwsExgKzI9VrSIiUnWx3OU1CLgMmGdms8NtdwNtAdz9SeBXQGPgiVD+UOLuuUAzYEK4LQUY6+7vxLBWERGpolie5TUZsIP0uRa4tpz2ZUCv764hIiLxSlfKi4hIVChQREQkKqrlOpR45+5MWrqReWu2kJ2RRscmmXRuWo+crHTCx3FEROQgan2gbNtTzLVj8pi+YtN3ljWvX4fBXZrQuF465/RpRZdmWQFUKCKSGGp9oGSlp5CTlc79w4/i3L6t2ba7hGVFO1iyYTufL9/EB4sK2ba7mNGTl3NGz5bsKy2jTcO6tG+SSb/2jejQJDPoryAiEhfMveZcXJ6bm+uxmHqlaPtefj5+LrNWbSEzPYV1W3ZTUuaYwXGdGpORlsKZvVpyZs8W2kUmIgnFzPLDl2tU/b0UKIeupLSM1Zt3M37mGt5fuIHte0pYu2U3GWnJ1EtP4erjOzC8d0taZNeNeS0iIlWhQKlAdQXK/krLnFfz17Doy20UFO7g06WhGffTkpNolJnGhf3akNu+IT1bNyC7bmq11yciUpFoBkqtP4YSDclJxgX92nzzevGX25ha8BWF2/ey+Mtt/OXDpQBkpCVzQW4bzuvbmh6tsoMqV0QkJhQoMdCteX26Na//zesN2/ZQULiDV/LX8I/PVzJm6gpO6NyEG07sRL8OjUhN1uVAIpL4tMurmm3ZtY+X89bw2MQCtu4uJqtOCid2yeHs3q0Y0jWHFIWLiFQjHUOpQCIEytd27i1hcsFGPly0gQ8XFfLVzn00qZfOhf1a86MTO1G/jo61iEjsKVAqkEiBEqm4tIyJiwv5Z94aPly8gYYZaQzv3ZIL+7X51q4zEZFoU6BUIFEDJdL8tVt55MOlfLykiH0lZZx8ZDNu/t4R9G7TIOjSRKQGUqBUoCYEyte27NrHmKkreHbKCrbuLuaYtg247eQuDO6SE3RpIlKDKFAqUJMC5Ws79pbw0ozVPDd1Bas27WJE/zbcffqRZOkYi4hEQTQDRacUxbl66Slcc3wH3rt9MNef2ImXZqzm1D9P4uW81ZSUlgVdnojINxQoCaJOajJ3ndaNV284jkb10rjjlbmc8ehkZq7aHHRpIiKAAiXh9GnbkDduPp4nLz2GbbuLuWjUNKb+Z2PQZYmIxC5QzKyNmU00s0VmtsDMbi2nj5nZI2ZWYGZzzeyYiGVXmNnS8OOKWNWZiMyMYT1a8NaPT6B94wyufS6PFz5bQWlZzTkeJiKJJ5ZbKCXAT939SGAgcJOZdd+vz2lA5/BjJPBXADNrBNwLDAD6A/eaWcMY1pqQGmam8fdrBtCnbQN++a8F3D1+XtAliUgtFrNAcff17j4z/Hw7sAhotV+34cDzHjINaGBmLYBTgffdfZO7bwbeB4bFqtZE1rR+Hf5+zQBuGNKJl/JWM3rycmrSmXsikjiq5RiKmbUH+gCf77eoFbA64vWacFtF7eW990gzyzOzvKKiomiVnFDMjJ8N7cqJXXK4782FnP34FCYtKVKwiEi1inmgmFk94FXgNnfftv/iclbxA7R/t9F9lLvnuntuTk7tvegvOcl45opcfn9uTzbu2Mflo6dz+ejpLCvaEXRpIlJLxDRQzCyVUJj8w93Hl9NlDdAm4nVrYN0B2uUAUpKTuKBfGz762Yn86ozuzF69heGPT2H26i1BlyYitUAsz/Iy4Blgkbs/VEG314HLw2d7DQS2uvt64F1gqJk1DB+MHxpuk0pIT0nm6uM78PatJ9AwI43Lnv5cWyoiEnOx3EIZBFwGfM/MZocfp5vZ9WZ2fbjPv4FlQAHwFHAjgLtvAu4HZoQf94Xb5BC0bpjBuJEDSUk2bho7iz3FpUGXJCI1mObyqgUmLi7kqjEz6NGqPn86vzddm2cFXZKIxAnN5SWH5KRuTXny0r58uXUPwx+fzBtzdDhKRKJPgVJLDOvRnLdvHUyPltncMm4Wv3tnsa6sF5GoUqDUIjlZ6Yy9biAXD2jLXz/+D9c8N4Otu4uDLktEaggFSi2TlpLEb845mgfO7sHkpRs5+/EpFBRuD7osEakBFCi11KUD2zH2uoFs31PM8Mem8MK0lZRpF5iIVIECpRbr36ERr998PH3aNuSXr83nZy/P0U27ROSwKVBquZYN6vLCNf35ySldGD9rLT9+cRb7ShQqInLoUoIuQIJnZvz4+53JSEvmgbcWsac4n0dH9CEzXT8eIlJ52kKRb1x7QkceOLsHH39RyHlPfsbaLbuDLklEEogCRb7l0oHtGH1lP9Zs2sXwxyaTv1Iz3ohI5ShQ5DuGdG3KhJuOo156CiNGfc6r+WuCLklEEoACRcp1RNMsXrtpELntG/LTl+fwzxmrD76SiNRqChSpUIOMNJ69qh8ndG7CXePn8tbc9UGXJCJxTIEiB5SekszfLutL33YNue2lWUz8ojDokkQkTilQ5KAy0lJ45sp+dG2exfUv5DNt2VdBlyQicUiBIpVSv04qz13VnzaNMrhmzAymFGwMuiQRiTMKFKm0xvXSGXvtANo0yuCqZ2fw73k6piIi/6VAkUPStH4dXhp5LD1bZ3PT2JmM/XxV0CWJSJxQoMghy85I5YVrBnBS16bcPWEej08sCLokEYkDMQsUMxttZoVmNr+C5XeY2ezwY76ZlZpZo/CyFWY2L7xMN4mPQ3XTQmd/ndOnFX949wuembw86JJEJGCxnP1vDPAY8Hx5C939D8AfAMzsTOB2d4+c5+Mkd9eR3ziWmpzEH8/vxZ7iUu5/cyEN6qZybt/WQZclIgGJ2RaKu08CKjsR1AhgXKxqkdhJTjIevqg3xx/RhDtfncsHCzcEXZKIBCTwYyhmlgEMA16NaHbgPTPLN7ORB1l/pJnlmVleUVFRLEuVCnx98WOPlvW5aexMTSgpUksFHijAmcCU/XZ3DXL3Y4DTgJvMbHBFK7v7KHfPdffcnJycWNcqFchMT2H0lf1o2aAu1zyXR0HhjqBLEpFqFg+BchH77e5y93XhfwuBCUD/AOqSQ9S4XjrPXdWflKQkrhg9nQ3b9gRdkohUo0ADxcyygROBf0W0ZZpZ1tfPgaFAuWeKSfxp2ziDMVf1Y8uufVwxejrb9hQHXZKIVJNYnjY8DvgM6Gpma8zsGjO73syuj+h2DvCeu++MaGsGTDazOcB04C13fydWdUr09WiVzZOX9aWgcAcjn89jb0lp0CWJSDUwdw+6hqjJzc31vDxdthIvXpu1lttems0ZPVvw6Ig+mFnQJYnIfsws391zo/FesbwORWq5s/u04stte/jt24vp3DSLW0/uHHRJIhJDChSJqR8N7siSDdv58wdL6NKsHqcd3SLokkQkRuLhLC+pwcyM35xzNH3aNuAn/5zDgnVbgy5JRGJEgSIxVyc1dOFjg4xURj6fz8Yde4MuSURiQIEi1aJpVh2eujyXr3bu5foX8nXml0gNpECRatOjVTZ/PL8XeSs3c8+E+dSkMwxFRAflpZqd0bMlS77cziMfFdC1eRbXntAx6JJEJEq0hSLV7raTuzDsqOb85t+L+GSJJvQUqSkUKFLtkpKMhy7sRdfm9bl57Ez+U6SJJEVqAgWKBCIjLYWnLu9LWnIS1z6Xx9ZdmvNLJNEpUCQwrRtm8LfL+rJm8y5uHjeTktKyoEsSkSpQoEigcts34sGzj+bTpRt54K1FQZcjIlWgs7wkcBf0a8PiL7czespyjmpZn/Nz2wRdkogcBm2hSFy4+/RuHNuxMb/61wLd7VEkQSlQJC6kJCfx8EW9qZOaxC3jZrGnWFfSiyQaBYrEjWb16/DH83uxaP02fvv24qDLEZFDpECRuPL9I5tx1aD2jJm6gg8Wbgi6HBE5BAoUiTt3ndaN7i3qc8crc/hy656gyxGRSlKgSNxJT0nm0Yv7sLekjNtemkVpmSaRFEkEChSJS51y6vHrs45i2rJNPDGxIOhyRKQSYhYoZjbazArNbH4Fy4eY2VYzmx1+/Cpi2TAz+8LMCszsrljVKPHtvL6tGd67JQ9/uJS8FZuCLkdEDiKWWyhjgGEH6fOpu/cOP+4DMLNk4HHgNKA7MMLMusewTolTZsYDZ/egVYO63PribM33JRLnYhYo7j4JOJw/K/sDBe6+zN33AS8Cw6NanCSMrDqpPDKiDxu27eGu8XN1Uy6ROBb0MZRjzWyOmb1tZkeF21oBqyP6rAm3lcvMRppZnpnlFRXp3ho1Ue82Dbjj1K68Pf9L/pm3+uAriEggggyUmUA7d+8FPAq8Fm63cvpW+Gepu49y91x3z83JyYlBmRIPrjuhIwM7NuL+NxexdsvuoMsRkXIEFijuvs3dd4Sf/xtINbMmhLZIImcHbA2sC6BEiSNJScbvz+1FmTs/Hz9Pu75E4lBggWJmzc3Mws/7h2v5CpgBdDazDmaWBlwEvB5UnRI/2jbO4K7TujFpSREv560JuhwR2U/Mpq83s3HAEKCJma0B7gVSAdz9SeA84AYzKwF2Axd56M/OEjO7GXgXSAZGu/uCWNUpieXSAe14a+567n9zISd0aUKL7LpBlyQiYVaTdh3k5uZ6Xl5e0GVIjK38aifDHv6U/h0aMeaqfoQ3dEXkMJhZvrvnRuO9gj7LS+SQtWucyf8M68onS4p4OV+7vkTihQJFEtLlx7anf4dG3P/mQtZv1VlfIvFAgSIJKSnJ+MN5PSkuLeNunfUlEhcUKJKwQru+ujHxiyJenbk26HJEaj0FiiS0K45tT//2jfj1Gwt07xSRgClQJKElJRm//3rX1wTt+hIJkgJFEl77JpnceWo3PlpcyHjt+hIJjAJFaoQrj2tPv/YN+fUbC9iwTbu+RIKgQJEaIbTrqxf7dNaXSGAqFShm1snM0sPPh5jZj82sQWxLEzk0HZpkcsep3fhwcSETZmnXl0h1q+wWyqtAqZkdATwDdADGxqwqkcN05XHtyW3XkP99fQGF2vUlUq0qGyhl7l4CnAM87O63Ay1iV5bI4UkOn/W1t0RnfYlUt8oGSrGZjQCuAN4Mt6XGpiSRqumYU487Tu3KB4sK+dN7SxQqItWkstPXXwVcDzzo7svNrAPw99iVJVI1Vw3qwNINO3hsYgF7iku554zuQZckUuNVKlDcfSHwYwAzawhkuftvY1mYSFUkJxm/Pfdo0lOTeHrycnLbN2JYj+ZBlyVSo1X2LK+Pzay+mTUC5gDPmtlDsS1NpGrMjHt+0J2erbO585U5rN60K+iSRGq0yh5DyXb3bcAPgWfdvS9wcuzKEomOtJQkHh3RB3e4Zdws9pWUBV2SSI1V2UBJMbMWwAX896C8SEJo1ziT357bk9mrt3DB3z5j3RbdP0UkFiobKPcRusf7f9x9hpl1BJbGriyR6PpBzxY8cckxFBTu4OoxM9hTXBp0SSI1TqUCxd1fdvee7n5D+PUydz/3QOuY2WgzKzSz+RUsv8TM5oYfU82sV8SyFWY2z8xmm5luEi9RcfrRLXj04j4s/nI7v/n3oqDLEalxKntQvrWZTQgHxAYze9XMWh9ktTHAsAMsXw6c6O49gfuBUfstP8nde7t7bmVqFKmMk7o25drjO/D8Zyt5b8GXQZcjUqNUdpfXs8DrQEugFfBGuK1C7j4J2HSA5VPdfXP45TTgYAElEhV3DOtKj1b1ufPVuazV8RSRqKlsoOS4+7PuXhJ+jAFyoljHNcDbEa8deM/M8s1s5IFWNLORZpZnZnlFRUVRLElqqvSUZB4dcQylpc71L+TreIpIlFQ2UDaa2aVmlhx+XAp8FY0CzOwkQoHyPxHNg9z9GOA04CYzG1zR+u4+yt1z3T03JyeaGSc1WYcmmfz5wt7MW7uVW1+cRXGpTicWqarKBsrVhE4Z/hJYD5xHaDqWKjGznsDTwHB3/yag3H1d+N9CYALQv6qfJbK/k7s3494zu/Pugg3c9tJszfklUkWVPctrlbuf5e457t7U3c8mdJHjYTOztsB44DJ3XxLRnmlmWV8/B4YC5Z4pJlJVVw3qwF2ndeOtuet5ZvLyoMsRSWiVnRyyPD8BHq5ooZmNA4YATcxsDXAv4RmK3f1J4FdAY+AJMwMoCZ/R1QyYEG5LAca6+ztVqFPkgH40uCP5Kzfzu3cWc1TLbI7t1DjokkQSkh3uZr6ZrXb3NlGup0pyc3M9L0+Xrcih27qrmHOfnMqXW/fw4siB9GiVHXRJItXCzPKjdXlGVe4prx3OUmNkZ6TywjX9qV8nhZHP5/HVjr1BlySScA4YKGa23cy2lfPYTuiaFJEao0V2Xf52WS4bd+7juufzWL9V16iIHIoDBoq7Z7l7/XIeWe5eleMvInHp6NbZPHxhbxat386whz9lwbqtQZckkjCqsstLpEY6/egW/PvWE8hIS+a65/Io3L4n6JJEEoICRaQcHZpk8tTluWzeVczI53U1vUhlKFBEKtCjVTZ/vrAXs1dv4acvz6FEV9OLHJACReQAhvVowd2nhy58vGWcpmgRORAFishBjBzciV+e0Z2353/Jna/MpaxMZ8yLlEdnaolUwjXHd2BPcSl/ePcL0lOSePCco0lOsqDLEokrChSRSrpxSCf2FJfy6EcFbN9TwkMX9iI9JTnoskTihgJFpJLMjJ8O7Up23VQeeGsR2/YU87fL+pKRpv9GIqBjKCKH7NoTOvL783oypWAjlzz9OVt27Qu6JJG4oEAROQwX5LbhiUv6smDtNoWKSJgCReQwDevRnFGX92Vp4Q6FiggKFJEqGdK1KaMuU6iIgAJFpMqGdG3KU5fnsrRwBxc/9TmbdipUpHZSoIhEwYldcnjq8lwKinZw7l+nsvKrnUGXJFLtFCgiUXJilxzGXjuALbv2cc4TU8lfuTnokkSqlQJFJIpy2zdi/I2DqF8nhYufmsbb89YHXZJItYlpoJjZaDMrNLP5FSw3M3vEzArMbK6ZHROx7AozWxp+XBHLOkWiqUOTTMbfOIgerbK5cexMnpq0DHfN/yU1X6y3UMYAww6w/DSgc/gxEvgrgJk1Au4FBgD9gXvNrGFMKxWJokaZafzj2gGc3qMFD/57Eb/813xNfy81XkwDxd0nAZsO0GU48LyHTAMamFkL4FTgfXff5O6bgfc5cDCJxJ06qck8OqIPPxrckb9PW8XIF/LZsbck6LJEYiboYyitgNURr9eE2ypq/w4zG2lmeWaWV1RUFLNCRQ5HUpLx89OP5IGze/DJkiLOf/Iz1m3ZHXRZIjERdKCUN/+3H6D9u43uo9w9191zc3JyolqcSLRcOrAdz1yRy+pNuzj78SlMWlKk+6pIjRN0oKwB2kS8bg2sO0C7SMIa0rUpr95wHKnJSVw+ejon/elj5qzeEnRZIlETdKC8DlwePttrILDV3dcD7wJDzaxh+GD80HCbSELr2jyL938ymL9c1JuSUuf8Jz9j7OerdBaY1AgxvZGDmY0DhgBNzGwNoTO3UgHc/Ung38DpQAGwC7gqvGyTmd0PzAi/1X3ufqCD+yIJIyMtheG9WzG4cw63vjSbuyfMY+aqzTxwdg/qpOqGXZK4rCb9ZZSbm+t5eXlBlyFSaaVlziMfLuWRj5ZyZPP6PHlpX9o2zgi6LKlFzCzf3XOj8V5B7/ISqdWSk4zbT+nC6Cv6sXbLbs549FOembycPcWlQZcmcsgUKCJx4KRuTXnzluPp0Sqb+99cyFmPTWbFRk0wKYlFgSISJ9o0ymDsdQN59sp+FG7fy1mPTWbiF4VBlyVSaQoUkThzUremvHHz8bRqmMHVY2bwiwnz2Kx7rEgCUKCIxKE2jTIYf8NxXHlce16csZqT/vQxL07X6cUS3xQoInGqbloy9555FG/9+Hi6NMvirvHzuP7v+UxaUsTeEh20l/ijQBGJc92a1+fF6wZy9+ndmLi4iMtHT+eHT0xl/VbNCSbxRYEikgCSkoyRgzsx81en8JeLerPyq12c9dgUZq3SXSElfihQRBJIvfTQVfbjbzyOuqnJXDhqGs9MXq6JJiUuKFBEElCXZlm8dtMgBnduwv1vLuTa5/PYvqc46LKkllOgiCSoRplpPHV5LvcNP4pPlhRx7l+nsuqrXUGXJbWYAkUkgZkZlx/bnheu7s+GbXsZ/vhkpi37KuiypJZSoIjUAMcd0YTXbhpEw8w0Ln36cx75cCm79ul2w1K9FCgiNUSHJplMuHEQp3RvxkPvL+GUhyYxd41u4CXVR4EiUoNk103lr5f25aWRAwE476+f8fdpK3WFvVQLBYpIDTSgY2PevOV4ju3UmHtem88Dby1SqEjMxfSOjSISnIaZaTx7ZT/ue3Mhz0xezsYdezmjZ0u+360pSUkWdHlSAylQRGqwpCTj3jO7k5xk/OPzlfxr9jqO69SY353bkzaNdGdIiS7t8hKp4cyMX57Rnbn3nsqD5/RgzuotDHt4Ev/MWx10aVLDxDRQzGyYmX1hZgVmdlc5y/9sZrPDjyVmtiViWWnEstdjWadIbZCWksQlA9rx7u2D6dWmAXe+MpeH3vtCx1YkamK2y8vMkoHHgVOANcAMM3vd3Rd+3cfdb4/ofwvQJ+Itdrt771jVJ1JbtW6YwfNX9+fuCfN45KMCNmzby4Pn9CAlWTsspGpieQylP1Dg7ssAzOxFYDiwsIL+I4B7Y1iPiISlJCfxu3N70rx+HR75qICiHXt57OI+ZKTpsKocvlj+SdIKiNxJuybc9h1m1g7oAHwU0VzHzPLMbJqZnV3Rh5jZyHC/vKKiomjULVIrmBk/GdqVB87uwcdfFDL8sSl8skT/h+TwxTJQyjsvsaKdtRcBr7h75G3o2rp7LnAx8LCZdSpvRXcf5e657p6bk5NTtYpFaqFLB7Zj9JX92FdaxhWjp3Pls9NZu0U375JDF8tAWQO0iXjdGlhXQd+LgHGRDe6+LvzvMuBjvn18RUSiaEjXprx3+2Du+cGR5K3YzA+fmKJpW+SQxTJQZgCdzayDmaURCo3vnK1lZl2BhsBnEW0NzSw9/LwJMIiKj72ISBSkpyRz7QkdeeWGYwE467EpXDTqM/JWbAq4MkkUMQsUdy8BbgbeBRYB/3T3BWZ2n5mdFdF1BPCif/vcxSOBPDObA0wEfht5dpiIxE635vV559bB3HVaN5YV7eS8Jz/j5+PnsXtf6cFXllrNatI56Lm5uZ6Xlxd0GSI1xq59Jfzlg6X8bdIyWmbX4fZTunBe39aYaeqWmsLM8sPHq6tMJ56LSIUy0lL4+elH8uLIgTStX4c7XpnL3RPmU1xaFnRpEocUKCJyUAM7Nmb8Dcdx45BOjJu+iqvHzKBw+56gy5I4o6uYRKRSkpKMO4d1o32TTO4eP4/+D35I20YZXHtCB0b0b0uqrrSv9RQoInJILshtQ4+W2Uwp2Mjb89fzq38t4KUZq/nTBb3o1rx+0OVJgHRQXkQOm7vz7oIN3PPaPLbuLubW73dm5OBOpKVoayVR6KC8iMQFM2NYj+a8e9tghnZvzh/fW8Kwhyfx7JTlbN1VHHR5Us0UKCJSZY3rpfP4Jcfw7FX9qJuWzK/fWMj3H/qEt+au1/T4tYgCRUSi5qSuTXnrxyfw+s2DaNmgDjeNncl1z+ezYZvOCKsNFCgiEnU9Wzdg/A3H8YvTj2RyQRGnPPQJf5+2Utev1HAKFBGJiZTkJK4b3JG3bx1Mtxb1uee1+Qx7eBLTl2/SbrAaSmd5iUjMuTsfLirk3tcXsHbLbuqmJjPoiMacn9uG73VrqmtYAhTNs7x0HYqIxJyZcXL3Zgzs1JjXZq1lyYbtvDP/Sz5YVEiTemn8aHAnLju2HXVSk4MuVapAWygiEoiS0jImLS3i2Skr+HTpRto2yuDXZx3FMW0b8tSny0gy6Nwsiy7NsujQJFPXtsRINLdQFCgiErgpBRu557X5LN+4k/SUpG8O3peFfz2lJBln9GzB7ad0oV3jzG/Wc3eKduylaVadIMquERQoFVCgiCSufSVlvDpzDdOXb+Ka4ztwRNN6LCvaydLC7cxatYUXZ6zCHX42tCtXH9+B5CTjj+9+wWMTC+jfvhEXD2jLsB7NtdvsEClQKqBAEam5Nmzbwy8mzOeDRRvo07YBI/q35e7x8+jdpgFFO/ay8qtdNMhI5Yd9WnPDkE7kZKUHXXJCUKBUQIEiUrO5O6/PWcev31jIpp37aJCRykc/HUKDuqlM/c9XvDhjFe/M/5K0lCSuPaEj1xzfgey6qUGXHdcUKBVQoIjUDnuKS/n4iyJaNqhDz9YNvrVs+cad/PG9L3hr7npSkoxjOzXm7tOP5MgWmgm5PAqUCihQRORrC9Zt5a2563lxxmq27i7mB0e34KaTjqBr86ygS4srCTPbsJkNM7MvzIjQWjoAAAxPSURBVKzAzO4qZ/mVZlZkZrPDj2sjll1hZkvDjytiWaeI1DxHtczmzmHd+OinJ3L1oPZ8tLiQ0/4yibtencuc1Vt0tX4MxGwLxcySgSXAKcAaYAYwwt0XRvS5Esh195v3W7cRkAfkAg7kA33dffOBPlNbKCJSkS279vHn95cwbsZq9pWU0atNA648rh1DuzcnM732XuOdKFfK9wcK3H0ZgJm9CAwHFh5wrZBTgffdfVN43feBYcC4GNUqIjVcg4w0fj28Bz89tSv/mrWWpycv5/aX5pBVZwE/7NOKdVv3cGSL+vxocEcy01PYuruYOqlJpKfoNOTKimWgtAJWR7xeAwwop9+5ZjaY0NbM7e6+uoJ1W5X3IWY2EhgJ0LZt2yiULSI1Wf06qVx2bHsuGdCOGSs2MWbqCp6ftpKW2XV5f+EGnv9sBb1aN2BywUay6qRwZs+WnNy9Gccf0YTkJAu6/LgWy0Apb+T337/2BjDO3fea2fXAc8D3KrluqNF9FDAKQru8Dr9cEalNkpKMAR0bM6BjY/aVlJGWksTMVZsZM2UF+Ss3c9nAdhTt2MvL+at5YdpK2jSqyxXHtuf83DbfnIpcUlpGqbu2YsJiGShrgDYRr1sD6yI7uPtXES+fAn4Xse6Q/db9OOoViojAN/OEHdO2Ice0bfitZXuKS/locSFjpqzggbcW8dD7Szj3mNac0bMF9725kFWbdnF+3za0yK7DEU3r0adtAxpkpAXxNQIXy4PyKYR2Y30fWEvooPzF7r4gok8Ld18ffn4O8D/uPjB8UD4fOCbcdSahg/KbDvSZOigvIrE0f+1Wnp2ygjfmrGNfaRmZackM7NiYiV8UfjPvGEC35ln86MSOnNmzJSnJSbg7ZvG5uyxhrkMxs9OBh4FkYLS7P2hm9wF57v66mf0fcBZQAmwCbnD3xeF1rwbuDr/Vg+7+7ME+T4EiItVh4469vDZrLSd0zqFr8yxKSsvYua+UReu3kb9yM2/OXc+i9dtoXr8O2XVTWblpJ2f1akmnnHp0yqnHkK45pMTJPWASJlCqmwJFROJBWZnz4eJCxk1fxZ7iUppn1+GtuevZWxKaRbl5/ToM69Gciwe0pUuzYC+0VKBUQIEiIvGquLSMvSVlTF66kVdnrmHSkiL2lpRxRs8W3POD7jTPDmYK/kS5DkVERMJSk5NITU5iWI/mDOvRnM079zF6ynJGTVrGxMWF3HZyFwZ2bMzW3cUs27iDtVt2075xJk2z0slIS+GoVvWpXye+J7rUFoqISIBWfbWLe1+fz8Qvir7VnpxklJZ9+/dzxyaZdMypR6ecTE7skkNu+0ZVvpOldnlVQIEiIonI3Zm/dhvrt+6mXnoKHXPq0TQrndWbd7F1dzGbdu5j/tqtzF2zlVWbdrGsaCf7Ssuol55Cdt1U6qWn8O7tgw/rs7XLS0SkBjEzjm6dzdGts7/VHnm74yFdm37zfOfeEqYUbOSTJUXsLi4lp1583ExMgSIikmAy01MYelRzhh7VPOhSviU+ToQWEZGEp0AREZGoUKCIiEhUKFBERCQqFCgiIhIVChQREYkKBYqIiESFAkVERKKiRk29YmZFwEqgCbAxSm+bDWyNYv8DLS9v2f5th/I6muNQUX1V6VtRn8qMw/5tGofyX8fLOFSm/6GMQ3ntGoeDvy5vHNq5e87By64Ed69xD0I38IrWe42KZv8DLS9v2f5th/I6muNwqGNRmb4V9anMOJTzXTUOBxmXIMehMv0PZRwO9r01DtU/Du6uXV6V8EaU+x9oeXnL9m871NfRdCjvXZm+FfWpzDjs36ZxKP91vIxDZfofyjiU165xOPjrWI5Dzdrl9TUzy/MozZ6ZyDQOIRqHEI1DiMYhJBbjUFO3UEYFXUCc0DiEaBxCNA4hGoeQqI9DjdxCERGR6ldTt1BERKSaKVBERCQq4jpQzGy0mRWa2fzDWLevmc0zswIze8TMLNz+kpnNDj9WmNns6FceXbEYh/CyW8zsCzNbYGa/j27VsRGjn4n/NbO1ET8Xp0e/8uiK1c9EePnPzMzNrEn0Ko6NGP083G9mc8M/C++ZWcvoVx5dMRqHP5jZ4vBYTDCzBgd9s2ifhxzl87sHA8cA8w9j3enAsYABbwOnldPnT8Cvgv6eQYwDcBLwAZAeft006O8Z4Fj8L/CzoL9b0OMQXtYGeJfwBcJBf8+Afh7qR/T5MfBk0N8zoHEYCqSEn/8O+N3B3iuut1DcfRKwKbLNzDqZ2Ttmlm9mn5pZt/3XM7MWhH4oPvPQaDwPnL1fHwMuAMbF7htER4zG4Qbgt+6+N/wZhbH9FtERy5+JRBLDcfgzcCeQEGfrxGIc3H1bRNdMEmAsYjQO77l7SbjrNKD1weqI60CpwCjgFnfvC/wMeKKcPq2ANRGv14TbIp0AbHD3pTGpMvaqOg5dgBPM7HMz+8TM+sW02tiKxs/EzeFN+9Fm1jB2pcZUlcbBzM4C1rr7nFgXGmNV/nkwswfNbDVwCfCrGNYaS9H6XQlwNaGtlwNKOYwiA2Nm9YDjgJcjdvuml9e1nLb9/8oYQQJsnZQnSuOQAjQEBgL9gH+aWcfwXykJI0pj8Vfg/vDr+wntCr06upXGVlXHwcwygF8Q2s2RsKL1O8LdfwH8wsx+DtwM3BvlUmMqmr8rzewXQAnwj4N9bkIFCqEtqi3u3juy0cySgfzwy9cJ/YKI3DxrDayL6J8C/BDoG9NqYyca47AGGB8OkOlmVkZosriiWBYeA1UeC3ffELHeU8CbsSw4Rqo6Dp2ADsCc8C+g1sBMM+vv7l/GuPZoisrviAhjgbdIsEAher8rrwDOAL5fqT82gz6YVIkDRu2JONAETAXODz83oFcF680g9Nf31weaTo9YNgz4JOjvFuQ4ANcD94WfdwFWE77QNd4fMRiLFhF9bgdeDPo7BjEO+/VZQQIclI/Rz0PniD63AK8E/R0DGodhwEIgp9I1BD0IBxmgccB6oJjQX9TXEPor6h1gTvjLlnuWFpALzAf+AzwW+csSGANcH/T3C3IcgDTg7+FlM4HvBf09AxyLF4B5wFxCf7W1qK7vE0/jsF+fFSRAoMTo5+HVcPtcQpMptgr6ewY0DgWE/tCcHX4c9Gw3Tb0iIiJRkYhneYmISBxSoIiISFQoUEREJCoUKCIiEhUKFBERiQoFitRoZrajmj/vaTPrHqX3Kg3PeDvfzN442GyvZtbAzG6MxmeLHA6dNiw1mpntcPd6UXy/FP/vhHkxFVm7mT0HLHH3Bw/Qvz3wprv3qI76RPanLRSpdcwsx8xeNbMZ4cegcHt/M5tqZrPC/3YNt19pZi+b2RvAe2Y2xMw+NrNXwveL+EfEPSQ+NrPc8PMd4UkG55jZNDNrFm7vFH49w8zuq+RW1Gf8dxLHemb2oZnNtNB9LIaH+/wW6BTeqvlDuO8d4c+Za2a/juIwinyHAkVqo78Af3b3fsC5wNPh9sXAYHfvQ2iG2d9ErHMscIW7fy/8ug9wG9Ad6AgMKudzMoFp7t4LmARcF/H5fwl/fnnzR31LeP6l7xO6ih9gD3COux9D6L42fwoH2l3Af9y9t7vfYWZDgc5Af6A30NfMBh/s80QOV6JNDikSDScD3SNmYa1vZllANvCcmXUmNONqasQ677t75P0mprv7GgAL3fWzPTB5v8/Zx38nmswHTgk/P5b/3oNkLPDHCuqsG/He+cD74XYDfhMOhzJCWy7Nyll/aPgxK/y6HqGAmVTB54lUiQJFaqMk4Fh33x3ZaGaPAhPd/Zzw8YiPIxbv3O899kY8L6X8/0vF/t+DlBX1OZDd7t7bzLIJBdNNwCOE7tGRA/R192IzWwHUKWd9A/7P3f92iJ8rcli0y0tqo/cI3eMCADP7eorvbGBt+PmVMfz8aYR2tQFcdLDO7r6V0K1of2ZmqYTqLAyHyUlAu3DX7UBWxKrvAleH742BmbUys6ZR+g4i36FAkZouw8zWRDx+QuiXc274QPVCQlP5A/we+D8zmwIkx7Cm24CfmNl0oAWw9WAruPssQrPGXkToRke5ZpZHaGtlcbjPV8CU8GnGf3D39wjtUvvMzOYBr/DtwBGJKp02LFLNwndH3O3ubmYXASPcffjB1hOJdzqGIlL9+gKPhc/M2kKC3W5YpCLaQhERkajQMRQREYkKBYqIiESFAkVERKJCgSIiIlGhQBERkaj4f75GXmo+ZfPRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_find(learn, num_it=400)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.210704</td>\n",
       "      <td>0.203583</td>\n",
       "      <td>0.974005</td>\n",
       "      <td>0.556441</td>\n",
       "      <td>0.877445</td>\n",
       "      <td>0.564374</td>\n",
       "      <td>05:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204501</td>\n",
       "      <td>0.201876</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.540219</td>\n",
       "      <td>0.880200</td>\n",
       "      <td>0.571359</td>\n",
       "      <td>05:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217851</td>\n",
       "      <td>0.180933</td>\n",
       "      <td>0.977930</td>\n",
       "      <td>0.567265</td>\n",
       "      <td>0.885530</td>\n",
       "      <td>0.608430</td>\n",
       "      <td>05:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187363</td>\n",
       "      <td>0.181227</td>\n",
       "      <td>0.977313</td>\n",
       "      <td>0.566786</td>\n",
       "      <td>0.886843</td>\n",
       "      <td>0.615561</td>\n",
       "      <td>05:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186578</td>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.979720</td>\n",
       "      <td>0.630603</td>\n",
       "      <td>0.899377</td>\n",
       "      <td>0.649751</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193060</td>\n",
       "      <td>0.158909</td>\n",
       "      <td>0.980248</td>\n",
       "      <td>0.675486</td>\n",
       "      <td>0.909994</td>\n",
       "      <td>0.689128</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165434</td>\n",
       "      <td>0.161674</td>\n",
       "      <td>0.980629</td>\n",
       "      <td>0.688209</td>\n",
       "      <td>0.915096</td>\n",
       "      <td>0.705524</td>\n",
       "      <td>05:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.178435</td>\n",
       "      <td>0.159382</td>\n",
       "      <td>0.980107</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.903398</td>\n",
       "      <td>0.686789</td>\n",
       "      <td>05:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.163246</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>0.980304</td>\n",
       "      <td>0.688581</td>\n",
       "      <td>0.911034</td>\n",
       "      <td>0.694085</td>\n",
       "      <td>05:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.156271</td>\n",
       "      <td>0.148171</td>\n",
       "      <td>0.981584</td>\n",
       "      <td>0.715938</td>\n",
       "      <td>0.921352</td>\n",
       "      <td>0.725638</td>\n",
       "      <td>05:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.8774449229240417.\n",
      "Better model found at epoch 1 with dice_coefficient value: 0.8802003264427185.\n",
      "Better model found at epoch 2 with dice_coefficient value: 0.8855295181274414.\n",
      "Better model found at epoch 3 with dice_coefficient value: 0.8868431448936462.\n",
      "Better model found at epoch 4 with dice_coefficient value: 0.8993771076202393.\n",
      "Better model found at epoch 5 with dice_coefficient value: 0.9099943041801453.\n",
      "Better model found at epoch 6 with dice_coefficient value: 0.91509610414505.\n",
      "Better model found at epoch 9 with dice_coefficient value: 0.9213515520095825.\n"
     ]
    }
   ],
   "source": [
    "train_learner(learn, slice(lr), epochs=10, pct_start=0.8, best_model_name='bestmodel-frozen-1', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-frozen-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CombinedDiceLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "learn.export(file='/kaggle/model/export-1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/100,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.163928</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>0.981743</td>\n",
       "      <td>0.720051</td>\n",
       "      <td>0.919637</td>\n",
       "      <td>0.724050</td>\n",
       "      <td>05:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.158752</td>\n",
       "      <td>0.146669</td>\n",
       "      <td>0.981914</td>\n",
       "      <td>0.716869</td>\n",
       "      <td>0.922488</td>\n",
       "      <td>0.732964</td>\n",
       "      <td>05:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155523</td>\n",
       "      <td>0.148330</td>\n",
       "      <td>0.980853</td>\n",
       "      <td>0.741496</td>\n",
       "      <td>0.921275</td>\n",
       "      <td>0.725375</td>\n",
       "      <td>05:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165156</td>\n",
       "      <td>0.146465</td>\n",
       "      <td>0.981966</td>\n",
       "      <td>0.705554</td>\n",
       "      <td>0.915786</td>\n",
       "      <td>0.717604</td>\n",
       "      <td>05:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.149147</td>\n",
       "      <td>0.150821</td>\n",
       "      <td>0.980260</td>\n",
       "      <td>0.723218</td>\n",
       "      <td>0.918364</td>\n",
       "      <td>0.712595</td>\n",
       "      <td>05:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154772</td>\n",
       "      <td>0.148231</td>\n",
       "      <td>0.980182</td>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.923175</td>\n",
       "      <td>0.730273</td>\n",
       "      <td>05:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.158132</td>\n",
       "      <td>0.149820</td>\n",
       "      <td>0.981884</td>\n",
       "      <td>0.706415</td>\n",
       "      <td>0.917149</td>\n",
       "      <td>0.713693</td>\n",
       "      <td>05:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.151295</td>\n",
       "      <td>0.144460</td>\n",
       "      <td>0.982041</td>\n",
       "      <td>0.736426</td>\n",
       "      <td>0.927686</td>\n",
       "      <td>0.744796</td>\n",
       "      <td>05:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.140953</td>\n",
       "      <td>0.141040</td>\n",
       "      <td>0.982625</td>\n",
       "      <td>0.743231</td>\n",
       "      <td>0.922104</td>\n",
       "      <td>0.733332</td>\n",
       "      <td>05:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141663</td>\n",
       "      <td>0.137530</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.766649</td>\n",
       "      <td>0.928940</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>05:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.9196370244026184.\n",
      "Better model found at epoch 1 with dice_coefficient value: 0.9224876165390015.\n",
      "Better model found at epoch 5 with dice_coefficient value: 0.923175036907196.\n",
      "Better model found at epoch 7 with dice_coefficient value: 0.9276857972145081.\n",
      "Better model found at epoch 9 with dice_coefficient value: 0.9289398193359375.\n"
     ]
    }
   ],
   "source": [
    "train_learner(learn, lrs, epochs=10, pct_start=0.8, best_model_name='bestmodel-unfrozen-1', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_learner(bs=4, size=size, transform_func=get_simple_transforms, model_to_load='bestmodel-unfrozen-1'):\n",
    "    data = (src.transform(transform_func(), size=size, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "    learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "    learn.model_dir = Path('/kaggle/model')\n",
    "    learn.loss_func = CombinedDiceLoss(zero_cat_factor=0.5)\n",
    "#     learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([1.5, .5, .5, .5, .5]).cuda())\n",
    "#     learn = to_fp16(learn, loss_scale=8.0)\n",
    "    if model_to_load is not None:\n",
    "        learn.load(model_to_load)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_large_learner(bs=bs, size=src_size, transform_func=get_simple_transforms, model_to_load='bestmodel-unfrozen-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_find(learn, num_it=400)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1742' class='' max='2828', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      61.60% [1742/2828 08:37<05:22 0.1659]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_learner(learn, slice(lr), epochs=5, pct_start=0.8, best_model_name='bestmodel-frozen-3', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-frozen-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_large_learner(bs=bs, transform_func=get_extra_transforms, model_to_load='bestmodel-frozen-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/1000,lr/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_learner(learn, lrs, epochs=10, pct_start=0.8, best_model_name='bestmodel-4', \n",
    "              patience_early_stop=5, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!cp /kaggle/model/export.pkl /opt/fastai/fastai-exercises/nbs_gil\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'export-4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = (path/'test_images').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_learn = load_learner('/kaggle/model/', file='export-2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_learn = to_fp16(inference_learn, loss_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    pred_class, pred_idx, outputs = inference_learn.predict(open_image(str(img_path)))\n",
    "    return pred_class, pred_idx, outputs\n",
    "\n",
    "def encode_classes(pred_class_data):\n",
    "    pixels = np.concatenate([[0], torch.transpose(pred_class_data.squeeze(), 0, 1).flatten(), [0]])\n",
    "    classes_dict = {1: [], 2: [], 3: [], 4: []}\n",
    "    count = 0\n",
    "    previous = pixels[0]\n",
    "    for i, val in enumerate(pixels):\n",
    "        if val != previous:\n",
    "            if previous in classes_dict:\n",
    "                classes_dict[previous].append((i - count, count))\n",
    "            count = 0\n",
    "        previous = val\n",
    "        count += 1\n",
    "    return classes_dict\n",
    "\n",
    "\n",
    "def convert_classes_to_text(classes_dict, clazz):\n",
    "    return ' '.join([f'{v[0]} {v[1]}' for v in classes_dict[clazz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_to_predict = train_images[16].name\n",
    "display_image_with_mask(image_to_predict)\n",
    "pred_class, pred_idx, outputs = predict(path/f'train_images/{image_to_predict}')\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(pred_class.data.squeeze(), 0, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking encoding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_all = encode_classes(pred_class.data)\n",
    "print(convert_classes_to_text(encoded_all, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = train_images[16]\n",
    "print(get_y_fn(image_name))\n",
    "img = open_mask(get_y_fn(image_name))\n",
    "img_data = img.data\n",
    "print(convert_classes_to_text(encode_classes(img_data), 3))\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the test images and create submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "defect_classes = [1, 2, 3, 4]\n",
    "with open('submission.csv', 'w') as submission_file:\n",
    "    submission_file.write('ImageId_ClassId,EncodedPixels\\n')\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        pred_class, pred_idx, outputs = predict(test_image)\n",
    "        encoded_all = encode_classes(pred_class.data)\n",
    "        for defect_class in defect_classes:\n",
    "            submission_file.write(f'{test_image.name}_{defect_class},{convert_classes_to_text(encoded_all, defect_class)}\\n')\n",
    "        if i % 5 == 0:\n",
    "            print(f'Processed {i} images\\r', end='')\n",
    "            \n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative prediction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Test, with_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_data = preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((path/'test_images').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
