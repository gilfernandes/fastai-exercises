{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from fastai.vision import *\n",
    "from fastai import *\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv('/root/.fastai/data/severstal/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/root/.fastai/data/severstal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/root/.fastai/data/severstal/train_images.zip'),\n",
       " PosixPath('/root/.fastai/data/severstal/sample_submission.csv'),\n",
       " PosixPath('/root/.fastai/data/severstal/test_images.zip'),\n",
       " PosixPath('/root/.fastai/data/severstal/train.csv'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images'),\n",
       " PosixPath('/root/.fastai/data/severstal/test_images')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/root/.fastai/data/severstal/train_images/5e581254c.jpg'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images/fd2f7b4f4.jpg'),\n",
       " PosixPath('/root/.fastai/data/severstal/train_images/82f4c0b69.jpg')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = get_image_files(path/'train_images')\n",
    "train_images[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check maximum size of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img_max_size(folder):\n",
    "    max_height = 0\n",
    "    max_width = 0\n",
    "    for train_image in train_images:\n",
    "        img = open_image(train_image)\n",
    "        if max_height < img.shape[1]:\n",
    "            max_height = img.shape[1]\n",
    "        if max_width < img.shape[2]:\n",
    "            max_width = img.shape[2]\n",
    "    return max_height, max_width\n",
    "\n",
    "def show_image(images, index):\n",
    "    img_f = images[index]\n",
    "    print(type(img_f))\n",
    "    img = open_image(img_f)\n",
    "    print(img)\n",
    "    img.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = Path('/kaggle/mask')\n",
    "if not os.path.exists(mask_path):\n",
    "    os.makedirs(str(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_encoded_to_array(encoded_pixels):\n",
    "    pos_array = []\n",
    "    len_array = []\n",
    "    splits = encoded_pixels.split()\n",
    "    pos_array = [int(n) - 1 for i, n in enumerate(splits) if i % 2 == 0]\n",
    "    len_array = [int(n) for i, n in enumerate(splits) if i % 2 == 1]\n",
    "    return pos_array, len_array\n",
    "        \n",
    "def convert_to_pair(pos_array, rows):\n",
    "    return [(p % rows, p // rows) for p in pos_array]\n",
    "\n",
    "def create_positions(single_pos, size):\n",
    "    return [i for i in range(single_pos, single_pos + size)]\n",
    "\n",
    "def create_positions_pairs(single_pos, size, row_size):\n",
    "    return convert_to_pair(create_positions(single_pos, size), row_size)\n",
    "\n",
    "def convert_to_mask(encoded_pixels, row_size, col_size, category):\n",
    "    pos_array, len_array = convert_encoded_to_array(encoded_pixels)\n",
    "    mask = np.zeros([row_size, col_size])\n",
    "    for(p, l) in zip(pos_array, len_array):\n",
    "        for row, col in create_positions_pairs(p, l, row_size):\n",
    "            mask[row][col] = category\n",
    "    return mask\n",
    "\n",
    "def save_to_image(masked, image_name):\n",
    "    im = PIL.Image.fromarray(masked)\n",
    "    im = im.convert(\"L\")\n",
    "    image_name = re.sub(r'(.+)\\.jpg', r'\\1', image_name) + \".png\"\n",
    "    real_path = mask_path/image_name\n",
    "    im.save(real_path)\n",
    "    return real_path\n",
    "\n",
    "def open_single_image(path):\n",
    "    img = open_image(path)\n",
    "    img.show(figsize=(20,20))\n",
    "    \n",
    "def get_y_fn(x):\n",
    "    return mask_path/(x.stem + '.png')\n",
    "\n",
    "def group_by(train_images, train_pd):\n",
    "    tran_dict = {image.name:[] for image in train_images}\n",
    "    pattern = re.compile('(.+)_(\\d+)')\n",
    "    for index, image_path in train_pd.iterrows():\n",
    "        m = pattern.match(image_path['ImageId_ClassId'])\n",
    "        file_name = m.group(1)\n",
    "        category = m.group(2)\n",
    "        tran_dict[file_name].append((int(category), image_path['EncodedPixels']))\n",
    "    return tran_dict\n",
    "\n",
    "def display_image_with_mask(img_name):\n",
    "    full_image = path/'train_images'/img_name\n",
    "    print(full_image)\n",
    "    open_single_image(full_image)\n",
    "    mask_image = get_y_fn(full_image)\n",
    "    mask = open_mask(mask_image)\n",
    "    print(full_image)\n",
    "    mask.show(figsize=(20, 20), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_categories_mask = group_by(train_images, train_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mask files and save these to kaggle/mask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 256\n",
    "image_width = 1600\n",
    "if not os.path.exists(mask_path/'0002cc93b.png'):\n",
    "    for image_name, cat_list in grouped_categories_mask.items():\n",
    "        masked = np.zeros([image_height, image_width])\n",
    "        for cat_mask in cat_list:\n",
    "            encoded_pixels = cat_mask[1]\n",
    "            if pd.notna(cat_mask[1]):\n",
    "                masked += convert_to_mask(encoded_pixels, image_height, image_width, cat_mask[0])\n",
    "        if np.amax(masked) > 4:\n",
    "            print(f'Check {image_name} for max category {np.amax(masked)}')\n",
    "        save_to_image(masked, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limited_dihedral_affine(k:partial(uniform_int,0,3)):\n",
    "    \"Randomly flip `x` image based on `k`.\"\n",
    "    x = -1 if k&1 else 1\n",
    "    y = -1 if k&2 else 1\n",
    "    if k&4: return [[0, x, 0.],\n",
    "                    [y, 0, 0],\n",
    "                    [0, 0, 1.]]\n",
    "    return [[x, 0, 0.],\n",
    "            [0, y, 0],\n",
    "            [0, 0, 1.]]\n",
    "\n",
    "dihedral_affine = TfmAffine(limited_dihedral_affine)\n",
    "\n",
    "def get_extra_transforms(max_rotate:float=3., max_zoom:float=1.1,\n",
    "                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "    p_lightings = [p_lighting, p_lighting + 0.2, p_lighting + 0.4, p_lighting + 0.6, p_lighting + 0.7]\n",
    "    max_lightings = [max_lighting, max_lighting + 0.2, max_lighting + 0.4, max_lighting + 0.6, max_lighting + 0.7]\n",
    "    res = [rand_crop(), dihedral_affine(), \n",
    "           symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine),\n",
    "           rotate(degrees=(-max_rotate,max_rotate), p=p_affine),\n",
    "           rand_zoom(scale=(1., max_zoom), p=p_affine)]\n",
    "    res.extend([brightness(change=(0.5*(1-mp[0]), 0.5*(1+mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    res.extend([contrast(scale=(1-mp[0], 1/(1-mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    #       train                   , valid\n",
    "    return (res, [crop_pad()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (path/'train_images').ls()\n",
    "src_size = np.array(open_image(str(train_images[0])).shape[1:])\n",
    "valid_pct = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = array(['0', '1', '2', '3', '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (SegmentationItemList.from_folder(path/'train_images')\n",
    "       .split_by_rand_pct(valid_pct=valid_pct)\n",
    "       .label_from_func(get_y_fn, classes=codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = src_size//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.transform(get_extra_transforms(), size=size, tfm_y=True)\n",
    "        .add_test(ImageList.from_folder(path/'test_images'), tfms=None, tfm_y=False)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create learner and training\n",
    "Starting with low resolution training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['0']\n",
    "\n",
    "def acc_camvid(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    comparison = argmax[mask]==target[mask]\n",
    "    return torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "\n",
    "def acc_camvid_with_zero_check(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        if(torch.sum(argmax[b]).item() == 0.0 and torch.sum(target[b]).item() == 0.0):\n",
    "            total[b] = 1\n",
    "        else:\n",
    "            mask = target[b] != void_code\n",
    "            comparison = argmax[b][mask]==target[b][mask]\n",
    "            total[b] = torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def calc_dice_coefficients(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        if sum_seg + sum_gt == 0:\n",
    "            return torch.tensor(1.0)\n",
    "        return (torch.sum((seg[gt == cat] / cat).float()) * 2.0) / (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats)])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i] = calc_dice_coefficient(argmax, target, c)\n",
    "    return total_avg.mean()\n",
    "\n",
    "\n",
    "def dice_coefficient(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "def calc_dice_coefficients_2(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        return (torch.sum((seg[gt == cat] / cat).float())), (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats), 2])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i][0], total_avg[i][1] = calc_dice_coefficient(argmax, target, c)\n",
    "    total_sum = total_avg.sum(axis=0)\n",
    "    if (total_sum[1] == 0.0):\n",
    "        return torch.tensor(1.0)\n",
    "    return total_sum[0] * 2.0 / total_sum[1]\n",
    "\n",
    "\n",
    "def dice_coefficient_2(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients_2(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def accuracy_simple(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedCrossEntropyFlat():\n",
    "    \"Same as `func`, but flattens input and target.\"\n",
    "    def __init__(self):\n",
    "        self.func = nn.CrossEntropyLoss(weight=torch.tensor([2.0, .5, .5, .5, .5])).cuda()\n",
    "\n",
    "    def __repr__(self): return f\"CombinedCrossEntropyFlat\"\n",
    "    \n",
    "    def dice_loss(self, target, output, eps=1e-7):\n",
    "        \"\"\"Computes the Sørensen–Dice loss.\n",
    "        Note that PyTorch optimizers minimize a loss. In this\n",
    "        case, we would like to maximize the dice loss so we\n",
    "        return the negated dice loss.\n",
    "        Args:\n",
    "            target: a tensor of shape [B, 1, H, W].\n",
    "            output: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "                the raw output or logits of the model.\n",
    "            eps: added to the denominator for numerical stability.\n",
    "        Returns:\n",
    "            dice_loss: the Sørensen–Dice loss.\n",
    "        \"\"\"\n",
    "        # skip the batch and class axis for calculating Dice score\n",
    "        num_classes = output.shape[1]\n",
    "        y_true = F.one_hot(target.long().squeeze(), num_classes)\n",
    "        y_pred = F.softmax(output, dim=1).permute(0, 2, 3, 1)\n",
    "        y_true = y_true.type(y_pred.type())\n",
    "        axes = tuple(range(1, len(y_pred.shape)-1))\n",
    "        numerator = 2. * torch.sum(y_pred * y_true, axes)\n",
    "        denominator = torch.sum(y_pred ** 2 + y_true ** 2, axes)\n",
    "        # When intersection and cardinality are all zero you have 100% score and not 0% score\n",
    "#         mask_is_zero_on_both = ((numerator == 0).float() + (denominator < eps).float()) == 2.0\n",
    "#         numerator[mask_is_zero_on_both] = 1.0\n",
    "#         denominator[mask_is_zero_on_both] = 1.0 - eps\n",
    "\n",
    "        return 1 - torch.mean(numerator / (denominator + eps)) # average over classes and batch\n",
    "\n",
    "\n",
    "    def convert_max_to_one_hot(self, tensor1):\n",
    "        tensor1_shape = tensor1.shape\n",
    "        tensor1_input_view = tensor1.view(tensor1_shape[0], tensor1_shape[1], -1)\n",
    "        return (tensor1_input_view == tensor1_input_view.max(dim = 1, keepdim=True)[0]).float().view_as(tensor1)\n",
    "    \n",
    "    \n",
    "    def __call__(self, input:Tensor, target:Tensor)->Rank0Tensor:\n",
    "        input_changed = input.transpose(1,-1).contiguous()\n",
    "        target_changed = target.transpose(1,-1).contiguous()\n",
    "        input_changed = input_changed.view(-1, input_changed.shape[-1])\n",
    "        cel = self.func.__call__(input_changed, target_changed.view(-1))\n",
    "        dice_loss = self.dice_loss(target, input)\n",
    "#         print('cross entropy loss', cel, 'dice_loss', dice_loss)\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import callbacks\n",
    "\n",
    "def train_learner(learn, slice_lr, epochs=10, pct_start=0.8, best_model_name='best_model', \n",
    "                  patience_early_stop=4, patience_reduce_lr = 3):\n",
    "    learn.fit_one_cycle(epochs, slice_lr, pct_start=pct_start, \n",
    "                    callbacks=[callbacks.SaveModelCallback(learn, monitor='dice_coefficient',mode='max', name=best_model_name),\n",
    "                              callbacks.EarlyStoppingCallback(learn=learn, monitor='dice_coefficient', patience=patience_early_stop),\n",
    "                              callbacks.ReduceLROnPlateauCallback(learn=learn, monitor='dice_coefficient', patience=patience_reduce_lr),\n",
    "                              callbacks.TerminateOnNaNCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=accuracy_simple, acc_camvid_with_zero_check, dice_coefficient, dice_coefficient_2\n",
    "wd=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedCrossEntropyFlat"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "# learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([2.0, .5, .5, .5, .5]).cuda())\n",
    "learn.loss_func = CombinedCrossEntropyFlat()\n",
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model_dir = Path('/kaggle/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = to_fp16(learn, loss_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_find(learn, num_it=300)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='14', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      85.71% [12/14 45:04<07:30]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.778906</td>\n",
       "      <td>0.763741</td>\n",
       "      <td>0.948912</td>\n",
       "      <td>0.230178</td>\n",
       "      <td>0.821159</td>\n",
       "      <td>0.262918</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.768322</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>0.935306</td>\n",
       "      <td>0.285872</td>\n",
       "      <td>0.633809</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.758567</td>\n",
       "      <td>0.743721</td>\n",
       "      <td>0.940114</td>\n",
       "      <td>0.298753</td>\n",
       "      <td>0.500126</td>\n",
       "      <td>0.266945</td>\n",
       "      <td>03:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.759148</td>\n",
       "      <td>0.743757</td>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.308385</td>\n",
       "      <td>0.546037</td>\n",
       "      <td>0.292718</td>\n",
       "      <td>03:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.758287</td>\n",
       "      <td>0.742977</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>0.537163</td>\n",
       "      <td>0.337739</td>\n",
       "      <td>03:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.803659</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.803158</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.804130</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.803972</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.803872</td>\n",
       "      <td>0.804049</td>\n",
       "      <td>0.964023</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>0.854299</td>\n",
       "      <td>0.462580</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='314' class='' max='314', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [314/314 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.8211592435836792.\n",
      "Better model found at epoch 5 with dice_coefficient value: 0.8542993664741516.\n",
      "Epoch 11: reducing lr to 0.00016233583715952207\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_learner(learn, slice(lr), epochs=14, pct_start=0.8, best_model_name='bestmodel-frozen-1', \n",
    "              patience_early_stop=6, patience_reduce_lr = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-frozen-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/100,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.490994</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>0.968352</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>0.607110</td>\n",
       "      <td>0.165581</td>\n",
       "      <td>17:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.513807</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.539949</td>\n",
       "      <td>17:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.516624</td>\n",
       "      <td>0.873031</td>\n",
       "      <td>0.549959</td>\n",
       "      <td>17:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.039546</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.977222</td>\n",
       "      <td>0.543884</td>\n",
       "      <td>0.868581</td>\n",
       "      <td>0.571587</td>\n",
       "      <td>17:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>0.976414</td>\n",
       "      <td>0.552692</td>\n",
       "      <td>0.881641</td>\n",
       "      <td>0.588907</td>\n",
       "      <td>17:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033293</td>\n",
       "      <td>0.023206</td>\n",
       "      <td>0.978306</td>\n",
       "      <td>0.575209</td>\n",
       "      <td>0.887149</td>\n",
       "      <td>0.609152</td>\n",
       "      <td>17:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.6071099638938904.\n",
      "Better model found at epoch 1 with dice_coefficient value: 0.8627054691314697.\n",
      "Better model found at epoch 2 with dice_coefficient value: 0.873031497001648.\n",
      "Better model found at epoch 4 with dice_coefficient value: 0.8816407918930054.\n",
      "Better model found at epoch 5 with dice_coefficient value: 0.8871487379074097.\n"
     ]
    }
   ],
   "source": [
    "train_learner(learn, lrs, epochs=6, pct_start=0.8, best_model_name='bestmodel-unfrozen-1', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-unfrozen-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_learner(bs=4, transform_func=get_extra_transforms, model_to_load='bestmodel-unfrozen-1'):\n",
    "    src = (SegmentationItemList.from_folder(path/'train_images')\n",
    "       .split_by_rand_pct(valid_pct=valid_pct)\n",
    "       .label_from_func(get_y_fn, classes=codes))\n",
    "    data = (src.transform(transform_func(), size=src_size, tfm_y=True)\n",
    "        .add_test(ImageList.from_folder(path/'test_images'), tfms=None, tfm_y=False)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "    learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "    learn.model_dir = Path('/kaggle/model')\n",
    "    learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([2.0, .5, .5, .5, .5]).cuda())\n",
    "    learn = to_fp16(learn, loss_scale=4.0)\n",
    "    learn.load(model_to_load)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_large_learner(bs=bs, transform_func=get_extra_transforms, model_to_load='bestmodel-unfrozen-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_find(learn, num_it=400)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [6/8 5:40:11<1:53:23]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064356</td>\n",
       "      <td>0.063455</td>\n",
       "      <td>0.964433</td>\n",
       "      <td>0.452251</td>\n",
       "      <td>0.852917</td>\n",
       "      <td>0.452272</td>\n",
       "      <td>56:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.964429</td>\n",
       "      <td>0.468153</td>\n",
       "      <td>0.857882</td>\n",
       "      <td>0.468154</td>\n",
       "      <td>56:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.049120</td>\n",
       "      <td>0.058670</td>\n",
       "      <td>0.964438</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.453202</td>\n",
       "      <td>56:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048207</td>\n",
       "      <td>0.059026</td>\n",
       "      <td>0.964450</td>\n",
       "      <td>0.454092</td>\n",
       "      <td>0.854425</td>\n",
       "      <td>0.454323</td>\n",
       "      <td>56:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.063129</td>\n",
       "      <td>0.964466</td>\n",
       "      <td>0.458232</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.458589</td>\n",
       "      <td>56:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>0.964528</td>\n",
       "      <td>0.457419</td>\n",
       "      <td>0.854842</td>\n",
       "      <td>0.458380</td>\n",
       "      <td>56:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='628' class='' max='628', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [628/628 02:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.8529166579246521.\n",
      "Better model found at epoch 1 with dice_coefficient value: 0.8578823804855347.\n",
      "Epoch 5: reducing lr to 1.9815599641068586e-07\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_learner(learn, slice(lr), epochs=8, pct_start=0.8, best_model_name='bestmodel-frozen-3', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-frozen-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_large_learner(bs=bs, transform_func=get_extra_transforms, model_to_load='bestmodel-frozen-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/1000,lr/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      70.00% [7/10 6:50:22<2:55:52]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_simple</th>\n",
       "      <th>acc_camvid_with_zero_check</th>\n",
       "      <th>dice_coefficient</th>\n",
       "      <th>dice_coefficient_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>0.055464</td>\n",
       "      <td>0.968823</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.861067</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.057401</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>0.968823</td>\n",
       "      <td>0.480892</td>\n",
       "      <td>0.861465</td>\n",
       "      <td>0.480892</td>\n",
       "      <td>58:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043538</td>\n",
       "      <td>0.053718</td>\n",
       "      <td>0.968823</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.861266</td>\n",
       "      <td>0.480097</td>\n",
       "      <td>58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.053127</td>\n",
       "      <td>0.968823</td>\n",
       "      <td>0.478505</td>\n",
       "      <td>0.860869</td>\n",
       "      <td>0.478508</td>\n",
       "      <td>58:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052151</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>0.968823</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.861067</td>\n",
       "      <td>0.479301</td>\n",
       "      <td>58:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>0.051997</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.476124</td>\n",
       "      <td>0.860275</td>\n",
       "      <td>0.476133</td>\n",
       "      <td>58:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>0.053134</td>\n",
       "      <td>0.968827</td>\n",
       "      <td>0.469777</td>\n",
       "      <td>0.858694</td>\n",
       "      <td>0.469808</td>\n",
       "      <td>58:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='5656', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with dice_coefficient value: 0.861066997051239.\n",
      "Better model found at epoch 1 with dice_coefficient value: 0.8614651560783386.\n",
      "Epoch 5: reducing lr to 1.7188225099390853e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f4925f3b69b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_learner(learn, lrs, epochs=10, pct_start=0.8, best_model_name='bestmodel-4', \n\u001b[0;32m----> 2\u001b[0;31m               patience_early_stop=5, patience_reduce_lr = 3)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-f266707c06c5>\u001b[0m in \u001b[0;36mtrain_learner\u001b[0;34m(learn, slice_lr, epochs, pct_start, best_model_name, patience_early_stop, patience_reduce_lr)\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStoppingCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dice_coefficient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience_early_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateauCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dice_coefficient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience_reduce_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               callbacks.TerminateOnNaNCallback()])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/deeplearning/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_backward_begin\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;34m\"Handle gradient calculation on `loss`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoothener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_learner(learn, lrs, epochs=10, pct_start=0.8, best_model_name='bestmodel-4', \n",
    "              patience_early_stop=5, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!cp /kaggle/model/export.pkl /opt/fastai/fastai-exercises/nbs_gil\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'export-4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = (path/'test_images').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /kaggle/model/export-4.pkl /kaggle/model/export.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_learn = load_learner('/kaggle/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    pred_class, pred_idx, outputs = inference_learn.predict(open_image(str(img_path)))\n",
    "    return pred_class, pred_idx, outputs\n",
    "\n",
    "def encode_classes(pred_class_data):\n",
    "    pixels = np.concatenate([[0], torch.transpose(pred_class_data.squeeze(), 0, 1).flatten(), [0]])\n",
    "    classes_dict = {1: [], 2: [], 3: [], 4: []}\n",
    "    count = 0\n",
    "    previous = pixels[0]\n",
    "    for i, val in enumerate(pixels):\n",
    "        if val != previous:\n",
    "            if previous in classes_dict:\n",
    "                classes_dict[previous].append((i - count, count))\n",
    "            count = 0\n",
    "        previous = val\n",
    "        count += 1\n",
    "    return classes_dict\n",
    "\n",
    "\n",
    "def convert_classes_to_text(classes_dict, clazz):\n",
    "    return ' '.join([f'{v[0]} {v[1]}' for v in classes_dict[clazz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_to_predict = train_images[16].name\n",
    "display_image_with_mask(image_to_predict)\n",
    "pred_class, pred_idx, outputs = predict(path/f'train_images/{image_to_predict}')\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(pred_class.data.squeeze(), 0, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking encoding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_all = encode_classes(pred_class.data)\n",
    "print(convert_classes_to_text(encoded_all, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = train_images[16]\n",
    "print(get_y_fn(image_name))\n",
    "img = open_mask(get_y_fn(image_name))\n",
    "img_data = img.data\n",
    "print(convert_classes_to_text(encode_classes(img_data), 3))\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the test images and create submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "defect_classes = [1, 2, 3, 4]\n",
    "with open('submission.csv', 'w') as submission_file:\n",
    "    submission_file.write('ImageId_ClassId,EncodedPixels\\n')\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        pred_class, pred_idx, outputs = predict(test_image)\n",
    "        encoded_all = encode_classes(pred_class.data)\n",
    "        for defect_class in defect_classes:\n",
    "            submission_file.write(f'{test_image.name}_{defect_class},{convert_classes_to_text(encoded_all, defect_class)}\\n')\n",
    "        if i % 5 == 0:\n",
    "            print(f'Processed {i} images\\r', end='')\n",
    "            \n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative prediction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Test, with_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_data = preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((path/'test_images').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
