{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.tabular import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/kaggle/m5_forecasting/')\n",
    "assert(path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/kaggle/m5_forecasting/sales_train_validation.csv'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model_0.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model_1.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model_3.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_best_2.pth'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_best_1.pth'),\n",
       " PosixPath('/kaggle/m5_forecasting/walmartTrends0.csv'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model_2.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/calendar.csv'),\n",
       " PosixPath('/kaggle/m5_forecasting/sample_submission.csv'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_model_4.lgb'),\n",
       " PosixPath('/kaggle/m5_forecasting/m5_dt'),\n",
       " PosixPath('/kaggle/m5_forecasting/sell_prices.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n",
    "# CAL_DTYPES = {\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "#          \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "#         \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "CAL_DTYPES = {\"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv(path/\"sales_train_validation.csv\", nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    prices = pd.read_csv(path/\"sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "    cal = pd.read_csv(path/\"calendar.csv\", dtype = CAL_DTYPES)\n",
    "    walmart_trends = pd.read_csv(path/\"walmartTrends0.csv\")\n",
    "    return prices, cal, walmart_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices, cal, walmart_trends = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN      0.0      0.0      0.0  \n",
       "1          NaN          NaN          NaN      0.0      0.0      0.0  \n",
       "2          NaN          NaN          NaN      0.0      0.0      0.0  \n",
       "3          NaN          NaN          NaN      1.0      1.0      0.0  \n",
       "4          NaN          NaN          NaN      1.0      0.0      1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal[\"date\"] = pd.to_datetime(cal[\"date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2011-01-29 00:00:00'), Timestamp('2016-06-19 00:00:00'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal['date'].min(), cal['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk      1969 non-null   int16         \n",
      " 2   weekday       1969 non-null   category      \n",
      " 3   wday          1969 non-null   int16         \n",
      " 4   month         1969 non-null   int16         \n",
      " 5   year          1969 non-null   int16         \n",
      " 6   d             1969 non-null   object        \n",
      " 7   event_name_1  162 non-null    object        \n",
      " 8   event_type_1  162 non-null    category      \n",
      " 9   event_name_2  5 non-null      category      \n",
      " 10  event_type_2  5 non-null      category      \n",
      " 11  snap_CA       1969 non-null   float32       \n",
      " 12  snap_TX       1969 non-null   float32       \n",
      " 13  snap_WI       1969 non-null   float32       \n",
      "dtypes: category(4), datetime64[ns](1), float32(3), int16(4), object(2)\n",
      "memory usage: 93.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_map(field):\n",
    "    return {v: k for k, v in enumerate(cal[field].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1_map = create_event_map('event_name_1')\n",
    "cal.replace({'event_name_1': event_name_1_map}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed(dt, event_name='Christmas', col='event_name_1', event_map=event_name_1_map, before=False):\n",
    "    dt.sort_values(['date'], ascending=[(not before)], inplace=True)\n",
    "    day1 = np.timedelta64(1, 'D')\n",
    "    last_date = np.datetime64()\n",
    "    res = []\n",
    "    event = event_map[event_name]\n",
    "    for v,d in zip(dt[col].values, dt.date.values):\n",
    "        if v == event:\n",
    "            last_date = d\n",
    "        elapsed = ((d-last_date).astype('timedelta64[D]') / day1)\n",
    "        res.append(elapsed)\n",
    "    field_name = f\"{'before' if before else 'after'}_{event_name.lower().replace(' ', '_')}\"\n",
    "    dt[field_name] = res\n",
    "    dt[field_name] = dt[field_name].fillna(0)\n",
    "    dt[field_name] = dt[field_name].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_elapsed(cal, 'Christmas', 'event_name_1', event_name_1_map, False)\n",
    "# get_elapsed(cal, 'Easter', 'event_name_1', event_name_1_map, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df, type_map):\n",
    "    for col, col_dtype in type_map.items():\n",
    "        if col_dtype == \"category\":\n",
    "            df[col] = df[col].cat.codes.astype('int16')\n",
    "            df[col] -= df[col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalize(prices, PRICE_DTYPES)\n",
    "numericalize(cal, CAL_DTYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_type(df, cols, dt_type):\n",
    "    for type_name in cols:\n",
    "        print(type_name)\n",
    "        df[type_name] = df[type_name].astype(dt_type)\n",
    "\n",
    "def convert_uint8(df, cols):\n",
    "    convert_to_type(df, cols, \"uint8\")\n",
    "    \n",
    "def convert_float16(df, cols):\n",
    "    convert_to_type(df, cols, \"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "month\n",
      "wday\n",
      "weekday\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   date          1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk      1969 non-null   int16         \n",
      " 2   weekday       1969 non-null   uint8         \n",
      " 3   wday          1969 non-null   uint8         \n",
      " 4   month         1969 non-null   uint8         \n",
      " 5   year          1969 non-null   int16         \n",
      " 6   d             1969 non-null   object        \n",
      " 7   event_name_1  1969 non-null   uint8         \n",
      " 8   event_type_1  1969 non-null   uint8         \n",
      " 9   event_name_2  1969 non-null   uint8         \n",
      " 10  event_type_2  1969 non-null   uint8         \n",
      " 11  snap_CA       1969 non-null   uint8         \n",
      " 12  snap_TX       1969 non-null   uint8         \n",
      " 13  snap_WI       1969 non-null   uint8         \n",
      "dtypes: datetime64[ns](1), int16(2), object(1), uint8(10)\n",
      "memory usage: 57.8+ KB\n"
     ]
    }
   ],
   "source": [
    "uint8_types= ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'month', 'wday', 'weekday', \n",
    "              'snap_CA', 'snap_TX', 'snap_WI']\n",
    "convert_uint8(cal, uint8_types)\n",
    "cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lags 57\n"
     ]
    }
   ],
   "source": [
    "pred_days = 28\n",
    "max_lags = pred_days * 2 + 1\n",
    "print('max_lags', max_lags)\n",
    "num_cols = [c for c in pd.read_csv(path/\"sales_train_validation.csv\", nrows=2).columns if c.find('d_') == 0]\n",
    "tr_last = len(num_cols)\n",
    "catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "# For more training data use a lower value\n",
    "FIRST_DAY=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dt(is_train = True, nrows = None, first_day = 1200):\n",
    "    start_day = max(1 if is_train else tr_last - max_lags, first_day)\n",
    "    print('start_day', start_day)\n",
    "    dtype = {num: 'float32' for num in num_cols}\n",
    "    dtype.update({cat: 'category' for cat in catcols if cat != 'id'})\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    dt = pd.read_csv(path/\"sales_train_validation.csv\", nrows=nrows, usecols = catcols + numcols, dtype=dtype)\n",
    "    for col in catcols:\n",
    "        if col != 'id':\n",
    "            dt[col] = dt[col].cat.codes.astype('int16')\n",
    "            dt[col] -= dt[col].min()\n",
    "    if not is_train:\n",
    "        for day in range(tr_last + 1, tr_last + 1 + pred_days):\n",
    "            dt[f'd_{day}'] = np.nan\n",
    "            \n",
    "    dt = dt.melt(id_vars=catcols, value_vars=[col for col in dt.columns if col.startswith(\"d_\")], var_name='d', value_name='sales')\n",
    "    dt = dt.merge(cal, on='d', copy=False)\n",
    "    dt = dt.merge(prices, on=['store_id', 'item_id', 'wm_yr_wk'], copy=False)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_day 1\n",
      "CPU times: user 16.8 s, sys: 2.95 s, total: 19.7 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dt = read_dt(first_day=FIRST_DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46027957 entries, 0 to 46027956\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       uint8         \n",
      " 11  wday          uint8         \n",
      " 12  month         uint8         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  uint8         \n",
      " 15  event_type_1  uint8         \n",
      " 16  event_name_2  uint8         \n",
      " 17  event_type_2  uint8         \n",
      " 18  snap_CA       uint8         \n",
      " 19  snap_TX       uint8         \n",
      " 20  snap_WI       uint8         \n",
      " 21  sell_price    float32       \n",
      "dtypes: datetime64[ns](1), float32(2), int16(7), object(2), uint8(10)\n",
      "memory usage: 2.7+ GB\n"
     ]
    }
   ],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027952</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>3046</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027953</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>3047</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>11613</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027954</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>3047</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027955</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>3048</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>11613</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027956</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>3048</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46027957 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  item_id  dept_id  store_id  cat_id  \\\n",
       "0         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "1         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "2         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "3         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "4         HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "...                                 ...      ...      ...       ...     ...   \n",
       "46027952    FOODS_3_825_WI_3_validation     3046        6         9       2   \n",
       "46027953    FOODS_3_826_WI_3_validation     3047        6         9       2   \n",
       "46027954    FOODS_3_826_WI_3_validation     3047        6         9       2   \n",
       "46027955    FOODS_3_827_WI_3_validation     3048        6         9       2   \n",
       "46027956    FOODS_3_827_WI_3_validation     3048        6         9       2   \n",
       "\n",
       "          state_id       d  sales       date  wm_yr_wk  weekday  wday  month  \\\n",
       "0                0     d_1   12.0 2011-01-29     11101        2     1      1   \n",
       "1                0     d_2   15.0 2011-01-30     11101        3     2      1   \n",
       "2                0     d_3    0.0 2011-01-31     11101        1     3      1   \n",
       "3                0     d_4    0.0 2011-02-01     11101        5     4      2   \n",
       "4                0     d_5    0.0 2011-02-02     11101        6     5      2   \n",
       "...            ...     ...    ...        ...       ...      ...   ...    ...   \n",
       "46027952         2  d_1913    0.0 2016-04-24     11613        3     2      4   \n",
       "46027953         2  d_1912    1.0 2016-04-23     11613        2     1      4   \n",
       "46027954         2  d_1913    3.0 2016-04-24     11613        3     2      4   \n",
       "46027955         2  d_1912    0.0 2016-04-23     11613        2     1      4   \n",
       "46027956         2  d_1913    0.0 2016-04-24     11613        3     2      4   \n",
       "\n",
       "          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "0         2011             0             0             0             0   \n",
       "1         2011             0             0             0             0   \n",
       "2         2011             0             0             0             0   \n",
       "3         2011             0             0             0             0   \n",
       "4         2011             0             0             0             0   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "46027952  2016             0             0             0             0   \n",
       "46027953  2016             0             0             0             0   \n",
       "46027954  2016             0             0             0             0   \n",
       "46027955  2016             0             0             0             0   \n",
       "46027956  2016             0             0             0             0   \n",
       "\n",
       "          snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0               0        0        0        0.46  \n",
       "1               0        0        0        0.46  \n",
       "2               0        0        0        0.46  \n",
       "3               1        1        0        0.46  \n",
       "4               1        0        1        0.46  \n",
       "...           ...      ...      ...         ...  \n",
       "46027952        0        0        0        3.98  \n",
       "46027953        0        0        0        1.28  \n",
       "46027954        0        0        0        1.28  \n",
       "46027955        0        0        0        1.00  \n",
       "46027956        0        0        0        1.00  \n",
       "\n",
       "[46027957 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2011-01-29 00:00:00'), Timestamp('2016-04-24 00:00:00'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.date.min(), dt.date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_boolean_attrs(df):\n",
    "    boolean_attrs = ['Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', \n",
    "             'Is_year_start']\n",
    "    for ba in boolean_attrs:\n",
    "        df[ba] = getattr(df['date'].dt, ba.lower()).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_day_of_year(df):\n",
    "    day_of_year = 'Dayofyear'\n",
    "    df[day_of_year] = getattr(df['date'].dt, day_of_year.lower()).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "        \n",
    "    simple_lags = [1]\n",
    "    for simple_lag in simple_lags:\n",
    "        dt[f'lag_{simple_lag}'] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(simple_lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "    \n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "            \n",
    "    prepare_date_boolean_attrs(dt)\n",
    "    prepare_day_of_year(dt)\n",
    "    \n",
    "    uint8_types= ['month', 'wday', 'quarter', 'mday', 'week']\n",
    "    convert_uint8(dt, uint8_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_name_1\n",
      "event_type_1\n",
      "event_name_2\n",
      "event_type_2\n",
      "month\n",
      "wday\n",
      "weekday\n",
      "snap_CA\n",
      "snap_TX\n",
      "snap_WI\n",
      "CPU times: user 2min 1s, sys: 6.65 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_fea(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44351007 entries, 617364 to 46027956\n",
      "Data columns (total 39 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           int16         \n",
      " 3   store_id          int16         \n",
      " 4   cat_id            int16         \n",
      " 5   state_id          int16         \n",
      " 6   d                 object        \n",
      " 7   sales             float32       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              int16         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  sell_price        float32       \n",
      " 22  lag_7             float32       \n",
      " 23  lag_28            float32       \n",
      " 24  lag_1             float32       \n",
      " 25  rmean_7_7         float32       \n",
      " 26  rmean_28_7        float32       \n",
      " 27  rmean_7_28        float32       \n",
      " 28  rmean_28_28       float32       \n",
      " 29  week              int16         \n",
      " 30  quarter           int16         \n",
      " 31  mday              int16         \n",
      " 32  Is_month_end      uint8         \n",
      " 33  Is_month_start    uint8         \n",
      " 34  Is_quarter_end    uint8         \n",
      " 35  Is_quarter_start  uint8         \n",
      " 36  Is_year_end       uint8         \n",
      " 37  Is_year_start     uint8         \n",
      " 38  Dayofyear         uint16        \n",
      "dtypes: datetime64[ns](1), float32(9), int16(10), object(2), uint16(1), uint8(16)\n",
      "memory usage: 4.4+ GB\n"
     ]
    }
   ],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_7', 'lag_28',\n",
       "       'lag_1', 'rmean_7_7', 'rmean_28_7', 'rmean_7_28', 'rmean_28_28', 'week',\n",
       "       'quarter', 'mday', 'Is_month_end', 'Is_month_start', 'Is_quarter_end',\n",
       "       'Is_quarter_start', 'Is_year_end', 'Is_year_start', 'Dayofyear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.to_pickle(path/'m5_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2G\t/kaggle/m5_forecasting/m5_dt\r\n"
     ]
    }
   ],
   "source": [
    "!du -h {path/'m5_dt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', 'event_name_1', \n",
    "             'event_type_1', 'event_name_2', 'event_type_2']\n",
    "ignore_cols = ['id', 'date', 'sales', 'd', 'wm_yr_wk', 'weekday']\n",
    "train_cols = [c for c in dt.columns if c not in ignore_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = int(dt.shape[0] * 0.1)\n",
    "np.random.seed(777)\n",
    "\n",
    "valid_idx = np.random.choice(dt.index.values, valid_size, replace=False)\n",
    "train_idx = np.setdiff1d(dt.index.values, valid_idx)\n",
    "assert valid_idx.size + train_idx.size == dt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = torch.tensor(x.values, dtype=torch.float32), torch.tensor(y.values, dtype=torch.float32)\n",
    "        assert(len(self.x) == len(self.y))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'x: {self.x.shape} y: {self.y.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dt[train_cols].loc[train_idx]\n",
    "train_y = dt['sales'].loc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ArrayDataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_x, train_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_pickle(path/'m5_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = dt[train_cols].loc[valid_idx]\n",
    "valid_y = dt['sales'].loc[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = ArrayDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dt, valid_x, valid_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0770e+03, 5.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         3.1600e+02],\n",
       "        [1.3080e+03, 3.0000e+00, 3.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.7000e+02],\n",
       "        [2.0300e+03, 3.0000e+00, 4.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         2.3900e+02],\n",
       "        ...,\n",
       "        [4.6700e+02, 1.0000e+00, 9.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         2.3100e+02],\n",
       "        [1.7490e+03, 4.0000e+00, 3.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         9.2000e+01],\n",
       "        [3.0150e+03, 6.0000e+00, 4.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         1.7000e+01]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 2048\n",
    "data = DataBunch.create(train_ds, valid_ds, bs=bs, num_workers=11)\n",
    "data.one_batch()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composed_layer(nh, nh2, is_last=False):\n",
    "    if is_last:\n",
    "        return nn.Linear(nh, nh2), nn.ReLU(), nn.BatchNorm1d(nh2, momentum=0.1)\n",
    "    return nn.Linear(nh, nh2), nn.ReLU(), nn.BatchNorm1d(nh2, momentum=0.1), nn.Dropout(p=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = train_ds.x.shape[1]\n",
    "nh = 100\n",
    "nh2 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=33, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.001, inplace=False)\n",
       "  (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.001, inplace=False)\n",
       "  (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(*create_composed_layer(ni, nh), *create_composed_layer(nh, nh2), *create_composed_layer(nh2, 1, is_last=True))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5 # mse\n",
    "# lr = 1e-4 # mae\n",
    "# lr = 1e-3 # mape\n",
    "# lr = 1e-7 # mqe\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar.csv   m5_model_0.lgb  m5_model_4.lgb\t\t   sell_prices.csv\r\n",
      "m5_best_1.pth  m5_model_1.lgb  m5_model.lgb\t\t   walmartTrends0.csv\r\n",
      "m5_best_2.pth  m5_model_2.lgb  sales_train_validation.csv\r\n",
      "m5_dt\t       m5_model_3.lgb  sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {path}\n",
    "!rm {path/'m5_best_1.pth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_pointwise_loss',\n",
       " '_smooth_l1_loss',\n",
       " 'cosine_embedding_loss',\n",
       " 'ctc_loss',\n",
       " 'hinge_embedding_loss',\n",
       " 'l1_loss',\n",
       " 'margin_ranking_loss',\n",
       " 'mse_loss',\n",
       " 'multi_margin_loss',\n",
       " 'multilabel_margin_loss',\n",
       " 'multilabel_soft_margin_loss',\n",
       " 'nll_loss',\n",
       " 'poisson_nll_loss',\n",
       " 'smooth_l1_loss',\n",
       " 'soft_margin_loss',\n",
       " 'triplet_margin_loss']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in dir(F) if f.find('loss') > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn([10, 10]).contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return F.mse_loss(pred, targ)\n",
    "\n",
    "def mqe_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean((pred - targ) ** 4)\n",
    "\n",
    "def mae_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean(torch.abs(pred - targ))\n",
    "\n",
    "def mape_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean(torch.abs((targ - pred) / (targ + 1e-5)))\n",
    "\n",
    "def poisson_loss(pred, targ):\n",
    "    \"\"\"Custom loss function for Poisson model.\"\"\"\n",
    "    pred, targ = flatten_check(pred, targ)\n",
    "    return F.poisson_nll_loss(pred, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??flatten_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data=data, model=model, model_dir = path, metrics=[rmse], loss_func=mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.870758</td>\n",
       "      <td>12.984248</td>\n",
       "      <td>3.547443</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.131829</td>\n",
       "      <td>9.418804</td>\n",
       "      <td>3.008631</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.389310</td>\n",
       "      <td>6.562395</td>\n",
       "      <td>2.502014</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.306353</td>\n",
       "      <td>5.738266</td>\n",
       "      <td>2.340715</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.977338</td>\n",
       "      <td>5.343266</td>\n",
       "      <td>2.258778</td>\n",
       "      <td>01:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.726808</td>\n",
       "      <td>5.371672</td>\n",
       "      <td>2.264397</td>\n",
       "      <td>01:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.724778</td>\n",
       "      <td>5.314131</td>\n",
       "      <td>2.252314</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.769021</td>\n",
       "      <td>5.300624</td>\n",
       "      <td>2.249187</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.542991</td>\n",
       "      <td>5.286193</td>\n",
       "      <td>2.247263</td>\n",
       "      <td>01:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5.913835</td>\n",
       "      <td>5.279285</td>\n",
       "      <td>2.244982</td>\n",
       "      <td>01:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with root_mean_squared_error value: 3.547442674636841.\n",
      "Better model found at epoch 1 with root_mean_squared_error value: 3.008631467819214.\n",
      "Better model found at epoch 2 with root_mean_squared_error value: 2.502014398574829.\n",
      "Better model found at epoch 3 with root_mean_squared_error value: 2.340714931488037.\n",
      "Better model found at epoch 4 with root_mean_squared_error value: 2.258777618408203.\n",
      "Better model found at epoch 6 with root_mean_squared_error value: 2.252314329147339.\n",
      "Better model found at epoch 7 with root_mean_squared_error value: 2.2491865158081055.\n",
      "Better model found at epoch 8 with root_mean_squared_error value: 2.247262716293335.\n",
      "Better model found at epoch 9 with root_mean_squared_error value: 2.2449824810028076.\n",
      "CPU times: user 16min 24s, sys: 1min 35s, total: 17min 59s\n",
      "Wall time: 17min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.fit_one_cycle(10, lr, callbacks=[callbacks.EarlyStoppingCallback(learn, monitor=\"root_mean_squared_error\", \n",
    "                                                                       mode=\"min\", patience=30),\n",
    "                                     callbacks.SaveModelCallback(learn, monitor='root_mean_squared_error',mode='min', \n",
    "                                                                 name='m5_best_1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = 1e-5\n",
    "lr = 5e-5\n",
    "learn.fit_one_cycle(3, lr, callbacks=[callbacks.EarlyStoppingCallback(learn, monitor=\"root_mean_squared_error\", \n",
    "                                                                       mode=\"min\", patience=30),\n",
    "                                     callbacks.SaveModelCallback(learn, monitor='root_mean_squared_error',mode='min', \n",
    "                                                                 name='m5_best_2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(file = str(path/'m5_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb = lgb.Booster(model_file=str(path/'m5_model.lgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1 / len(alphas)] * len(alphas)\n",
    "assert sum(weights) == 1.0\n",
    "fday = datetime(2016, 4, 25) \n",
    "assert datetime(2011, 1, 29) + timedelta(days=1914 - 1) == fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'F{i}' for i in range(1, pred_days + 1)]\n",
    "sub = pd.DataFrame()\n",
    "te = read_dt(False)\n",
    "\n",
    "for icount, (alpha, weight) in tqdm(enumerate(zip(alphas, weights)), total=len(alphas)):\n",
    "    for tdelta in tqdm(range(0, pred_days), total=pred_days):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "        create_features(tst)\n",
    "        prepare_date_cols(tst)\n",
    "        tst = tst.loc[tst.date == day, train_cols]\n",
    "        te.loc[te.date == day, 'sales'] = alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n",
    "    \n",
    "    te_sub = te.loc[te.date >= fday, ['id', 'sales']].copy()\n",
    "    te_sub['F'] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()['sales'][cols]\n",
    "    te_sub.fillna(0., inplace=True)\n",
    "    te_sub.sort_values([\"id\"], inplace=True)\n",
    "    te_sub.reset_index(drop=False, inplace = True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "    \n",
    "    if icount == 0:\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols] * weight\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
