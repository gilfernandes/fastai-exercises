{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts import m5_common\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Union\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/kaggle/m5_forecasting/')\n",
    "assert(path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 25, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 28 \n",
    "tr_last = 1913\n",
    "fday = datetime(2016, 4, 25) \n",
    "fday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to MLflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 5000\n",
    "# server in /opt/mlflow_server/start.sh\n",
    "remote_server_uri = \"http://localhost:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('M5_Public')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 180 ms, total: 1.58 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prices, cal = m5_common.prepare_tables(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(path/'weather/weather_2010_2020.csv')\n",
    "weather_df[\"date\"] = pd.to_datetime(weather_df[\"Date\"])\n",
    "del weather_df[\"Date\"]\n",
    "del weather_df[\"Anomaly\"]\n",
    "weather_df['Value'] = weather_df['Value'].astype('float16')\n",
    "weather_df.columns = ['temperature',  'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3257 entries, 0 to 3256\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   temperature  3257 non-null   float16       \n",
      " 1   date         3257 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float16(1)\n",
      "memory usage: 31.9 KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# cal = cal.merge(weather_df, on=['date'], copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1_map, event_type_1_map = m5_common.replace_cal_cols(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>11149</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>11149</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11149</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  wm_yr_wk  weekday  wday  month  year      d  event_name_1  \\\n",
       "338 2012-01-02     11149        1     3      1  2012  d_339             0   \n",
       "339 2012-01-03     11149        5     4      1  2012  d_340             0   \n",
       "340 2012-01-04     11149        6     5      1  2012  d_341             0   \n",
       "\n",
       "     event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "338             0             0             0      1.0      0.0      1.0  \n",
       "339             0             0             0      1.0      1.0      1.0  \n",
       "340             0             0             0      1.0      0.0      0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal[(cal.date > '2012-01-01') & (cal.date < '2012-01-05')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_types= ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'month', 'wday', 'weekday', \n",
    "              'snap_CA', 'snap_TX', 'snap_WI']\n",
    "m5_common.convert_uint8(cal, uint8_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed(dt, event_name='Christmas', col='event_name_1', event_map=event_name_1_map, before=False):\n",
    "    dt.sort_values(['date'], ascending=[(not before)], inplace=True)\n",
    "    day1 = np.timedelta64(1, 'D')\n",
    "    last_date = np.datetime64()\n",
    "    res = []\n",
    "    event = event_map[event_name]\n",
    "    for v,d in zip(dt[col].values, dt.date.values):\n",
    "        if v == event:\n",
    "            last_date = d\n",
    "        elapsed = ((d-last_date).astype('timedelta64[D]') / day1)\n",
    "        res.append(elapsed)\n",
    "    field_name = f\"{'before' if before else 'after'}_{event_name.lower().replace(' ', '_')}\"\n",
    "    dt[field_name] = res\n",
    "    dt[field_name] = dt[field_name].fillna(0)\n",
    "    dt[field_name] = dt[field_name].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ellapsed_fields = ['Christmas', 'Easter', 'Ramadan starts']\n",
    "# for f in ellapsed_fields:\n",
    "#     get_elapsed(cal, f, 'event_name_1', event_name_1_map, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_over_period(dt, period='weekday'):\n",
    "    df_sales_id_period = dt[['id', 'sales', period]].groupby(['id', period])[['sales']].mean().reset_index()\n",
    "    df_sales_id_period['sales'] = df_sales_id_period['sales'].astype('float16')\n",
    "    df_sales_id_period.rename(columns={'sales': f'sales_by_{period}'}, inplace=True)\n",
    "    return dt.merge(df_sales_id_period, on=['id', period], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_year = 'Dayofyear'\n",
    "\n",
    "def prepare_day_of_year(df):\n",
    "    df[day_of_year] = getattr(df['date'].dt, day_of_year.lower()).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_before(dt, day=25, month=12, col_name='before_christmas'):\n",
    "    diff_list = []\n",
    "    for d in dt['date']:\n",
    "        target = datetime(d.year, month, day)\n",
    "        diff = (target - d.to_pydatetime()).days\n",
    "        if(diff < 0):\n",
    "            christmas = datetime(d.year + 1, month, day)\n",
    "            diff = (christmas - d.to_pydatetime()).days\n",
    "            if diff < 0:\n",
    "                print('target', target, d, diff)\n",
    "        diff_list.append(diff)\n",
    "    dt[col_name] = diff_list\n",
    "    dt[col_name] = dt[col_name].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_days_before(cal)\n",
    "# add_days_before(cal, day=31, month=10, col_name='before_halloween')\n",
    "# add_days_before(cal, day=4, month=7, col_name='before_independence_day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_in_week(event_field='event_name_1', cal_field_name='events_in_week'):\n",
    "    events_in_week = []\n",
    "    no_monday_yet = True\n",
    "    for i, row in cal.iterrows():\n",
    "        if row['date'].weekday() == 0: # Monday\n",
    "            no_monday_yet = False\n",
    "            counter = 0\n",
    "            for j in range(7):\n",
    "                data = cal.loc[i + j]\n",
    "                if data[event_field] > 0:\n",
    "                    counter += 1\n",
    "            for j in range(7):\n",
    "                events_in_week.append(counter)\n",
    "        if no_monday_yet:\n",
    "            events_in_week.append(0)\n",
    "    assert(len(events_in_week) == len(cal))\n",
    "    cal[cal_field_name] = events_in_week\n",
    "    cal[cal_field_name] = cal[cal_field_name].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_in_week('event_name_1', 'events1_in_week')\n",
    "# cal['events1_in_week_before_7'] = cal['events1_in_week'].shift(7, fill_value=0).astype('uint8')\n",
    "# cal['events1_in_week_after_7'] = cal['events1_in_week'].shift(-7, fill_value=0).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "easter_western = {2011: datetime(2011, 4, 24), 2012: datetime(2012, 4, 8), 2013: datetime(2013, 3, 31)\n",
    " , 2014: datetime(2014, 4, 20), 2015: datetime(2015, 4, 5), 2016: datetime(2016, 4, 27), 2017: datetime(2017, 4, 16)}\n",
    "\n",
    "def add_days_before_special_date(dt, date_dict=easter_western, col_name='before_easter'):\n",
    "    diff_list = []\n",
    "    for d in cal['date']:\n",
    "        year = d.year\n",
    "        target = date_dict[year]\n",
    "        diff = (target - d.to_pydatetime()).days\n",
    "        if(diff < 0):\n",
    "            target = date_dict[year + 1]\n",
    "            diff = (target - d.to_pydatetime()).days\n",
    "        diff_list.append(diff)\n",
    "    dt[col_name] = diff_list\n",
    "    dt[col_name] = dt[col_name].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_days_before_special_date(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk          1969 non-null   int16         \n",
      " 2   weekday           1969 non-null   uint8         \n",
      " 3   wday              1969 non-null   uint8         \n",
      " 4   month             1969 non-null   uint8         \n",
      " 5   year              1969 non-null   int16         \n",
      " 6   d                 1969 non-null   object        \n",
      " 7   event_name_1      1969 non-null   uint8         \n",
      " 8   event_type_1      1969 non-null   uint8         \n",
      " 9   event_name_2      1969 non-null   uint8         \n",
      " 10  event_type_2      1969 non-null   uint8         \n",
      " 11  snap_CA           1969 non-null   uint8         \n",
      " 12  snap_TX           1969 non-null   uint8         \n",
      " 13  snap_WI           1969 non-null   uint8         \n",
      " 14  before_christmas  1969 non-null   uint16        \n",
      "dtypes: datetime64[ns](1), int16(2), object(1), uint16(1), uint8(10)\n",
      "memory usage: 61.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>11620</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>11620</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>11620</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1969 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  wm_yr_wk  weekday  wday  month  year       d  event_name_1  \\\n",
       "0    2011-01-29     11101        2     1      1  2011     d_1             0   \n",
       "1    2011-01-30     11101        3     2      1  2011     d_2             0   \n",
       "2    2011-01-31     11101        1     3      1  2011     d_3             0   \n",
       "3    2011-02-01     11101        5     4      2  2011     d_4             0   \n",
       "4    2011-02-02     11101        6     5      2  2011     d_5             0   \n",
       "...         ...       ...      ...   ...    ...   ...     ...           ...   \n",
       "1964 2016-06-15     11620        6     5      6  2016  d_1965             0   \n",
       "1965 2016-06-16     11620        4     6      6  2016  d_1966             0   \n",
       "1966 2016-06-17     11620        0     7      6  2016  d_1967             0   \n",
       "1967 2016-06-18     11621        2     1      6  2016  d_1968             0   \n",
       "1968 2016-06-19     11621        3     2      6  2016  d_1969            14   \n",
       "\n",
       "      event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "0                0             0             0        0        0        0   \n",
       "1                0             0             0        0        0        0   \n",
       "2                0             0             0        0        0        0   \n",
       "3                0             0             0        1        1        0   \n",
       "4                0             0             0        1        0        1   \n",
       "...            ...           ...           ...      ...      ...      ...   \n",
       "1964             0             0             0        0        1        1   \n",
       "1965             0             0             0        0        0        0   \n",
       "1966             0             0             0        0        0        0   \n",
       "1967             0             0             0        0        0        0   \n",
       "1968             1             3             1        0        0        0   \n",
       "\n",
       "      before_christmas  \n",
       "0                  330  \n",
       "1                  329  \n",
       "2                  328  \n",
       "3                  327  \n",
       "4                  326  \n",
       "...                ...  \n",
       "1964               193  \n",
       "1965               192  \n",
       "1966               191  \n",
       "1967               190  \n",
       "1968               189  \n",
       "\n",
       "[1969 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = {'CA': 0, 'TX': 1, 'WI': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_snap(dt):\n",
    "    dt['snap'] = ((dt['snap_CA'] == 1) & (dt['state_id'] == state_map['CA']) \n",
    "              | (dt['snap_TX'] == 1) & (dt['state_id'] == state_map['TX']) \n",
    "              | (dt['snap_WI'] == 1) & (dt['state_id'] == state_map['WI']))\n",
    "    \n",
    "    dt['snap'] = dt['snap'].astype('uint8')\n",
    "    \n",
    "    for c in ['snap_CA', 'snap_TX', 'snap_WI']:\n",
    "        del dt[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 1 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 5.8 s, total: 47.7 s\n",
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = m5_common.create_dt(cal, prices, is_train=True, first_day= FIRST_DAY, tr_last=tr_last, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_cat(dt, field, target_type='uint8'):\n",
    "    uniques = dt[field].unique()\n",
    "    uniques.sort()\n",
    "    mapping = {e: i for i, e in enumerate(uniques)}\n",
    "    print(mapping)\n",
    "    dt.replace({field: mapping}, inplace=True)\n",
    "    dt[field] = dt[field].astype(target_type)\n",
    "\n",
    "def replace_cats(dt):\n",
    "    replace_cat(dt, 'wday')\n",
    "    replace_cat(dt, 'month')\n",
    "    replace_cat(dt, 'year')\n",
    "    replace_cat(dt, 'mday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11}\n",
      "{2011: 0, 2012: 1, 2013: 2, 2014: 3, 2015: 4, 2016: 5}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30}\n"
     ]
    }
   ],
   "source": [
    "replace_cats(df)\n",
    "\n",
    "# replace_cat(df, 'Dayofyear', 'uint16')\n",
    "# replace_cat(df, 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46027957 entries, 4081 to 46025082\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           int16         \n",
      " 3   store_id          int16         \n",
      " 4   cat_id            int16         \n",
      " 5   state_id          int16         \n",
      " 6   d                 object        \n",
      " 7   sales             float16       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              uint8         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  before_christmas  uint16        \n",
      " 22  sell_price        float16       \n",
      " 23  Dayofyear         uint16        \n",
      " 24  week              uint8         \n",
      " 25  mday              uint8         \n",
      " 26  lag_price_1       float16       \n",
      "dtypes: datetime64[ns](1), float16(3), int16(6), object(2), uint16(2), uint8(13)\n",
      "memory usage: 2.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6115931671701179"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction of zeros\n",
    "df[df['sales'] == 0.].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "      <th>lag_price_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1536</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>5.269531</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1536</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>5.269531</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1536</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>5.269531</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>5.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1536</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>d_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>5.269531</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1536</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>d_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>5.269531</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.269531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956915</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>11612</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956916</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>11612</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>112</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956917</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>11612</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025081</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>11613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025082</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46027957 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  item_id  dept_id  store_id  cat_id  \\\n",
       "4081          FOODS_1_001_CA_1_evaluation     1536        4         0       2   \n",
       "4082          FOODS_1_001_CA_1_evaluation     1536        4         0       2   \n",
       "4083          FOODS_1_001_CA_1_evaluation     1536        4         0       2   \n",
       "4084          FOODS_1_001_CA_1_evaluation     1536        4         0       2   \n",
       "4085          FOODS_1_001_CA_1_evaluation     1536        4         0       2   \n",
       "...                                   ...      ...      ...       ...     ...   \n",
       "45956915  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "45956916  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "45956917  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46025081  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46025082  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "\n",
       "          state_id       d  sales       date  wm_yr_wk  weekday  wday  month  \\\n",
       "4081             0     d_1    3.0 2011-01-29     11101        2     0      0   \n",
       "4082             0     d_2    0.0 2011-01-30     11101        3     1      0   \n",
       "4083             0     d_3    0.0 2011-01-31     11101        1     2      0   \n",
       "4084             0     d_4    1.0 2011-02-01     11101        5     3      1   \n",
       "4085             0     d_5    4.0 2011-02-02     11101        6     4      1   \n",
       "...            ...     ...    ...        ...       ...      ...   ...    ...   \n",
       "45956915         2  d_1909    0.0 2016-04-20     11612        6     4      3   \n",
       "45956916         2  d_1910    0.0 2016-04-21     11612        4     5      3   \n",
       "45956917         2  d_1911    0.0 2016-04-22     11612        0     6      3   \n",
       "46025081         2  d_1912    0.0 2016-04-23     11613        2     0      3   \n",
       "46025082         2  d_1913    0.0 2016-04-24     11613        3     1      3   \n",
       "\n",
       "          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "4081         0             0             0             0             0   \n",
       "4082         0             0             0             0             0   \n",
       "4083         0             0             0             0             0   \n",
       "4084         0             0             0             0             0   \n",
       "4085         0             0             0             0             0   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "45956915     5             0             0             0             0   \n",
       "45956916     5             0             0             0             0   \n",
       "45956917     5             0             0             0             0   \n",
       "46025081     5             0             0             0             0   \n",
       "46025082     5             0             0             0             0   \n",
       "\n",
       "          snap_CA  snap_TX  snap_WI  before_christmas  sell_price  Dayofyear  \\\n",
       "4081            0        0        0               330    5.269531         29   \n",
       "4082            0        0        0               329    5.269531         30   \n",
       "4083            0        0        0               328    5.269531         31   \n",
       "4084            1        1        0               327    5.269531         32   \n",
       "4085            1        0        1               326    5.269531         33   \n",
       "...           ...      ...      ...               ...         ...        ...   \n",
       "45956915        0        0        0               249    1.000000        111   \n",
       "45956916        0        0        0               248    1.000000        112   \n",
       "45956917        0        0        0               247    1.000000        113   \n",
       "46025081        0        0        0               246    1.000000        114   \n",
       "46025082        0        0        0               245    1.000000        115   \n",
       "\n",
       "          week  mday  lag_price_1  \n",
       "4081         4    28          NaN  \n",
       "4082         4    29     5.269531  \n",
       "4083         5    30     5.269531  \n",
       "4084         5     0     5.269531  \n",
       "4085         5     1     5.269531  \n",
       "...        ...   ...          ...  \n",
       "45956915    16    19     1.000000  \n",
       "45956916    16    20     1.000000  \n",
       "45956917    16    21     1.000000  \n",
       "46025081    16    22     1.000000  \n",
       "46025082    16    23     1.000000  \n",
       "\n",
       "[46027957 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt, dropna=True):\n",
    "    \n",
    "    wins = [7, 28]\n",
    "    lags = [7, 28]\n",
    "    \n",
    "    grouped_sales = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"]\n",
    "    \n",
    "    for win in wins:\n",
    "        mean_col = f'mean_{win}'\n",
    "        emean_col = f'e{mean_col}' # exponential mean average\n",
    "        esmean_col = f'es{mean_col}'\n",
    "        dt[emean_col] = grouped_sales.transform(lambda x : x.ewm(span=win, adjust=False).mean())\n",
    "        dt[esmean_col] = grouped_sales.transform(lambda x : x.ewm(alpha=1/win, adjust=False).mean())\n",
    "        for lag in lags:\n",
    "            dt[f'emean_{win}_{lag}'] = dt[[\"id\", emean_col]].groupby(\"id\").shift(lag)\n",
    "            dt[f'esmean_{win}_{lag}'] = dt[[\"id\", esmean_col]].groupby(\"id\").shift(lag)\n",
    "        del dt[emean_col]\n",
    "        del dt[esmean_col]\n",
    "            \n",
    "    ra = [2, 4, 5, 7]\n",
    "    for simple_lag in ra:\n",
    "        dt[f'lag_{simple_lag}'] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(simple_lag)\n",
    "    \n",
    "    if dropna == True:\n",
    "        dt.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 8.57 s, total: 1min 49s\n",
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45174237, 39)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "      <th>lag_price_1</th>\n",
       "      <th>emean_7_7</th>\n",
       "      <th>esmean_7_7</th>\n",
       "      <th>emean_7_28</th>\n",
       "      <th>esmean_7_28</th>\n",
       "      <th>emean_28_7</th>\n",
       "      <th>esmean_28_7</th>\n",
       "      <th>emean_28_28</th>\n",
       "      <th>esmean_28_28</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45956915</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>11612</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.079956</td>\n",
       "      <td>0.083252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956916</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>11612</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.018723</td>\n",
       "      <td>0.050201</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.080261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956917</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>11612</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.077393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025081</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>11613</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.034760</td>\n",
       "      <td>0.064514</td>\n",
       "      <td>0.074646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025082</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.031616</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.060089</td>\n",
       "      <td>0.071960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  item_id  dept_id  store_id  cat_id  \\\n",
       "45956915  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "45956916  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "45956917  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46025081  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46025082  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "\n",
       "          state_id       d  sales       date  wm_yr_wk  weekday  wday  month  \\\n",
       "45956915         2  d_1909    0.0 2016-04-20     11612        6     4      3   \n",
       "45956916         2  d_1910    0.0 2016-04-21     11612        4     5      3   \n",
       "45956917         2  d_1911    0.0 2016-04-22     11612        0     6      3   \n",
       "46025081         2  d_1912    0.0 2016-04-23     11613        2     0      3   \n",
       "46025082         2  d_1913    0.0 2016-04-24     11613        3     1      3   \n",
       "\n",
       "          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "45956915     5             0             0             0             0   \n",
       "45956916     5             0             0             0             0   \n",
       "45956917     5             0             0             0             0   \n",
       "46025081     5             0             0             0             0   \n",
       "46025082     5             0             0             0             0   \n",
       "\n",
       "          snap_CA  snap_TX  snap_WI  before_christmas  sell_price  Dayofyear  \\\n",
       "45956915        0        0        0               249         1.0        111   \n",
       "45956916        0        0        0               248         1.0        112   \n",
       "45956917        0        0        0               247         1.0        113   \n",
       "46025081        0        0        0               246         1.0        114   \n",
       "46025082        0        0        0               245         1.0        115   \n",
       "\n",
       "          week  mday  lag_price_1  emean_7_7  esmean_7_7  emean_7_28  \\\n",
       "45956915    16    19          1.0   0.000059    0.002300    0.024963   \n",
       "45956916    16    20          1.0   0.000045    0.001972    0.018723   \n",
       "45956917    16    21          1.0   0.000033    0.001690    0.014038   \n",
       "46025081    16    22          1.0   0.000025    0.001449    0.010529   \n",
       "46025082    16    23          1.0   0.000019    0.001242    0.007896   \n",
       "\n",
       "          esmean_7_28  emean_28_7  esmean_28_7  emean_28_28  esmean_28_28  \\\n",
       "45956915     0.058594    0.017822     0.038788     0.079956      0.083252   \n",
       "45956916     0.050201    0.016602     0.037384     0.074463      0.080261   \n",
       "45956917     0.043030    0.015457     0.036041     0.069336      0.077393   \n",
       "46025081     0.036896    0.014389     0.034760     0.064514      0.074646   \n",
       "46025082     0.031616    0.013397     0.033539     0.060089      0.071960   \n",
       "\n",
       "          lag_2  lag_4  lag_5  lag_7  \n",
       "45956915    0.0    0.0    0.0    0.0  \n",
       "45956916    0.0    0.0    0.0    0.0  \n",
       "45956917    0.0    0.0    0.0    0.0  \n",
       "46025081    0.0    0.0    0.0    0.0  \n",
       "46025082    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45174237 entries, 342559 to 46025082\n",
      "Data columns (total 39 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           int16         \n",
      " 3   store_id          int16         \n",
      " 4   cat_id            int16         \n",
      " 5   state_id          int16         \n",
      " 6   d                 object        \n",
      " 7   sales             float16       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              uint8         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  before_christmas  uint16        \n",
      " 22  sell_price        float16       \n",
      " 23  Dayofyear         uint16        \n",
      " 24  week              uint8         \n",
      " 25  mday              uint8         \n",
      " 26  lag_price_1       float16       \n",
      " 27  emean_7_7         float16       \n",
      " 28  esmean_7_7        float16       \n",
      " 29  emean_7_28        float16       \n",
      " 30  esmean_7_28       float16       \n",
      " 31  emean_28_7        float16       \n",
      " 32  esmean_28_7       float16       \n",
      " 33  emean_28_28       float16       \n",
      " 34  esmean_28_28      float16       \n",
      " 35  lag_2             float16       \n",
      " 36  lag_4             float16       \n",
      " 37  lag_5             float16       \n",
      " 38  lag_7             float16       \n",
      "dtypes: datetime64[ns](1), float16(15), int16(6), object(2), uint16(2), uint8(13)\n",
      "memory usage: 3.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_features ['Dayofyear', 'before_christmas', 'cat_id', 'date', 'dept_id', 'emean_28_28', 'emean_28_7', 'emean_7_28', 'emean_7_7', 'esmean_7_28', 'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2', 'id', 'item_id', 'lag_1', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'lag_price_1', 'mday', 'month', 'sales', 'sell_price', 'snap_CA', 'snap_TX', 'snap_WI', 'state_id', 'store_id', 'wday', 'year']\n"
     ]
    }
   ],
   "source": [
    "feature_lags = [f'lag_{i}' for i in range(1, 8)]\n",
    "feature_pool = ['before_christmas', 'sell_price', 'Dayofyear', 'week', 'lag_price_1', 'emean_7_7', 'esmean_7_7', 'emean_7_28',            \n",
    "                'esmean_7_28', 'emean_28_7', 'esmean_28_7', 'emean_28_28', 'esmean_28_28'] + feature_lags                  \n",
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id', \n",
    "             \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "\n",
    "import random\n",
    "\n",
    "def reduce_features(feature_pool, size):    \n",
    "    random.shuffle(feature_pool)\n",
    "    return feature_pool[:size]\n",
    "\n",
    "selected_features = reduce_features(feature_pool, 15)\n",
    "\n",
    "selected_features = selected_features + cat_feats + ['id', 'date', 'sales', 'wday', 'month', 'year', 'mday']\n",
    "selected_features.sort()\n",
    "\n",
    "print('selected_features', selected_features)\n",
    "\n",
    "def remove_features(dt, selected_features):\n",
    "    for col in dt.columns:\n",
    "        if col not in selected_features:\n",
    "            del dt[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_features(df, selected_features)\n",
    "selected_features = ['Dayofyear', 'cat_id', 'date', 'dept_id', 'emean_28_28', 'emean_28_7', 'emean_7_28', 'emean_7_7', 'esmean_28_28', 'esmean_28_7', \n",
    "                     'esmean_7_28', 'esmean_7_7', 'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2', 'id', 'item_id', \n",
    "                     'lag_2', 'lag_4', 'lag_5', 'lag_7', 'lag_price_1', 'mday', 'month', 'sales', 'snap_CA', 'snap_TX', 'snap_WI', \n",
    "                     'state_id', 'store_id', 'week', 'wday', 'year']\n",
    "remove_features(df, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45174237 entries, 342559 to 46025082\n",
      "Data columns (total 33 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   sales         float16       \n",
      " 7   date          datetime64[ns]\n",
      " 8   wday          uint8         \n",
      " 9   month         uint8         \n",
      " 10  year          uint8         \n",
      " 11  event_name_1  uint8         \n",
      " 12  event_type_1  uint8         \n",
      " 13  event_name_2  uint8         \n",
      " 14  event_type_2  uint8         \n",
      " 15  snap_CA       uint8         \n",
      " 16  snap_TX       uint8         \n",
      " 17  snap_WI       uint8         \n",
      " 18  Dayofyear     uint16        \n",
      " 19  mday          uint8         \n",
      " 20  lag_price_1   float16       \n",
      " 21  emean_7_7     float16       \n",
      " 22  esmean_7_7    float16       \n",
      " 23  emean_7_28    float16       \n",
      " 24  esmean_7_28   float16       \n",
      " 25  emean_28_7    float16       \n",
      " 26  esmean_28_7   float16       \n",
      " 27  emean_28_28   float16       \n",
      " 28  esmean_28_28  float16       \n",
      " 29  lag_2         float16       \n",
      " 30  lag_4         float16       \n",
      " 31  lag_5         float16       \n",
      " 32  lag_7         float16       \n",
      "dtypes: datetime64[ns](1), float16(14), int16(5), object(1), uint16(1), uint8(11)\n",
      "memory usage: 3.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "size_valid_set = 2_000_000\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, size_valid_set, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.loc[train_inds]\n",
    "y = y_train.loc[train_inds]\n",
    "\n",
    "X_valid = X_train.loc[fake_valid_inds]\n",
    "y_valid = y_train.loc[fake_valid_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_size = 10\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.25,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "#         \"lambda_l1\" : 0.2,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"nthread\" : 10,\n",
    "        \"metric\": [\"rmse\"],\n",
    "        'verbosity': 20,\n",
    "        'num_leaves': 2**leave_size-1,\n",
    "        \"min_data_in_leaf\": 2**(leave_size + 1)-1,\n",
    "        \"n_estimators\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importance():\n",
    "    \n",
    "    def __init__(self, model, eval_metric):\n",
    "        self.model, self.eval_metric = model, eval_metric\n",
    "        self.feature_importances = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats, ax=ax)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "    \n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in [self.model]:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.evals_result_.keys():\n",
    "                evals_result[k] = model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "#         categorical_feature  plt.title('Training progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pred(m_lgb):\n",
    "    max_lags = h * 2 + 1\n",
    "    sub = 0.\n",
    "    cols = [f\"F{i}\" for i in range(1,29)]\n",
    "    te = m5_common.create_dt(cal, prices, False, first_day=FIRST_DAY, path=path)\n",
    "    replace_cats(te)\n",
    "\n",
    "    for tdelta in tqdm(range(0, h), total=h):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "        create_fea(tst, False)\n",
    "        remove_features(tst, selected_features)\n",
    "        tst = tst.loc[tst.date == day, train_cols]\n",
    "        te.loc[te.date == day, \"sales\"] = m_lgb.predict(tst)\n",
    "\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "    te_sub[\"id\"] = te_sub[\"id\"].str.replace(\"evaluation$\", \"validation\")\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace = True)\n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    sub = te_sub\n",
    "\n",
    "    sub2 = sub.copy()\n",
    "    sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "    sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "    sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation metric\n",
    "## from https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834 and edited to get scores at all levels\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'cat_id',\n",
    "            'state_id',\n",
    "            'dept_id',\n",
    "            'store_id',\n",
    "            'item_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        group_ids = []\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            group_ids.append(group_id)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return group_ids, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public LB rank\n",
    "def get_lb_rank(df_lb, score):\n",
    "    \"\"\"\n",
    "    Get rank on public LB as of 2020-05-31 23:59:59\n",
    "    \"\"\"\n",
    "    return (df_lb.Score <= score).sum() + 1\n",
    "\n",
    "def validation_ranking(mlflow):\n",
    "    ## new train data\n",
    "    df_train_full = pd.read_csv(path/\"sales_train_evaluation.csv\")\n",
    "    df_train_full.iloc[:, -31:].head()\n",
    "    \n",
    "    df_lb = pd.read_csv(path/\"m5-forecasting-accuracy-publicleaderboard-rank.csv\")\n",
    "    \n",
    "    ## reading data\n",
    "    df_calendar = pd.read_csv(path/\"calendar.csv\")\n",
    "    df_prices = pd.read_csv(path/\"sell_prices.csv\")\n",
    "    df_sample_submission = pd.read_csv(path/\"sample_submission.csv\")\n",
    "    df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "    df_train = df_train_full.iloc[:, :-28]\n",
    "    df_valid = df_train_full.iloc[:, -28:]\n",
    "\n",
    "    evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)\n",
    "    \n",
    "    ## structure of validation data\n",
    "    preds_valid = df_valid.copy() + np.random.randint(100, size = df_valid.shape)\n",
    "\n",
    "    ## evaluating submission from public kernel M5 - Three shades of Dark: Darker magic\n",
    "    preds_valid = pd.read_csv(\"submission.csv\")\n",
    "    preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "    preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "    preds_valid.rename(columns = {\n",
    "        \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "        \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "        \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "        \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "    }, inplace = True)\n",
    "\n",
    "    groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "    score_public_lb = np.mean(scores)\n",
    "    score_public_rank = get_lb_rank(df_lb, score_public_lb)\n",
    "\n",
    "    for i in range(len(groups)):\n",
    "        print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "    print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "    mlflow.log_metric(key=\"Public LB Score\", value=round(score_public_lb, 5))\n",
    "    mlflow.set_tag(key=\"Public LB Rank\", value=str(score_public_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_to_string(X_train, m_lgb_regressor):\n",
    "    importances = [f'{f} : {c}' for (c, f) in zip(X_train.columns, m_lgb_regressor.feature_importances_)]\n",
    "    importances.sort()\n",
    "    return ','.join(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/lightgbm/basic.py:1247: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['cat_id', 'dept_id', 'event_name_1', 'event_name_2', 'event_type_1', 'event_type_2', 'item_id', 'snap_CA', 'snap_TX', 'snap_WI', 'state_id', 'store_id']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttrain sales's rmse: 2.82975\tvalid sales's rmse: 2.75537\n",
      "[40]\ttrain sales's rmse: 2.38193\tvalid sales's rmse: 2.32436\n",
      "[60]\ttrain sales's rmse: 2.3244\tvalid sales's rmse: 2.2775\n",
      "[80]\ttrain sales's rmse: 2.28933\tvalid sales's rmse: 2.25486\n",
      "[100]\ttrain sales's rmse: 2.26885\tvalid sales's rmse: 2.24154\n",
      "[120]\ttrain sales's rmse: 2.25547\tvalid sales's rmse: 2.2326\n",
      "[140]\ttrain sales's rmse: 2.24381\tvalid sales's rmse: 2.22553\n",
      "[160]\ttrain sales's rmse: 2.23293\tvalid sales's rmse: 2.21985\n",
      "[180]\ttrain sales's rmse: 2.22395\tvalid sales's rmse: 2.21473\n",
      "[200]\ttrain sales's rmse: 2.21689\tvalid sales's rmse: 2.21162\n",
      "[220]\ttrain sales's rmse: 2.21009\tvalid sales's rmse: 2.20846\n",
      "[240]\ttrain sales's rmse: 2.20323\tvalid sales's rmse: 2.20535\n",
      "[260]\ttrain sales's rmse: 2.19721\tvalid sales's rmse: 2.20294\n",
      "[280]\ttrain sales's rmse: 2.19171\tvalid sales's rmse: 2.2009\n",
      "[300]\ttrain sales's rmse: 2.18596\tvalid sales's rmse: 2.19876\n",
      "[320]\ttrain sales's rmse: 2.18168\tvalid sales's rmse: 2.19705\n",
      "[340]\ttrain sales's rmse: 2.1764\tvalid sales's rmse: 2.19487\n",
      "[360]\ttrain sales's rmse: 2.17182\tvalid sales's rmse: 2.19334\n",
      "[380]\ttrain sales's rmse: 2.16656\tvalid sales's rmse: 2.19137\n",
      "[400]\ttrain sales's rmse: 2.16231\tvalid sales's rmse: 2.18953\n",
      "[420]\ttrain sales's rmse: 2.15716\tvalid sales's rmse: 2.18778\n",
      "[440]\ttrain sales's rmse: 2.15316\tvalid sales's rmse: 2.18672\n",
      "[460]\ttrain sales's rmse: 2.14887\tvalid sales's rmse: 2.18534\n",
      "[480]\ttrain sales's rmse: 2.14558\tvalid sales's rmse: 2.18426\n",
      "[500]\ttrain sales's rmse: 2.14225\tvalid sales's rmse: 2.18369\n",
      "[520]\ttrain sales's rmse: 2.13876\tvalid sales's rmse: 2.18295\n",
      "[540]\ttrain sales's rmse: 2.13462\tvalid sales's rmse: 2.18188\n",
      "[560]\ttrain sales's rmse: 2.13137\tvalid sales's rmse: 2.18122\n",
      "[580]\ttrain sales's rmse: 2.12814\tvalid sales's rmse: 2.18045\n",
      "[600]\ttrain sales's rmse: 2.12447\tvalid sales's rmse: 2.1795\n",
      "[620]\ttrain sales's rmse: 2.12129\tvalid sales's rmse: 2.17874\n",
      "[640]\ttrain sales's rmse: 2.11898\tvalid sales's rmse: 2.1786\n",
      "[660]\ttrain sales's rmse: 2.11519\tvalid sales's rmse: 2.17775\n",
      "[680]\ttrain sales's rmse: 2.11177\tvalid sales's rmse: 2.17668\n",
      "[700]\ttrain sales's rmse: 2.10909\tvalid sales's rmse: 2.17595\n",
      "[720]\ttrain sales's rmse: 2.10645\tvalid sales's rmse: 2.17536\n",
      "[740]\ttrain sales's rmse: 2.10393\tvalid sales's rmse: 2.17457\n",
      "[760]\ttrain sales's rmse: 2.10079\tvalid sales's rmse: 2.17419\n",
      "[780]\ttrain sales's rmse: 2.09785\tvalid sales's rmse: 2.17338\n",
      "[800]\ttrain sales's rmse: 2.09533\tvalid sales's rmse: 2.17281\n",
      "[820]\ttrain sales's rmse: 2.09245\tvalid sales's rmse: 2.17224\n",
      "[840]\ttrain sales's rmse: 2.08955\tvalid sales's rmse: 2.17158\n",
      "[860]\ttrain sales's rmse: 2.08715\tvalid sales's rmse: 2.17083\n",
      "[880]\ttrain sales's rmse: 2.08455\tvalid sales's rmse: 2.17036\n",
      "[900]\ttrain sales's rmse: 2.08196\tvalid sales's rmse: 2.16993\n",
      "[920]\ttrain sales's rmse: 2.07963\tvalid sales's rmse: 2.16945\n",
      "[940]\ttrain sales's rmse: 2.07757\tvalid sales's rmse: 2.16901\n",
      "[960]\ttrain sales's rmse: 2.07549\tvalid sales's rmse: 2.16871\n",
      "[980]\ttrain sales's rmse: 2.07362\tvalid sales's rmse: 2.16844\n",
      "[1000]\ttrain sales's rmse: 2.07138\tvalid sales's rmse: 2.16812\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain sales's rmse: 2.07138\tvalid sales's rmse: 2.16812\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11}\n",
      "{2011: 0, 2012: 1, 2013: 2, 2014: 3, 2015: 4, 2016: 5}\n",
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a93dea123d745d5be5b2c5c74d976ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25 00:00:00\n",
      "1 2016-04-26 00:00:00\n",
      "2 2016-04-27 00:00:00\n",
      "3 2016-04-28 00:00:00\n",
      "4 2016-04-29 00:00:00\n",
      "5 2016-04-30 00:00:00\n",
      "6 2016-05-01 00:00:00\n",
      "7 2016-05-02 00:00:00\n",
      "8 2016-05-03 00:00:00\n",
      "9 2016-05-04 00:00:00\n",
      "10 2016-05-05 00:00:00\n",
      "11 2016-05-06 00:00:00\n",
      "12 2016-05-07 00:00:00\n",
      "13 2016-05-08 00:00:00\n",
      "14 2016-05-09 00:00:00\n",
      "15 2016-05-10 00:00:00\n",
      "16 2016-05-11 00:00:00\n",
      "17 2016-05-12 00:00:00\n",
      "18 2016-05-13 00:00:00\n",
      "19 2016-05-14 00:00:00\n",
      "20 2016-05-15 00:00:00\n",
      "21 2016-05-16 00:00:00\n",
      "22 2016-05-17 00:00:00\n",
      "23 2016-05-18 00:00:00\n",
      "24 2016-05-19 00:00:00\n",
      "25 2016-05-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(key=\"features\", value=str(selected_features))\n",
    "    m_lgb_regressor = lgb.LGBMRegressor(**params)\n",
    "    m_lgb_regressor.fit(X=X, y=y, \n",
    "              eval_set=[(X, y), (X_valid, y_valid)],\n",
    "              eval_names=['train sales', 'valid sales'], \n",
    "              eval_metric=params['metric'],\n",
    "              verbose=params['verbosity'],\n",
    "              early_stopping_rounds=100,\n",
    "              categorical_feature=cat_feats)\n",
    "    mlflow.log_metric(key=\"train_rmse_best\", value=m_lgb_regressor.best_score_['train sales']['rmse'])\n",
    "    mlflow.log_metric(key=\"valid_rmse_best\", value=m_lgb_regressor.best_score_['valid sales']['rmse'])\n",
    "    mlflow.set_tag(key=\"importance\", value=importance_to_string(X_train, m_lgb_regressor))\n",
    "    run_pred(m_lgb_regressor)\n",
    "    validation_ranking(mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = Importance(m_lgb_regressor, 'rmse')\n",
    "importance.plot_feature_importance(top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in [None, 800, 1000, 1200]:\n",
    "    m_lgb_regressor.booster_.save_model(str(path/f\"m5_model_{'best' if iter is None else iter}.lgb\"), num_iteration=iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb = lgb.Booster(model_file=str(path/\"m5_model_best.lgb\"))\n",
    "# m_lgb = lgb.Booster(model_file=str(path/\"m5_model_1200.lgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {path/\"m5_model*.lgb\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
