{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.tabular import *\n",
    "from scripts import m5_common\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/kaggle/m5_forecasting/')\n",
    "assert(path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28 \n",
    "max_lags = h * 2 + 1\n",
    "tr_last = 1913\n",
    "fday = datetime(2016, 4, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 160 ms, total: 1.58 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prices, cal = m5_common.prepare_tables(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1_map, event_type_1_map = m5_common.replace_cal_cols(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>11149</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>11149</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11149</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  wm_yr_wk  weekday  wday  month  year      d  event_name_1  \\\n",
       "338 2012-01-02     11149        1     3      1  2012  d_339             0   \n",
       "339 2012-01-03     11149        5     4      1  2012  d_340             0   \n",
       "340 2012-01-04     11149        6     5      1  2012  d_341             0   \n",
       "\n",
       "     event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "338             0             0             0      1.0      0.0      1.0  \n",
       "339             0             0             0      1.0      1.0      1.0  \n",
       "340             0             0             0      1.0      0.0      0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal[(cal.date > '2012-01-01') & (cal.date < '2012-01-05')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_types= ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'month', 'wday', 'weekday', \n",
    "              'snap_CA', 'snap_TX', 'snap_WI']\n",
    "m5_common.convert_uint8(cal, uint8_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_common.add_days_before(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42 s, sys: 5.93 s, total: 47.9 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = m5_common.create_dt(cal, prices, is_train=True, first_day=FIRST_DAY, tr_last=tr_last, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2011-01-29 00:00:00'), Timestamp('2016-04-24 00:00:00'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.min(), df.date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    \n",
    "    wins = [7, 28]\n",
    "    lags = [7, 28]\n",
    "    \n",
    "    grouped_sales = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"]\n",
    "    \n",
    "    for win in tqdm(wins, total=len(wins)):\n",
    "        mean_col = f'mean_{win}'\n",
    "        emean_col = f'e{mean_col}' # exponential mean average\n",
    "        esmean_col = f'es{mean_col}'\n",
    "        dt[emean_col] = grouped_sales.transform(lambda x : x.ewm(span=win, adjust=False).mean())\n",
    "        dt[esmean_col] = grouped_sales.transform(lambda x : x.ewm(alpha=1/win, adjust=False).mean())\n",
    "        for lag in lags:\n",
    "            dt[f'emean_{win}_{lag}'] = dt[[\"id\", emean_col]].groupby(\"id\").shift(lag)\n",
    "            dt[f'esmean_{win}_{lag}'] = dt[[\"id\", esmean_col]].groupby(\"id\").shift(lag)\n",
    "        del dt[emean_col]\n",
    "        del dt[esmean_col]\n",
    "            \n",
    "    ra = [1, 2]\n",
    "    for simple_lag in ra:\n",
    "        dt[f'lag_{simple_lag}'] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(simple_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6664888427364d3aadcde464f4a479c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['wday', 'month', 'year', 'Dayofyear', 'before_christmas', 'week', 'mday','item_id', 'dept_id','store_id', 'cat_id', 'state_id', \n",
    "             \"event_name_1\", \"event_name_2\", \"event_type_1\",  \"event_type_2\", 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "useless_cols = [\"id\", \"date\", \"sales\", \"sales_positive\", \"d\", \"wm_yr_wk\", \"weekday\", \"revenue\"]\n",
    "\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "cont_names = [col for col in train_cols if col not in cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float32(df):\n",
    "    for c in ['sell_price', 'lag_price_1', 'emean_7_7', 'esmean_7_7', 'emean_7_28', 'esmean_7_28', 'emean_28_7', 'esmean_28_7', 'emean_28_28', 'esmean_28_28', 'lag_1', 'lag_2']:\n",
    "        df[c] = df[c].astype('float32')\n",
    "        \n",
    "convert_float32(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TabularList.from_df(df, path=path, cat_names=cat_feats, cont_names=cont_names, procs=procs)\n",
    "                           .split_by_rand_pct(valid_pct=0.1)\n",
    "                           .label_from_df(cols='sales', label_cls=FloatList)\n",
    "                           .databunch())\n",
    "data.batch_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x.cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = np.max(df['sales'] * 1.2)\n",
    "y_range = torch.tensor([0., max_y], device=defaults.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inline static double LossOnPoint(label_t label, double score, const Config& config) {\n",
    "#     const double rho = config.tweedie_variance_power;\n",
    "#     const double eps = 1e-10f;\n",
    "#     if (score < eps) {\n",
    "#       score = eps;\n",
    "#     }\n",
    "#     const double a = label * std::exp((1 - rho) * std::log(score)) / (1 - rho);\n",
    "#     const double b = std::exp((2 - rho) * std::log(score)) / (2 - rho);\n",
    "#     return -a + b;\n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return F.mse_loss(pred, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweedie_variance_power = 1.1\n",
    "rho = tensor(tweedie_variance_power).cuda()\n",
    "eps = tensor(1e-10).cuda()\n",
    "\n",
    "def tweedie_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1), targ.contiguous().view(-1)\n",
    "    pred = torch.where(pred < eps, eps, pred)\n",
    "    a = targ * torch.exp((1 - rho) * torch.log(pred)) / (1 - rho)\n",
    "    b = torch.exp((2 - rho) * torch.log(pred)) / (2 - rho)\n",
    "    return torch.mean(-a + b)\n",
    "\n",
    "def mse_tweedie_loss(pred, targ):\n",
    "    return (mse_loss(pred, targ) * 0.7 + tweedie_loss(pred, targ) * 0.3) / tensor(2.).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mqe_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean((pred - targ) ** 4)\n",
    "\n",
    "def mae_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean(torch.abs(pred - targ))\n",
    "\n",
    "def mape_loss(pred, targ):\n",
    "    pred, targ = pred.contiguous().view(-1),targ.contiguous().view(-1)\n",
    "    return torch.mean(torch.abs((targ - pred) / (targ + 1e-5)))\n",
    "\n",
    "def poisson_loss(pred, targ):\n",
    "    \"\"\"Custom loss function for Poisson model.\"\"\"\n",
    "    pred, targ = flatten_check(pred, targ)\n",
    "    return F.poisson_nll_loss(pred, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModelCallback(callbacks.TrackerCallback):\n",
    "    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n",
    "    def __init__(self, learn:Learner, monitor:str='valid_loss', mode:str='auto', every:str='improvement', name:str='bestmodel'):\n",
    "        super().__init__(learn, monitor=monitor, mode=mode)\n",
    "        self.every,self.name = every,name\n",
    "        if self.every not in ['improvement', 'epoch']:\n",
    "            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n",
    "            self.every = 'improvement'\n",
    "\n",
    "    def jump_to_epoch(self, epoch:int)->None:\n",
    "        try:\n",
    "            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n",
    "            print(f\"Loaded {self.name}_{epoch-1}\")\n",
    "        except: print(f'Model {self.name}_{epoch-1} not found.')\n",
    "\n",
    "    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n",
    "        \"Compare the value monitored to its best score and maybe save the model.\"\n",
    "        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n",
    "        else: #every=\"improvement\"\n",
    "            current = self.get_monitor_value()\n",
    "            if current is not None and self.operator(current, self.best):\n",
    "                print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n",
    "                self.best = current\n",
    "                learn.export(file=str(path/f'm5_model_{epoch}_export.pkl'))\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        \"Load the best model.\"\n",
    "        if self.every==\"improvement\" and (self.learn.path/f'{self.learn.model_dir}/{self.name}.pth').is_file():\n",
    "            self.learn.load(f'{self.name}', purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(data, layers=[1500, 750], y_range=y_range, metrics=rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = tweedie_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(num_it=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "learn.fit_one_cycle(10, lr, callbacks=[callbacks.EarlyStoppingCallback(learn, monitor=\"root_mean_squared_error\", \n",
    "                                                                       mode=\"min\", patience=30),\n",
    "                                     callbacks.ExportModelCallback(learn, monitor='root_mean_squared_error',mode='min', \n",
    "                                                                 name='m5_best_1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = 1e-5\n",
    "learn.fit_one_cycle(10, lr, callbacks=[callbacks.EarlyStoppingCallback(learn, monitor=\"root_mean_squared_error\", \n",
    "                                                                       mode=\"min\", patience=30),\n",
    "                                     callbacks.ExportModelCallback(learn, monitor='root_mean_squared_error',mode='min', \n",
    "                                                                 name='m5_best_2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file=str(path/'m5_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path=str(path), file='m5_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastai_tabular_predict(tst):\n",
    "    '''\n",
    "    tst - a dataframe missing the label for which we want to be able to predict\n",
    "    '''\n",
    "    # sales is the label\n",
    "    tst['sales'] = 0\n",
    "    # Create a databunch with the same categorical features, continuous features and procedures as for the training set, split so that you only have training data\n",
    "    tbldb = TabularList.from_df(tst, path=path, cat_names=cat_feats, cont_names=cont_names, procs=procs).split_by_rand_pct(valid_pct=0.).label_from_df(cols='sales', label_cls=FloatList).databunch()\n",
    "    # Set the batch size to the length of the dataframe\n",
    "    tbldb.batch_size = len(tst)\n",
    "    # Fetch the training data features\n",
    "    x, _ = next(iter(tbldb.dl(ds_type=DatasetType.Train)))\n",
    "    # Call the model using first the categorical data and then the continuous data, convert to numpy\n",
    "    return to_np(learn.model(x[0].cuda(), x[1].cuda()).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_lags = h * 2 + 1\n",
    "sub = 0.\n",
    "cols = [f\"F{i}\" for i in range(1,29)]\n",
    "te = m5_common.create_dt(cal, prices, False, first_day=FIRST_DAY, path=path)\n",
    "\n",
    "learn.model.eval()\n",
    "\n",
    "for tdelta in tqdm(range(0, h), total=h):\n",
    "    day = fday + timedelta(days=tdelta)\n",
    "    print(tdelta, day)\n",
    "    tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "    create_fea(tst)\n",
    "    tst = tst.loc[tst.date == day, train_cols]\n",
    "    convert_float32(tst)\n",
    "    te.loc[te.date == day, \"sales\"] = fastai_tabular_predict(tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "te_sub.loc[te.date >= fday+ timedelta(days=h), \"id\"] = te_sub.loc[te.date >= fday+timedelta(days=h), \n",
    "                                                                      \"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "te_sub.fillna(0., inplace = True)\n",
    "te_sub.sort_values(\"id\", inplace = True)\n",
    "te_sub.reset_index(drop=True, inplace = True)\n",
    "sub = te_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
