{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts import m5_common\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/kaggle/m5_forecasting/')\n",
    "assert(path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28\n",
    "tr_last = 1941\n",
    "fday = datetime(2016, 4, 25) + timedelta(days=h)\n",
    "fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prices, cal = m5_common.prepare_tables(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(path/'weather/weather_2010_2020.csv')\n",
    "weather_df[\"date\"] = pd.to_datetime(weather_df[\"Date\"])\n",
    "del weather_df[\"Date\"]\n",
    "del weather_df[\"Anomaly\"]\n",
    "weather_df['Value'] = weather_df['Value'].astype('float16')\n",
    "weather_df.columns = ['temperature',  'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# cal = cal.merge(weather_df, on=['date'], copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name_1_map, event_type_1_map = m5_common.replace_cal_cols(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_types= ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'month', 'wday', 'weekday', \n",
    "              'snap_CA', 'snap_TX', 'snap_WI']\n",
    "m5_common.convert_uint8(cal, uint8_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_year = 'Dayofyear'\n",
    "\n",
    "def prepare_day_of_year(df):\n",
    "    df[day_of_year] = getattr(df['date'].dt, day_of_year.lower()).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_before(dt, day=25, month=12, col_name='before_christmas'):\n",
    "    diff_list = []\n",
    "    for d in dt['date']:\n",
    "        target = datetime(d.year, month, day)\n",
    "        diff = (target - d.to_pydatetime()).days\n",
    "        if(diff < 0):\n",
    "            christmas = datetime(d.year + 1, 12, 25)\n",
    "            diff = (target - d.to_pydatetime()).days\n",
    "        diff_list.append(diff)\n",
    "    dt[col_name] = diff_list\n",
    "    dt[col_name] = dt[col_name].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_days_before(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk          1969 non-null   int16         \n",
      " 2   weekday           1969 non-null   uint8         \n",
      " 3   wday              1969 non-null   uint8         \n",
      " 4   month             1969 non-null   uint8         \n",
      " 5   year              1969 non-null   int16         \n",
      " 6   d                 1969 non-null   object        \n",
      " 7   event_name_1      1969 non-null   uint8         \n",
      " 8   event_type_1      1969 non-null   uint8         \n",
      " 9   event_name_2      1969 non-null   uint8         \n",
      " 10  event_type_2      1969 non-null   uint8         \n",
      " 11  snap_CA           1969 non-null   uint8         \n",
      " 12  snap_TX           1969 non-null   uint8         \n",
      " 13  snap_WI           1969 non-null   uint8         \n",
      " 14  before_christmas  1969 non-null   uint16        \n",
      "dtypes: datetime64[ns](1), int16(2), object(1), uint16(1), uint8(10)\n",
      "memory usage: 61.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>11620</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>11620</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>11620</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1969 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  wm_yr_wk  weekday  wday  month  year       d  event_name_1  \\\n",
       "0    2011-01-29     11101        2     1      1  2011     d_1             0   \n",
       "1    2011-01-30     11101        3     2      1  2011     d_2             0   \n",
       "2    2011-01-31     11101        1     3      1  2011     d_3             0   \n",
       "3    2011-02-01     11101        5     4      2  2011     d_4             0   \n",
       "4    2011-02-02     11101        6     5      2  2011     d_5             0   \n",
       "...         ...       ...      ...   ...    ...   ...     ...           ...   \n",
       "1964 2016-06-15     11620        6     5      6  2016  d_1965             0   \n",
       "1965 2016-06-16     11620        4     6      6  2016  d_1966             0   \n",
       "1966 2016-06-17     11620        0     7      6  2016  d_1967             0   \n",
       "1967 2016-06-18     11621        2     1      6  2016  d_1968             0   \n",
       "1968 2016-06-19     11621        3     2      6  2016  d_1969            14   \n",
       "\n",
       "      event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "0                0             0             0        0        0        0   \n",
       "1                0             0             0        0        0        0   \n",
       "2                0             0             0        0        0        0   \n",
       "3                0             0             0        1        1        0   \n",
       "4                0             0             0        1        0        1   \n",
       "...            ...           ...           ...      ...      ...      ...   \n",
       "1964             0             0             0        0        1        1   \n",
       "1965             0             0             0        0        0        0   \n",
       "1966             0             0             0        0        0        0   \n",
       "1967             0             0             0        0        0        0   \n",
       "1968             1             3             1        0        0        0   \n",
       "\n",
       "      before_christmas  \n",
       "0                  330  \n",
       "1                  329  \n",
       "2                  328  \n",
       "3                  327  \n",
       "4                  326  \n",
       "...                ...  \n",
       "1964               193  \n",
       "1965               192  \n",
       "1966               191  \n",
       "1967               190  \n",
       "1968               189  \n",
       "\n",
       "[1969 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = {'CA': 0, 'TX': 1, 'WI': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 1 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.3 s, sys: 5.82 s, total: 48.1 s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = m5_common.create_dt(cal, prices, is_train = True, first_day = FIRST_DAY, tr_last=tr_last, path=path, h = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-22 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46881677 entries, 4081 to 46878802\n",
      "Data columns (total 27 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           int16         \n",
      " 3   store_id          int16         \n",
      " 4   cat_id            int16         \n",
      " 5   state_id          int16         \n",
      " 6   d                 object        \n",
      " 7   sales             float16       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              int16         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  before_christmas  uint16        \n",
      " 22  sell_price        float16       \n",
      " 23  Dayofyear         uint16        \n",
      " 24  week              uint8         \n",
      " 25  mday              uint8         \n",
      " 26  lag_price_1       float16       \n",
      "dtypes: datetime64[ns](1), float16(3), int16(7), object(2), uint16(2), uint8(12)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6103687161190927"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction of zeros\n",
    "df[df['sales'] == 0.].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt, dropna=True):\n",
    "    \n",
    "    wins = [7, 28]\n",
    "    lags = [7, 28]\n",
    "    \n",
    "    grouped_sales = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"]\n",
    "    \n",
    "    for win in wins:\n",
    "        mean_col = f'mean_{win}'\n",
    "        emean_col = f'e{mean_col}' # exponential mean average\n",
    "        esmean_col = f'es{mean_col}'\n",
    "        dt[emean_col] = grouped_sales.transform(lambda x : x.ewm(span=win, adjust=False).mean())\n",
    "        dt[esmean_col] = grouped_sales.transform(lambda x : x.ewm(alpha=1/win, adjust=False).mean())\n",
    "        for lag in lags:\n",
    "            dt[f'emean_{win}_{lag}'] = dt[[\"id\", emean_col]].groupby(\"id\").shift(lag)\n",
    "            dt[f'esmean_{win}_{lag}'] = dt[[\"id\", esmean_col]].groupby(\"id\").shift(lag)\n",
    "        del dt[emean_col]\n",
    "        del dt[esmean_col]\n",
    "            \n",
    "    ra = [1, 2]\n",
    "    for simple_lag in ra:\n",
    "        dt[f'lag_{simple_lag}'] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(simple_lag)\n",
    "    \n",
    "    if dropna == True:\n",
    "        dt.dropna(inplace = True)\n",
    "        \n",
    "    return m5_common.ridge_trend(dt, period='month', field='lag_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 10.7 s, total: 3min 57s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "      <th>lag_price_1</th>\n",
       "      <th>emean_7_7</th>\n",
       "      <th>esmean_7_7</th>\n",
       "      <th>emean_7_28</th>\n",
       "      <th>esmean_7_28</th>\n",
       "      <th>emean_28_7</th>\n",
       "      <th>esmean_28_7</th>\n",
       "      <th>emean_28_28</th>\n",
       "      <th>esmean_28_28</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>trend_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46027952</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>11616</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027953</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>11616</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.028992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027954</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>11616</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.034485</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027955</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>11617</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.253418</td>\n",
       "      <td>0.156982</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.068970</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.026947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46027956</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190063</td>\n",
       "      <td>0.134644</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.088013</td>\n",
       "      <td>0.066528</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.025986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  item_id  dept_id  store_id  cat_id  \\\n",
       "46027952  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46027953  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46027954  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46027955  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "46027956  HOUSEHOLD_2_516_WI_3_evaluation     2047        3         9       1   \n",
       "\n",
       "          state_id       d  sales       date  wm_yr_wk  weekday  wday  month  \\\n",
       "46027952         2  d_1937    0.0 2016-05-18     11616        6     5      5   \n",
       "46027953         2  d_1938    0.0 2016-05-19     11616        4     6      5   \n",
       "46027954         2  d_1939    0.0 2016-05-20     11616        0     7      5   \n",
       "46027955         2  d_1940    0.0 2016-05-21     11617        2     1      5   \n",
       "46027956         2  d_1941    0.0 2016-05-22     11617        3     2      5   \n",
       "\n",
       "          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "46027952  2016             0             0             0             0   \n",
       "46027953  2016             0             0             0             0   \n",
       "46027954  2016             0             0             0             0   \n",
       "46027955  2016             0             0             0             0   \n",
       "46027956  2016             0             0             0             0   \n",
       "\n",
       "          snap_CA  snap_TX  snap_WI  before_christmas  sell_price  Dayofyear  \\\n",
       "46027952        0        0        0               221         1.0        139   \n",
       "46027953        0        0        0               220         1.0        140   \n",
       "46027954        0        0        0               219         1.0        141   \n",
       "46027955        0        0        0               218         1.0        142   \n",
       "46027956        0        0        0               217         1.0        143   \n",
       "\n",
       "          week  mday  lag_price_1  emean_7_7  esmean_7_7  emean_7_28  \\\n",
       "46027952    20    18          1.0   0.007919    0.022491    0.000008   \n",
       "46027953    20    19          1.0   0.005939    0.019287    0.000006   \n",
       "46027954    20    20          1.0   0.004456    0.016525    0.000004   \n",
       "46027955    20    21          1.0   0.253418    0.156982    0.000003   \n",
       "46027956    20    22          1.0   0.190063    0.134644    0.000003   \n",
       "\n",
       "          esmean_7_28  emean_28_7  esmean_28_7  emean_28_28  esmean_28_28  \\\n",
       "46027952     0.000782    0.031677     0.037079     0.010811      0.030060   \n",
       "46027953     0.000670    0.029480     0.035767     0.010063      0.028992   \n",
       "46027954     0.000575    0.027451     0.034485     0.009369      0.027954   \n",
       "46027955     0.000493    0.094543     0.068970     0.008728      0.026947   \n",
       "46027956     0.000422    0.088013     0.066528     0.008125      0.025986   \n",
       "\n",
       "          lag_1  lag_2  trend_month  \n",
       "46027952    0.0    0.0     0.000024  \n",
       "46027953    0.0    0.0     0.000024  \n",
       "46027954    0.0    0.0     0.000024  \n",
       "46027955    0.0    0.0     0.000024  \n",
       "46027956    0.0    0.0     0.000024  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.distplot(df['sales'][:200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id', \n",
    "             \"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\", 'snap_CA', 'snap_TX', 'snap_WI']\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\", \"revenue\"]\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_date = datetime(2016, 4, 15)\n",
    "train_df = df[df['date'] < cut_off_date]\n",
    "valid_df = df[df['date'] >= cut_off_date]\n",
    "X = train_df[train_cols]\n",
    "y = train_df[\"sales\"]\n",
    "X_valid = valid_df[train_cols]\n",
    "y_valid = valid_df[\"sales\"]\n",
    "len(X), len(X_valid), len(X_valid) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df \n",
    "del train_df \n",
    "del valid_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(777)\n",
    "\n",
    "# size_valid_set = 2_000_000\n",
    "# fake_valid_inds = np.random.choice(X_train.index.values, size_valid_set, replace = False)\n",
    "# train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "\n",
    "# X = X_train.loc[train_inds]\n",
    "# y = y_train.loc[train_inds]\n",
    "\n",
    "# X_valid = X_train.loc[fake_valid_inds]\n",
    "# y_valid = y_train.loc[fake_valid_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "leave_size = 10\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        \"objective\" : \"tweedie\",\n",
    "        'tweedie_variance_power': 1.25,\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.035,\n",
    "#         \"learning_rate\" : 0.08,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "#         \"lambda_l1\" : 0.2,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"nthread\" : 10,\n",
    "        \"metric\": [\"rmse\"],\n",
    "        'verbosity': 20,\n",
    "        'num_leaves': 2**leave_size-1,\n",
    "        \"min_data_in_leaf\": 2**(leave_size + 1)-1,\n",
    "        \"n_estimators\": 1300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'tweedie',\n",
    "#     'tweedie_variance_power': 1.1,\n",
    "#     'metric': 'rmse',\n",
    "#     'subsample': 0.5,\n",
    "#     'subsample_freq': 1,\n",
    "#     'learning_rate': 0.03,\n",
    "#     'num_leaves': 2**11-1,\n",
    "#     'min_data_in_leaf': 2**12-1,\n",
    "#     'feature_fraction': 0.5,\n",
    "#     'max_bin': 100,\n",
    "#     'n_estimators': 1400,\n",
    "#     'boost_from_average': False,\n",
    "# #     'verbose': -1,\n",
    "#     'verbosity': 20,\n",
    "# } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb_regressor = lgb.LGBMRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m_lgb_regressor.fit(X=X, y=y, \n",
    "          eval_set=[(X, y), (X_valid, y_valid)],\n",
    "          eval_names=['train sales', 'valid sales'], \n",
    "          eval_metric=params['metric'],\n",
    "          verbose=params['verbosity'],\n",
    "          early_stopping_rounds=100,\n",
    "          categorical_feature=cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importance():\n",
    "    \n",
    "    def __init__(self, model, eval_metric):\n",
    "        self.model, self.eval_metric = model, eval_metric\n",
    "        self.feature_importances = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats, ax=ax)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "    \n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in [self.model]:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.evals_result_.keys():\n",
    "                evals_result[k] = model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "#         categorical_feature  plt.title('Training progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = Importance(m_lgb_regressor, 'rmse')\n",
    "importance.plot_feature_importance(top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in [None, 800, 1000, 1200]:\n",
    "    m_lgb_regressor.booster_.save_model(str(path/f\"m5_model_{'best' if iter is None else iter}.lgb\"), num_iteration=iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf /kaggle/m5_forecasting/m5_model_best.lgb.tgz /kaggle/m5_forecasting/m5_model_best.lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb = lgb.Booster(model_file=str(path/\"m5_model_best.lgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {path/\"m5_model.lgb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_lags = h * 2 + 1\n",
    "sub = 0.\n",
    "cols = [f\"F{i}\" for i in range(1,29)]\n",
    "te = m5_common.create_dt(cal, prices, False, first_day=FIRST_DAY, tr_last=tr_last, path=path)\n",
    "\n",
    "for tdelta in tqdm(range(0, h), total=h):\n",
    "    day = fday + timedelta(days=tdelta)\n",
    "    print(tdelta, day)\n",
    "    tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "    tst = create_fea(tst, False)\n",
    "    tst = tst.loc[tst.date == day, train_cols]\n",
    "    te.loc[te.date == day, \"sales\"] = m_lgb.predict(tst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_sub = te.loc[te.date >= fday - timedelta(days=h), [\"id\", \"sales\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_filter = (te.date >= fday - timedelta(days=h)) & (te.date < fday)\n",
    "\n",
    "te_sub.loc[day_filter, \"id\"] = te_sub.loc[day_filter, \"id\"].str.replace(\"evaluation$\", \"validation\")\n",
    "te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "te_sub.fillna(0., inplace = True)\n",
    "te_sub.sort_values(\"id\", inplace = True)\n",
    "te_sub.reset_index(drop=True, inplace = True)\n",
    "sub = te_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "sub_validation = sub[sub['id'].str.contains(\"validation\")].copy()\n",
    "sub_evaluation = sub[sub['id'].str.contains(\"evaluation\")].copy()\n",
    "sub = pd.concat([sub_validation, sub_evaluation], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('submission.csv')\n",
    "check[(check['id'] == 'FOODS_1_001_CA_1_validation') | (check['id'] == 'FOODS_1_001_CA_1_evaluation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
