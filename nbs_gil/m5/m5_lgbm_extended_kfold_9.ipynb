{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_2\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/kaggle/m5_forecasting/')\n",
    "assert(path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 25, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 28 \n",
    "max_lags = 57\n",
    "tr_last = 1913\n",
    "fday = datetime(2016,4, 25) \n",
    "fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tables():\n",
    "    prices = pd.read_csv(path/\"sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "            \n",
    "    cal = pd.read_csv(path/\"calendar.csv\", dtype = CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "    \n",
    "#     boolean_attrs = ['Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "#     for ba in boolean_attrs:\n",
    "#         cal[ba] = getattr(cal['date'].dt, ba.lower()).astype('uint8')\n",
    "    \n",
    "    return prices, cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 184 ms, total: 1.58 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prices, cal = prepare_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_map(field):\n",
    "    return {v: k for k, v in enumerate(cal[field].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_type(df, cols, dt_type):\n",
    "    for type_name in cols:\n",
    "        df[type_name] = df[type_name].astype(dt_type)\n",
    "\n",
    "def convert_uint8(df, cols):\n",
    "    convert_to_type(df, cols, \"uint8\")\n",
    "    \n",
    "def convert_float16(df, cols):\n",
    "    convert_to_type(df, cols, \"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_cal_cols():\n",
    "    event_name_1_map = create_event_map('event_name_1')\n",
    "    cal.replace({'event_name_1': event_name_1_map}, inplace=True)\n",
    "    event_type_1_map = create_event_map('event_type_1')\n",
    "    cal.replace({'event_type_1': event_type_1_map}, inplace=True)\n",
    "    return event_name_1_map, event_type_1_map\n",
    "\n",
    "event_name_1_map, event_type_1_map = replace_cal_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>11149</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>d_338</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  wm_yr_wk  weekday  wday  month  year      d  event_name_1  \\\n",
       "337 2012-01-01     11149        3     2      1  2012  d_338            27   \n",
       "\n",
       "     event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "337             3             0             0      1.0      1.0      0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal[cal.date == '2012-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8_types= ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'month', 'wday', 'weekday', \n",
    "              'snap_CA', 'snap_TX', 'snap_WI']\n",
    "convert_uint8(cal, uint8_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed(dt, event_name='Christmas', col='event_name_1', event_map=event_name_1_map, before=False):\n",
    "    dt.sort_values(['date'], ascending=[(not before)], inplace=True)\n",
    "    day1 = np.timedelta64(1, 'D')\n",
    "    last_date = np.datetime64()\n",
    "    res = []\n",
    "    event = event_map[event_name]\n",
    "    for v,d in zip(dt[col].values, dt.date.values):\n",
    "        if v == event:\n",
    "            last_date = d\n",
    "        elapsed = ((d-last_date).astype('timedelta64[D]') / day1)\n",
    "        res.append(elapsed)\n",
    "    field_name = f\"{'before' if before else 'after'}_{event_name.lower().replace(' ', '_')}\"\n",
    "    dt[field_name] = res\n",
    "    dt[field_name] = dt[field_name].fillna(0)\n",
    "    dt[field_name] = dt[field_name].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ellapsed_fields = ['Christmas', 'Easter', 'Ramadan starts']\n",
    "# for f in ellapsed_fields:\n",
    "#     get_elapsed(cal, f, 'event_name_1', event_name_1_map, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_over_period(dt, period='weekday'):\n",
    "    df_sales_id_period = dt[['id', 'sales', period]].groupby(['id', period])[['sales']].mean().reset_index()\n",
    "    df_sales_id_period['sales'] = df_sales_id_period['sales'].astype('float16')\n",
    "    df_sales_id_period.rename(columns={'sales': f'sales_by_{period}'}, inplace=True)\n",
    "    return dt.merge(df_sales_id_period, on=['id', period], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_year = 'Dayofyear'\n",
    "\n",
    "def prepare_day_of_year(df):\n",
    "    df[day_of_year] = getattr(df['date'].dt, day_of_year.lower()).astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_before(dt, day=25, month=12, col_name='before_christmas'):\n",
    "    diff_list = []\n",
    "    for d in cal['date']:\n",
    "        target = datetime(d.year, month, day)\n",
    "        diff = (target - d.to_pydatetime()).days\n",
    "        if(diff < 0):\n",
    "            christmas = datetime(d.year + 1, 12, 25)\n",
    "            diff = (target - d.to_pydatetime()).days\n",
    "        diff_list.append(diff)\n",
    "    dt[col_name] = diff_list\n",
    "    dt[col_name] = dt[col_name].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_days_before(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              1969 non-null   datetime64[ns]\n",
      " 1   wm_yr_wk          1969 non-null   int16         \n",
      " 2   weekday           1969 non-null   uint8         \n",
      " 3   wday              1969 non-null   uint8         \n",
      " 4   month             1969 non-null   uint8         \n",
      " 5   year              1969 non-null   int16         \n",
      " 6   d                 1969 non-null   object        \n",
      " 7   event_name_1      1969 non-null   uint8         \n",
      " 8   event_type_1      1969 non-null   uint8         \n",
      " 9   event_name_2      1969 non-null   uint8         \n",
      " 10  event_type_2      1969 non-null   uint8         \n",
      " 11  snap_CA           1969 non-null   uint8         \n",
      " 12  snap_TX           1969 non-null   uint8         \n",
      " 13  snap_WI           1969 non-null   uint8         \n",
      " 14  before_christmas  1969 non-null   uint16        \n",
      "dtypes: datetime64[ns](1), int16(2), object(1), uint16(1), uint8(10)\n",
      "memory usage: 61.7+ KB\n"
     ]
    }
   ],
   "source": [
    "cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>11620</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>11620</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>11620</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1969 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  wm_yr_wk  weekday  wday  month  year       d  event_name_1  \\\n",
       "0    2011-01-29     11101        2     1      1  2011     d_1             0   \n",
       "1    2011-01-30     11101        3     2      1  2011     d_2             0   \n",
       "2    2011-01-31     11101        1     3      1  2011     d_3             0   \n",
       "3    2011-02-01     11101        5     4      2  2011     d_4             0   \n",
       "4    2011-02-02     11101        6     5      2  2011     d_5             0   \n",
       "...         ...       ...      ...   ...    ...   ...     ...           ...   \n",
       "1964 2016-06-15     11620        6     5      6  2016  d_1965             0   \n",
       "1965 2016-06-16     11620        4     6      6  2016  d_1966             0   \n",
       "1966 2016-06-17     11620        0     7      6  2016  d_1967             0   \n",
       "1967 2016-06-18     11621        2     1      6  2016  d_1968             0   \n",
       "1968 2016-06-19     11621        3     2      6  2016  d_1969            14   \n",
       "\n",
       "      event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "0                0             0             0        0        0        0   \n",
       "1                0             0             0        0        0        0   \n",
       "2                0             0             0        0        0        0   \n",
       "3                0             0             0        1        1        0   \n",
       "4                0             0             0        1        0        1   \n",
       "...            ...           ...           ...      ...      ...      ...   \n",
       "1964             0             0             0        0        1        1   \n",
       "1965             0             0             0        0        0        0   \n",
       "1966             0             0             0        0        0        0   \n",
       "1967             0             0             0        0        0        0   \n",
       "1968             1             3             1        0        0        0   \n",
       "\n",
       "      before_christmas  \n",
       "0                  330  \n",
       "1                  329  \n",
       "2                  328  \n",
       "3                  327  \n",
       "4                  326  \n",
       "...                ...  \n",
       "1964               193  \n",
       "1965               192  \n",
       "1966               191  \n",
       "1967               190  \n",
       "1968               189  \n",
       "\n",
       "[1969 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(is_train = True, nrows = None, first_day = 1200):\n",
    "    \n",
    "    start_day = max(1, first_day)\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(path/\"sales_train_validation.csv\", \n",
    "                     nrows = nrows, usecols = catcols + numcols, dtype = dtype)\n",
    "    \n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "    \n",
    "    if not is_train:\n",
    "        for day in range(tr_last+1, tr_last+ 28 +1):\n",
    "            dt[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    dt = pd.melt(dt,\n",
    "                  id_vars = catcols,\n",
    "                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n",
    "                  var_name = \"d\",\n",
    "                  value_name = \"sales\")\n",
    "    \n",
    "    dt = dt.merge(cal, on= \"d\", copy = False)\n",
    "    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    dt.sort_values(['id', 'date'], inplace=True)\n",
    "    prepare_day_of_year(dt)\n",
    "    \n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "            \n",
    "    uint8_types= ['month', 'wday', 'mday', 'week']\n",
    "    convert_uint8(dt, uint8_types)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 1 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 5.33 s, total: 43.4 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = create_dt(is_train=True, first_day= FIRST_DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_uint8(df, ['dept_id', 'store_id', 'cat_id', 'state_id'])\n",
    "convert_float16(df, ['sales', 'sell_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46027957 entries, 4081 to 46025082\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           uint8         \n",
      " 3   store_id          uint8         \n",
      " 4   cat_id            uint8         \n",
      " 5   state_id          uint8         \n",
      " 6   d                 object        \n",
      " 7   sales             float16       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              int16         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  before_christmas  uint16        \n",
      " 22  sell_price        float16       \n",
      " 23  Dayofyear         uint16        \n",
      " 24  week              uint8         \n",
      " 25  mday              uint8         \n",
      "dtypes: datetime64[ns](1), float16(2), int16(3), object(2), uint16(2), uint8(16)\n",
      "memory usage: 2.7+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_boolean_attrs(df, boolean_attrs):\n",
    "    for ba in boolean_attrs:\n",
    "        df[ba] = getattr(df['date'].dt, ba.lower()).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "    print('lags', lags)\n",
    "        \n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            for stat in ['mean']:\n",
    "                dt[f\"r{stat}_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(\n",
    "                    lambda x : x.rolling(win).agg(stat))\n",
    "                print(f\"r{stat}_{lag}_{win}\")\n",
    "                \n",
    "    print('wins', wins)\n",
    "    \n",
    "    for simple_lag in range(1, 3):\n",
    "        dt[f'lag_{simple_lag}'] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(simple_lag)\n",
    "        \n",
    "    print('simple_lags', range(1, 3))\n",
    "        \n",
    "    dt[f'lag_price_1'] = dt[[\"id\",\"sell_price\"]].groupby(\"id\")[\"sell_price\"].shift(1)\n",
    "    \n",
    "    for lag_col in lag_cols:\n",
    "        del dt[lag_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lags [7, 28]\n",
      "rmean_7_7\n",
      "rmean_28_7\n",
      "rmean_7_28\n",
      "rmean_28_28\n",
      "wins [7, 28]\n",
      "simple_lags range(1, 3)\n",
      "CPU times: user 1min 26s, sys: 5.92 s, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_fea(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44351007, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>before_christmas</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>week</th>\n",
       "      <th>mday</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_price_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45956915</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>11612</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956916</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>11612</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45956917</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>11612</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025081</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>11613</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46025082</th>\n",
       "      <td>HOUSEHOLD_2_516_WI_3_validation</td>\n",
       "      <td>2047</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  item_id  dept_id  store_id  cat_id  \\\n",
       "45956915  HOUSEHOLD_2_516_WI_3_validation     2047        3         9       1   \n",
       "45956916  HOUSEHOLD_2_516_WI_3_validation     2047        3         9       1   \n",
       "45956917  HOUSEHOLD_2_516_WI_3_validation     2047        3         9       1   \n",
       "46025081  HOUSEHOLD_2_516_WI_3_validation     2047        3         9       1   \n",
       "46025082  HOUSEHOLD_2_516_WI_3_validation     2047        3         9       1   \n",
       "\n",
       "          state_id       d  sales       date  wm_yr_wk  weekday  wday  month  \\\n",
       "45956915         2  d_1909    0.0 2016-04-20     11612        6     5      4   \n",
       "45956916         2  d_1910    0.0 2016-04-21     11612        4     6      4   \n",
       "45956917         2  d_1911    0.0 2016-04-22     11612        0     7      4   \n",
       "46025081         2  d_1912    0.0 2016-04-23     11613        2     1      4   \n",
       "46025082         2  d_1913    0.0 2016-04-24     11613        3     2      4   \n",
       "\n",
       "          year  event_name_1  event_type_1  event_name_2  event_type_2  \\\n",
       "45956915  2016             0             0             0             0   \n",
       "45956916  2016             0             0             0             0   \n",
       "45956917  2016             0             0             0             0   \n",
       "46025081  2016             0             0             0             0   \n",
       "46025082  2016             0             0             0             0   \n",
       "\n",
       "          snap_CA  snap_TX  snap_WI  before_christmas  sell_price  Dayofyear  \\\n",
       "45956915        0        0        0               249         1.0        111   \n",
       "45956916        0        0        0               248         1.0        112   \n",
       "45956917        0        0        0               247         1.0        113   \n",
       "46025081        0        0        0               246         1.0        114   \n",
       "46025082        0        0        0               245         1.0        115   \n",
       "\n",
       "          week  mday  rmean_7_7  rmean_28_7  rmean_7_28  rmean_28_28  lag_1  \\\n",
       "45956915    16    20        0.0         0.0         0.0     0.107117    0.0   \n",
       "45956916    16    21        0.0         0.0         0.0     0.107117    0.0   \n",
       "45956917    16    22        0.0         0.0         0.0     0.107117    0.0   \n",
       "46025081    16    23        0.0         0.0         0.0     0.107117    0.0   \n",
       "46025082    16    24        0.0         0.0         0.0     0.071411    0.0   \n",
       "\n",
       "          lag_2  lag_price_1  \n",
       "45956915    0.0          1.0  \n",
       "45956916    0.0          1.0  \n",
       "45956917    0.0          1.0  \n",
       "46025081    0.0          1.0  \n",
       "46025082    0.0          1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44351007 entries, 622628 to 46025082\n",
      "Data columns (total 33 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   id                object        \n",
      " 1   item_id           int16         \n",
      " 2   dept_id           uint8         \n",
      " 3   store_id          uint8         \n",
      " 4   cat_id            uint8         \n",
      " 5   state_id          uint8         \n",
      " 6   d                 object        \n",
      " 7   sales             float16       \n",
      " 8   date              datetime64[ns]\n",
      " 9   wm_yr_wk          int16         \n",
      " 10  weekday           uint8         \n",
      " 11  wday              uint8         \n",
      " 12  month             uint8         \n",
      " 13  year              int16         \n",
      " 14  event_name_1      uint8         \n",
      " 15  event_type_1      uint8         \n",
      " 16  event_name_2      uint8         \n",
      " 17  event_type_2      uint8         \n",
      " 18  snap_CA           uint8         \n",
      " 19  snap_TX           uint8         \n",
      " 20  snap_WI           uint8         \n",
      " 21  before_christmas  uint16        \n",
      " 22  sell_price        float16       \n",
      " 23  Dayofyear         uint16        \n",
      " 24  week              uint8         \n",
      " 25  mday              uint8         \n",
      " 26  rmean_7_7         float16       \n",
      " 27  rmean_28_7        float16       \n",
      " 28  rmean_7_28        float16       \n",
      " 29  rmean_28_28       float16       \n",
      " 30  lag_1             float16       \n",
      " 31  lag_2             float16       \n",
      " 32  lag_price_1       float16       \n",
      "dtypes: datetime64[ns](1), float16(9), int16(3), object(2), uint16(2), uint8(16)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "X = df[train_cols]\n",
    "Y = df[\"sales\"]\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(path/'m5_dt')\n",
    "# !du -h {path/'m5_dt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#         \"objective\" : \"poisson\",\n",
    "        \"objective\" : \"tweedie\",\n",
    "#         \"objective\" : \"mse\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"nthread\" : 10,\n",
    "        \"metric\": [\"rmse\"],\n",
    "        'verbosity': 100,\n",
    "        'num_leaves': 128,\n",
    "        \"min_data_in_leaf\": 100,\n",
    "        \"n_estimators\": 1200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed27208f375412a83c711b22bea17bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tsales's rmse: 2.26358\n",
      "[200]\tsales's rmse: 2.23197\n",
      "[300]\tsales's rmse: 2.21865\n",
      "[400]\tsales's rmse: 2.20999\n",
      "[500]\tsales's rmse: 2.20385\n",
      "[600]\tsales's rmse: 2.19858\n",
      "[700]\tsales's rmse: 2.19449\n",
      "[800]\tsales's rmse: 2.18994\n",
      "[900]\tsales's rmse: 2.18797\n",
      "[1000]\tsales's rmse: 2.18631\n",
      "[1100]\tsales's rmse: 2.1848\n",
      "[1200]\tsales's rmse: 2.18319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tsales's rmse: 2.18312\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tsales's rmse: 2.29806\n",
      "[200]\tsales's rmse: 2.27195\n",
      "[300]\tsales's rmse: 2.26011\n",
      "[400]\tsales's rmse: 2.25226\n",
      "[500]\tsales's rmse: 2.24685\n",
      "[600]\tsales's rmse: 2.24112\n",
      "[700]\tsales's rmse: 2.23804\n",
      "[800]\tsales's rmse: 2.23521\n",
      "[900]\tsales's rmse: 2.23238\n",
      "[1000]\tsales's rmse: 2.22869\n",
      "[1100]\tsales's rmse: 2.22504\n",
      "[1200]\tsales's rmse: 2.22317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tsales's rmse: 2.22317\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tsales's rmse: 2.25102\n",
      "[200]\tsales's rmse: 2.22113\n",
      "[300]\tsales's rmse: 2.20778\n",
      "[400]\tsales's rmse: 2.19987\n",
      "[500]\tsales's rmse: 2.1944\n",
      "[600]\tsales's rmse: 2.18717\n",
      "[700]\tsales's rmse: 2.18187\n",
      "[800]\tsales's rmse: 2.17794\n",
      "[900]\tsales's rmse: 2.17614\n",
      "[1000]\tsales's rmse: 2.17334\n",
      "[1100]\tsales's rmse: 2.17168\n",
      "[1200]\tsales's rmse: 2.16869\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\tsales's rmse: 2.16869\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tsales's rmse: 2.29915\n",
      "[200]\tsales's rmse: 2.26697\n",
      "[300]\tsales's rmse: 2.2528\n",
      "[400]\tsales's rmse: 2.24254\n",
      "[500]\tsales's rmse: 2.23605\n",
      "[600]\tsales's rmse: 2.23097\n",
      "[700]\tsales's rmse: 2.22647\n",
      "[800]\tsales's rmse: 2.22244\n",
      "[900]\tsales's rmse: 2.2193\n",
      "[1000]\tsales's rmse: 2.21688\n",
      "[1100]\tsales's rmse: 2.21485\n",
      "[1200]\tsales's rmse: 2.21321\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1198]\tsales's rmse: 2.21321\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tsales's rmse: 2.26401\n",
      "[200]\tsales's rmse: 2.23496\n",
      "[300]\tsales's rmse: 2.21972\n",
      "[400]\tsales's rmse: 2.21308\n",
      "[500]\tsales's rmse: 2.20658\n",
      "[600]\tsales's rmse: 2.20121\n",
      "[700]\tsales's rmse: 2.19538\n",
      "[800]\tsales's rmse: 2.19311\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "kf = KFold(n_splits=num_splits, shuffle=True)\n",
    "models = []\n",
    "for fold, (train_idx, valid_idx) in enumerate(tqdm(kf.split(X), total=num_splits)):\n",
    "    print(f'Fold: {fold+1}')\n",
    "    x_train, x_val = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_val = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "    train_set = lgb.Dataset(x_train, y_train, categorical_feature=cat_feats)\n",
    "    val_set = lgb.Dataset(x_val, y_val, categorical_feature=cat_feats)\n",
    "    m_lgb = lgb.LGBMRegressor(**params)\n",
    "    m_lgb.fit(X=x_train, y=y_train, eval_set=[(x_val, y_val)], eval_names=['sales'],eval_metric=params['metric'], \n",
    "              verbose=params['verbosity'], early_stopping_rounds=100)\n",
    "    models.append(m_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importance():\n",
    "    \n",
    "    def __init__(self, models, eval_metric):\n",
    "        self.models, self.eval_metric = models, eval_metric\n",
    "        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n",
    "        for model in self.models:\n",
    "            fold_importance = pd.DataFrame(list(zip(train_cols, model.feature_importances_)),\n",
    "                                           columns=['feature', 'importance'])\n",
    "            self.feature_importances = self.feature_importances.append(fold_importance)\n",
    "\n",
    "    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Plot default feature importance.\n",
    "\n",
    "        :param drop_null_importance: drop columns with null feature importance\n",
    "        :param top_n: show top n columns\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        top_feats = self.get_top_features(drop_null_importance, top_n)\n",
    "        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n",
    "        feature_importances['feature'] = feature_importances['feature'].astype(str)\n",
    "        top_feats = [str(i) for i in top_feats]\n",
    "        a4_dims = (11.7, 8.27)\n",
    "        fig, ax = plt.subplots(figsize=a4_dims)\n",
    "        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats, ax=ax)\n",
    "        plt.title('Feature importances')\n",
    "\n",
    "    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n",
    "        \"\"\"\n",
    "        Get top features by importance.\n",
    "\n",
    "        :param drop_null_importance:\n",
    "        :param top_n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n",
    "        if drop_null_importance:\n",
    "            grouped_feats = grouped_feats[grouped_feats != 0]\n",
    "        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n",
    "    \n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "        Plot training progress.\n",
    "        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        full_evals_results = pd.DataFrame()\n",
    "        for model in self.models:\n",
    "            evals_result = pd.DataFrame()\n",
    "            for k in model.evals_result_.keys():\n",
    "                evals_result[k] = model.evals_result_[k][self.eval_metric]\n",
    "            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n",
    "            full_evals_results = full_evals_results.append(evals_result)\n",
    "\n",
    "        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n",
    "                                                                                            'variable': 'dataset'})\n",
    "        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n",
    "#         categorical_feature  plt.title('Training progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance = Importance(models, 'rmse')\n",
    "importance.plot_feature_importance(top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.plot_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m_lgb in enumerate(models):\n",
    "    m_lgb.booster_.save_model(str(path/f\"m5_model_{i}.lgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf m5_models.tgz {path/f\"m5_model_*.lgb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -latr {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predictions(models, df):\n",
    "    y_pred = np.zeros((len(df), 1))\n",
    "    print(y_pred.shape)\n",
    "    for i, model in enumerate(models):\n",
    "        y_pred += model.predict(df).reshape([len(df), 1])\n",
    "    return y_pred / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "alphas = [1.0]\n",
    "weights = [1/len(alphas)]*len(alphas)\n",
    "sub = 0.\n",
    "cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "    te = create_dt(False, first_day=FIRST_DAY)\n",
    "\n",
    "    for tdelta in tqdm(range(0, h), total=h):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day)\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags)) & (te.date <= day)].copy()\n",
    "        create_fea(tst)\n",
    "        tst = tst.loc[tst.date == day, train_cols]\n",
    "        prediction = run_predictions(models, tst)\n",
    "        te.loc[te.date == day, \"sales\"] = alpha * prediction\n",
    "\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "    te_sub.loc[te.date >= fday+ timedelta(days=h), \"id\"] = te_sub.loc[te.date >= fday+timedelta(days=h), \n",
    "                                                                          \"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    te_sub.fillna(0., inplace = True)\n",
    "    te_sub.sort_values(\"id\", inplace = True)\n",
    "    te_sub.reset_index(drop=True, inplace = True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n",
    "    if icount == 0 :\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
