{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ff5b99e8260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcadene_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/fastai/vision/models/cadene_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpretrainedmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrainedmodels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpretrainedmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m __all__ = ['inceptionv4', 'inceptionresnetv2', 'nasnetamobile', 'dpn92', 'xception_cadene', 'se_resnet50',\n",
      "\u001b[0;31mException\u001b[0m: Error: `pretrainedmodels` is needed. `pip install pretrainedmodels`"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from fastai.vision import *\n",
    "from fastai import *\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from fastai.vision.models.cadene_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv('/root/.fastai/data/severstal/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/root/.fastai/data/severstal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = get_image_files(path/'train_images')\n",
    "train_images[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check maximum size of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img_max_size(folder):\n",
    "    max_height = 0\n",
    "    max_width = 0\n",
    "    for train_image in train_images:\n",
    "        img = open_image(train_image)\n",
    "        if max_height < img.shape[1]:\n",
    "            max_height = img.shape[1]\n",
    "        if max_width < img.shape[2]:\n",
    "            max_width = img.shape[2]\n",
    "    return max_height, max_width\n",
    "\n",
    "def show_image(images, index):\n",
    "    img_f = images[index]\n",
    "    print(type(img_f))\n",
    "    img = open_image(img_f)\n",
    "    print(img)\n",
    "    img.show(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = Path('/kaggle/mask')\n",
    "if not os.path.exists(mask_path):\n",
    "    os.makedirs(str(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_encoded_to_array(encoded_pixels):\n",
    "    pos_array = []\n",
    "    len_array = []\n",
    "    splits = encoded_pixels.split()\n",
    "    pos_array = [int(n) - 1 for i, n in enumerate(splits) if i % 2 == 0]\n",
    "    len_array = [int(n) for i, n in enumerate(splits) if i % 2 == 1]\n",
    "    return pos_array, len_array\n",
    "        \n",
    "def convert_to_pair(pos_array, rows):\n",
    "    return [(p % rows, p // rows) for p in pos_array]\n",
    "\n",
    "def create_positions(single_pos, size):\n",
    "    return [i for i in range(single_pos, single_pos + size)]\n",
    "\n",
    "def create_positions_pairs(single_pos, size, row_size):\n",
    "    return convert_to_pair(create_positions(single_pos, size), row_size)\n",
    "\n",
    "def convert_to_mask(encoded_pixels, row_size, col_size, category):\n",
    "    pos_array, len_array = convert_encoded_to_array(encoded_pixels)\n",
    "    mask = np.zeros([row_size, col_size])\n",
    "    for(p, l) in zip(pos_array, len_array):\n",
    "        for row, col in create_positions_pairs(p, l, row_size):\n",
    "            mask[row][col] = category\n",
    "    return mask\n",
    "\n",
    "def save_to_image(masked, image_name):\n",
    "    im = PIL.Image.fromarray(masked)\n",
    "    im = im.convert(\"L\")\n",
    "    image_name = re.sub(r'(.+)\\.jpg', r'\\1', image_name) + \".png\"\n",
    "    real_path = mask_path/image_name\n",
    "    im.save(real_path)\n",
    "    return real_path\n",
    "\n",
    "def open_single_image(path):\n",
    "    img = open_image(path)\n",
    "    img.show(figsize=(20,20))\n",
    "    \n",
    "def get_y_fn(x):\n",
    "    return mask_path/(x.stem + '.png')\n",
    "\n",
    "def group_by(train_images, train_pd):\n",
    "    tran_dict = {image.name:[] for image in train_images}\n",
    "    pattern = re.compile('(.+)_(\\d+)')\n",
    "    for index, image_path in train_pd.iterrows():\n",
    "        m = pattern.match(image_path['ImageId_ClassId'])\n",
    "        file_name = m.group(1)\n",
    "        category = m.group(2)\n",
    "        tran_dict[file_name].append((int(category), image_path['EncodedPixels']))\n",
    "    return tran_dict\n",
    "\n",
    "def display_image_with_mask(img_name):\n",
    "    full_image = path/'train_images'/img_name\n",
    "    print(full_image)\n",
    "    open_single_image(full_image)\n",
    "    mask_image = get_y_fn(full_image)\n",
    "    mask = open_mask(mask_image)\n",
    "    print(full_image)\n",
    "    mask.show(figsize=(20, 20), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_categories_mask = group_by(train_images, train_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mask files and save these to kaggle/mask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 256\n",
    "image_width = 1600\n",
    "if not os.path.exists(mask_path/'0002cc93b.png'):\n",
    "    for image_name, cat_list in grouped_categories_mask.items():\n",
    "        masked = np.zeros([image_height, image_width])\n",
    "        for cat_mask in cat_list:\n",
    "            encoded_pixels = cat_mask[1]\n",
    "            if pd.notna(cat_mask[1]):\n",
    "                masked += convert_to_mask(encoded_pixels, image_height, image_width, cat_mask[0])\n",
    "        if np.amax(masked) > 4:\n",
    "            print(f'Check {image_name} for max category {np.amax(masked)}')\n",
    "        save_to_image(masked, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limited_dihedral_affine(k:partial(uniform_int,0,3)):\n",
    "    \"Randomly flip `x` image based on `k`.\"\n",
    "    x = -1 if k&1 else 1\n",
    "    y = -1 if k&2 else 1\n",
    "    if k&4: return [[0, x, 0.],\n",
    "                    [y, 0, 0],\n",
    "                    [0, 0, 1.]]\n",
    "    return [[x, 0, 0.],\n",
    "            [0, y, 0],\n",
    "            [0, 0, 1.]]\n",
    "\n",
    "dihedral_affine = TfmAffine(limited_dihedral_affine)\n",
    "\n",
    "def get_extra_transforms(max_rotate:float=3., max_zoom:float=1.1,\n",
    "                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "    p_lightings = [p_lighting, p_lighting + 0.2, p_lighting + 0.4, p_lighting + 0.6, p_lighting + 0.7]\n",
    "    max_lightings = [max_lighting, max_lighting + 0.2, max_lighting + 0.4, max_lighting + 0.6, max_lighting + 0.7]\n",
    "    res = [rand_crop(), dihedral_affine(), \n",
    "           symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine),\n",
    "           rotate(degrees=(-max_rotate,max_rotate), p=p_affine),\n",
    "           rand_zoom(scale=(1., max_zoom), p=p_affine)]\n",
    "    res.extend([brightness(change=(0.5*(1-mp[0]), 0.5*(1+mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    res.extend([contrast(scale=(1-mp[0], 1/(1-mp[0])), p=mp[1]) for mp in zip(max_lightings, p_lightings)])\n",
    "    #       train                   , valid\n",
    "    return (res, [crop_pad()])\n",
    "\n",
    "def get_simple_transforms(max_rotate:float=3., max_zoom:float=1.1,\n",
    "                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n",
    "                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n",
    "    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n",
    "    res = [\n",
    "        rand_crop(),\n",
    "        symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine),\n",
    "        rotate(degrees=(-max_rotate,max_rotate), p=p_affine),\n",
    "        rand_zoom(scale=(1., max_zoom), p=p_affine)\n",
    "          ]\n",
    "    #       train                   , valid\n",
    "    return (res, [crop_pad()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (path/'train_images').ls()\n",
    "src_size = np.array(open_image(str(train_images[0])).shape[1:])\n",
    "valid_pct = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = array(['0', '1', '2', '3', '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_bunch(bs, size):\n",
    "    src = (SegmentationItemList.from_folder(path/'train_images')\n",
    "       .split_by_rand_pct(valid_pct=valid_pct)\n",
    "       .label_from_func(get_y_fn, classes=codes))\n",
    "    data = (src.transform(get_simple_transforms(), size=size, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "    return src, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "size = src_size//2\n",
    "src, data = create_data_bunch(bs, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create learner and training\n",
    "Starting with low resolution training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['0']\n",
    "\n",
    "def acc_camvid(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    comparison = argmax[mask]==target[mask]\n",
    "    return torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "\n",
    "def acc_camvid_with_zero_check(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        if(torch.sum(argmax[b]).item() == 0.0 and torch.sum(target[b]).item() == 0.0):\n",
    "            total[b] = 1\n",
    "        else:\n",
    "            mask = target[b] != void_code\n",
    "            comparison = argmax[b][mask]==target[b][mask]\n",
    "            total[b] = torch.tensor(0.) if comparison.numel() == 0 else comparison.float().mean()\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def calc_dice_coefficients(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        if sum_seg + sum_gt == 0:\n",
    "            return torch.tensor(1.0)\n",
    "        return (torch.sum((seg[gt == cat] / cat).float()) * 2.0) / (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats)])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i] = calc_dice_coefficient(argmax, target, c)\n",
    "    return total_avg.mean()\n",
    "\n",
    "\n",
    "def dice_coefficient(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "def calc_dice_coefficients_2(argmax, target, cats):\n",
    "    def calc_dice_coefficient(seg, gt, cat: int):\n",
    "        mask_seg = seg == cat\n",
    "        mask_gt = gt == cat\n",
    "        sum_seg = torch.sum(mask_seg.float())\n",
    "        sum_gt = torch.sum(mask_gt.float())\n",
    "        return (torch.sum((seg[gt == cat] / cat).float())), (sum_seg + sum_gt)\n",
    "\n",
    "    total_avg = torch.empty([len(cats), 2])\n",
    "    for i, c in enumerate(cats):\n",
    "        total_avg[i][0], total_avg[i][1] = calc_dice_coefficient(argmax, target, c)\n",
    "    total_sum = total_avg.sum(axis=0)\n",
    "    if (total_sum[1] == 0.0):\n",
    "        return torch.tensor(1.0)\n",
    "    return total_sum[0] * 2.0 / total_sum[1]\n",
    "\n",
    "\n",
    "def dice_coefficient_2(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    argmax = (input.argmax(dim=1))\n",
    "    batch_size = input.shape[0]\n",
    "    cats = [1, 2, 3, 4]\n",
    "    total = torch.empty([batch_size])\n",
    "    for b in range(batch_size):\n",
    "        total[b] = calc_dice_coefficients_2(argmax[b], target[b], cats)\n",
    "    return total.mean()\n",
    "\n",
    "\n",
    "def accuracy_simple(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()\n",
    "\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    smooth = 1.\n",
    "    num = pred.size(0)\n",
    "    m1 = pred.view(num, -1)  # Flatten\n",
    "    m2 = target.view(num, -1)  # Flatten\n",
    "    intersection = (m1 * m2).sum()\n",
    "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDiceLoss(nn.Module):\n",
    "    def __init__(self, zero_cat_factor=0.1):\n",
    "        super().__init__()\n",
    "        self.zero_cat_factor = zero_cat_factor\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.dice_loss(target, input, self.zero_cat_factor)\n",
    "\n",
    "    def dice_loss(self, target, output, eps=1e-7, zero_cat_factor=0.1):\n",
    "        '''\n",
    "        Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "        Assumes the `channels_last` format.\n",
    "\n",
    "        # Arguments\n",
    "            target: b x 1 x X x Y( x Z...) ground truth\n",
    "            output: b x c x X x Y( x Z...) Network output, must sum to 1 over c channel (such as after softmax)\n",
    "            epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "\n",
    "        # References\n",
    "            V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation\n",
    "            https://arxiv.org/abs/1606.04797\n",
    "            More details on Dice loss formulation\n",
    "            https://mediatum.ub.tum.de/doc/1395260/1395260.pdf (page 72)\n",
    "\n",
    "            Adapted from https://github.com/Lasagne/Recipes/issues/99#issuecomment-347775022\n",
    "        '''\n",
    "\n",
    "        # skip the batch and class axis for calculating Dice score\n",
    "        num_classes = output.shape[1]\n",
    "        y_true = F.one_hot(target.long().squeeze(), num_classes)\n",
    "        y_pred = F.softmax(output, dim=1).permute(0, 2, 3, 1)\n",
    "        y_true = y_true.type(y_pred.type())\n",
    "        y_true = y_true.permute(0, 3, 1, 2)\n",
    "        y_true[:,0,:] *= zero_cat_factor # Factor used to take power away from the zeroth category\n",
    "        y_true = y_true.permute(0, 2, 3, 1)\n",
    "        axes = tuple(range(1, len(y_pred.shape)-1))\n",
    "        numerator = 2. * torch.sum(y_pred * y_true, axes)\n",
    "        denominator = torch.sum(y_pred ** 2 + y_true ** 2, axes)\n",
    "        # When intersection and cardinality are all zero you have 100% score and not 0% score\n",
    "        # For this we use the eps parameter\n",
    "        loss_array = ((numerator + eps) / (denominator + eps))\n",
    "        loss_array = (loss_array).mean(dim=0)\n",
    "        return ((1 - torch.mean(loss_array)) + F.cross_entropy(output, target.squeeze())) / 2.\n",
    "\n",
    "    def __del__(self): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import callbacks\n",
    "\n",
    "def train_learner(learn, slice_lr, epochs=10, pct_start=0.8, best_model_name='best_model', \n",
    "                  patience_early_stop=4, patience_reduce_lr = 3):\n",
    "    learn.fit_one_cycle(epochs, slice_lr, pct_start=pct_start, \n",
    "                    callbacks=[callbacks.SaveModelCallback(learn, monitor='dice_coefficient',mode='max', name=best_model_name),\n",
    "                              callbacks.EarlyStoppingCallback(learn=learn, monitor='dice_coefficient', patience=patience_early_stop),\n",
    "                              callbacks.ReduceLROnPlateauCallback(learn=learn, monitor='dice_coefficient', patience=patience_reduce_lr),\n",
    "                              callbacks.TerminateOnNaNCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=accuracy_simple, acc_camvid_with_zero_check, dice_coefficient, dice_coefficient_2\n",
    "wd=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "# learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([1.0, .5, .5, .5, .5]).cuda())\n",
    "learn.loss_func = CombinedDiceLoss(zero_cat_factor=0.5)\n",
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model_dir = Path('/kaggle/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = to_fp16(learn, loss_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_find(learn, num_it=400)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_learner(learn, slice(lr), epochs=10, pct_start=0.8, best_model_name='bestmodel-frozen-1', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-frozen-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/100,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_learner(learn, lrs, epochs=10, pct_start=0.8, best_model_name='bestmodel-unfrozen-1', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_learner(bs=4, size=size, transform_func=get_simple_transforms, model_to_load='bestmodel-unfrozen-1'):\n",
    "    data = (src.transform(transform_func(), size=size, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "    learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd, bottle=True)\n",
    "    learn.model_dir = Path('/kaggle/model')\n",
    "    learn.loss_func = CombinedDiceLoss(zero_cat_factor=0.5)\n",
    "#     learn.loss_func = CrossEntropyFlat(axis=1, weight=torch.tensor([1.5, .5, .5, .5, .5]).cuda())\n",
    "#     learn = to_fp16(learn, loss_scale=8.0)\n",
    "    if model_to_load is not None:\n",
    "        learn.load(model_to_load)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_large_learner(bs=bs, size=src_size, transform_func=get_simple_transforms, model_to_load='bestmodel-unfrozen-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn, num_it=400)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_learner(learn, slice(lr), epochs=10, pct_start=0.8, best_model_name='bestmodel-frozen-3', \n",
    "              patience_early_stop=4, patience_reduce_lr = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('bestmodel-frozen-3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/1000,lr/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_learner(learn, lrs, epochs=12, pct_start=0.8, best_model_name='bestmodel-4', \n",
    "              patience_early_stop=7, patience_reduce_lr = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bestmodel-4');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file='/kaggle/model/export-4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!cp /kaggle/model/export.pkl /opt/fastai/fastai-exercises/nbs_gil\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'export-4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = (path/'test_images').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_learn = load_learner('/kaggle/model/', file='export-4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_learn = to_fp16(inference_learn, loss_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    pred_class, pred_idx, outputs = inference_learn.predict(open_image(str(img_path)))\n",
    "    return pred_class, pred_idx, outputs\n",
    "\n",
    "def encode_classes(pred_class_data):\n",
    "    pixels = np.concatenate([[0], torch.transpose(pred_class_data.squeeze(), 0, 1).flatten(), [0]])\n",
    "    classes_dict = {1: [], 2: [], 3: [], 4: []}\n",
    "    count = 0\n",
    "    previous = pixels[0]\n",
    "    for i, val in enumerate(pixels):\n",
    "        if val != previous:\n",
    "            if previous in classes_dict:\n",
    "                classes_dict[previous].append((i - count, count))\n",
    "            count = 0\n",
    "        previous = val\n",
    "        count += 1\n",
    "    return classes_dict\n",
    "\n",
    "\n",
    "def convert_classes_to_text(classes_dict, clazz):\n",
    "    return ' '.join([f'{v[0]} {v[1]}' for v in classes_dict[clazz]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_to_predict = train_images[16].name\n",
    "display_image_with_mask(image_to_predict)\n",
    "pred_class, pred_idx, outputs = predict(path/f'train_images/{image_to_predict}')\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(pred_class.data.squeeze(), 0, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking encoding methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_all = encode_classes(pred_class.data)\n",
    "print(convert_classes_to_text(encoded_all, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = train_images[16]\n",
    "print(get_y_fn(image_name))\n",
    "img = open_mask(get_y_fn(image_name))\n",
    "img_data = img.data\n",
    "print(convert_classes_to_text(encode_classes(img_data), 3))\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through the test images and create submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "defect_classes = [1, 2, 3, 4]\n",
    "with open('submission.csv', 'w') as submission_file:\n",
    "    submission_file.write('ImageId_ClassId,EncodedPixels\\n')\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        pred_class, pred_idx, outputs = predict(test_image)\n",
    "        encoded_all = encode_classes(pred_class.data)\n",
    "        for defect_class in defect_classes:\n",
    "            submission_file.write(f'{test_image.name}_{defect_class},{convert_classes_to_text(encoded_all, defect_class)}\\n')\n",
    "        if i % 5 == 0:\n",
    "            print(f'Processed {i} images\\r', end='')\n",
    "            \n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative prediction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,y = learn.get_preds(ds_type=DatasetType.Test, with_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_data = preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((path/'test_images').ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
